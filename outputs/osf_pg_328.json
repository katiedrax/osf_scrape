{"data": [{"id": "ze283", "type": "registrations", "attributes": {"title": "Metodolog\u00eda", "description": "", "category": "", "custom_citation": "", "date_created": "2020-02-05T13:35:36.050230", "date_modified": "2020-01-28T20:29:01.830836", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "2f87f90c7243ee4d8f385b9fc1a665653a1a952114e227f5d77ff67773c6ce7e4de0152741785b6f5834d69129767b84147493c4f19fb771a4f2cbf63b8618576bf520a10eb79be07ad05402482fa911d2fb21e94f24d7052122bd649616c1ba12fb726464d730f74a7bb1bf75d53464b798757d74ad3fec25ef1335a0b7f8ebef3b726f53bbcd037c4db0c3c98cd1ec", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-02-05T13:35:36.034727", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Open-Ended Registration", "registered_meta": {"summary": {"extra": [], "value": "PRE REGISTRO\nSe espera que los tweets m\u00e1s compartidos van a ser los que se alinean con la identidad pol\u00edtica del participante y contienen palabras de carga emocional.\nSe espera que los tweets compartidos que tengan contenido emocional sean compartidos m\u00e1s r\u00e1pido que los compartidos que no lo tengan.\nSe espera que el reporte de los participantes de que sientieron y pensaron durante el experimento incluya descriptores emocionales (similares a los utilizados para categorizar los tweets)"}, "uploader": {"extra": [], "value": ""}}, "registration_responses": {"summary": "PRE REGISTRO\nSe espera que los tweets m\u00e1s compartidos van a ser los que se alinean con la identidad pol\u00edtica del participante y contienen palabras de carga emocional.\nSe espera que los tweets compartidos que tengan contenido emocional sean compartidos m\u00e1s r\u00e1pido que los compartidos que no lo tengan.\nSe espera que el reporte de los participantes de que sientieron y pensaron durante el experimento incluya descriptores emocionales (similares a los utilizados para categorizar los tweets)"}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ze283/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ze283/comments/?format=json&filter%5Btarget%5D=ze283", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ze283/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ze283/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ze283/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ze283/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ze283/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ze283/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ze283/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ze283/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ze283/linked_by_registrations/?format=json", "meta": {}}}}, "parent": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/?format=json", "meta": {}}}, "data": {"id": "fvth5", "type": "registrations"}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ze283/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ze283/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/ze283/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/?format=json", "meta": {}}}, "data": {"id": "fvth5", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ze283/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ze283/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/ze283/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ze283/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/ze283/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ze283/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ze283/citation/?format=json", "meta": {}}}, "data": {"id": "ze283", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/38eyk/?format=json", "meta": {}}}, "data": {"id": "38eyk", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/m8zvf/?format=json", "meta": {}}}, "data": {"id": "m8zvf", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5df83f7dd28338001ac0ab0d/?format=json", "meta": {}}}, "data": {"id": "5df83f7dd28338001ac0ab0d", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/ze283/", "self": "https://api.osf.io/v2/registrations/ze283/"}}, {"id": "eqfvp", "type": "registrations", "attributes": {"title": "Marco te\u00f3rico", "description": "", "category": "", "custom_citation": "", "date_created": "2020-02-05T13:35:35.525927", "date_modified": "2020-01-28T20:30:22.426444", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "15c7c584ba2245dc6fa8ee5f2571c4b8da04f04dfddb5610147304644317317e6cfcb753bd44328c01dd7b6eb8782f6238dce7b352af13c3059336f067001ac0c8a6681e743b3d1c59ba952a6bf8f958b98c173638f921973a5a2aa0fe840094ad376e6f95d8015a0d8b954d3d30e24b895f066849776d130a99afc90f58249ae052bac231fa6a69d9e6f1debca20393", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-02-05T13:35:35.506013", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Open-Ended Registration", "registered_meta": {"summary": {"extra": [], "value": "PRE REGISTRO\nSe espera que los tweets m\u00e1s compartidos van a ser los que se alinean con la identidad pol\u00edtica del participante y contienen palabras de carga emocional.\nSe espera que los tweets compartidos que tengan contenido emocional sean compartidos m\u00e1s r\u00e1pido que los compartidos que no lo tengan.\nSe espera que el reporte de los participantes de que sientieron y pensaron durante el experimento incluya descriptores emocionales (similares a los utilizados para categorizar los tweets)"}, "uploader": {"extra": [], "value": ""}}, "registration_responses": {"summary": "PRE REGISTRO\nSe espera que los tweets m\u00e1s compartidos van a ser los que se alinean con la identidad pol\u00edtica del participante y contienen palabras de carga emocional.\nSe espera que los tweets compartidos que tengan contenido emocional sean compartidos m\u00e1s r\u00e1pido que los compartidos que no lo tengan.\nSe espera que el reporte de los participantes de que sientieron y pensaron durante el experimento incluya descriptores emocionales (similares a los utilizados para categorizar los tweets)"}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/eqfvp/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/eqfvp/comments/?format=json&filter%5Btarget%5D=eqfvp", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/eqfvp/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/eqfvp/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/eqfvp/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/eqfvp/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/eqfvp/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/eqfvp/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/eqfvp/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/eqfvp/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/eqfvp/linked_by_registrations/?format=json", "meta": {}}}}, "parent": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/?format=json", "meta": {}}}, "data": {"id": "fvth5", "type": "registrations"}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/eqfvp/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/eqfvp/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/eqfvp/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/?format=json", "meta": {}}}, "data": {"id": "fvth5", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/eqfvp/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/eqfvp/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/eqfvp/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/eqfvp/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/eqfvp/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/eqfvp/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/eqfvp/citation/?format=json", "meta": {}}}, "data": {"id": "eqfvp", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/38eyk/?format=json", "meta": {}}}, "data": {"id": "38eyk", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/pr2n9/?format=json", "meta": {}}}, "data": {"id": "pr2n9", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5df83f7dd28338001ac0ab0d/?format=json", "meta": {}}}, "data": {"id": "5df83f7dd28338001ac0ab0d", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/eqfvp/", "self": "https://api.osf.io/v2/registrations/eqfvp/"}}, {"id": "fvth5", "type": "registrations", "attributes": {"title": "Tesis pregrado: contagio emocional y la viralizaci\u00f3n de contenido pol\u00edtico en redes sociales", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-02-05T13:35:35.002013", "date_modified": "2020-02-04T19:10:03.779040", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "a435451138c9359972fde8ce9ed521be8b39e9ab9798080f2be031c82585d0cddfdfee63398fc5dff657374bffdbbad043e0c5e730ef91fc980ccb2f386150812e152fbaa59f3b05e97958f6082ec076b5ab8e52429c484adeab64d4c11fe6a3153449fd39151b5526ee0d73317959943a5ff102db06505fabf9f066bfd82c0226f9be60ae8d87ad6c67b2d13a94219f", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-02-05T13:35:34.977391", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Open-Ended Registration", "registered_meta": {"summary": {"extra": [], "value": "PRE REGISTRO\nSe espera que los tweets m\u00e1s compartidos van a ser los que se alinean con la identidad pol\u00edtica del participante y contienen palabras de carga emocional.\nSe espera que los tweets compartidos que tengan contenido emocional sean compartidos m\u00e1s r\u00e1pido que los compartidos que no lo tengan.\nSe espera que el reporte de los participantes de que sientieron y pensaron durante el experimento incluya descriptores emocionales (similares a los utilizados para categorizar los tweets)"}, "uploader": {"extra": [], "value": ""}}, "registration_responses": {"summary": "PRE REGISTRO\nSe espera que los tweets m\u00e1s compartidos van a ser los que se alinean con la identidad pol\u00edtica del participante y contienen palabras de carga emocional.\nSe espera que los tweets compartidos que tengan contenido emocional sean compartidos m\u00e1s r\u00e1pido que los compartidos que no lo tengan.\nSe espera que el reporte de los participantes de que sientieron y pensaron durante el experimento incluya descriptores emocionales (similares a los utilizados para categorizar los tweets)", "uploader": []}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/comments/?format=json&filter%5Btarget%5D=fvth5", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/fvth5/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/?format=json", "meta": {}}}, "data": {"id": "fvth5", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/fvth5/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/fvth5/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fvth5/citation/?format=json", "meta": {}}}, "data": {"id": "fvth5", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/38eyk/?format=json", "meta": {}}}, "data": {"id": "38eyk", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/9drxp/?format=json", "meta": {}}}, "data": {"id": "9drxp", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5df83f7dd28338001ac0ab0d/?format=json", "meta": {}}}, "data": {"id": "5df83f7dd28338001ac0ab0d", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/fvth5/", "self": "https://api.osf.io/v2/registrations/fvth5/"}}, {"id": "f64tx", "type": "registrations", "attributes": {"title": "Gist-guided attention", "description": "Between-subjects follow-up to \"Gist-guided attention 2-01\"", "category": "project", "custom_citation": "", "date_created": "2020-02-05T16:03:31.461939", "date_modified": "2020-02-05T16:05:01.058554", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "ac6e0807ca71d5d46971b59f5581d7cfe52e23fb081b2f6e7cb6c5b04c3f54536e4a86bb87a0b2ac18d3d51b8bfedb2db7957a4c9f2ea22050e07fbdffab662aa314a210d221712974619b47967af843c63b550cef415bb9d41158286cc2838a91ecc427636454cfaec06f7abba01033da2e4a0f789d256cf7c4607a04a559758bcb83b9fc6a221c3735ad556995e1eb", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-02-05T16:03:31.439889", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Preregistration Template from AsPredicted.org", "registered_meta": {"data": {"extra": [], "value": "No, no data have been collected for this study yet."}, "name": {"extra": [], "value": "Gist-guided attention: The effects of gist-absent vs. gist-present image previews on visual search. "}, "other": {"extra": [], "value": "We may study the effects of repetition on RT by comparing sets of trials grouped into \u2018bins\u2019. The width of these bins (i.e., number of trials included in each of bin) will be varied to identify to best capture learning dynamics. For instance, the first and second halves of trials may be compared, or changes between every twenty trials may be compared.\nAdditionally, we will study changes in response accuracy over trial repetitions, though RT will remain the primary effect of interest."}, "sample": {"extra": [], "value": "From a review of related studies, and a power analysis of the pilot data, we have determined that our sample size will be 64 participants, where 32 participants will be assigned to the experimental condition."}, "analyses": {"extra": [], "value": "We will use a linear mixed-effects regression model with Bayesian estimation as our primary method of analysis. We will model log-transformed RT as predicted by fixed effects for trial repetition (i.e., number of trial repetitions split by category), scene category, preview type, and their interaction. Random effects will include participant, trial repetition, scene images, and category. A model comparison approach will be leveraged to select which random effects should be included in the statistical models opting. The incorporation of the log transform and Bayes estimator serves to account for the skewness inherent to measures of RT (Matzke et al., 2013) and to relax the normality assumptions of linear regression. "}, "outliers": {"extra": [], "value": "A participant\u2019s data will be excluded if their response accuracy is less than 85%."}, "dependent": {"extra": [], "value": "The key dependent variable is reaction time (RT), where RT is assumed to be a sufficient analog for visual search efficiency (Wolfe et al., 2011). Specifically, we will measure the amount of time from search display onset until participants make a correct target detection. We intend to observe if, and how, RT transforms with gained experience in the visual search task over trials, and if, and how, RT transforms with the presence of scene gist in the search preview."}, "conditions": {"extra": [], "value": "There are two conditions based on preview type: intact (experimental) and phase-scrambled (control). Participants will be pseudorandomly assigned to one of two conditions, where one or the other type of preview will be exclusively used; they will then be randomly assigned to one of four versions of their pseudorandomly chosen condition. If we reach the desired number of participants in one condition, then the remainder of participants will be assigned to the other condition. There will be one hundred and eighty trials, where each trial lasts up to ten seconds, depending on the speed of participants\u2019 responses. Participants will receive an equal number of each type of scene category image, and comparisons will be made between-subjects."}, "hypothesis": {"extra": [], "value": "Can scene gist and its associated vast semantic knowledge be flexibly, and usefully, used in new learning? We hypothesize that participants\u2019 visual search strategies will become more efficient (faster target detection) after repeatedly experiencing search targets located in positions unique to scene categories with progressing trials, such that they are able to identify a target in an image more quickly based on the scene\u2019s category. Moreover, it is expected that visual search will be more efficient when the same search image, rather than a phase-scrambled version of the search image (scene gist is absent), is used as a preview. "}, "study_type": {"extra": [], "value": "Experiment"}, "study_type_other": {"extra": [], "value": ""}}, "registration_responses": {"data": "No, no data have been collected for this study yet.", "name": "Gist-guided attention: The effects of gist-absent vs. gist-present image previews on visual search. ", "other": "We may study the effects of repetition on RT by comparing sets of trials grouped into \u2018bins\u2019. The width of these bins (i.e., number of trials included in each of bin) will be varied to identify to best capture learning dynamics. For instance, the first and second halves of trials may be compared, or changes between every twenty trials may be compared.\nAdditionally, we will study changes in response accuracy over trial repetitions, though RT will remain the primary effect of interest.", "sample": "From a review of related studies, and a power analysis of the pilot data, we have determined that our sample size will be 64 participants, where 32 participants will be assigned to the experimental condition.", "analyses": "We will use a linear mixed-effects regression model with Bayesian estimation as our primary method of analysis. We will model log-transformed RT as predicted by fixed effects for trial repetition (i.e., number of trial repetitions split by category), scene category, preview type, and their interaction. Random effects will include participant, trial repetition, scene images, and category. A model comparison approach will be leveraged to select which random effects should be included in the statistical models opting. The incorporation of the log transform and Bayes estimator serves to account for the skewness inherent to measures of RT (Matzke et al., 2013) and to relax the normality assumptions of linear regression. ", "outliers": "A participant\u2019s data will be excluded if their response accuracy is less than 85%.", "dependent": "The key dependent variable is reaction time (RT), where RT is assumed to be a sufficient analog for visual search efficiency (Wolfe et al., 2011). Specifically, we will measure the amount of time from search display onset until participants make a correct target detection. We intend to observe if, and how, RT transforms with gained experience in the visual search task over trials, and if, and how, RT transforms with the presence of scene gist in the search preview.", "conditions": "There are two conditions based on preview type: intact (experimental) and phase-scrambled (control). Participants will be pseudorandomly assigned to one of two conditions, where one or the other type of preview will be exclusively used; they will then be randomly assigned to one of four versions of their pseudorandomly chosen condition. If we reach the desired number of participants in one condition, then the remainder of participants will be assigned to the other condition. There will be one hundred and eighty trials, where each trial lasts up to ten seconds, depending on the speed of participants\u2019 responses. Participants will receive an equal number of each type of scene category image, and comparisons will be made between-subjects.", "hypothesis": "Can scene gist and its associated vast semantic knowledge be flexibly, and usefully, used in new learning? We hypothesize that participants\u2019 visual search strategies will become more efficient (faster target detection) after repeatedly experiencing search targets located in positions unique to scene categories with progressing trials, such that they are able to identify a target in an image more quickly based on the scene\u2019s category. Moreover, it is expected that visual search will be more efficient when the same search image, rather than a phase-scrambled version of the search image (scene gist is absent), is used as a preview. ", "study_type": "Experiment", "study_type_other": ""}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/f64tx/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/f64tx/comments/?format=json&filter%5Btarget%5D=f64tx", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/f64tx/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/f64tx/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/f64tx/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/f64tx/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/f64tx/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/f64tx/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/f64tx/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/f64tx/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/f64tx/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/f64tx/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/f64tx/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/f64tx/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/f64tx/?format=json", "meta": {}}}, "data": {"id": "f64tx", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/f64tx/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/f64tx/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/f64tx/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/f64tx/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/f64tx/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/f64tx/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/f64tx/citation/?format=json", "meta": {}}}, "data": {"id": "f64tx", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/umcjw/?format=json", "meta": {}}}, "data": {"id": "umcjw", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/ryb4m/?format=json", "meta": {}}}, "data": {"id": "ryb4m", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5d2d2268d28338002c2432d2/?format=json", "meta": {}}}, "data": {"id": "5d2d2268d28338002c2432d2", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/f64tx/", "self": "https://api.osf.io/v2/registrations/f64tx/"}}, {"id": "xw6m7", "type": "registrations", "attributes": {"title": "Perspective Taking in International Relations Phase III", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-01-31T19:06:21.443805", "date_modified": "2020-02-08T05:00:05.538779", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "911cc892834c9f810311d36768a832d0ddeb30af5fadd574ab5b2ce818dd4a5e480085d578384aa3845b87aeedc0edacadcec432a528b2ad6d14c6bc6b3b840b0fe8bdc519a6708b3f869a75d2f1912b8bc557f3fdf9d69409f0f20c02130841312b195af0e5085b3589dd80bc3bbd7188fbab2046ab531298e9a2e74715ef8a7c4829700cc1f73f14877e7866958cda", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-31T19:06:21.428148", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "OSF-Standard Pre-Data Collection Registration", "registered_meta": {"looked": {"extra": [], "value": "No"}, "comments": {"extra": [], "value": ""}, "datacompletion": {"extra": [], "value": "No, data collection has not begun"}}, "registration_responses": {"looked": "No", "datacompletion": "No, data collection has not begun"}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/xw6m7/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/xw6m7/comments/?format=json&filter%5Btarget%5D=xw6m7", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/xw6m7/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/xw6m7/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/xw6m7/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/xw6m7/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/xw6m7/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/xw6m7/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/xw6m7/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/xw6m7/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/xw6m7/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/xw6m7/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/xw6m7/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/xw6m7/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/xw6m7/?format=json", "meta": {}}}, "data": {"id": "xw6m7", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/xw6m7/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/xw6m7/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/xw6m7/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/xw6m7/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/xw6m7/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/xw6m7/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/xw6m7/citation/?format=json", "meta": {}}}, "data": {"id": "xw6m7", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/6tvmp/?format=json", "meta": {}}}, "data": {"id": "6tvmp", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/x2m8y/?format=json", "meta": {}}}, "data": {"id": "x2m8y", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/564d31db8c5e4a7c9694b2c0/?format=json", "meta": {}}}, "data": {"id": "564d31db8c5e4a7c9694b2c0", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/xw6m7/", "self": "https://api.osf.io/v2/registrations/xw6m7/"}}, {"id": "x79bu", "type": "registrations", "attributes": {"title": "Cognitive Foundations of Moral Relativism", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-02-08T01:45:13.041796", "date_modified": "2020-02-08T01:44:14.304307", "registration": true, "preprint": false, "fork": true, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "e9c00f6edd6644f7a9a74322f7954c19acd70705569350a06596247e6d4d9a96c9820b694f1c52f18d9062272d0945fbe0915a8d4a340cb7c9a47cb40053b852eeeefdca735a2c67e95ba9e52da8bd9fbef971e61ff880c018db076c71e8dfd76957fd8c06e80f8a3bf22e0f6b036ff53d692bd39dc8cce6076201b7a5c4fd45d556682a5261e822ca0a78e6ff485734", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-02-08T01:45:13.014431", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "OSF Preregistration", "registered_meta": {"q1": {"extra": [], "value": "Moral Subjectivism and Cognitive processing - Time Manipulation"}, "q2": {"extra": [], "value": "Cristian Rodriguez, Peter Ditto"}, "q3": {"extra": [], "value": "Prior research (Yilmaz and Bah\u00e7ekapili, 2018) suggests that Type 1 cognitive processing might decrease subjectivist meta-ethical beliefs (i.e., moral relativism). It can be argued that the scarcity of cognitive resources will increase the tendency to judge morality as objective in comparison to conditions of no cognitive load. In this study, we manipulate effortful cognitive engagement by means of time manipulation (forced delay vs. time pressure)."}, "q4": {"extra": [], "value": "We hypothesize that moral subjectivism will vary as a function of cognitive processing: \n- Activating intuition (i.e., time-pressure condition) will decrease subjectivist meta-ethical judgments than the control condition.\n- Subjectivist meta-ethical judgments in the reflection condition (i.e., forced-delay response) should not differ from the control condition."}, "q5": {"extra": [], "value": "Experiment - A researcher randomly assigns treatments to study subjects, this includes field or lab experiments. This is also known as an intervention experiment and includes randomized controlled trials."}, "q6": {"extra": [], "value": ["For studies that involve human subjects, they will not know the treatment group to which they have been assigned."]}, "q7": {"extra": [], "value": ""}, "q8": {"value": {"question": {"extra": [], "value": "Between subjects design with 1 factor (time manipulation) and 3 levels (control, time-pressure, forced-delay)"}, "uploader": {"extra": [], "value": ""}}}, "q9": {"extra": [], "value": "Participants will be randomly assigned to one of the three conditions (block randomization), by the Qualtrics survey engine."}, "q10": {"extra": [], "value": "Registration prior to creation of data"}, "q11": {"extra": [], "value": ""}, "q12": {"value": {"question": {"extra": [], "value": "We will collect data from Amazon MTurk services. Adults, US MTurk workers with high-quality performance in prior HITs will be offered to participate for a payment of $0.80."}, "uploader": {"extra": [{"data": {"name": "Power calculation.rtf"}, "nodeId": "h4b87", "sha256": "b55c1370f61da4a6e7502ba12bda45d4f256c44373ae99b1267a76725948685c", "viewUrl": "/project/x79bu/files/osfstorage/5e3e12ad032a4d01ece6fa8c/", "selectedFileName": "Power calculation.rtf"}], "value": ""}}}, "q13": {"extra": [], "value": "We expect to recruit 600 participants."}, "q14": {"extra": [], "value": "For effect size calculations, we took as reference prior research (Experiment 3 from Yilmaz and Bah\u00e7ekapili, 2018): manipulation of intuitive thinking by mortality salience showed a decrease in subjectivist responses (d = 0.26). Using G*Power software (Faul, Erdfelner, Buchner, &amp; Lang, 2009), we determined a minimum sample size of 578 to detect that effect seize, (two-tailed \u03b1 =.05, 1 \u2013 \u03b2 =80; see Power Calculations.rtf). "}, "q15": {"extra": [], "value": ""}, "q16": {"value": {"question": {"extra": [], "value": "Independent variable: Cognitive effort.\nParticipants will be randomly assigned to one of three conditions: control, delayed response and time-restraint (cf. Tr\u00e9moli\u00e8re, De Neys, &amp; Bonnefon, 2017). The only difference among conditions will be limitations in response time. Participants in the delayed response condition will be able to indicate their views only after 15 seconds, whereas participants in the time-restraint condition will be asked to read the vignettes and report their preference within a time limit of 25 seconds."}, "uploader": {"extra": [], "value": ""}}}, "q17": {"value": {"question": {"extra": [], "value": "We will measure moral subjectivism (dependent variable) using moral dilemmas from prior research (cf. Goodwin &amp; Darley 2012, Experiment 1, pp. 251-252 and Appendix 1). Participants will be exposed to 18 different vignettes describing moral disagreements (12), as well as disagreement on factual statements, taste judgments and social conventions (6).\nFollowing prior research, we will ask participants the degree to which they agree with either of the characters in the discussion. Additionally, we will ask whether the disagreement does not have a right or wrong answer."}, "uploader": {"extra": [], "value": ""}}}, "q18": {"value": {"question": {"extra": [], "value": "The absolute scores of agreement with either character will be subtracted to obtain a measure of objectivism. "}, "uploader": {"extra": [], "value": ""}}}, "q19": {"value": {"question": {"extra": [], "value": "A one-way ANOVA model will be conducted to test differences among conditions. Tukey HSD tests will be conducted to determine the effect sizes of differences across conditions. "}, "uploader": {"extra": [], "value": ""}}}, "q20": {"extra": [], "value": ""}, "q21": {"extra": [], "value": "We will make inferences based on p-values (Bonferroni corrected in post-hoc tests), 95% confidence intervals and effect sizes (Cohen's d)."}, "q22": {"extra": [], "value": ""}, "q23": {"extra": [], "value": "Participants with missing data in more than 3 trials will be discarded."}, "q24": {"extra": [], "value": "We plan to explore whether our manipulation interacts with demographics, political ideology and religiosity."}, "q25": {"extra": [], "value": ""}}, "registration_responses": {"q1": "Moral Subjectivism and Cognitive processing - Time Manipulation", "q2": "Cristian Rodriguez, Peter Ditto", "q3": "Prior research (Yilmaz and Bah\u00e7ekapili, 2018) suggests that Type 1 cognitive processing might decrease subjectivist meta-ethical beliefs (i.e., moral relativism). It can be argued that the scarcity of cognitive resources will increase the tendency to judge morality as objective in comparison to conditions of no cognitive load. In this study, we manipulate effortful cognitive engagement by means of time manipulation (forced delay vs. time pressure).", "q4": "We hypothesize that moral subjectivism will vary as a function of cognitive processing: \n- Activating intuition (i.e., time-pressure condition) will decrease subjectivist meta-ethical judgments than the control condition.\n- Subjectivist meta-ethical judgments in the reflection condition (i.e., forced-delay response) should not differ from the control condition.", "q5": "Experiment - A researcher randomly assigns treatments to study subjects, this includes field or lab experiments. This is also known as an intervention experiment and includes randomized controlled trials.", "q6": ["For studies that involve human subjects, they will not know the treatment group to which they have been assigned."], "q7": "", "q9": "Participants will be randomly assigned to one of the three conditions (block randomization), by the Qualtrics survey engine.", "q10": "Registration prior to creation of data", "q11": "", "q13": "We expect to recruit 600 participants.", "q14": "For effect size calculations, we took as reference prior research (Experiment 3 from Yilmaz and Bah\u00e7ekapili, 2018): manipulation of intuitive thinking by mortality salience showed a decrease in subjectivist responses (d = 0.26). Using G*Power software (Faul, Erdfelner, Buchner, &amp; Lang, 2009), we determined a minimum sample size of 578 to detect that effect seize, (two-tailed \u03b1 =.05, 1 \u2013 \u03b2 =80; see Power Calculations.rtf). ", "q15": "", "q20": "", "q21": "We will make inferences based on p-values (Bonferroni corrected in post-hoc tests), 95% confidence intervals and effect sizes (Cohen's d).", "q22": "", "q23": "Participants with missing data in more than 3 trials will be discarded.", "q24": "We plan to explore whether our manipulation interacts with demographics, political ideology and religiosity.", "q25": "", "q8.question": "Between subjects design with 1 factor (time manipulation) and 3 levels (control, time-pressure, forced-delay)", "q8.uploader": [], "q12.question": "We will collect data from Amazon MTurk services. Adults, US MTurk workers with high-quality performance in prior HITs will be offered to participate for a payment of $0.80.", "q12.uploader": [{"file_id": "5e3e12ad032a4d01ece6fa8c", "file_name": "Power calculation.rtf", "file_urls": {"html": "https://osf.io/project/x79bu/files/osfstorage/5e3e12ad032a4d01ece6fa8c", "download": "https://osf.io/download/5e3e12ad032a4d01ece6fa8c"}, "file_hashes": {"sha256": "b55c1370f61da4a6e7502ba12bda45d4f256c44373ae99b1267a76725948685c"}}], "q16.question": "Independent variable: Cognitive effort.\nParticipants will be randomly assigned to one of three conditions: control, delayed response and time-restraint (cf. Tr\u00e9moli\u00e8re, De Neys, &amp; Bonnefon, 2017). The only difference among conditions will be limitations in response time. Participants in the delayed response condition will be able to indicate their views only after 15 seconds, whereas participants in the time-restraint condition will be asked to read the vignettes and report their preference within a time limit of 25 seconds.", "q16.uploader": [], "q17.question": "We will measure moral subjectivism (dependent variable) using moral dilemmas from prior research (cf. Goodwin &amp; Darley 2012, Experiment 1, pp. 251-252 and Appendix 1). Participants will be exposed to 18 different vignettes describing moral disagreements (12), as well as disagreement on factual statements, taste judgments and social conventions (6).\nFollowing prior research, we will ask participants the degree to which they agree with either of the characters in the discussion. Additionally, we will ask whether the disagreement does not have a right or wrong answer.", "q17.uploader": [], "q18.question": "The absolute scores of agreement with either character will be subtracted to obtain a measure of objectivism. ", "q18.uploader": [], "q19.question": "A one-way ANOVA model will be conducted to test differences among conditions. Tukey HSD tests will be conducted to determine the effect sizes of differences across conditions. ", "q19.uploader": []}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/x79bu/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/x79bu/comments/?format=json&filter%5Btarget%5D=x79bu", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/x79bu/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/x79bu/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/x79bu/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/x79bu/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/x79bu/wikis/?format=json", "meta": {}}}}, "forked_from": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/687956/?format=json", "meta": {}}}, "data": {"id": "687956", "type": "registrations"}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/x79bu/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/x79bu/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/x79bu/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/x79bu/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/x79bu/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/x79bu/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/x79bu/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/x79bu/?format=json", "meta": {}}}, "data": {"id": "x79bu", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/x79bu/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/x79bu/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/x79bu/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/x79bu/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/x79bu/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/x79bu/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/x79bu/citation/?format=json", "meta": {}}}, "data": {"id": "x79bu", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/pxc53/?format=json", "meta": {}}}, "data": {"id": "pxc53", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/h4b87/?format=json", "meta": {}}}, "data": {"id": "h4b87", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5c08457ed283380029cf73bf/?format=json", "meta": {}}}, "data": {"id": "5c08457ed283380029cf73bf", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/x79bu/", "self": "https://api.osf.io/v2/registrations/x79bu/"}}, {"id": "4tdqz", "type": "registrations", "attributes": {"title": "Pre-analysis plan", "description": "", "category": "", "custom_citation": "", "date_created": "2020-02-07T23:51:09.539128", "date_modified": "2020-02-07T23:48:52.719287", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": ["bangladesh", "enteric parasite infection", "giardia", "household flooring", "kenya", "soil-transmitted helminths"], "access_requests_enabled": false, "node_license": null, "analytics_key": "1023f75278a391ec68583ae73edbbe49ef52f86307f808b6efec6f61554925c2fc8963ecc9a6fb6c1d9fd4f7e9d0078f369e15770a25111e01f86c1fd2807c51182772aaec3cc189e37c0aa987012484cddc1f47b0a44412fa333690208c654503330f2d0ecd06aa03c89128e5a035f759a6eca20a835eed629ef2387f4ead9774982d54cbb25e28bd5729b779332805", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-02-07T23:51:09.521796", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Open-Ended Registration", "registered_meta": {"summary": {"extra": [], "value": "This pre-analysis plan is for a cohort study nested within the WASH Benefits trials to estimate the association between household flooring status and enteric parasite infection in children in Bangladesh and Kenya. "}, "uploader": {"extra": [], "value": ""}}, "registration_responses": {"summary": "This pre-analysis plan is for a cohort study nested within the WASH Benefits trials to estimate the association between household flooring status and enteric parasite infection in children in Bangladesh and Kenya. ", "uploader": []}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/4tdqz/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/4tdqz/comments/?format=json&filter%5Btarget%5D=4tdqz", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/4tdqz/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/4tdqz/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/4tdqz/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/4tdqz/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/4tdqz/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/4tdqz/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/4tdqz/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/4tdqz/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/4tdqz/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/4tdqz/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/4tdqz/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/4tdqz/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/4tdqz/?format=json", "meta": {}}}, "data": {"id": "4tdqz", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/4tdqz/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/4tdqz/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/4tdqz/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/4tdqz/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/4tdqz/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/4tdqz/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/4tdqz/citation/?format=json", "meta": {}}}, "data": {"id": "4tdqz", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/xgz2q/?format=json", "meta": {}}}, "data": {"id": "xgz2q", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/mtf8x/?format=json", "meta": {}}}, "data": {"id": "mtf8x", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5df83f7dd28338001ac0ab0d/?format=json", "meta": {}}}, "data": {"id": "5df83f7dd28338001ac0ab0d", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/4tdqz/", "self": "https://api.osf.io/v2/registrations/4tdqz/"}}, {"id": "5pcex", "type": "registrations", "attributes": {"title": "Gates Open Research Protocol Paper - Extended data", "description": "Information and Consent form, Last Menstrual Period (LMP) form, Maternal Morbidity form", "category": "procedure", "custom_citation": "", "date_created": "2020-01-29T20:45:44.319093", "date_modified": "2020-02-07T21:43:22.429800", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": {"copyright_holders": [], "year": null}, "analytics_key": "3d3013bcf8b001b71329db85145eeaecd409e80c6db60d57117c29aa051cdd7cd1a5aa4ec2b3c26920d2e305665641841df0a0812ef9b5ea6e8e46102b9863932c41e71d59ae1da49216e71c814483b745fc2abf668302bd802b3f7d53fc66b5ad62511a4101204286e036f529033f75d32afdd72439993d69d17d1150318dbbf788e06e8554a11e29e421c571485285", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-29T20:45:44.300313", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Open-Ended Registration", "registered_meta": {"summary": {"extra": [], "value": "This is a registration of forms that were used in the process of recruitment for the HERO-G study. "}, "uploader": {"extra": [{"data": {"name": "LMP.pdf"}, "nodeId": "jyzks", "sha256": "53ce4f1e3f04f39abf5647478254c600077c7d586f8cb9d439cb0cb077346f77", "viewUrl": "/project/jyzks/files/osfstorage/5e2103eeedceab003c82ee4f", "selectedFileName": "LMP.pdf"}, {"data": {"name": "HERO-G Information Sheet and Consent Form.docx"}, "nodeId": "jyzks", "sha256": "0cf6cf8ce971eccedd87b054bc539e7c76052add9fbc1f007f27a9ce19507120", "viewUrl": "/project/jyzks/files/osfstorage/5e2103ee675e0e002d6b60a6", "selectedFileName": "HERO-G Information Sheet and Consent Form.docx"}, {"data": {"name": "MatMorbidity.pdf"}, "nodeId": "jyzks", "sha256": "3654946f9880db225938ab14d5696f2e34c869003b45d4c01834608cbe675ee5", "viewUrl": "/project/jyzks/files/osfstorage/5e2103eeedceab003c82ee53", "selectedFileName": "MatMorbidity.pdf"}], "value": ""}}, "registration_responses": {"summary": "This is a registration of forms that were used in the process of recruitment for the HERO-G study. ", "uploader": [{"file_id": "5e2103eeedceab003c82ee4f", "file_name": "LMP.pdf", "file_urls": {"html": "https://osf.io/jyzks/files/osfstorage/5e2103eeedceab003c82ee4f", "download": "https://osf.io/download/5e2103eeedceab003c82ee4f/"}, "file_hashes": {"sha256": "53ce4f1e3f04f39abf5647478254c600077c7d586f8cb9d439cb0cb077346f77"}}, {"file_id": "5e2103ee675e0e002d6b60a6", "file_name": "HERO-G Information Sheet and Consent Form.docx", "file_urls": {"html": "https://osf.io/jyzks/files/osfstorage/5e2103ee675e0e002d6b60a6", "download": "https://osf.io/download/5e2103ee675e0e002d6b60a6/"}, "file_hashes": {"sha256": "0cf6cf8ce971eccedd87b054bc539e7c76052add9fbc1f007f27a9ce19507120"}}, {"file_id": "5e2103eeedceab003c82ee53", "file_name": "MatMorbidity.pdf", "file_urls": {"html": "https://osf.io/jyzks/files/osfstorage/5e2103eeedceab003c82ee53", "download": "https://osf.io/download/5e2103eeedceab003c82ee53/"}, "file_hashes": {"sha256": "3654946f9880db225938ab14d5696f2e34c869003b45d4c01834608cbe675ee5"}}]}, "subjects": []}, "relationships": {"license": {"links": {"related": {"href": "https://api.osf.io/v2/licenses/563c1cf88c5e4a3877f9e96a/?format=json", "meta": {}}}, "data": {"id": "563c1cf88c5e4a3877f9e96a", "type": "licenses"}}, "children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5pcex/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5pcex/comments/?format=json&filter%5Btarget%5D=5pcex", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5pcex/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5pcex/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5pcex/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5pcex/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5pcex/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5pcex/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5pcex/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5pcex/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5pcex/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5pcex/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5pcex/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/5pcex/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5pcex/?format=json", "meta": {}}}, "data": {"id": "5pcex", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5pcex/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5pcex/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/5pcex/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5pcex/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/5pcex/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5pcex/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5pcex/citation/?format=json", "meta": {}}}, "data": {"id": "5pcex", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/phx8b/?format=json", "meta": {}}}, "data": {"id": "phx8b", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/jyzks/?format=json", "meta": {}}}, "data": {"id": "jyzks", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5df83f7dd28338001ac0ab0d/?format=json", "meta": {}}}, "data": {"id": "5df83f7dd28338001ac0ab0d", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/5pcex/", "self": "https://api.osf.io/v2/registrations/5pcex/"}}, {"id": "wsqtj", "type": "registrations", "attributes": {"title": "Young people\u2019s perceptions about abortion in Southwest Nigeria: Findings from formative audience research (Extended data)", "description": "This is the focus group discussion guide and code dictionary for the study \"Young people\u2019s perceptions about abortion in Southwest Nigeria: Findings from formative audience research\"", "category": "methods and measures", "custom_citation": "", "date_created": "2020-02-07T20:34:23.547211", "date_modified": "2020-02-07T21:02:24.818107", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": ["Abortion", "Adolescents and young people", "Formative audience research", "Nigeria", "Termination of pregnancy"], "access_requests_enabled": false, "node_license": {"copyright_holders": [""], "year": "2020"}, "analytics_key": "0b2b3742b76e4d029746c5c222ff8817c51c84e4f235d140767e85d89d443e4e9d17d718a6f4f121ed709342b509a4fd2ffd0fe25507d25866d7738d0225978c5f286481ec948c0bebd4d29d5b92b1fd711d0785ee337300fca2bfdc1f30e55b7669b79d555dae988720ae420b4db409c8263b0218a4944eed49025fcc0ec779cd6022d9840f2599231dabd2ed937201", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-02-07T20:34:23.510817", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Open-Ended Registration", "registered_meta": {"summary": {"extra": [], "value": "This is the focus group discussion guide and code dictionary for the study \"Young people\u2019s perceptions about abortion in Southwest Nigeria: Findings from formative audience research\""}, "uploader": {"extra": [{"data": {"name": "Formative audience research_FGD guide_15-25yrs Version A.docx"}, "nodeId": "8ehbs", "sha256": "e04581deace5621ba35b283fba87f6bc18bd4260422050074a7ad60d222d46f5", "viewUrl": "/project/wsqtj/files/osfstorage/5e3dc9d3032a4d0197e70411/", "selectedFileName": "Formative audience research_FGD guide_15-25yrs Version A.docx"}, {"data": {"name": "Formative audience research_Abortion_Code dictionary.docx"}, "nodeId": "8ehbs", "sha256": "c1c8d70ad9285cd7a09bb980acdff7da9b20a411d225493f4046a9b1ddda9aab", "viewUrl": "/project/wsqtj/files/osfstorage/5e3dc9d4032a4d0197e70413/", "selectedFileName": "Formative audience research_Abortion_Code dictionary.docx"}], "value": ""}}, "registration_responses": {"summary": "This is the focus group discussion guide and code dictionary for the study \"Young people\u2019s perceptions about abortion in Southwest Nigeria: Findings from formative audience research\"", "uploader": [{"file_id": "5e3dc9d3032a4d0197e70411", "file_name": "Formative audience research_FGD guide_15-25yrs Version A.docx", "file_urls": {"html": "https://osf.io/project/wsqtj/files/osfstorage/5e3dc9d3032a4d0197e70411", "download": "https://osf.io/download/5e3dc9d3032a4d0197e70411"}, "file_hashes": {"sha256": "e04581deace5621ba35b283fba87f6bc18bd4260422050074a7ad60d222d46f5"}}, {"file_id": "5e3dc9d4032a4d0197e70413", "file_name": "Formative audience research_Abortion_Code dictionary.docx", "file_urls": {"html": "https://osf.io/project/wsqtj/files/osfstorage/5e3dc9d4032a4d0197e70413", "download": "https://osf.io/download/5e3dc9d4032a4d0197e70413"}, "file_hashes": {"sha256": "c1c8d70ad9285cd7a09bb980acdff7da9b20a411d225493f4046a9b1ddda9aab"}}]}, "subjects": [[{"id": "584240da54be81056cecaaaa", "text": "Medicine and Health Sciences"}, {"id": "584240da54be81056cecaa96", "text": "Public Health"}]]}, "relationships": {"license": {"links": {"related": {"href": "https://api.osf.io/v2/licenses/563c1cf88c5e4a3877f9e96c/?format=json", "meta": {}}}, "data": {"id": "563c1cf88c5e4a3877f9e96c", "type": "licenses"}}, "children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/wsqtj/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/wsqtj/comments/?format=json&filter%5Btarget%5D=wsqtj", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/wsqtj/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/wsqtj/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/wsqtj/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/wsqtj/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/wsqtj/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/wsqtj/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/wsqtj/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/wsqtj/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/wsqtj/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/wsqtj/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/wsqtj/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/wsqtj/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/wsqtj/?format=json", "meta": {}}}, "data": {"id": "wsqtj", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/wsqtj/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/wsqtj/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/wsqtj/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/wsqtj/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/wsqtj/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/wsqtj/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/wsqtj/citation/?format=json", "meta": {}}}, "data": {"id": "wsqtj", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/nqhz4/?format=json", "meta": {}}}, "data": {"id": "nqhz4", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/8ehbs/?format=json", "meta": {}}}, "data": {"id": "8ehbs", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5df83f7dd28338001ac0ab0d/?format=json", "meta": {}}}, "data": {"id": "5df83f7dd28338001ac0ab0d", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/wsqtj/", "self": "https://api.osf.io/v2/registrations/wsqtj/"}}, {"id": "y2tej", "type": "registrations", "attributes": {"title": "Task constraints on interpersonal coordination: Effects of task goals on alignment in eye-movements and speech", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-02-07T19:51:09.450014", "date_modified": "2020-02-03T21:42:15.750901", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "0bff5dfab3235dfa5e8859352bcd8cb2598f324a975094dccdd7374390bfffa5025d732f1a626d49faf5c98364bb5946003fe8fd2b984dc6da3aa66a34cb3ace4eb0feb3fd8c7f4ba406752d8de07bf3ee0ada8d1ebf13913400ba5bb81e604be7eebf2fd3a548d55a31a4599ae68f34624fc7f415b0c21d9a9e73c9725a45b46cdd7b069c1d31452aa3d2cd660294d4", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-02-07T19:51:09.421856", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "OSF Preregistration", "registered_meta": {"q1": {"extra": [], "value": "Constraints on interpersonal coordination: Effects of task on alignment in eye-movements and speech"}, "q2": {"extra": [], "value": "Alexia Galati, Camila Alviar, Moreno I. Coco, Rick Dale"}, "q3": {"extra": [], "value": "People must closely coordinate with one another in order to successfully accomplish a variety \nof joint tasks: from playing a game of basketball with friends, to searching for misplaced keys \nwith a spouse, to writing a manuscript collaboratively. As they fluidly organize their behavior to \nmeet shared goals, interlocutors contingently adapt their descriptions (Galati &amp; Brennan, 2010; \nHorton &amp; Gerrig, 2002), their eye movements (D. C. Richardson &amp; Dale, 2005), their non-verbal \nfeedback (Louwerse et al., 2012), their gestures (Galati &amp; Brennan, 2014), and their \ninstrumental actions (Clark &amp; Krych, 2004). Despite this documented adaptation, the underlying \nprocesses that support such versatile coordination are not well understood. \nOne prominent account of interpersonal coordination is that task partners automatically align their language use\u2013from their articulation, to their word choices and the syntactic structures they use\u2013through the mechanism of priming (Pickering &amp; Garrod, 2004). In this view, as task partners align linguistically they converge conceptually, which supports their task performance. Lexical and syntactic alignment has indeed been shown to support performance in spatial tasks that require partners to closely monitor each other\u2019s perspective (e.g., Anderson et al., 1991; Reitter &amp; Moore, 2014). In these tasks, speakers must monitor their partner\u2019s perspective as they describe geometric shapes to identify target objects (Brennan &amp; Clark, 1996), object locations to reconstruct target arrays (Nenkova et al., 2008; Galati &amp; Avraamides, 2013) or paths on maps or mazes to draw target routes (Anderson et al., 1991; Garrod &amp; Anderson, 1987; Reitter &amp; Moore, 2014; Pardo et al., 2019). As linguistic alignment increases, through the re-use of syntactic structures (Reitter &amp; Moore, 2014; Ferreira et al., 2012) or spatial terms (Galati &amp; Avraamides, 2013), task accuracy and efficiency typically improves.\nStill, recent work suggests that the benefits of alignment may not extent to all domains. In many complex problem-solving tasks, a \u201cdivision of labor\u201d strategy, associated with the complementarity of joint behavior, could be more beneficial to performance. Indeed, there is evidence that high levels of interpersonal alignment in joint perceptual or motor tasks are detrimental to task performance. For instance, in a perceptual task where partners had to detect an \u201coddball\u201d stimulus (a target with distinct characteristics), moderate levels of alignment in the partner\u2019s language use resulted in better performance compared to high levels of alignment (Fusaroli et al., 2012). Similarly, in a joint attention task where task partners had to detect a difference across two images, increased levels of alignment in gaze fixations were associated with inaccurate performance (Coco et al., 2018). And in joint motor tasks (such as building model cars, Wallot et al., 2016, playing Double Dutch, Gorman et al., 2017,or moving dots on a screen while avoiding collision, M. J. Richardson et al., 2015), complementarity in movement dynamics was more functional than synchrony. These studies suggest that when the task affords more degrees-of-freedom in how to structure the interaction (e.g., when partners can speak freely, Coco et al., 2018, or have symmetrical roles, Wallot et al., 2016), too much interpersonal alignment can constrain behavioral flexibility and result in performance decrements. \nThese two conflicting lines of evidence reveal that, depending on the task, alignment or disalignment can be an emerging property of the interaction that serves task goals. Although a few studies have examined the impact of task constraints on both interpersonal coordination patterns and on task outcomes (M. J. Richardson et al., 2015; Wallot et al., 2016; Eloy et al., 2019), the relative benefits of interpersonal alignment (vs. disalignment) have not been systematically assessed across contexts. \nIn this study we examine the impact of task goals on interpersonal coordination and on performance outcomes. There is some tentative evidence that task goals influence linguistic choices. For example, when discussing otherwise identical material, speakers adapt their descriptions in terms of length and semantic attributes, depending on whether they are asked to identify a building or to provide a route direction (Baltaretu et al., 2019). Still, the effect of task goals on attentional processes\u2014as reflected in eye movements\u2014remains controversial. The influential yet anecdotal illustration of Yarbus (1967) is suggestive of this possibility. Yarbus demonstrated that an observer\u2019s scan patterns can differ according to task goals (e.g., viewing a painting to estimate the material wealth of the characters vs. remember their locations). However, empirical evidence has since been mixed, with some studies providing support for the idea that eye movement patterns are diagnostic of the task (e.g., Borji &amp; Itti, 2014; Henderson et al., 2013; Hutt et al., 2019) and others not (Greene et al., 2012). Still, no studies to our knowledge have examined whether the alignment of eye movements of collaborating partners can be diagnostic of task goals. Here, we examine directly whether the task goal\u00ac (joint visual search vs. joint route planning) influences the degree of behavioral alignment among interacting partners, and whether the benefits of alignment differ across task goals. \n\nReferences: \n\nAnderson, A. H., Bader, M., Bard, E. G., Boyle, E., Doherty, G., Garrod, S., Isard, S., Kowtko, J., McAllister, J., Miller, J., Sotillo, C., Thompson, H. S., &amp; Weinert, R. (1991). The HCRC Map Task Corpus. Language and Speech, 34(4), 351\u2013366. https://doi.org/10.1177/002383099103400404\n\nBaltaretu, A., Krahmer, E., &amp; Maes, A. (2019). Producing Referring Expressions in Identification Tasks and Route Directions: What\u2019s the Difference? Discourse Processes, 56(2), 136\u2013154. https://doi.org/10.1080/0163853X.2017.1386522\n\nBorji, A., &amp; Itti, L. (2014). Defending Yarbus: Eye movements reveal observers\u2019 task. Journal of Vision, 14(3), 29\u201329. https://doi.org/10.1167/14.3.29\n\nBrennan, S. E., &amp; Clark, H. H. (1996). Conceptual Pacts and Lexical Choice in Conversation. Journal of Experimental Psychology: Learning, Memory, and Cognition, 22(6), 1482\u20131493.\n\nClark, H. H., &amp; Krych, M. A. (2004). Speaking while monitoring addressees for understanding. Journal of Memory and Language, 50(1), 62\u201381. https://doi.org/10.1016/j.jml.2003.08.004\n\nCoco, M. I., Dale, R., &amp; Keller, F. (2018). Performance in a Collaborative Search Task: The Role of Feedback and Alignment. Topics in Cognitive Science, 10(1), 55\u201379. https://doi.org/10.1111/tops.12300\n\nEloy, L., E.B. Stewart, A., Jean Amon, M., Reinhardt, C., Michaels, A., Sun, C., Shute, V., Duran, N. D., &amp; D\u2019Mello, S. (2019). Modeling Team-level Multimodal Dynamics during Multiparty Collaboration. 2019 International Conference on Multimodal Interaction on   - ICMI \u201919, 244\u2013258. https://doi.org/10.1145/3340555.3353748\n\nFerreira, V. S., Kleinman, D., Kraljic, T., &amp; Siu, Y. (2012). Do priming effects in dialogue reflect partner- or task-based expectations? Psychonomic Bulletin &amp; Review, 19(2), 309\u2013316. https://doi.org/10.3758/s13423-011-0191-9\n\nFusaroli, R., Bahrami, B., Olsen, K., Roepstorff, A., Rees, G., Frith, C., &amp; Tyl\u00e9n, K. (2012). Coming to Terms: Quantifying the Benefits of Linguistic Coordination. Psychological Science, 23(8), 931\u2013939. https://doi.org/10.1177/0956797612436816\n\nGalati, A., &amp; Avraamides, M. N. (2013). Flexible spatial perspective-taking: Conversational partners weigh multiple cues in collaborative tasks. Frontiers in Human Neuroscience, 7, 618. https://doi.org/10.3389/fnhum.2013.00618\n\nGalati, A., &amp; Brennan, S. E. (2010). Attenuating information in spoken communication: For the speaker, or for the addressee? Journal of Memory and Language, 62(1), 35\u201351. https://doi.org/10.1016/j.jml.2009.09.002\n\nGalati, A., &amp; Brennan, S. E. (2014). Speakers adapt gestures to addressees\u2019 knowledge: Implications for models of co-speech gesture. Language, Cognition and Neuroscience, 29(4), 435\u2013451. https://doi.org/10.1080/01690965.2013.796397\n\nGarrod, S., &amp; Anderson, A. (1987). Saying what you mean in dialogue: A study in conceptual and semantic co-ordination. Cognition, 27(2), 181\u2013218. https://doi.org/10.1016/0010-0277(87)90018-7\n\nGorman, J. C., Amazeen, P. G., Crites, M. J., &amp; Gipson, C. L. (2017). Deviations from mirroring in interpersonal multifrequency coordination when visual information is occluded. Experimental Brain Research, 235(4), 1209\u20131221. https://doi.org/10.1007/s00221-017-4888-5\n\nGreene, M. R., Liu, T., &amp; Wolfe, J. M. (2012). Reconsidering Yarbus: A failure to predict observers\u2019 task from eye movement patterns. Vision Research, 62, 1\u20138. https://doi.org/10.1016/j.visres.2012.03.019\n\nHenderson, J. M., Shinkareva, S. V., Wang, J., Luke, S. G., &amp; Olejarczyk, J. (2013). Predicting Cognitive State from Eye Movements. PLOS ONE, 8(5), e64937. https://doi.org/10.1371/journal.pone.0064937\n\nHorton, W. S., &amp; Gerrig, R. J. (2002). Speakers\u2019 experiences and audience design: Knowing when and knowing how to adjust utterances to addressees. Journal of Memory and Language, 18.\n\nHutt, S., Krasich, K., Mills, C., Bosch, N., White, S., Brockmole, J. R., &amp; D\u2019Mello, S. K. (2019). Automated gaze-based mind wandering detection during computerized learning in classrooms. User Modeling and User-Adapted Interaction, 29(4), 821\u2013867. https://doi.org/10.1007/s11257-019-09228-5\n\nLouwerse, M. M., Dale, R., Bard, E. G., &amp; Jeuniaux, P. (2012). Behavior Matching in Multimodal Communication Is Synchronized. Cognitive Science, 36(8), 1404\u20131426. https://doi.org/10.1111/j.1551-6709.2012.01269.x\n\nNenkova, A., Gravano, A., &amp; Hirschberg, J. (2008). High Frequency Word Entertainment in Spoken Dialogue. 46th Annual Meeting of the Association for Computational Linguistics, 169\u2013172. https://doi.org/anthology/P08-2043\n\nPardo, J. S., Urmanche, A., Gash, H., Wiener, J., Mason, N., Wilman, S., Francis, K., &amp; Decker, A. (2019). The Montclair Map Task: Balance, Efficacy, and Efficiency in Conversational Interaction. Language and Speech, 62(2), 378\u2013398. https://doi.org/10.1177/0023830918775435\n\nPickering, M. J., &amp; Garrod, S. (2004). Toward a mechanistic psychology of dialogue. Behavioral and Brain Sciences, 27(02), 167\u2013226. https://doi.org/10.1017/S0140525X04000056\n\nReitter, D., &amp; Moore, J. D. (2014). Alignment and task success in spoken dialogue. Journal of Memory and Language, 76, 29\u201346. https://doi.org/10.1016/j.jml.2014.05.008\n\nRichardson, D. C., &amp; Dale, R. (2005). Looking To Understand: The Coupling Between Speakers\u2019 and Listeners\u2019 Eye Movements and Its Relationship to Discourse Comprehension. Cognitive Science, 29(6), 1045\u20131060. https://doi.org/10.1207/s15516709cog0000_29\n\nRichardson, M. J., Harrison, S. J., Kallen, R. W., Walton, A., Eiler, B. A., Saltzman, E., &amp; Schmidt, R. C. (2015). Self-organized complementary joint action: Behavioral dynamics of an interpersonal collision-avoidance task. Journal of Experimental Psychology: Human Perception and Performance, 41(3), 665\u2013679. https://doi.org/10.1037/xhp0000041\n\nYarbus, A. L. (1967). Eye movements during perception of complex objects. In Eye movements and vision (pp. 171-211). Springer US.\n\nWallot, S., Mitkidis, P., McGraw, J. J., &amp; Roepstorff, A. (2016). Beyond Synchrony: Joint Action in a Complex Production Task Reveals Beneficial Effects of Decreased Interpersonal Synchrony. PLOS ONE, 11(12), e0168306. https://doi.org/10.1371/journal.pone.0168306\n"}, "q4": {"extra": [], "value": "1.\tWe hypothesize that interpersonal alignment will increase when task constraints require mutual responsiveness to others\u2019 states and involve fewer degrees-of-freedom for organizing the interaction. Specifically, we reason that because joint route planning requires continually monitoring the location and heading of the imagined navigator, the task will result in increased alignment compared to joint visual search. In contrast, because joint visual search affords more flexibility for achieving task goals (e.g., partners can divide the search space), it will result in lower levels of interpersonal alignment. This is a directional hypothesis concerning the effect of task type. \n\n2.\tWe hypothesize that the benefits of interpersonal alignment will be selective. Increased alignment will be beneficial in tasks that support mutual responsiveness (e.g., perspective monitoring), more so than in tasks that afford more degrees-of-freedom for organizing the interaction. Therefore, we predict that increased levels of interpersonal alignment will be more beneficial to task outcomes in route planning than visual search. This is a directional hypothesis concerning the interaction between task type and levels of interpersonal alignment. \n"}, "q5": {"extra": [], "value": "Experiment - A researcher randomly assigns treatments to study subjects, this includes field or lab experiments. This is also known as an intervention experiment and includes randomized controlled trials."}, "q6": {"extra": [], "value": ["No blinding is involved in this study."]}, "q7": {"extra": [], "value": "No"}, "q8": {"value": {"question": {"extra": [], "value": "Participants from the University of North Carolina at Charlotte will be recruited in 52 dyads. Participants will sit at adjacent work stations, 93 cm from a monitor (covering a region of approximately 18\uf0b0 of visual angle), on which stimuli will be presented (resolution: 1920 x 1080 pixels). Participants\u2019 eye movements will be recorded at a sampling rate of 1000 Hz with unobtrusive desktop mounted SR EyeLink 1000 Plus eye trackers. Eye movements will be co-registered, with the onset of each target stimulus (i.e., map) and with the timestamps of the two trackers being synchronized. Sessions will be also audiotaped with high-quality microphones.\n\nAfter eye-tracker calibration and 12-point validation, dyads will complete a practice trial for each task (route planning and visual search). Then, dyads they will complete the 10 experimental trials, each involving one of 10 subway maps from the cities of London, Berlin, Barcelona, Paris, Sydney, Rome, Milan, Vienna, Lisbon, and Montreal. Between trials, a drift correction will be performed on both participants. \n\nThere will be 5 trials for each type of task (route planning vs. visual search) in two blocks, with block order counterbalanced across dyads. Within each block, 5 maps will be presented in order of increasing difficulty. \n\nFor route planning, dyads will have to find the most efficient route between two stations. This is defined as the route \u201cinvolving the fewest number of intervening stops between the starting point and destination, regardless of the number of changes between subway lines\u201d. Task partners will be informed that they each have unique information about stations undergoing construction (indicated by traffic cones), which they need to share to ensure planning the most efficient route. We use cones to eliminate solutions that are equally efficient in terms of the number of stops between origin and destination, so that each map has a unique solution. For the visual search task, dyads will have to count the number of stations sharing some feature (e.g., starting with a certain letter or containing a specific word). For both tasks, accuracy and agreement on the response will be emphasized. \n\nWhen ready, both participants will press the spacebar to advance to the screen with the map and will perform the task without a time limit (map screen). Eye movements and speech will be automatically recorded during this phase, yielding a record of the interaction. Upon reaching agreement, both partners will have to press the spacebar to terminate the trial, advancing to the response screen. One partner (A) will type the mutually agreed upon response in a response field (i.e., number of stops between stations or number of stations with the target feature).\n\nIn sum, task type (route planning vs. search) will be a within-participants factor, and task order and the pairing map set to task type will both be counterbalanced across dyads.\n"}, "uploader": {"extra": [], "value": ""}}}, "q9": {"extra": [], "value": "Participants will be randomly assigned to the roles of A and B in each dyad.\n\nNo other factors are randomized. Trials (maps) within blocks appear in order of increasing difficulty (from the 1st to the 5th trial). Map difficulty was established in a previous norming study. The assignment of map sets to task type (route planning vs. visual search) is counterbalanced across dyads. The order of each blocks is also counterbalanced across dyads. \n"}, "q10": {"extra": [], "value": "Registration prior to analysis of the data"}, "q11": {"extra": [], "value": "\nData collection for this study is ongoing. \n\nThe data of the first 7 dyads collected were analyzed and reported as preliminary results in grant proposal. \n\nData from the dyads subsequently collected have not been accessed or analyzed.  \n"}, "q12": {"value": {"question": {"extra": [], "value": "Participants will be native speakers of American English, over 18 years of age, with normal to normal-corrected vision and no reported speech or hearing impairments. They will be recruited through UNCC\u2019s Psychology subject pool via SONA and through community announcements distributed to targeted groups of University students, faculty, and/or staff by the Office of Research Compliance. They will be compensated for their time with prorated payment, at the rate of $10 / hour. Experimental sessions are estimated to take 1.5-2 hours. Participants will be paired into dyads according to their schedule.\n\nExperimental sessions will be terminated and dyads will be excluded from data analysis if one or both participants do not reach good levels of calibration and validation prior to the onset of the experimental trials. Individual trials will also be excluded due to poor calibration: the threshold for excluding trials will be set at &gt;10% of out of range fixations for either partner of the dyad. Dyads will also be excluded from analysis due to failed synchronization between the eye-trackers.  \n\nData collection started in December 2019 and is expected to be completed by summer 2020. \n"}, "uploader": {"extra": [], "value": ""}}}, "q13": {"extra": [], "value": "In total data from 104 participants will be collected, in 52 dyads."}, "q14": {"extra": [], "value": "We selected a sample size of 52 dyads (104 participants) based on an a priori power analysis using G*Power (Faul et al., 2007) on the preliminary data of the first 7 dyads. This analysis was conducted for a linear multiple regression model with effect size f2 = .33 (based on the smallest effect size in the pilot data, for the model predicting trial accuracy), alpha = .05, power =.80, with 7 tested predictors (constraint type, map difficulty, cRQA metric, and the interactions). \n\nFaul, F., Erdfelder, E., Lang, A.-G., &amp; Buchner, A. (2007). G*Power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences. Behavior Research Methods, 39(2), 175\u2013191. https://doi.org/10.3758/BF03193146\n"}, "q15": {"extra": [], "value": "We are not using a stopping rule. We plan to reach the specified sample of 52 dyads. \n"}, "q16": {"value": {"question": {"extra": [], "value": "1.\tTask type: 2 levels (route planning vs. visual search)\n2.\tMap difficulty: 5 levels (ordinal scale 1-5)\n3.\tBlock: 2 levels (first vs. second)\n4.\tPairing of map set to task type: 2 levels (map set 1 to route planning and map set 2 to visual search, and vice versa)\n\u2003\n"}, "uploader": {"extra": [], "value": ""}}}, "q17": {"value": {"question": {"extra": [], "value": "cRQA approach:\nOur analytic approach is grounded in dynamical systems theory, used to explain the emerging non-linear shifts in behavior of biological, cognitive, and social systems that involve a large number of interacting components. We applied cross-Recurrence Quantification Analysis to each pair\u2019s eye fixations (cRQA; Zbilut et al., 1998; Coco &amp; Dale, 2014). Recurrence Quantification Analysis (RQA) is a nonlinear time-series analysis that quantifies how much a signal from a system revisits similar states over time (how much it \u201crecurs\u201d). cRQA is applied to pairs of time series to quantify how recurrent those trajectories are. These methods have been developed for continuous data, such as body movement and acoustic properties of speech, but have been extended to categorical data, such as syntactic choices (Dale &amp; Spivey, 2006) and eye fixations (Coco et al., 2018). RQA and cRQA use a recurrence plot, a graphical depiction of the recurrence in the time series, to extract a number of measures. \n\nMeasures of coordination for gaze fixations:\nEach eye fixation will be categorized as being incident in one of 64 cells of an 8 x 8 grid, which was superimposed on each map (but was not visible to participants). Categorical cRQA will be applied to gaze fixations yielding the following measures:\n\n1.\trecurrence rate (RR), which summarizes the amount of overall recurrence by capturing the density of recurrence points in the resulting cross-Recurrence Plot (cRP).\n2.\tthe average length (L) of the diagonal of the cRP, which captures how frequently dyads look at the same map locations and reflects the regularity of the system\n3.\tdeterminism (DET), which quantifies the percentage of recurrence points forming diagonal lines and reflects the system\u2019s predictability,\n4.\tentropy (ENTR) of the line distribution, which captures how widely the segments of gaze alignment vary.  \n\nMeasures of coordination for acoustic properties of speech:\nThe same 4 measures (RR, L, DET, ENTR) will be extracted from continuous cRQA applied to acoustic properties of speech. \n\nWe will focus on the fundamental frequency and intensity of the speech of each participant in a dyad. Fundamental frequency, reflecting pitch, will be computed using the autocorrelation method in Praat (Boersma &amp; Weenink, 2010), and intensity will be computed based on intensity contours. Measures will be z-score standardized for each speaker to account for individual differences. To select cRQA parameters, we will reconstruct the phase space for each pair in each condition following Paxton and Dal (2017). \n\nTo define the speech signals of each task partner we will use a semi-automated diarization technique on the native audio recording from the SR (Anguera et al., 2012), which provides only mixed-down audio files. To achieve speaker diarization, we will use a semi-automated techniques by adapting recent methods in Variational Bayes (VB) inference applied to the speech stream. Though the VB approach can be deployed automatically, we will validate speaker diarization and conduct any necessary adjustment through human coders. \n\nPerformance measures:\n\u2022\tTrial accuracy will indicate whether the dyad indicate the correct numerical response for the task or not (number of intervening stations, or number of stations sharing some feature), as a binary variable.  \n\u2022\tTrial duration will indicate the amount of time in milliseconds that participants took to complete the trial. \n"}, "uploader": {"extra": [], "value": ""}}}, "q18": {"value": {"question": {"extra": [], "value": "We don\u2019t plan to compute indices beyond the cRQA metrics described above. "}, "uploader": {"extra": [], "value": ""}}}, "q19": {"value": {"question": {"extra": [], "value": "In linear mixed effects models, we will evaluate: (a) the effect of task type on interpersonal coordination, captured by the cRQA metrics (RR, L, DET, ENTR) and (b) the effects of task type, interpersonal coordination, and their interaction on task performance (trial accuracy and duration). Map difficulty and its interactions with task type (and interpersonal coordination, as relevant in the model) will also be included as predictors. Linear mixed-effects models will have the maximal random effect structure that permitted convergence (Barr et al., 2013) with fixed effects contrast coded and continuous fixed effects (trial difficulty, RR) centered and scaled. Dependent measures will be log-transformed if visual inspection of the initial residual plots suggests deviation from normality and homoscedasticity."}, "uploader": {"extra": [], "value": ""}}}, "q20": {"extra": [], "value": "Acoustic measures of speech will be z-score standardized for each speaker to account for individual differences.\nDependent measures will be log-transformed if visual inspection of the initial residual plots suggests deviation from normality and homoscedasticity.\nContinuous fixed effects (trial difficulty, RR) centered and scaled.\n"}, "q21": {"extra": [], "value": "The effect of the model predictors will be assessed at the alpha level of .05. All tests assessing model parameters will be two-tailed. "}, "q22": {"extra": [], "value": "We will exclude data from dyads if one or both participants do not reach good levels of calibration and validation prior to the onset of the experimental trials. Individual trials will also be excluded due to poor calibration: the threshold for excluding trials will be set at &gt;10% of out of range fixations for either partner of the dyad. Dyads will also be excluded from analysis due to failed synchronization between the eye-trackers, which would compromise the validity of the measures based on the time series of eye fixations. We base these practices on Coco, Dale, &amp; Keller (2018), who used a similar experimental set-up and apparatuses. "}, "q23": {"extra": [], "value": "Participants with missing trials (due to gaze fixations reaching the threshold of out of range fixations for exclusion) will still be included in the linear mixed effects models. "}, "q24": {"extra": [], "value": "In addition to obtaining cRQA measures to characterize alignment across an entire interaction, we will windowed analysis, which computes cRQA measures at time intervals. For this, a cross-Recurrence Plot of the two series is computed in overlapping windows of a specified size for a number of delays smaller than the size of the window over the two series. Our time series will be normalized to be 101 bins, and we will use a window of size 10, a delay of 5, and will move the window by a step of 2, yielding 50 time points. On each cRP, the same measures described above (RR, L, DET, ENTR) will be extracted. Time will be entered as an orthogonal polynomial of order two in the models, along with the interaction of these parameters with task type. \n\nThis will allow us to explore how alignment changes over the interaction (e.g., does it tend to go up as participants establish their routine?). We don\u2019t have a priori predictions about whether alignment will evolve differently across the two tasks.\n"}, "q25": {"extra": [], "value": ""}}, "registration_responses": {"q1": "Constraints on interpersonal coordination: Effects of task on alignment in eye-movements and speech", "q2": "Alexia Galati, Camila Alviar, Moreno I. Coco, Rick Dale", "q3": "People must closely coordinate with one another in order to successfully accomplish a variety \nof joint tasks: from playing a game of basketball with friends, to searching for misplaced keys \nwith a spouse, to writing a manuscript collaboratively. As they fluidly organize their behavior to \nmeet shared goals, interlocutors contingently adapt their descriptions (Galati &amp; Brennan, 2010; \nHorton &amp; Gerrig, 2002), their eye movements (D. C. Richardson &amp; Dale, 2005), their non-verbal \nfeedback (Louwerse et al., 2012), their gestures (Galati &amp; Brennan, 2014), and their \ninstrumental actions (Clark &amp; Krych, 2004). Despite this documented adaptation, the underlying \nprocesses that support such versatile coordination are not well understood. \nOne prominent account of interpersonal coordination is that task partners automatically align their language use\u2013from their articulation, to their word choices and the syntactic structures they use\u2013through the mechanism of priming (Pickering &amp; Garrod, 2004). In this view, as task partners align linguistically they converge conceptually, which supports their task performance. Lexical and syntactic alignment has indeed been shown to support performance in spatial tasks that require partners to closely monitor each other\u2019s perspective (e.g., Anderson et al., 1991; Reitter &amp; Moore, 2014). In these tasks, speakers must monitor their partner\u2019s perspective as they describe geometric shapes to identify target objects (Brennan &amp; Clark, 1996), object locations to reconstruct target arrays (Nenkova et al., 2008; Galati &amp; Avraamides, 2013) or paths on maps or mazes to draw target routes (Anderson et al., 1991; Garrod &amp; Anderson, 1987; Reitter &amp; Moore, 2014; Pardo et al., 2019). As linguistic alignment increases, through the re-use of syntactic structures (Reitter &amp; Moore, 2014; Ferreira et al., 2012) or spatial terms (Galati &amp; Avraamides, 2013), task accuracy and efficiency typically improves.\nStill, recent work suggests that the benefits of alignment may not extent to all domains. In many complex problem-solving tasks, a \u201cdivision of labor\u201d strategy, associated with the complementarity of joint behavior, could be more beneficial to performance. Indeed, there is evidence that high levels of interpersonal alignment in joint perceptual or motor tasks are detrimental to task performance. For instance, in a perceptual task where partners had to detect an \u201coddball\u201d stimulus (a target with distinct characteristics), moderate levels of alignment in the partner\u2019s language use resulted in better performance compared to high levels of alignment (Fusaroli et al., 2012). Similarly, in a joint attention task where task partners had to detect a difference across two images, increased levels of alignment in gaze fixations were associated with inaccurate performance (Coco et al., 2018). And in joint motor tasks (such as building model cars, Wallot et al., 2016, playing Double Dutch, Gorman et al., 2017,or moving dots on a screen while avoiding collision, M. J. Richardson et al., 2015), complementarity in movement dynamics was more functional than synchrony. These studies suggest that when the task affords more degrees-of-freedom in how to structure the interaction (e.g., when partners can speak freely, Coco et al., 2018, or have symmetrical roles, Wallot et al., 2016), too much interpersonal alignment can constrain behavioral flexibility and result in performance decrements. \nThese two conflicting lines of evidence reveal that, depending on the task, alignment or disalignment can be an emerging property of the interaction that serves task goals. Although a few studies have examined the impact of task constraints on both interpersonal coordination patterns and on task outcomes (M. J. Richardson et al., 2015; Wallot et al., 2016; Eloy et al., 2019), the relative benefits of interpersonal alignment (vs. disalignment) have not been systematically assessed across contexts. \nIn this study we examine the impact of task goals on interpersonal coordination and on performance outcomes. There is some tentative evidence that task goals influence linguistic choices. For example, when discussing otherwise identical material, speakers adapt their descriptions in terms of length and semantic attributes, depending on whether they are asked to identify a building or to provide a route direction (Baltaretu et al., 2019). Still, the effect of task goals on attentional processes\u2014as reflected in eye movements\u2014remains controversial. The influential yet anecdotal illustration of Yarbus (1967) is suggestive of this possibility. Yarbus demonstrated that an observer\u2019s scan patterns can differ according to task goals (e.g., viewing a painting to estimate the material wealth of the characters vs. remember their locations). However, empirical evidence has since been mixed, with some studies providing support for the idea that eye movement patterns are diagnostic of the task (e.g., Borji &amp; Itti, 2014; Henderson et al., 2013; Hutt et al., 2019) and others not (Greene et al., 2012). Still, no studies to our knowledge have examined whether the alignment of eye movements of collaborating partners can be diagnostic of task goals. Here, we examine directly whether the task goal\u00ac (joint visual search vs. joint route planning) influences the degree of behavioral alignment among interacting partners, and whether the benefits of alignment differ across task goals. \n\nReferences: \n\nAnderson, A. H., Bader, M., Bard, E. G., Boyle, E., Doherty, G., Garrod, S., Isard, S., Kowtko, J., McAllister, J., Miller, J., Sotillo, C., Thompson, H. S., &amp; Weinert, R. (1991). The HCRC Map Task Corpus. Language and Speech, 34(4), 351\u2013366. https://doi.org/10.1177/002383099103400404\n\nBaltaretu, A., Krahmer, E., &amp; Maes, A. (2019). Producing Referring Expressions in Identification Tasks and Route Directions: What\u2019s the Difference? Discourse Processes, 56(2), 136\u2013154. https://doi.org/10.1080/0163853X.2017.1386522\n\nBorji, A., &amp; Itti, L. (2014). Defending Yarbus: Eye movements reveal observers\u2019 task. Journal of Vision, 14(3), 29\u201329. https://doi.org/10.1167/14.3.29\n\nBrennan, S. E., &amp; Clark, H. H. (1996). Conceptual Pacts and Lexical Choice in Conversation. Journal of Experimental Psychology: Learning, Memory, and Cognition, 22(6), 1482\u20131493.\n\nClark, H. H., &amp; Krych, M. A. (2004). Speaking while monitoring addressees for understanding. Journal of Memory and Language, 50(1), 62\u201381. https://doi.org/10.1016/j.jml.2003.08.004\n\nCoco, M. I., Dale, R., &amp; Keller, F. (2018). Performance in a Collaborative Search Task: The Role of Feedback and Alignment. Topics in Cognitive Science, 10(1), 55\u201379. https://doi.org/10.1111/tops.12300\n\nEloy, L., E.B. Stewart, A., Jean Amon, M., Reinhardt, C., Michaels, A., Sun, C., Shute, V., Duran, N. D., &amp; D\u2019Mello, S. (2019). Modeling Team-level Multimodal Dynamics during Multiparty Collaboration. 2019 International Conference on Multimodal Interaction on   - ICMI \u201919, 244\u2013258. https://doi.org/10.1145/3340555.3353748\n\nFerreira, V. S., Kleinman, D., Kraljic, T., &amp; Siu, Y. (2012). Do priming effects in dialogue reflect partner- or task-based expectations? Psychonomic Bulletin &amp; Review, 19(2), 309\u2013316. https://doi.org/10.3758/s13423-011-0191-9\n\nFusaroli, R., Bahrami, B., Olsen, K., Roepstorff, A., Rees, G., Frith, C., &amp; Tyl\u00e9n, K. (2012). Coming to Terms: Quantifying the Benefits of Linguistic Coordination. Psychological Science, 23(8), 931\u2013939. https://doi.org/10.1177/0956797612436816\n\nGalati, A., &amp; Avraamides, M. N. (2013). Flexible spatial perspective-taking: Conversational partners weigh multiple cues in collaborative tasks. Frontiers in Human Neuroscience, 7, 618. https://doi.org/10.3389/fnhum.2013.00618\n\nGalati, A., &amp; Brennan, S. E. (2010). Attenuating information in spoken communication: For the speaker, or for the addressee? Journal of Memory and Language, 62(1), 35\u201351. https://doi.org/10.1016/j.jml.2009.09.002\n\nGalati, A., &amp; Brennan, S. E. (2014). Speakers adapt gestures to addressees\u2019 knowledge: Implications for models of co-speech gesture. Language, Cognition and Neuroscience, 29(4), 435\u2013451. https://doi.org/10.1080/01690965.2013.796397\n\nGarrod, S., &amp; Anderson, A. (1987). Saying what you mean in dialogue: A study in conceptual and semantic co-ordination. Cognition, 27(2), 181\u2013218. https://doi.org/10.1016/0010-0277(87)90018-7\n\nGorman, J. C., Amazeen, P. G., Crites, M. J., &amp; Gipson, C. L. (2017). Deviations from mirroring in interpersonal multifrequency coordination when visual information is occluded. Experimental Brain Research, 235(4), 1209\u20131221. https://doi.org/10.1007/s00221-017-4888-5\n\nGreene, M. R., Liu, T., &amp; Wolfe, J. M. (2012). Reconsidering Yarbus: A failure to predict observers\u2019 task from eye movement patterns. Vision Research, 62, 1\u20138. https://doi.org/10.1016/j.visres.2012.03.019\n\nHenderson, J. M., Shinkareva, S. V., Wang, J., Luke, S. G., &amp; Olejarczyk, J. (2013). Predicting Cognitive State from Eye Movements. PLOS ONE, 8(5), e64937. https://doi.org/10.1371/journal.pone.0064937\n\nHorton, W. S., &amp; Gerrig, R. J. (2002). Speakers\u2019 experiences and audience design: Knowing when and knowing how to adjust utterances to addressees. Journal of Memory and Language, 18.\n\nHutt, S., Krasich, K., Mills, C., Bosch, N., White, S., Brockmole, J. R., &amp; D\u2019Mello, S. K. (2019). Automated gaze-based mind wandering detection during computerized learning in classrooms. User Modeling and User-Adapted Interaction, 29(4), 821\u2013867. https://doi.org/10.1007/s11257-019-09228-5\n\nLouwerse, M. M., Dale, R., Bard, E. G., &amp; Jeuniaux, P. (2012). Behavior Matching in Multimodal Communication Is Synchronized. Cognitive Science, 36(8), 1404\u20131426. https://doi.org/10.1111/j.1551-6709.2012.01269.x\n\nNenkova, A., Gravano, A., &amp; Hirschberg, J. (2008). High Frequency Word Entertainment in Spoken Dialogue. 46th Annual Meeting of the Association for Computational Linguistics, 169\u2013172. https://doi.org/anthology/P08-2043\n\nPardo, J. S., Urmanche, A., Gash, H., Wiener, J., Mason, N., Wilman, S., Francis, K., &amp; Decker, A. (2019). The Montclair Map Task: Balance, Efficacy, and Efficiency in Conversational Interaction. Language and Speech, 62(2), 378\u2013398. https://doi.org/10.1177/0023830918775435\n\nPickering, M. J., &amp; Garrod, S. (2004). Toward a mechanistic psychology of dialogue. Behavioral and Brain Sciences, 27(02), 167\u2013226. https://doi.org/10.1017/S0140525X04000056\n\nReitter, D., &amp; Moore, J. D. (2014). Alignment and task success in spoken dialogue. Journal of Memory and Language, 76, 29\u201346. https://doi.org/10.1016/j.jml.2014.05.008\n\nRichardson, D. C., &amp; Dale, R. (2005). Looking To Understand: The Coupling Between Speakers\u2019 and Listeners\u2019 Eye Movements and Its Relationship to Discourse Comprehension. Cognitive Science, 29(6), 1045\u20131060. https://doi.org/10.1207/s15516709cog0000_29\n\nRichardson, M. J., Harrison, S. J., Kallen, R. W., Walton, A., Eiler, B. A., Saltzman, E., &amp; Schmidt, R. C. (2015). Self-organized complementary joint action: Behavioral dynamics of an interpersonal collision-avoidance task. Journal of Experimental Psychology: Human Perception and Performance, 41(3), 665\u2013679. https://doi.org/10.1037/xhp0000041\n\nYarbus, A. L. (1967). Eye movements during perception of complex objects. In Eye movements and vision (pp. 171-211). Springer US.\n\nWallot, S., Mitkidis, P., McGraw, J. J., &amp; Roepstorff, A. (2016). Beyond Synchrony: Joint Action in a Complex Production Task Reveals Beneficial Effects of Decreased Interpersonal Synchrony. PLOS ONE, 11(12), e0168306. https://doi.org/10.1371/journal.pone.0168306\n", "q4": "1.\tWe hypothesize that interpersonal alignment will increase when task constraints require mutual responsiveness to others\u2019 states and involve fewer degrees-of-freedom for organizing the interaction. Specifically, we reason that because joint route planning requires continually monitoring the location and heading of the imagined navigator, the task will result in increased alignment compared to joint visual search. In contrast, because joint visual search affords more flexibility for achieving task goals (e.g., partners can divide the search space), it will result in lower levels of interpersonal alignment. This is a directional hypothesis concerning the effect of task type. \n\n2.\tWe hypothesize that the benefits of interpersonal alignment will be selective. Increased alignment will be beneficial in tasks that support mutual responsiveness (e.g., perspective monitoring), more so than in tasks that afford more degrees-of-freedom for organizing the interaction. Therefore, we predict that increased levels of interpersonal alignment will be more beneficial to task outcomes in route planning than visual search. This is a directional hypothesis concerning the interaction between task type and levels of interpersonal alignment. \n", "q5": "Experiment - A researcher randomly assigns treatments to study subjects, this includes field or lab experiments. This is also known as an intervention experiment and includes randomized controlled trials.", "q6": ["No blinding is involved in this study."], "q7": "No", "q9": "Participants will be randomly assigned to the roles of A and B in each dyad.\n\nNo other factors are randomized. Trials (maps) within blocks appear in order of increasing difficulty (from the 1st to the 5th trial). Map difficulty was established in a previous norming study. The assignment of map sets to task type (route planning vs. visual search) is counterbalanced across dyads. The order of each blocks is also counterbalanced across dyads. \n", "q10": "Registration prior to analysis of the data", "q11": "\nData collection for this study is ongoing. \n\nThe data of the first 7 dyads collected were analyzed and reported as preliminary results in grant proposal. \n\nData from the dyads subsequently collected have not been accessed or analyzed.  \n", "q13": "In total data from 104 participants will be collected, in 52 dyads.", "q14": "We selected a sample size of 52 dyads (104 participants) based on an a priori power analysis using G*Power (Faul et al., 2007) on the preliminary data of the first 7 dyads. This analysis was conducted for a linear multiple regression model with effect size f2 = .33 (based on the smallest effect size in the pilot data, for the model predicting trial accuracy), alpha = .05, power =.80, with 7 tested predictors (constraint type, map difficulty, cRQA metric, and the interactions). \n\nFaul, F., Erdfelder, E., Lang, A.-G., &amp; Buchner, A. (2007). G*Power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences. Behavior Research Methods, 39(2), 175\u2013191. https://doi.org/10.3758/BF03193146\n", "q15": "We are not using a stopping rule. We plan to reach the specified sample of 52 dyads. \n", "q20": "Acoustic measures of speech will be z-score standardized for each speaker to account for individual differences.\nDependent measures will be log-transformed if visual inspection of the initial residual plots suggests deviation from normality and homoscedasticity.\nContinuous fixed effects (trial difficulty, RR) centered and scaled.\n", "q21": "The effect of the model predictors will be assessed at the alpha level of .05. All tests assessing model parameters will be two-tailed. ", "q22": "We will exclude data from dyads if one or both participants do not reach good levels of calibration and validation prior to the onset of the experimental trials. Individual trials will also be excluded due to poor calibration: the threshold for excluding trials will be set at &gt;10% of out of range fixations for either partner of the dyad. Dyads will also be excluded from analysis due to failed synchronization between the eye-trackers, which would compromise the validity of the measures based on the time series of eye fixations. We base these practices on Coco, Dale, &amp; Keller (2018), who used a similar experimental set-up and apparatuses. ", "q23": "Participants with missing trials (due to gaze fixations reaching the threshold of out of range fixations for exclusion) will still be included in the linear mixed effects models. ", "q24": "In addition to obtaining cRQA measures to characterize alignment across an entire interaction, we will windowed analysis, which computes cRQA measures at time intervals. For this, a cross-Recurrence Plot of the two series is computed in overlapping windows of a specified size for a number of delays smaller than the size of the window over the two series. Our time series will be normalized to be 101 bins, and we will use a window of size 10, a delay of 5, and will move the window by a step of 2, yielding 50 time points. On each cRP, the same measures described above (RR, L, DET, ENTR) will be extracted. Time will be entered as an orthogonal polynomial of order two in the models, along with the interaction of these parameters with task type. \n\nThis will allow us to explore how alignment changes over the interaction (e.g., does it tend to go up as participants establish their routine?). We don\u2019t have a priori predictions about whether alignment will evolve differently across the two tasks.\n", "q25": "", "q8.question": "Participants from the University of North Carolina at Charlotte will be recruited in 52 dyads. Participants will sit at adjacent work stations, 93 cm from a monitor (covering a region of approximately 18\uf0b0 of visual angle), on which stimuli will be presented (resolution: 1920 x 1080 pixels). Participants\u2019 eye movements will be recorded at a sampling rate of 1000 Hz with unobtrusive desktop mounted SR EyeLink 1000 Plus eye trackers. Eye movements will be co-registered, with the onset of each target stimulus (i.e., map) and with the timestamps of the two trackers being synchronized. Sessions will be also audiotaped with high-quality microphones.\n\nAfter eye-tracker calibration and 12-point validation, dyads will complete a practice trial for each task (route planning and visual search). Then, dyads they will complete the 10 experimental trials, each involving one of 10 subway maps from the cities of London, Berlin, Barcelona, Paris, Sydney, Rome, Milan, Vienna, Lisbon, and Montreal. Between trials, a drift correction will be performed on both participants. \n\nThere will be 5 trials for each type of task (route planning vs. visual search) in two blocks, with block order counterbalanced across dyads. Within each block, 5 maps will be presented in order of increasing difficulty. \n\nFor route planning, dyads will have to find the most efficient route between two stations. This is defined as the route \u201cinvolving the fewest number of intervening stops between the starting point and destination, regardless of the number of changes between subway lines\u201d. Task partners will be informed that they each have unique information about stations undergoing construction (indicated by traffic cones), which they need to share to ensure planning the most efficient route. We use cones to eliminate solutions that are equally efficient in terms of the number of stops between origin and destination, so that each map has a unique solution. For the visual search task, dyads will have to count the number of stations sharing some feature (e.g., starting with a certain letter or containing a specific word). For both tasks, accuracy and agreement on the response will be emphasized. \n\nWhen ready, both participants will press the spacebar to advance to the screen with the map and will perform the task without a time limit (map screen). Eye movements and speech will be automatically recorded during this phase, yielding a record of the interaction. Upon reaching agreement, both partners will have to press the spacebar to terminate the trial, advancing to the response screen. One partner (A) will type the mutually agreed upon response in a response field (i.e., number of stops between stations or number of stations with the target feature).\n\nIn sum, task type (route planning vs. search) will be a within-participants factor, and task order and the pairing map set to task type will both be counterbalanced across dyads.\n", "q8.uploader": [], "q12.question": "Participants will be native speakers of American English, over 18 years of age, with normal to normal-corrected vision and no reported speech or hearing impairments. They will be recruited through UNCC\u2019s Psychology subject pool via SONA and through community announcements distributed to targeted groups of University students, faculty, and/or staff by the Office of Research Compliance. They will be compensated for their time with prorated payment, at the rate of $10 / hour. Experimental sessions are estimated to take 1.5-2 hours. Participants will be paired into dyads according to their schedule.\n\nExperimental sessions will be terminated and dyads will be excluded from data analysis if one or both participants do not reach good levels of calibration and validation prior to the onset of the experimental trials. Individual trials will also be excluded due to poor calibration: the threshold for excluding trials will be set at &gt;10% of out of range fixations for either partner of the dyad. Dyads will also be excluded from analysis due to failed synchronization between the eye-trackers.  \n\nData collection started in December 2019 and is expected to be completed by summer 2020. \n", "q12.uploader": [], "q16.question": "1.\tTask type: 2 levels (route planning vs. visual search)\n2.\tMap difficulty: 5 levels (ordinal scale 1-5)\n3.\tBlock: 2 levels (first vs. second)\n4.\tPairing of map set to task type: 2 levels (map set 1 to route planning and map set 2 to visual search, and vice versa)\n\u2003\n", "q16.uploader": [], "q17.question": "cRQA approach:\nOur analytic approach is grounded in dynamical systems theory, used to explain the emerging non-linear shifts in behavior of biological, cognitive, and social systems that involve a large number of interacting components. We applied cross-Recurrence Quantification Analysis to each pair\u2019s eye fixations (cRQA; Zbilut et al., 1998; Coco &amp; Dale, 2014). Recurrence Quantification Analysis (RQA) is a nonlinear time-series analysis that quantifies how much a signal from a system revisits similar states over time (how much it \u201crecurs\u201d). cRQA is applied to pairs of time series to quantify how recurrent those trajectories are. These methods have been developed for continuous data, such as body movement and acoustic properties of speech, but have been extended to categorical data, such as syntactic choices (Dale &amp; Spivey, 2006) and eye fixations (Coco et al., 2018). RQA and cRQA use a recurrence plot, a graphical depiction of the recurrence in the time series, to extract a number of measures. \n\nMeasures of coordination for gaze fixations:\nEach eye fixation will be categorized as being incident in one of 64 cells of an 8 x 8 grid, which was superimposed on each map (but was not visible to participants). Categorical cRQA will be applied to gaze fixations yielding the following measures:\n\n1.\trecurrence rate (RR), which summarizes the amount of overall recurrence by capturing the density of recurrence points in the resulting cross-Recurrence Plot (cRP).\n2.\tthe average length (L) of the diagonal of the cRP, which captures how frequently dyads look at the same map locations and reflects the regularity of the system\n3.\tdeterminism (DET), which quantifies the percentage of recurrence points forming diagonal lines and reflects the system\u2019s predictability,\n4.\tentropy (ENTR) of the line distribution, which captures how widely the segments of gaze alignment vary.  \n\nMeasures of coordination for acoustic properties of speech:\nThe same 4 measures (RR, L, DET, ENTR) will be extracted from continuous cRQA applied to acoustic properties of speech. \n\nWe will focus on the fundamental frequency and intensity of the speech of each participant in a dyad. Fundamental frequency, reflecting pitch, will be computed using the autocorrelation method in Praat (Boersma &amp; Weenink, 2010), and intensity will be computed based on intensity contours. Measures will be z-score standardized for each speaker to account for individual differences. To select cRQA parameters, we will reconstruct the phase space for each pair in each condition following Paxton and Dal (2017). \n\nTo define the speech signals of each task partner we will use a semi-automated diarization technique on the native audio recording from the SR (Anguera et al., 2012), which provides only mixed-down audio files. To achieve speaker diarization, we will use a semi-automated techniques by adapting recent methods in Variational Bayes (VB) inference applied to the speech stream. Though the VB approach can be deployed automatically, we will validate speaker diarization and conduct any necessary adjustment through human coders. \n\nPerformance measures:\n\u2022\tTrial accuracy will indicate whether the dyad indicate the correct numerical response for the task or not (number of intervening stations, or number of stations sharing some feature), as a binary variable.  \n\u2022\tTrial duration will indicate the amount of time in milliseconds that participants took to complete the trial. \n", "q17.uploader": [], "q18.question": "We don\u2019t plan to compute indices beyond the cRQA metrics described above. ", "q18.uploader": [], "q19.question": "In linear mixed effects models, we will evaluate: (a) the effect of task type on interpersonal coordination, captured by the cRQA metrics (RR, L, DET, ENTR) and (b) the effects of task type, interpersonal coordination, and their interaction on task performance (trial accuracy and duration). Map difficulty and its interactions with task type (and interpersonal coordination, as relevant in the model) will also be included as predictors. Linear mixed-effects models will have the maximal random effect structure that permitted convergence (Barr et al., 2013) with fixed effects contrast coded and continuous fixed effects (trial difficulty, RR) centered and scaled. Dependent measures will be log-transformed if visual inspection of the initial residual plots suggests deviation from normality and homoscedasticity.", "q19.uploader": []}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y2tej/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y2tej/comments/?format=json&filter%5Btarget%5D=y2tej", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y2tej/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y2tej/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y2tej/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y2tej/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y2tej/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y2tej/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y2tej/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y2tej/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y2tej/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y2tej/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y2tej/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/y2tej/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y2tej/?format=json", "meta": {}}}, "data": {"id": "y2tej", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y2tej/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y2tej/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/y2tej/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y2tej/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/y2tej/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y2tej/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y2tej/citation/?format=json", "meta": {}}}, "data": {"id": "y2tej", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/u764f/?format=json", "meta": {}}}, "data": {"id": "u764f", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/jzs7h/?format=json", "meta": {}}}, "data": {"id": "jzs7h", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5c08457ed283380029cf73bf/?format=json", "meta": {}}}, "data": {"id": "5c08457ed283380029cf73bf", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/y2tej/", "self": "https://api.osf.io/v2/registrations/y2tej/"}}], "links": {"first": "https://api.osf.io/v2/registrations/?filter%5Bdate_created%5D%5Bgt%5D=2019-12-31&format=json", "last": "https://api.osf.io/v2/registrations/?filter%5Bdate_created%5D%5Bgt%5D=2019-12-31&format=json&page=547", "prev": "https://api.osf.io/v2/registrations/?filter%5Bdate_created%5D%5Bgt%5D=2019-12-31&format=json&page=327", "next": "https://api.osf.io/v2/registrations/?filter%5Bdate_created%5D%5Bgt%5D=2019-12-31&format=json&page=329", "meta": {"total": 5469, "per_page": 10}}}