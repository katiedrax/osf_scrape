{"data": [{"id": "qdmej", "type": "registrations", "attributes": {"title": "PA Treasury - markers of credibility Propel study", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-01-14T06:33:28.692134", "date_modified": "2019-09-06T16:19:46.116605", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "b8b5e6dfd3fdb3e594e569e98298a19b1107a6e8bb2bd397b2332a46be3e51b66ee830dc931e5a7b09fcbd2b51f799ec8c8963ef4fd5f1305269307feb7faa0f4d0f0f4c02a22eea88f3a184aa3b1a6024b6ab149709ba25ae1f46bf8d6e63ba50cec3dbb52cd711a80c49874ed1b1d64f2a0b62686c2eeb9f0c7119fa9bb9c5b9b4392a9d6daff0b7d7a8b90a6d53ba", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-14T06:33:28.674451", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "OSF Preregistration", "registered_meta": {"q1": {"extra": [], "value": "PA treasury - markers of credibility Propel study"}, "q2": {"extra": [], "value": "Sarah Ratkiewicz, Michelle Zong"}, "q3": {"extra": [], "value": "The Pennsylvania Treasury (PA) Department runs a program called Keystone Scholars, in which all parents of newborn babies have the opportunity to claim a $100 grant within the year after their child is born. This $100 can be applied toward any expenses for the child's higher education. In a research partnership with the PA Treasury, our research team aims to increase the number of families that click on ads for the program by conducting an experiment to assess the impact of what markers of credibility are present in ads for the program.\n\nThere is the possibility that the relatively low uptake on the PA Treasury Keystone Scholars program is caused in part by skepticism. New parents might see the offer of a free $100 as a scam that must be \u2018too good to be true.\u2019 The purpose of the current experiment is to determine if manipulating the markers of credibility present in a Keystone Scholars ad run in the Propel app will affect clickthrough rates on ads for the program.\n\nOur research questions are as follows:\n\n(1) Does including the PA Treasury logo in addition to the Keystone Scholars logo increase clickthrough rates on ads for the program?\n\n(2) Does providing an endorsement from Propel, an app that users trust, increase clickthrough rates on ads for Keystone Scholars?\n\n(3) Does including testimonials from PA residents who overcame their skepticism to benefit from the program increase clickthrough rates?"}, "q4": {"extra": [], "value": "(1) Propel users who receive an ad with the combined PA Treasury and Keystone Scholars logo will be more likely to click through compared to Propel users who receive an ad with the Keystone Scholars logo alone.\n\n(2) Propel users who receive an ad with the combined PA Treasury and Keystone Scholars logo and a personal testimonial will be more likely to click through compared to Propel users who receive either (a) the Keystone Scholars logo + Propel endorsement ad and (b) the combined logo + Propel endorsement ad."}, "q5": {"extra": [], "value": "Experiment - A researcher randomly assigns treatments to study subjects, this includes field or lab experiments. This is also known as an intervention experiment and includes randomized controlled trials."}, "q6": {"extra": [], "value": ["For studies that involve human subjects, they will not know the treatment group to which they have been assigned."]}, "q7": {"extra": [], "value": ""}, "q8": {"value": {"question": {"extra": [], "value": "We will use a between-subject study design with three conditions."}, "uploader": {"extra": [], "value": ""}}}, "q9": {"extra": [], "value": "We will use simple randomization, where each participant will be randomly assigned to one of the three conditions. Randomization will be performed by the Propel app in which the advertisements will be run."}, "q10": {"extra": [], "value": "Registration prior to creation of data"}, "q11": {"extra": [], "value": ""}, "q12": {"value": {"question": {"extra": [], "value": "Participants will be users of Propel, a phone app that lets users check their SNAP EBT benefits. Users will be shown one of three advertisement types through this app, each including a \"Learn more\" button that will link to more information about the Keystone Scholars program. Propel will collect data on how many users in each group click to follow the link."}, "uploader": {"extra": [], "value": ""}}}, "q13": {"extra": [], "value": "Approximately 150,000 PA residents will be shown the advertisements. An estimated 3,000 will click on the link."}, "q14": {"extra": [], "value": "The sample size is determined by the number of PA residents using Propel and by the average click rate for previous advertisements for the Keystone Scholars program run in Propel."}, "q15": {"extra": [], "value": "Data collection will be stopped after 3,000 unique clicks are collected or on 10/1/2020, whichever comes first."}, "q16": {"value": {"question": {"extra": [], "value": "We will manipulate the markers of credibility present in the ad. There are three conditions: \n\n(a) Keystone logo + Propel endorsement (Propel wants you to know about the Keystone Scholars program to help plan for your child\u2019s higher education!)\n\n(b) Combination logo + Propel endorsement (Propel wants you to know about the Keystone Scholars program to help plan for your child\u2019s higher education!)\n\n(c) Combination logo + PA resident testimonial (\u201cIt was pretty quick and easy to register. This process helped start our financial planning and any little bit helps!\u201d \u2013PA Resident)\n"}, "uploader": {"extra": [], "value": ""}}}, "q17": {"value": {"question": {"extra": [], "value": "We will measuring the following four variables: general impressions, unique impressions, general clickthrough rates, and unique clickthrough rates."}, "uploader": {"extra": [], "value": ""}}}, "q18": {"value": {"question": {"extra": [], "value": ""}, "uploader": {"extra": [], "value": ""}}}, "q19": {"value": {"question": {"extra": [], "value": "Our primary outcome will be the proportion of unique clicks out of unique impressions by condition. Our secondary outcomes include totally unique click through rates, general click through rates, and general proportion of clicks out of general impressions. We will use a one-way between subjects\u2019 ANOVA to analyze the data. For our first hypothesis, we will compare the outcome variables between condition a to b, for our second hypothesis we will compare the outcome variables between condition b and c.  "}, "uploader": {"extra": [], "value": ""}}}, "q20": {"extra": [], "value": ""}, "q21": {"extra": [], "value": "We will use the standard p&lt;.05 criteria for determining statistical significance."}, "q22": {"extra": [], "value": ""}, "q23": {"extra": [], "value": ""}, "q24": {"extra": [], "value": ""}, "q25": {"extra": [], "value": ""}}, "registration_responses": {"q1": "PA treasury - markers of credibility Propel study", "q2": "Sarah Ratkiewicz, Michelle Zong", "q3": "The Pennsylvania Treasury (PA) Department runs a program called Keystone Scholars, in which all parents of newborn babies have the opportunity to claim a $100 grant within the year after their child is born. This $100 can be applied toward any expenses for the child's higher education. In a research partnership with the PA Treasury, our research team aims to increase the number of families that click on ads for the program by conducting an experiment to assess the impact of what markers of credibility are present in ads for the program.\n\nThere is the possibility that the relatively low uptake on the PA Treasury Keystone Scholars program is caused in part by skepticism. New parents might see the offer of a free $100 as a scam that must be \u2018too good to be true.\u2019 The purpose of the current experiment is to determine if manipulating the markers of credibility present in a Keystone Scholars ad run in the Propel app will affect clickthrough rates on ads for the program.\n\nOur research questions are as follows:\n\n(1) Does including the PA Treasury logo in addition to the Keystone Scholars logo increase clickthrough rates on ads for the program?\n\n(2) Does providing an endorsement from Propel, an app that users trust, increase clickthrough rates on ads for Keystone Scholars?\n\n(3) Does including testimonials from PA residents who overcame their skepticism to benefit from the program increase clickthrough rates?", "q4": "(1) Propel users who receive an ad with the combined PA Treasury and Keystone Scholars logo will be more likely to click through compared to Propel users who receive an ad with the Keystone Scholars logo alone.\n\n(2) Propel users who receive an ad with the combined PA Treasury and Keystone Scholars logo and a personal testimonial will be more likely to click through compared to Propel users who receive either (a) the Keystone Scholars logo + Propel endorsement ad and (b) the combined logo + Propel endorsement ad.", "q5": "Experiment - A researcher randomly assigns treatments to study subjects, this includes field or lab experiments. This is also known as an intervention experiment and includes randomized controlled trials.", "q6": ["For studies that involve human subjects, they will not know the treatment group to which they have been assigned."], "q7": "", "q9": "We will use simple randomization, where each participant will be randomly assigned to one of the three conditions. Randomization will be performed by the Propel app in which the advertisements will be run.", "q10": "Registration prior to creation of data", "q11": "", "q13": "Approximately 150,000 PA residents will be shown the advertisements. An estimated 3,000 will click on the link.", "q14": "The sample size is determined by the number of PA residents using Propel and by the average click rate for previous advertisements for the Keystone Scholars program run in Propel.", "q15": "Data collection will be stopped after 3,000 unique clicks are collected or on 10/1/2020, whichever comes first.", "q20": "", "q21": "We will use the standard p&lt;.05 criteria for determining statistical significance.", "q22": "", "q23": "", "q24": "", "q25": "", "q8.question": "We will use a between-subject study design with three conditions.", "q8.uploader": [], "q12.question": "Participants will be users of Propel, a phone app that lets users check their SNAP EBT benefits. Users will be shown one of three advertisement types through this app, each including a \"Learn more\" button that will link to more information about the Keystone Scholars program. Propel will collect data on how many users in each group click to follow the link.", "q12.uploader": [], "q16.question": "We will manipulate the markers of credibility present in the ad. There are three conditions: \n\n(a) Keystone logo + Propel endorsement (Propel wants you to know about the Keystone Scholars program to help plan for your child\u2019s higher education!)\n\n(b) Combination logo + Propel endorsement (Propel wants you to know about the Keystone Scholars program to help plan for your child\u2019s higher education!)\n\n(c) Combination logo + PA resident testimonial (\u201cIt was pretty quick and easy to register. This process helped start our financial planning and any little bit helps!\u201d \u2013PA Resident)\n", "q16.uploader": [], "q17.question": "We will measuring the following four variables: general impressions, unique impressions, general clickthrough rates, and unique clickthrough rates.", "q17.uploader": [], "q18.question": "", "q18.uploader": [], "q19.question": "Our primary outcome will be the proportion of unique clicks out of unique impressions by condition. Our secondary outcomes include totally unique click through rates, general click through rates, and general proportion of clicks out of general impressions. We will use a one-way between subjects\u2019 ANOVA to analyze the data. For our first hypothesis, we will compare the outcome variables between condition a to b, for our second hypothesis we will compare the outcome variables between condition b and c.  ", "q19.uploader": []}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/qdmej/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/qdmej/comments/?format=json&filter%5Btarget%5D=qdmej", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/qdmej/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/qdmej/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/qdmej/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/qdmej/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/qdmej/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/qdmej/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/qdmej/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/qdmej/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/qdmej/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/qdmej/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/qdmej/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/qdmej/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/qdmej/?format=json", "meta": {}}}, "data": {"id": "qdmej", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/qdmej/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/qdmej/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/qdmej/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/qdmej/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/qdmej/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/qdmej/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/qdmej/citation/?format=json", "meta": {}}}, "data": {"id": "qdmej", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/dvuwx/?format=json", "meta": {}}}, "data": {"id": "dvuwx", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/fu8w9/?format=json", "meta": {}}}, "data": {"id": "fu8w9", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5c08457ed283380029cf73bf/?format=json", "meta": {}}}, "data": {"id": "5c08457ed283380029cf73bf", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/qdmej/", "self": "https://api.osf.io/v2/registrations/qdmej/"}}, {"id": "dtp79", "type": "registrations", "attributes": {"title": "Reading medium and reading purpose", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-01-14T16:41:38.924168", "date_modified": "2020-01-14T16:41:10.968102", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "4fedb7c7dbc19a0a09575608bc3b9785e711e14d6c2637b59e36d9a4c3f702bb6c84ef735cea25e46535f67e1ca6029d5eb6b72afb00635a309d519dfa30ad9cfdf48755e4bc81a1baac1d5e9e6d80182cd7f63332985280f8818e6222ee344dcd0fdfe904269fe1e2a3b3e6f82a0889d2fa700d8a9dce3a93adb0dd6075d84d2378cce87e7e13e4e25dc8493db9abbc", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-14T16:41:38.900112", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Registered Report Protocol Preregistration", "registered_meta": {"q1": {"extra": [], "value": "Investigating Reading from Screens and Mind Wandering in the Context of Standards of Coherence"}, "q2": {"extra": [], "value": "Virginia Clinton"}, "q3": {"extra": [], "value": "I confirm this study has been granted in-principle acceptance."}, "q4": {"extra": [], "value": "Scientific Studies of Reading"}, "q5": {"extra": [], "value": "2019-11-11"}, "q6": {"extra": [{"data": {"name": "masked_final.docx"}, "nodeId": "u3gne", "sha256": "48de21acdf91e3a4e9c8a1fe5685b2f8b880f21f1b025b3b0026a337ddcdaa01", "viewUrl": "/project/dtp79/files/osfstorage/5e1def466822bd0138feda14/", "selectedFileName": "masked_final.docx"}], "value": ""}, "q7": {"extra": [{"data": {"name": "Appendix.docx"}, "nodeId": "u3gne", "sha256": "4f9c720f16c257220a74c504f0fa9d7cb5ccc70ec379072c4a1b26982cfe7078", "viewUrl": "/project/dtp79/files/osfstorage/5e1def466822bd0138feda12/", "selectedFileName": "Appendix.docx"}], "value": ""}, "q8": {"extra": [], "value": ""}}, "registration_responses": {"q1": "Investigating Reading from Screens and Mind Wandering in the Context of Standards of Coherence", "q2": "Virginia Clinton", "q3": "I confirm this study has been granted in-principle acceptance.", "q4": "Scientific Studies of Reading", "q5": "2019-11-11", "q6": [{"file_id": "5e1def466822bd0138feda14", "file_name": "masked_final.docx", "file_urls": {"html": "https://osf.io/project/dtp79/files/osfstorage/5e1def466822bd0138feda14", "download": "https://osf.io/download/5e1def466822bd0138feda14"}, "file_hashes": {"sha256": "48de21acdf91e3a4e9c8a1fe5685b2f8b880f21f1b025b3b0026a337ddcdaa01"}}], "q7": [{"file_id": "5e1def466822bd0138feda12", "file_name": "Appendix.docx", "file_urls": {"html": "https://osf.io/project/dtp79/files/osfstorage/5e1def466822bd0138feda12", "download": "https://osf.io/download/5e1def466822bd0138feda12"}, "file_hashes": {"sha256": "4f9c720f16c257220a74c504f0fa9d7cb5ccc70ec379072c4a1b26982cfe7078"}}], "q8": ""}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dtp79/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dtp79/comments/?format=json&filter%5Btarget%5D=dtp79", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dtp79/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dtp79/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dtp79/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dtp79/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dtp79/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dtp79/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dtp79/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dtp79/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dtp79/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dtp79/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dtp79/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/dtp79/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dtp79/?format=json", "meta": {}}}, "data": {"id": "dtp79", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dtp79/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dtp79/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/dtp79/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dtp79/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/dtp79/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dtp79/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dtp79/citation/?format=json", "meta": {}}}, "data": {"id": "dtp79", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/qmr8p/?format=json", "meta": {}}}, "data": {"id": "qmr8p", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/u3gne/?format=json", "meta": {}}}, "data": {"id": "u3gne", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5df83f7dd28338001ac0ab0e/?format=json", "meta": {}}}, "data": {"id": "5df83f7dd28338001ac0ab0e", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/dtp79/", "self": "https://api.osf.io/v2/registrations/dtp79/"}}, {"id": "cztyx", "type": "registrations", "attributes": {"title": "Visual information is required to reduce the global effect", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-01-14T15:36:45.931982", "date_modified": "2019-12-04T09:30:36.627866", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "6df83f59ca714e779844698737c69d9d54d9fed6d7f0890d8a31047cbf813ed74fbee2922a6b825745d1ef73556cee406d8e128f0200600d3e1302c06bf47ab7d669684ed51d31f759da273aedb7a0278eea0ed8d632556c408f19f24494f1b1df7882c0a06bf3a89d7eb1cb48b55b3cc93667886cb92f015b59b74a1e1256e77496a75d8f61e9811431219a14057102", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-14T15:36:45.891377", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Open-Ended Registration", "registered_meta": {"summary": {"extra": [], "value": "Unfiltered data from manuscript titled: 'Visual information is required to reduce the global effect' that is currently submitted for publication.  "}, "uploader": {"extra": [], "value": ""}}, "registration_responses": {"summary": "Unfiltered data from manuscript titled: 'Visual information is required to reduce the global effect' that is currently submitted for publication.  "}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/cztyx/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/cztyx/comments/?format=json&filter%5Btarget%5D=cztyx", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/cztyx/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/cztyx/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/cztyx/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/cztyx/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/cztyx/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/cztyx/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/cztyx/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/cztyx/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/cztyx/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/cztyx/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/cztyx/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/cztyx/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/cztyx/?format=json", "meta": {}}}, "data": {"id": "cztyx", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/cztyx/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/cztyx/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/cztyx/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/cztyx/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/cztyx/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/cztyx/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/cztyx/citation/?format=json", "meta": {}}}, "data": {"id": "cztyx", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/4bf9w/?format=json", "meta": {}}}, "data": {"id": "4bf9w", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/f2enq/?format=json", "meta": {}}}, "data": {"id": "f2enq", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5df83f7dd28338001ac0ab0d/?format=json", "meta": {}}}, "data": {"id": "5df83f7dd28338001ac0ab0d", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/cztyx/", "self": "https://api.osf.io/v2/registrations/cztyx/"}}, {"id": "fgrmc", "type": "registrations", "attributes": {"title": "Observer Behavior during Interviews", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-01-14T14:26:13.173193", "date_modified": "2019-11-12T10:45:33.696151", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "03210a2526cc6ccd05c2e7fe1deac39e52abe9ccc6f9839c7fbd468f7401c953c14f8ee7d3cbe9e2419a5693f011020dd787ab76a5f2955b4dbb5308cd550c62eb2d9e5ed3febac70152e3044b30ac71540154748f7c8d41cece4746508c6d6fdd1078deebd3ede48fa3d58dc0feae8f838f8ae7e4de5e903d378cba54aeab5c6f4cfeee304eb46c7ee106b737ac4faa", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-14T14:26:13.145492", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Preregistration Template from AsPredicted.org", "registered_meta": {"data": {"extra": [], "value": "No, no data have been collected for this study yet."}, "name": {"extra": [], "value": "Observer Behavior during Interviews \u2013 Using expectancy violations to explain candidate reactions to job interviews"}, "other": {"extra": [], "value": "(1) Job Recommendation Intentions: 1 item from Cable and Judge (1996)\n(2) Product Purchase Intention: measured with one item adapted from Yung &amp; Seock (2016)\n(3) Observer Likeability: 3-item scale from Nicholson, Compeau, &amp; Sethi (2001)\n"}, "sample": {"extra": [], "value": "We calculated the needed sample size based on a medium effect size by using GPower (Faul, Erdfelder, Lang, &amp; Buchner, 2007) N = 177"}, "analyses": {"extra": [], "value": "We intend to carry out multivariate analysis of variance (MANOVA) to estimate main and interaction effects.\nWe will also estimate the model using participants\u2019 prior interview experience as a control variable. Only in case of a significant change in model coefficients, we will use the corrected model (Spector &amp; Brannick, 2011)\n"}, "outliers": {"extra": [], "value": "Prior to data analysis, we will check the data for outliers and potentially exclude participants from further estimations. "}, "dependent": {"extra": [], "value": "(1) Social Justice: as proxy for procedural justice from the Selection Procedural Justice Scale (SPJS) by Bauer et al. (2001), additionally 3-item scale for procedural justice from Smither, Reilly, Millsap, Pearlman, &amp; Stoffey (1993)\n(2) Organizational Attractiveness: measured with 4 items from Cable and Judge (1996) and Judge and cable (1997)\n(3) Likelihood of Job Acceptance: measured with one item from Judge &amp; Cable (1997)\n(4) Person-Organization-Fit: 9-item scale from Cable &amp; De Rue (2002), 3 additional items for overall PO-fit\n"}, "conditions": {"extra": [], "value": "In this study we will use a 2 (answer valence; positive vs. negative) x3 (reaction valence; positive vs. neutral vs. negative) x2 (organizational desirability; high vs. low) between subject design. \nParticipants will be randomly assigned to one of 12 conditions:\n1)\tGood Applicant Answer \u2013 positive Observer Reaction \u2013 High Desirability\n2)\tGood Applicant Answer \u2013 positive Observer Reaction \u2013 Low Desirability\n3)\tGood Applicant Answer \u2013 neutral Observer Reaction \u2013 High Desirability \n4)\tGood Applicant Answer \u2013 neutral Observer Reaction \u2013 Low Desirability \n5)\tGood Applicant Answer \u2013 negative Observer Reaction \u2013 High Desirability \n6)\tGood Applicant Answer \u2013 negative Observer Reaction \u2013 Low Desirability\n7)\tBad Applicant Answer \u2013 positive Observer Reaction \u2013 High Desirability\n8)\tBad Applicant Answer \u2013 positive Observer Reaction \u2013 Low Desirability \n9)\tBad Applicant Answer \u2013 neutral Observer Reaction \u2013 High Desirability \n10)\tBad Applicant Answer \u2013 neutral Observer Reaction \u2013 Low Desirability\n11)\tBad Applicant Answer \u2013 negative Observer Reaction \u2013 High Desirability\n12)\tBad Applicant Answer \u2013 negative Observer Reaction \u2013 Low Desirability\n"}, "hypothesis": {"extra": [], "value": "How do organizational desirability and expectancy violation (answer-feedback-incongruence) in the job interview influence organizational attractiveness?\nHypothesis:\n1.\tA positive feedback to a good applicant answer will affect the dependent outcomes more positively than a negative feedback to a bad applicant answer.\n\n2.\tAnswer-Feedback-Incongruence/Incongruent observer reaction to an applicant answer affects/influences the dependent outcomes/organizational attractiveness in direction of the incongruence.\na.\tPositive feedback to a bad answer will affect the dependent outcomes in a positive way.\ni.\tPositive feedback to a bad answer will affect the dependent outcomes more positively than the expected negative feedback (answer-feedback-congruence)\nb.\tNegative feedback to a good answer will have a negative effect on the dependent variables.\ni.\tNegative feedback to a good answer will affect the dependent variables more negatively than the expected positive feedback (answer-feedback-congruence)\nc.\tThe direction in which neutral feedback to a good answer will affect the dependent variables depends on the organizational desirability.\ni.\tNeutral feedback to a good answer will affect the dependent variables more negatively when the organization has a low desirability than when it has a high desirability. \nii.\tNeutral feedback to a negative answer will not significantly influence the dependent variables in a positive way.\n\n3.\tOrganizational desirability\na.\tA low-desirability observer committing a positive expectancy violation (bad answer \u2013 positive feedback) will have a stronger effect on the applicant\u2019s attraction towards the company/the dependent variables than a high-desirability observer enacting the same behavior.\n\nb.\tA high-desirability observer committing a negative expectancy violation (good answer \u2013 negative feedback/good answer \u2013 neutral feedback) will have a stronger effect on the applicant\u2019s attraction towards the company/the dependent variables than a low-desirability observer enacting the same behavior.\n"}, "study_type": {"extra": [], "value": "Experiment"}, "study_type_other": {"extra": [], "value": ""}}, "registration_responses": {"data": "No, no data have been collected for this study yet.", "name": "Observer Behavior during Interviews \u2013 Using expectancy violations to explain candidate reactions to job interviews", "other": "(1) Job Recommendation Intentions: 1 item from Cable and Judge (1996)\n(2) Product Purchase Intention: measured with one item adapted from Yung &amp; Seock (2016)\n(3) Observer Likeability: 3-item scale from Nicholson, Compeau, &amp; Sethi (2001)\n", "sample": "We calculated the needed sample size based on a medium effect size by using GPower (Faul, Erdfelder, Lang, &amp; Buchner, 2007) N = 177", "analyses": "We intend to carry out multivariate analysis of variance (MANOVA) to estimate main and interaction effects.\nWe will also estimate the model using participants\u2019 prior interview experience as a control variable. Only in case of a significant change in model coefficients, we will use the corrected model (Spector &amp; Brannick, 2011)\n", "outliers": "Prior to data analysis, we will check the data for outliers and potentially exclude participants from further estimations. ", "dependent": "(1) Social Justice: as proxy for procedural justice from the Selection Procedural Justice Scale (SPJS) by Bauer et al. (2001), additionally 3-item scale for procedural justice from Smither, Reilly, Millsap, Pearlman, &amp; Stoffey (1993)\n(2) Organizational Attractiveness: measured with 4 items from Cable and Judge (1996) and Judge and cable (1997)\n(3) Likelihood of Job Acceptance: measured with one item from Judge &amp; Cable (1997)\n(4) Person-Organization-Fit: 9-item scale from Cable &amp; De Rue (2002), 3 additional items for overall PO-fit\n", "conditions": "In this study we will use a 2 (answer valence; positive vs. negative) x3 (reaction valence; positive vs. neutral vs. negative) x2 (organizational desirability; high vs. low) between subject design. \nParticipants will be randomly assigned to one of 12 conditions:\n1)\tGood Applicant Answer \u2013 positive Observer Reaction \u2013 High Desirability\n2)\tGood Applicant Answer \u2013 positive Observer Reaction \u2013 Low Desirability\n3)\tGood Applicant Answer \u2013 neutral Observer Reaction \u2013 High Desirability \n4)\tGood Applicant Answer \u2013 neutral Observer Reaction \u2013 Low Desirability \n5)\tGood Applicant Answer \u2013 negative Observer Reaction \u2013 High Desirability \n6)\tGood Applicant Answer \u2013 negative Observer Reaction \u2013 Low Desirability\n7)\tBad Applicant Answer \u2013 positive Observer Reaction \u2013 High Desirability\n8)\tBad Applicant Answer \u2013 positive Observer Reaction \u2013 Low Desirability \n9)\tBad Applicant Answer \u2013 neutral Observer Reaction \u2013 High Desirability \n10)\tBad Applicant Answer \u2013 neutral Observer Reaction \u2013 Low Desirability\n11)\tBad Applicant Answer \u2013 negative Observer Reaction \u2013 High Desirability\n12)\tBad Applicant Answer \u2013 negative Observer Reaction \u2013 Low Desirability\n", "hypothesis": "How do organizational desirability and expectancy violation (answer-feedback-incongruence) in the job interview influence organizational attractiveness?\nHypothesis:\n1.\tA positive feedback to a good applicant answer will affect the dependent outcomes more positively than a negative feedback to a bad applicant answer.\n\n2.\tAnswer-Feedback-Incongruence/Incongruent observer reaction to an applicant answer affects/influences the dependent outcomes/organizational attractiveness in direction of the incongruence.\na.\tPositive feedback to a bad answer will affect the dependent outcomes in a positive way.\ni.\tPositive feedback to a bad answer will affect the dependent outcomes more positively than the expected negative feedback (answer-feedback-congruence)\nb.\tNegative feedback to a good answer will have a negative effect on the dependent variables.\ni.\tNegative feedback to a good answer will affect the dependent variables more negatively than the expected positive feedback (answer-feedback-congruence)\nc.\tThe direction in which neutral feedback to a good answer will affect the dependent variables depends on the organizational desirability.\ni.\tNeutral feedback to a good answer will affect the dependent variables more negatively when the organization has a low desirability than when it has a high desirability. \nii.\tNeutral feedback to a negative answer will not significantly influence the dependent variables in a positive way.\n\n3.\tOrganizational desirability\na.\tA low-desirability observer committing a positive expectancy violation (bad answer \u2013 positive feedback) will have a stronger effect on the applicant\u2019s attraction towards the company/the dependent variables than a high-desirability observer enacting the same behavior.\n\nb.\tA high-desirability observer committing a negative expectancy violation (good answer \u2013 negative feedback/good answer \u2013 neutral feedback) will have a stronger effect on the applicant\u2019s attraction towards the company/the dependent variables than a low-desirability observer enacting the same behavior.\n", "study_type": "Experiment"}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fgrmc/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fgrmc/comments/?format=json&filter%5Btarget%5D=fgrmc", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fgrmc/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fgrmc/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fgrmc/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fgrmc/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fgrmc/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fgrmc/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fgrmc/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fgrmc/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fgrmc/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fgrmc/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fgrmc/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/fgrmc/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/de-1/?format=json", "meta": {}}}, "data": {"id": "de-1", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fgrmc/?format=json", "meta": {}}}, "data": {"id": "fgrmc", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fgrmc/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fgrmc/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/fgrmc/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fgrmc/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/fgrmc/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fgrmc/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/fgrmc/citation/?format=json", "meta": {}}}, "data": {"id": "fgrmc", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/pd3ew/?format=json", "meta": {}}}, "data": {"id": "pd3ew", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/v7ap6/?format=json", "meta": {}}}, "data": {"id": "v7ap6", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5d2d2268d28338002c2432d2/?format=json", "meta": {}}}, "data": {"id": "5d2d2268d28338002c2432d2", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/fgrmc/", "self": "https://api.osf.io/v2/registrations/fgrmc/"}}, {"id": "zcuyn", "type": "registrations", "attributes": {"title": "Drinking juice, tasting coffee", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-01-14T10:12:59.095628", "date_modified": "2020-01-14T10:12:24.167023", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "92f340c2d57ed9aa956a4c89a67bb2ba9360532b40e701bad2395bef49667c3c287c5d7cfe99bdad8b5ff7449f400cb1717b02d86b393c4c79fe83f819ba95500b0bc330863cfec5bf2b6879ef16532003f55ded950cb1c7600d520f1740d20e28e538095c6aa0525371a635ca9edf0d9ff80d74bd908c6ff3dd848ddfd4c60e4f7dcf44cc54339968834f6682b1bdda", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-14T10:12:59.071523", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "OSF Preregistration", "registered_meta": {"q1": {"extra": [], "value": "Drinking coffee, tasting juice: Visuogustatory interactions and cross modulations in perception, memory and embodiment"}, "q2": {"extra": [], "value": "Lorena St\u00e4ger, Marte Roel, Bigna Lenggenhager"}, "q3": {"extra": [], "value": "Even though experiences are intrinsically multisensory, most psychological research on percep-tion and memory studies the senses in isolation (Quak, London, &amp; Talsma, 2015). However, to get a better understanding on our perception of the external and internal world it is important to study the interactions and cross modulations of our senses. That is why we intend to shed more light on multisensory perception and its integration in memory. \nAn example of multisensory experience comes from our perception of food and drink, which has been neglected in research. Previous research shows that the visual appearance of food and drink can have a significant impact on our perception of flavour (Zampini, &amp; Spence, 2012). The manipulation of the colour of foods or beverages has shown to significantly influence perceptu-al and preferential responses to them, which has been replicated in many different studies before (DuBose, Cardello, &amp; Maller, 1980; Shankar, Levitan, Prescott &amp; Spence, 2009; Zellner &amp; Durlach, 2003). Colours are not only aesthetic values, they also convey important information about the flavour of food and drink, and they provide information about their edibility, flavour identity and intensity (Shankar, Levitan, Prescott &amp; Spence, 2009). So, whenever we see food of a certain colour, that colour, together with other contextual cues, will lead us to generate spe-cific expectations regarding the likely taste of that food (Koch &amp; Koch, 2003; Levitan, Zampini, Li, &amp; Spence, 2008; Shankar, Levitan, Prescott, &amp; Spence, 2009; Zellner &amp; Durlach, 2003). Past work proposed that if these expectations about the flavour generated from the appearance of the food are confirmed, it enhances the flavour experience (Yeomans, Chambers, Blumenthal, &amp; Blake, 2008). Yeomans and colleagues (2008) also showed that if there is a lack of congruence between the expected and actual sensory quality of food, it might lead to a per-ceptual confusion, strong negative affective response and enhancement of the unexpected senso-ry qualities. In the current study we will try to replicate those findings and investigate this visuogustatory interaction through an embodied virtual reality setup. Participants will see a video in which they will see a virtual male body instead of their own body from a first-person perspective, enabling through the tracking natural exploration of the virtual body and environment. In the video of the matching condition, the participants will see that the virtual body is being fed with, for example, orange juice and they will also taste an orange flavoured drink. However, in the video of the mismatching condition, they will see that the virtual body is being fed with, for example, orange juice but the participants themselves will actually be fed with coffee flavour. Therefore, they will see and expect tasting orange juice, but they will be experiencing drinking a coffee flavoured drink. This will create a mismatch of sight and taste.\nWith this method, it allows us to investigate how the perception of taste is influenced in healthy participants in situation of visuogustatory conflicts (i.e. gustatory perception, see hypothesis 1). \nSo as pointed out, most papers on visuo-gustatory perception have focussed on how vision modulates taste, while to our best knowledge no study has looked at how taste modulates vi-sion. In the present study we will thus additionally investigate to what degree the taste might influence visual perception (i.e. colour perception, see hypothesis 2). \nAs sensory mismatches have not only shown to influence perception of the outer world (e.g. food) but also of the own body, we will additionally measure the sense of embodiment with the avatar in matching versus mismatching visuo-gustatory situation. Studies have shown that our sense of body is surprisingly plastic and constantly updated by the current multisensory inputs (Botvinick &amp; Cohen, 1998; Lenggenhager, Tadi, Metzinger, &amp; Blanke, 2007; Th\u00fcr, Roel Lesur, Lopez, &amp; Lenggenhager, 2019). It has been demonstrated that mismatches of multisensory signaling can influence the perception of body, e.g. visuotactile and visuomotor mismatches can induce a strong reduction in the feeling of embodiment, which confirms the importance of the multisensory processing for our sense of body (Roel Lesur, Weijs, Kannape, &amp; Lenggenhager, 2019). Here, we intend to study presumably for the first time, how visuogustatory mismatches in virtual reality might affect the sense of body, hence the embodiment of a male body seen from the first-person perspective (see hypothesis 4). \nBut how are these multisensory events remembered? As for research of perception, research of memory has traditional studies single sensory modalities (i.e. purely visual or purely auditory objects) (Matusz, Wallace, &amp; Murray, 2017). However, it is known that episodic memories are constructed from interactions among different basic systems like vision, audition, olfaction, gus-tation, other senses, spatial imagery, language emotion, narrative, motor output, explicit memory, search and retrieval (Rubin, 2006). In previous research these systems have not all been considered as interacting components of episodic memory. Nonetheless, the episodic memory can only be understood if the properties of basic cognitive systems are not only exam-ined individually but also in combination (Rubin, 2006). While some multisensory interactions have been studied in the context of memory, e.g. vision and audition (Matusz, Wallace, &amp; Murray, 2017; Moran, et al., 2013; Shams &amp; Seitz, 2008; Thelen &amp; Murray, 2013), taste in conjunction with other modalities has mostly been neglected. Typically, the different channels convey the same information yet if conflicting information of sight and taste is presented, little is known about how this conflict is perceived and integrated in episodic memory. In general, Yeomans and colleagues (2008) showed in their study that a lack of congruence between the expected and actual sensory quality of food can lead to a strong negative affective response. It has also been recognized that emotionally significant or arousing events can have a unique en-hancing influence on memory (Packard &amp; Cahill, 2001; Phelps, 2004). However, how the con-flicts of sight and taste are remembered and weighted, has been neglected in research. As a consequence, this study also attempts to not only understand the perception of the visuogustatory mismatches, the perception of body but also the relative weighting of visual and gustatory cues in episodic memory (see hypotheses 3.1 and 3.2). \nStudying the visuogustatory interactions and cross modulations in perception, memory and embodiment will provide some important implications. While this study is highly exploratory, it is important fundamental research on perception. First of all, the study will look at the two-way interactions and cross modulations of vision and taste, which might help to achieve a better un-derstanding of our multisensory perception and memory of food and drink. Furthermore, it will help achieving a thorough model of embodiment outside the primacy of vision. It could also shed light on the current debate on the contribution of different modalities to our sense of body and its plasticity. Lastly, it is widely believed that multisensory studies in flavour perception will have a number of important consequences for the food and beverage industries, for example a better understanding of the process which could be used by people to assess the acceptability, design and flavour of new products (Spence &amp; Auvray, 2008).\n"}, "q4": {"extra": [], "value": "Hypothesis 1: We expect that the participants will significantly adapt to the flavour (sweet-ness/saltiness/bitterness /sourness) associated with the seen liquid when they experience a mis-match. (directional hypothesis: significantly towards vision)\n\nHypothesis 2: We expect that the participants will significantly adapt to the colour associated with the taste when they experience a mismatch. (directional hypothesis: significantly towards taste)\n\nHypothesis 3.1: We expect that overall the participants will remember the mismatches signifi-cantly better than the matches. (directional hypothesis)\n\nHypothesis 3.2: We expect that overall the participants will remember the seen liquids in the mismatching condition significantly better than the tasted liquids. (directional hypothesis)\n\nHypothesis 4: We expect that embodiment (as measured by questionnaire scores) is higher in the matching than the mismatching conditions (directional hypothesis) \n"}, "q5": {"extra": [], "value": "Experiment - A researcher randomly assigns treatments to study subjects, this includes field or lab experiments. This is also known as an intervention experiment and includes randomized controlled trials."}, "q6": {"extra": [], "value": ["For studies that involve human subjects, they will not know the treatment group to which they have been assigned."]}, "q7": {"extra": [], "value": "There will be a cover story for the experiment, the participants will not know that they will have to do recognition memory task later. "}, "q8": {"value": {"question": {"extra": [], "value": "The study is designed as a within-subject experiment and it will consist of three blocks. After the preparation, the first block will be the episodic memory encoding (cover-story, see above) and the embodiment measurement, after 30min break there will be the 2nd block, i.e.  memory testing and then in the third block will be the colour and taste perception testing. To rule out any confounding variables, the stimuli will be presented in four different orders, and for the second and third blocks the tasks will be presented in a counterbalanced order. The participants will be randomly assigned to one of it."}, "uploader": {"extra": [], "value": ""}}}, "q9": {"extra": [], "value": "We will use simple randomization, where each participant will be randomly assigned to one of the four different orders prepared for each condition. The items in the four different orders are randomly counterbalanced. "}, "q10": {"extra": [], "value": "Registration prior to creation of data"}, "q11": {"extra": [], "value": ""}, "q12": {"value": {"question": {"extra": [], "value": "Participants will be recruited at the University of Zurich. There will be flyers to advertise for the experiment as well as an announcement in the mailing list for psychology students. The partici-pants will not receive any reward for the participation except psychology students that would be granted study credits. In order to leave the participants unaware of the real purpose of the study (i.e. studying memory), they will be told that the experiment is investigating food preference. The participants should not be on any kind of diet, have normal or corrected-to-normal vision, declare no history of psychiatric, neurological or vestibular disease, and they should not be sub-ject to any food allergy. Any intake of medication will also lead to the exclusion of the partici-pants. The participants will have to agree to be touched on the knee during the session. We de-cided to exclude any participant below the age of 18 and above the age of 35. If the participants are not able to do the task or quit the experiment they will be excluded as well. All participants will need to give written informed consent prior to starting the experiment. "}, "uploader": {"extra": [], "value": ""}}}, "q13": {"extra": [], "value": "30 valid data sets will be recorded.  "}, "q14": {"extra": [], "value": "Given the master thesis framework and the explorative character of this study, a bigger number of participants was not feasible. "}, "q15": {"extra": [], "value": "We will stop collecting data as soon as we have 30 valid datasets.  "}, "q16": {"value": {"question": {"extra": [], "value": "In this study we will have the following independent variables:\nMatch: A match exists if the participant will see the same as they will taste. In the videos they will see for example an orange juice and they will taste an orange flavour. For the tastes we will use artificial flavours to grant reproducibility. \nMismatch: A mismatch exists if the participant will see something different as they will taste. In the video they will see for example an orange juice, but they will taste coffee flavour. For the taste we will use again artificial flavours to grant reproducibility. \n"}, "uploader": {"extra": [], "value": ""}}}, "q17": {"value": {"question": {"extra": [], "value": "We will measure six variables: \n1.\tWe will measure the similarity of the tasted and seen product by asking the participants \u2018How similar did you experience the seen and the tasted liquid?\u2019 (on an analogue scale of 0-1, 0 being \u2018not at all\u2019, 1 being \u2018completely\u2019). \n2.\tThe variable embodiment we intend to investigate by letting the participants rate the fol-lowing statements: \u2018I felt as if the body I saw on the video when I was looking down was my body\u2019 and \u2018It felt as if the body I saw on the video when I was looking down was someone else\u2019 (on an analogue scale of 0-1, 0 being \u2018not at all\u2019, 1 being \u2018complete-ly\u2019). \n3.\tTo test the visual recognition, the participants will be showed a picture of a liquid and asked \u2018Have you seen this liquid in one of the videos before?\u2019 (forced-choice \u2018yes\u2019 or \u2018no\u2019) and \u2018How certain are you about that answer?\u2019 (on an analogue scale of 0-1, 0 be-ing \u2018not at all\u2019, 10 being \u2018completely\u2019). \n4.\tThe variable gustatory recognition will be measured through the questions \u2018Have you tasted this flavour in the experiment before the break?\u2019 (forced-choice \u2018yes\u2019 or \u2018no\u2019) and \u2018How certain are you about that answer?\u2019 (on an analogue scale of 0-1, 0 being \u2018not at all\u2019, 1 being \u2018completely\u2019). \n5.\tTo test the colour perception we will ask the participants \u2018How similar in colour did you perceive the tasted and seen liquid?\u2019 after experiencing a mismatch and \u2018Which colour did the liquid in the video have?\u2019 (on an RGB scale). After experiencing the unimodal vision we will ask \u2018Which colour did the liquid in the video have?\u2019 (on an RGB scale) and after the unimodal taste they will have to answer the question \u2018Which colour do you think the liquid you have tasted have?\u2019 (on an RGB scale)\n6.\tWe will measure the gustatory perception by asking \u2018How similar in taste did you per-ceive the tasted and seen liquid?\u2019 after experiencing a mismatch and \u2018How sweet did you experience this liquid?\u2019, \u2018How sour did you experience this liquid?\u2019, \u2018How bitter did you experience this liquid?\u2019, \u2018How salty did you experience this liquid?\u2019. After experi-encing the unimodal vision, they will have to answer the questions \u2018How sweet do you think this liquid would be?\u2019, \u2018How sour do you think this liquid would be?\u2019, \u2018How bit-ter do you think this liquid would be?\u2019 and \u2018How salty do you think this liquid would be?\u2019. When they have experienced the unimodal taste, they have to answer the following questions \u2018How sweet did you experience this liquid?\u2019, \u2018How sour did you experience this liquid?\u2019, \u2018How bitter did you experience this liquid?\u2019 and \u2018How salty did you expe-rience this liquid?\u2019 (all on a scale of 1-10, 1 being \u2018not at all\u2019, 10 being \u2018completely\u2019)\n"}, "uploader": {"extra": [], "value": ""}}}, "q18": {"value": {"question": {"extra": [], "value": "Embodiment: we will take the mean of the two analogue-scale questions (adjusted to match in direction) above to create a single measure of \u2018embodiment.\u2019\nVisual recognition: we will create a score of correctly recognized visual stimuli.\nTaste recognition: we will create a score of correctly recognized taste stimuli.\nMatch vs. Mismatch recognition: we will create a total score of correctly recognized matching items and a total score of correctly recognized matching items. \nColour perception: we will have three colour values for each mismatch, each unimodal taste and each unimodal vision. Then we would create three values of mismatch relative to taste and three values of mismatch relative to vision for each stimulus. Each value corresponds to the scales of red, green and blue, respectively.\nTaste perception: we will have four analogue-scale values for each mismatch, each unimodal taste and each unimodal vision. Then we would create four values mismatch relative to taste and four values mismatch relative to vision. "}, "uploader": {"extra": [], "value": ""}}}, "q19": {"value": {"question": {"extra": [], "value": "Hypothesis 1: The participants will answer the questions about the flavour on a visual analogue scale, resulting in VAS values of the mismatches, unimodal taste and unimodal vision. The four values mismatch relative to vision will be compared to the four values mismatch relative to taste through a T-test (or a non-parametric equivalent). The T-test will then confirm that the multisen-sory value is in the expected direction, so significantly towards the vision than taste. \n\nHypothesis 2: The participants will answer the questions about the colour on a colour wheel. So, we will then have the colour wheel values of the mismatches, unimodal taste and unimodal vision. The colour wheel values will be transformed into RGB values, which indicate the inten-sity of the red, green and blue. We will then have one RGB value mismatch relative to vision and one RGB value mismatch relative. A T-test (or a non-parametric equivalent) will be used to confirm that the multisensory value is in the expected direction, so significantly towards the taste than vision. \n\nHypothesis 3.1: The absolute memory will be tested by means of the signal detection method, which allows us to obtain a measure of recognition d\u2019, independent of the response bias cause by the participant\u2019s tendency to say yes or no. For each item the percentages of hits, misses, false alarms, and correct rejections will be determined. These percentages will then be trans-formed into z scores under the normal probability curve and the recognition index d\u2019 and the decision criterion k will be calculated for each participant. T-tests will be used to determine whether the d\u2019 of the participant for each of the distractors will be significantly higher than zero, indicating that learning had taken place. So we will compare the individual d\u2019 scores in the matching and in the mismatching conditions through a T-test (or a non-parametric equivalent) . \n\nHypothesis 3.2: We will compare the scores of the vision and taste recognition test in the mis-matching condition through a T-test (or a non-parametric equivalent). \n\nHypothesis 4: The participants will answer the question about embodiment on a visual analogue scale. We will then compare the values of the match and mismatch through a T-test (or a non-parametric equivalent). "}, "uploader": {"extra": [], "value": ""}}}, "q20": {"extra": [], "value": "We do not plan on doing any additional transformations. "}, "q21": {"extra": [], "value": "We will use the standard p &lt;.05 criteria for determining if the two-tailed T-tests suggest that the results are significantly different from those expected if the null hypothesis were correct. "}, "q22": {"extra": [], "value": "We will verify that each subject completed each test, any subject that didn\u2019t will be excluded. Outliers will be included in the analysis. We will not use any awareness check. "}, "q23": {"extra": [], "value": "If a subject does not complete one of the tests, that subject will not be included in the analysis for that one test, but we will still analyse the other test parts.  "}, "q24": {"extra": [], "value": "We also measure the past experiences with augmented/virtual reality of the participants by ask-ing three questions. (\u2018How many times have you used augmented/virtual reality before?\u2019, \u2018If you have used it before: have you experienced cybersickness?\u2019, \u2018If you have used it before: what for have you used it?\u2019). And we also measure the soft-drink consumption of the partici-pants (\u2018Do you consume drinks such as soft-drinks, coffee, juices, milk drinks?\u2019 \u2018If yes, which of the drinks do you consume?\u2019 \u2018If yes: how much do you consume those drinks in a regular week?\u2019 \u2018How much have you consumed those drinks five years ago per week?\u2019)"}, "q25": {"extra": [], "value": "DuBose, C. N., Cardello, A. V., &amp; Maller, O. (1980). Effects of colorants and flavorants on identification, perceived flavor intensity, and hedonic quality of fruit-flavored beverages and cake. J. Food Sci. \nGonzalez-Franco, M., &amp; Peck, T. C. (2018). Avatar Embodiment. Towards a Standardized Questionnaire. frontiers in Robotics and AI.\nHeed, T., &amp; R\u00f6der, B. (2012). The Body in a Multisensory World. In M. Murray, The Neural Bases of Multisensory Processes. Taylor &amp; Francis.\nMatusz, P. J., Wallace, M. T., &amp; Murray, M. M. (2017). A multisensory perspective on object memory. Neuropsychologia(105), S. 243-252.\nPackard, M. G., &amp; Cahill, L. (2001). Affective modulation of multiple memory systems. Current Opinion in Neurobiology, S. 752-756.\nPhelps, E. A. (2004). Human emotion and memory: interactions of the amygdala and hippocampal complex. Current Opinion in Neurobiology, S. 198-202.\nQuak, M., London, R. E., &amp; Talsma, D. (2015). A multisensory perspective of working memory. Frontiers in Human Neuroscience(9), S. 1-11.\nRoel Lesur, M., Weijs, M. L., Kannape, C. S., &amp; Lenggenhager, B. (2019). Achronopresence: How temporal visuotactile and visuomotor mismatches modulate embodiment. BioRxiv.\nRubin, D. C. (2006). The Basic-Systems Model of Episodic Memory. Perspectives On Psychological Science.\nSpence, C., &amp; Auvray, M. (2008). The multisensory perception of flavour. Consciousness and Cognition, S. 1016-1031.\nYeomans, M. R., Chambers, L., Blumenthal, H., &amp; Blake, A. (September 2008). The role of expectancy in sensory and hedonic evaluation. Food Quality and Preference, S. 565-573.\nZampini, M., &amp; Spence, C. (2012). Assessing the Role of Visual and Auditory Cues in Multisensory Perception. In M. M. Murray, &amp; M. T. Wallace, The Neural Bases of Multisensory Processes. CRC Press/Taylor &amp; Francis.\nZellner, D. A., &amp; Durlach, P. (2003). Effect of Color on Expected and Experienced Refreshment, Intensity and Liking of Beverages. The American Journal of Psychology, S. 633-647.\n"}}, "registration_responses": {"q1": "Drinking coffee, tasting juice: Visuogustatory interactions and cross modulations in perception, memory and embodiment", "q2": "Lorena St\u00e4ger, Marte Roel, Bigna Lenggenhager", "q3": "Even though experiences are intrinsically multisensory, most psychological research on percep-tion and memory studies the senses in isolation (Quak, London, &amp; Talsma, 2015). However, to get a better understanding on our perception of the external and internal world it is important to study the interactions and cross modulations of our senses. That is why we intend to shed more light on multisensory perception and its integration in memory. \nAn example of multisensory experience comes from our perception of food and drink, which has been neglected in research. Previous research shows that the visual appearance of food and drink can have a significant impact on our perception of flavour (Zampini, &amp; Spence, 2012). The manipulation of the colour of foods or beverages has shown to significantly influence perceptu-al and preferential responses to them, which has been replicated in many different studies before (DuBose, Cardello, &amp; Maller, 1980; Shankar, Levitan, Prescott &amp; Spence, 2009; Zellner &amp; Durlach, 2003). Colours are not only aesthetic values, they also convey important information about the flavour of food and drink, and they provide information about their edibility, flavour identity and intensity (Shankar, Levitan, Prescott &amp; Spence, 2009). So, whenever we see food of a certain colour, that colour, together with other contextual cues, will lead us to generate spe-cific expectations regarding the likely taste of that food (Koch &amp; Koch, 2003; Levitan, Zampini, Li, &amp; Spence, 2008; Shankar, Levitan, Prescott, &amp; Spence, 2009; Zellner &amp; Durlach, 2003). Past work proposed that if these expectations about the flavour generated from the appearance of the food are confirmed, it enhances the flavour experience (Yeomans, Chambers, Blumenthal, &amp; Blake, 2008). Yeomans and colleagues (2008) also showed that if there is a lack of congruence between the expected and actual sensory quality of food, it might lead to a per-ceptual confusion, strong negative affective response and enhancement of the unexpected senso-ry qualities. In the current study we will try to replicate those findings and investigate this visuogustatory interaction through an embodied virtual reality setup. Participants will see a video in which they will see a virtual male body instead of their own body from a first-person perspective, enabling through the tracking natural exploration of the virtual body and environment. In the video of the matching condition, the participants will see that the virtual body is being fed with, for example, orange juice and they will also taste an orange flavoured drink. However, in the video of the mismatching condition, they will see that the virtual body is being fed with, for example, orange juice but the participants themselves will actually be fed with coffee flavour. Therefore, they will see and expect tasting orange juice, but they will be experiencing drinking a coffee flavoured drink. This will create a mismatch of sight and taste.\nWith this method, it allows us to investigate how the perception of taste is influenced in healthy participants in situation of visuogustatory conflicts (i.e. gustatory perception, see hypothesis 1). \nSo as pointed out, most papers on visuo-gustatory perception have focussed on how vision modulates taste, while to our best knowledge no study has looked at how taste modulates vi-sion. In the present study we will thus additionally investigate to what degree the taste might influence visual perception (i.e. colour perception, see hypothesis 2). \nAs sensory mismatches have not only shown to influence perception of the outer world (e.g. food) but also of the own body, we will additionally measure the sense of embodiment with the avatar in matching versus mismatching visuo-gustatory situation. Studies have shown that our sense of body is surprisingly plastic and constantly updated by the current multisensory inputs (Botvinick &amp; Cohen, 1998; Lenggenhager, Tadi, Metzinger, &amp; Blanke, 2007; Th\u00fcr, Roel Lesur, Lopez, &amp; Lenggenhager, 2019). It has been demonstrated that mismatches of multisensory signaling can influence the perception of body, e.g. visuotactile and visuomotor mismatches can induce a strong reduction in the feeling of embodiment, which confirms the importance of the multisensory processing for our sense of body (Roel Lesur, Weijs, Kannape, &amp; Lenggenhager, 2019). Here, we intend to study presumably for the first time, how visuogustatory mismatches in virtual reality might affect the sense of body, hence the embodiment of a male body seen from the first-person perspective (see hypothesis 4). \nBut how are these multisensory events remembered? As for research of perception, research of memory has traditional studies single sensory modalities (i.e. purely visual or purely auditory objects) (Matusz, Wallace, &amp; Murray, 2017). However, it is known that episodic memories are constructed from interactions among different basic systems like vision, audition, olfaction, gus-tation, other senses, spatial imagery, language emotion, narrative, motor output, explicit memory, search and retrieval (Rubin, 2006). In previous research these systems have not all been considered as interacting components of episodic memory. Nonetheless, the episodic memory can only be understood if the properties of basic cognitive systems are not only exam-ined individually but also in combination (Rubin, 2006). While some multisensory interactions have been studied in the context of memory, e.g. vision and audition (Matusz, Wallace, &amp; Murray, 2017; Moran, et al., 2013; Shams &amp; Seitz, 2008; Thelen &amp; Murray, 2013), taste in conjunction with other modalities has mostly been neglected. Typically, the different channels convey the same information yet if conflicting information of sight and taste is presented, little is known about how this conflict is perceived and integrated in episodic memory. In general, Yeomans and colleagues (2008) showed in their study that a lack of congruence between the expected and actual sensory quality of food can lead to a strong negative affective response. It has also been recognized that emotionally significant or arousing events can have a unique en-hancing influence on memory (Packard &amp; Cahill, 2001; Phelps, 2004). However, how the con-flicts of sight and taste are remembered and weighted, has been neglected in research. As a consequence, this study also attempts to not only understand the perception of the visuogustatory mismatches, the perception of body but also the relative weighting of visual and gustatory cues in episodic memory (see hypotheses 3.1 and 3.2). \nStudying the visuogustatory interactions and cross modulations in perception, memory and embodiment will provide some important implications. While this study is highly exploratory, it is important fundamental research on perception. First of all, the study will look at the two-way interactions and cross modulations of vision and taste, which might help to achieve a better un-derstanding of our multisensory perception and memory of food and drink. Furthermore, it will help achieving a thorough model of embodiment outside the primacy of vision. It could also shed light on the current debate on the contribution of different modalities to our sense of body and its plasticity. Lastly, it is widely believed that multisensory studies in flavour perception will have a number of important consequences for the food and beverage industries, for example a better understanding of the process which could be used by people to assess the acceptability, design and flavour of new products (Spence &amp; Auvray, 2008).\n", "q4": "Hypothesis 1: We expect that the participants will significantly adapt to the flavour (sweet-ness/saltiness/bitterness /sourness) associated with the seen liquid when they experience a mis-match. (directional hypothesis: significantly towards vision)\n\nHypothesis 2: We expect that the participants will significantly adapt to the colour associated with the taste when they experience a mismatch. (directional hypothesis: significantly towards taste)\n\nHypothesis 3.1: We expect that overall the participants will remember the mismatches signifi-cantly better than the matches. (directional hypothesis)\n\nHypothesis 3.2: We expect that overall the participants will remember the seen liquids in the mismatching condition significantly better than the tasted liquids. (directional hypothesis)\n\nHypothesis 4: We expect that embodiment (as measured by questionnaire scores) is higher in the matching than the mismatching conditions (directional hypothesis) \n", "q5": "Experiment - A researcher randomly assigns treatments to study subjects, this includes field or lab experiments. This is also known as an intervention experiment and includes randomized controlled trials.", "q6": ["For studies that involve human subjects, they will not know the treatment group to which they have been assigned."], "q7": "There will be a cover story for the experiment, the participants will not know that they will have to do recognition memory task later. ", "q9": "We will use simple randomization, where each participant will be randomly assigned to one of the four different orders prepared for each condition. The items in the four different orders are randomly counterbalanced. ", "q10": "Registration prior to creation of data", "q11": "", "q13": "30 valid data sets will be recorded.  ", "q14": "Given the master thesis framework and the explorative character of this study, a bigger number of participants was not feasible. ", "q15": "We will stop collecting data as soon as we have 30 valid datasets.  ", "q20": "We do not plan on doing any additional transformations. ", "q21": "We will use the standard p &lt;.05 criteria for determining if the two-tailed T-tests suggest that the results are significantly different from those expected if the null hypothesis were correct. ", "q22": "We will verify that each subject completed each test, any subject that didn\u2019t will be excluded. Outliers will be included in the analysis. We will not use any awareness check. ", "q23": "If a subject does not complete one of the tests, that subject will not be included in the analysis for that one test, but we will still analyse the other test parts.  ", "q24": "We also measure the past experiences with augmented/virtual reality of the participants by ask-ing three questions. (\u2018How many times have you used augmented/virtual reality before?\u2019, \u2018If you have used it before: have you experienced cybersickness?\u2019, \u2018If you have used it before: what for have you used it?\u2019). And we also measure the soft-drink consumption of the partici-pants (\u2018Do you consume drinks such as soft-drinks, coffee, juices, milk drinks?\u2019 \u2018If yes, which of the drinks do you consume?\u2019 \u2018If yes: how much do you consume those drinks in a regular week?\u2019 \u2018How much have you consumed those drinks five years ago per week?\u2019)", "q25": "DuBose, C. N., Cardello, A. V., &amp; Maller, O. (1980). Effects of colorants and flavorants on identification, perceived flavor intensity, and hedonic quality of fruit-flavored beverages and cake. J. Food Sci. \nGonzalez-Franco, M., &amp; Peck, T. C. (2018). Avatar Embodiment. Towards a Standardized Questionnaire. frontiers in Robotics and AI.\nHeed, T., &amp; R\u00f6der, B. (2012). The Body in a Multisensory World. In M. Murray, The Neural Bases of Multisensory Processes. Taylor &amp; Francis.\nMatusz, P. J., Wallace, M. T., &amp; Murray, M. M. (2017). A multisensory perspective on object memory. Neuropsychologia(105), S. 243-252.\nPackard, M. G., &amp; Cahill, L. (2001). Affective modulation of multiple memory systems. Current Opinion in Neurobiology, S. 752-756.\nPhelps, E. A. (2004). Human emotion and memory: interactions of the amygdala and hippocampal complex. Current Opinion in Neurobiology, S. 198-202.\nQuak, M., London, R. E., &amp; Talsma, D. (2015). A multisensory perspective of working memory. Frontiers in Human Neuroscience(9), S. 1-11.\nRoel Lesur, M., Weijs, M. L., Kannape, C. S., &amp; Lenggenhager, B. (2019). Achronopresence: How temporal visuotactile and visuomotor mismatches modulate embodiment. BioRxiv.\nRubin, D. C. (2006). The Basic-Systems Model of Episodic Memory. Perspectives On Psychological Science.\nSpence, C., &amp; Auvray, M. (2008). The multisensory perception of flavour. Consciousness and Cognition, S. 1016-1031.\nYeomans, M. R., Chambers, L., Blumenthal, H., &amp; Blake, A. (September 2008). The role of expectancy in sensory and hedonic evaluation. Food Quality and Preference, S. 565-573.\nZampini, M., &amp; Spence, C. (2012). Assessing the Role of Visual and Auditory Cues in Multisensory Perception. In M. M. Murray, &amp; M. T. Wallace, The Neural Bases of Multisensory Processes. CRC Press/Taylor &amp; Francis.\nZellner, D. A., &amp; Durlach, P. (2003). Effect of Color on Expected and Experienced Refreshment, Intensity and Liking of Beverages. The American Journal of Psychology, S. 633-647.\n", "q8.question": "The study is designed as a within-subject experiment and it will consist of three blocks. After the preparation, the first block will be the episodic memory encoding (cover-story, see above) and the embodiment measurement, after 30min break there will be the 2nd block, i.e.  memory testing and then in the third block will be the colour and taste perception testing. To rule out any confounding variables, the stimuli will be presented in four different orders, and for the second and third blocks the tasks will be presented in a counterbalanced order. The participants will be randomly assigned to one of it.", "q8.uploader": [], "q12.question": "Participants will be recruited at the University of Zurich. There will be flyers to advertise for the experiment as well as an announcement in the mailing list for psychology students. The partici-pants will not receive any reward for the participation except psychology students that would be granted study credits. In order to leave the participants unaware of the real purpose of the study (i.e. studying memory), they will be told that the experiment is investigating food preference. The participants should not be on any kind of diet, have normal or corrected-to-normal vision, declare no history of psychiatric, neurological or vestibular disease, and they should not be sub-ject to any food allergy. Any intake of medication will also lead to the exclusion of the partici-pants. The participants will have to agree to be touched on the knee during the session. We de-cided to exclude any participant below the age of 18 and above the age of 35. If the participants are not able to do the task or quit the experiment they will be excluded as well. All participants will need to give written informed consent prior to starting the experiment. ", "q12.uploader": [], "q16.question": "In this study we will have the following independent variables:\nMatch: A match exists if the participant will see the same as they will taste. In the videos they will see for example an orange juice and they will taste an orange flavour. For the tastes we will use artificial flavours to grant reproducibility. \nMismatch: A mismatch exists if the participant will see something different as they will taste. In the video they will see for example an orange juice, but they will taste coffee flavour. For the taste we will use again artificial flavours to grant reproducibility. \n", "q16.uploader": [], "q17.question": "We will measure six variables: \n1.\tWe will measure the similarity of the tasted and seen product by asking the participants \u2018How similar did you experience the seen and the tasted liquid?\u2019 (on an analogue scale of 0-1, 0 being \u2018not at all\u2019, 1 being \u2018completely\u2019). \n2.\tThe variable embodiment we intend to investigate by letting the participants rate the fol-lowing statements: \u2018I felt as if the body I saw on the video when I was looking down was my body\u2019 and \u2018It felt as if the body I saw on the video when I was looking down was someone else\u2019 (on an analogue scale of 0-1, 0 being \u2018not at all\u2019, 1 being \u2018complete-ly\u2019). \n3.\tTo test the visual recognition, the participants will be showed a picture of a liquid and asked \u2018Have you seen this liquid in one of the videos before?\u2019 (forced-choice \u2018yes\u2019 or \u2018no\u2019) and \u2018How certain are you about that answer?\u2019 (on an analogue scale of 0-1, 0 be-ing \u2018not at all\u2019, 10 being \u2018completely\u2019). \n4.\tThe variable gustatory recognition will be measured through the questions \u2018Have you tasted this flavour in the experiment before the break?\u2019 (forced-choice \u2018yes\u2019 or \u2018no\u2019) and \u2018How certain are you about that answer?\u2019 (on an analogue scale of 0-1, 0 being \u2018not at all\u2019, 1 being \u2018completely\u2019). \n5.\tTo test the colour perception we will ask the participants \u2018How similar in colour did you perceive the tasted and seen liquid?\u2019 after experiencing a mismatch and \u2018Which colour did the liquid in the video have?\u2019 (on an RGB scale). After experiencing the unimodal vision we will ask \u2018Which colour did the liquid in the video have?\u2019 (on an RGB scale) and after the unimodal taste they will have to answer the question \u2018Which colour do you think the liquid you have tasted have?\u2019 (on an RGB scale)\n6.\tWe will measure the gustatory perception by asking \u2018How similar in taste did you per-ceive the tasted and seen liquid?\u2019 after experiencing a mismatch and \u2018How sweet did you experience this liquid?\u2019, \u2018How sour did you experience this liquid?\u2019, \u2018How bitter did you experience this liquid?\u2019, \u2018How salty did you experience this liquid?\u2019. After experi-encing the unimodal vision, they will have to answer the questions \u2018How sweet do you think this liquid would be?\u2019, \u2018How sour do you think this liquid would be?\u2019, \u2018How bit-ter do you think this liquid would be?\u2019 and \u2018How salty do you think this liquid would be?\u2019. When they have experienced the unimodal taste, they have to answer the following questions \u2018How sweet did you experience this liquid?\u2019, \u2018How sour did you experience this liquid?\u2019, \u2018How bitter did you experience this liquid?\u2019 and \u2018How salty did you expe-rience this liquid?\u2019 (all on a scale of 1-10, 1 being \u2018not at all\u2019, 10 being \u2018completely\u2019)\n", "q17.uploader": [], "q18.question": "Embodiment: we will take the mean of the two analogue-scale questions (adjusted to match in direction) above to create a single measure of \u2018embodiment.\u2019\nVisual recognition: we will create a score of correctly recognized visual stimuli.\nTaste recognition: we will create a score of correctly recognized taste stimuli.\nMatch vs. Mismatch recognition: we will create a total score of correctly recognized matching items and a total score of correctly recognized matching items. \nColour perception: we will have three colour values for each mismatch, each unimodal taste and each unimodal vision. Then we would create three values of mismatch relative to taste and three values of mismatch relative to vision for each stimulus. Each value corresponds to the scales of red, green and blue, respectively.\nTaste perception: we will have four analogue-scale values for each mismatch, each unimodal taste and each unimodal vision. Then we would create four values mismatch relative to taste and four values mismatch relative to vision. ", "q18.uploader": [], "q19.question": "Hypothesis 1: The participants will answer the questions about the flavour on a visual analogue scale, resulting in VAS values of the mismatches, unimodal taste and unimodal vision. The four values mismatch relative to vision will be compared to the four values mismatch relative to taste through a T-test (or a non-parametric equivalent). The T-test will then confirm that the multisen-sory value is in the expected direction, so significantly towards the vision than taste. \n\nHypothesis 2: The participants will answer the questions about the colour on a colour wheel. So, we will then have the colour wheel values of the mismatches, unimodal taste and unimodal vision. The colour wheel values will be transformed into RGB values, which indicate the inten-sity of the red, green and blue. We will then have one RGB value mismatch relative to vision and one RGB value mismatch relative. A T-test (or a non-parametric equivalent) will be used to confirm that the multisensory value is in the expected direction, so significantly towards the taste than vision. \n\nHypothesis 3.1: The absolute memory will be tested by means of the signal detection method, which allows us to obtain a measure of recognition d\u2019, independent of the response bias cause by the participant\u2019s tendency to say yes or no. For each item the percentages of hits, misses, false alarms, and correct rejections will be determined. These percentages will then be trans-formed into z scores under the normal probability curve and the recognition index d\u2019 and the decision criterion k will be calculated for each participant. T-tests will be used to determine whether the d\u2019 of the participant for each of the distractors will be significantly higher than zero, indicating that learning had taken place. So we will compare the individual d\u2019 scores in the matching and in the mismatching conditions through a T-test (or a non-parametric equivalent) . \n\nHypothesis 3.2: We will compare the scores of the vision and taste recognition test in the mis-matching condition through a T-test (or a non-parametric equivalent). \n\nHypothesis 4: The participants will answer the question about embodiment on a visual analogue scale. We will then compare the values of the match and mismatch through a T-test (or a non-parametric equivalent). ", "q19.uploader": []}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/zcuyn/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/zcuyn/comments/?format=json&filter%5Btarget%5D=zcuyn", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/zcuyn/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/zcuyn/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/zcuyn/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/zcuyn/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/zcuyn/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/zcuyn/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/zcuyn/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/zcuyn/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/zcuyn/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/zcuyn/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/zcuyn/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/zcuyn/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/de-1/?format=json", "meta": {}}}, "data": {"id": "de-1", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/zcuyn/?format=json", "meta": {}}}, "data": {"id": "zcuyn", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/zcuyn/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/zcuyn/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/zcuyn/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/zcuyn/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/zcuyn/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/zcuyn/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/zcuyn/citation/?format=json", "meta": {}}}, "data": {"id": "zcuyn", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/2mvup/?format=json", "meta": {}}}, "data": {"id": "2mvup", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/xju3h/?format=json", "meta": {}}}, "data": {"id": "xju3h", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5c08457ed283380029cf73bf/?format=json", "meta": {}}}, "data": {"id": "5c08457ed283380029cf73bf", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/zcuyn/", "self": "https://api.osf.io/v2/registrations/zcuyn/"}}, {"id": "q7xsu", "type": "registrations", "attributes": {"title": "Statistical training on UK undergraduate psychology courses", "description": "An exploratory analysis of the statistical content taught on undergraduate psychology courses in the UK.", "category": "project", "custom_citation": "", "date_created": "2020-01-14T09:43:05.155904", "date_modified": "2019-12-04T12:43:27.269734", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "0169902974ec95e40babd16c860d1f10070fcc3e56485d9221b9e693288d164f04e6b05a257f90605dbcc7c7d1d238a6bcd11f872fc0ffb136ec8dc5d7e9dd43236ff7dc019b1d73c11c6d79321ec66278f9b42b8c675858a12564f195b490d6ec51de2bec92a647dc818085a0ecc2cd01350f6b5da03a67bf043ddd56ee85514c21b883034d7cf83b36a3a3e7a0289e", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-14T09:43:05.128167", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Open-Ended Registration", "registered_meta": {"summary": {"extra": [], "value": "The preregistered protocol is attached and available at https://osf.io/hme7q/"}, "uploader": {"extra": [{"data": {"name": "Protocol.doc"}, "nodeId": "9jyub", "sha256": "5ce7856847ab5253c54b3e3fc6777e8a582fbcc191ae711b90b1a587c0dc1185", "viewUrl": "/project/9jyub/files/osfstorage/5dde74b4e1e62f000b2c79ee", "selectedFileName": "Protocol.doc"}], "value": ""}}, "registration_responses": {"summary": "The preregistered protocol is attached and available at https://osf.io/hme7q/", "uploader": [{"file_id": "5dde74b4e1e62f000b2c79ee", "file_name": "Protocol.doc", "file_urls": {"html": "https://osf.io/9jyub/files/osfstorage/5dde74b4e1e62f000b2c79ee", "download": "https://osf.io/download/hme7q/"}, "file_hashes": {"sha256": "5ce7856847ab5253c54b3e3fc6777e8a582fbcc191ae711b90b1a587c0dc1185"}}]}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/q7xsu/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/q7xsu/comments/?format=json&filter%5Btarget%5D=q7xsu", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/q7xsu/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/q7xsu/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/q7xsu/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/q7xsu/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/q7xsu/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/q7xsu/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/q7xsu/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/q7xsu/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/q7xsu/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/q7xsu/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/q7xsu/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/q7xsu/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/q7xsu/?format=json", "meta": {}}}, "data": {"id": "q7xsu", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/q7xsu/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/q7xsu/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/q7xsu/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/q7xsu/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/q7xsu/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/q7xsu/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/q7xsu/citation/?format=json", "meta": {}}}, "data": {"id": "q7xsu", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/ng2hk/?format=json", "meta": {}}}, "data": {"id": "ng2hk", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/9jyub/?format=json", "meta": {}}}, "data": {"id": "9jyub", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5df83f7dd28338001ac0ab0d/?format=json", "meta": {}}}, "data": {"id": "5df83f7dd28338001ac0ab0d", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/q7xsu/", "self": "https://api.osf.io/v2/registrations/q7xsu/"}}, {"id": "ceh7y", "type": "registrations", "attributes": {"title": "Valence, Well Being and Passage of Time", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-01-14T09:19:02.324820", "date_modified": "2020-01-14T09:15:49.118467", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "80c7f861a13f867f8fda27bf2d167318a4becd403c583aa65ba37bba6226062b94e9ddfaf3b64a3b231912ac7b9c5acf3da41deb5f303252b844fd568b683dc5ff88d538c6b0538d47a90b1ac23971db3aacf1e120ed2358e9a825d835eda1f8bba9114e7e8e5f4e6f7aaabae8d825047c0f1dbd9eeb3b431cdb27b59a1985667d2b1535b4bcef75aad8f71001c85458", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-14T09:19:02.306506", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "OSF Preregistration", "registered_meta": {"q1": {"extra": [], "value": "The faster time passes, the happier? Investigating a surprising relationship."}, "q2": {"extra": [], "value": "Ferdinand Kosak, Christof Kuhbandner"}, "q3": {"extra": [], "value": "In exploratory analyses of data from previous studies (e.g., Kosak, Kuhbandner, &amp; Hilbert, 2019), we found a small but positive correlation between Subjective Well Being (SWB) and Passage of Time Judgements, suggesting that people reporting time to pass by fast report higher well-being. The aim of this study is to validate this finding. \n\nFurthermore, we want to investigate whether a strong belief in norms, subsumed under a protestant work ethic, may help to explain this relation since previous literature suggests that unemployment (i.e., having little to do) mitigates SWB, particularly for people with a strong protestant work ethic (e.g., van Hoorn &amp; Maseland, 2013). This might imply that in particular people with a strong identification with protestant work ethic believe that successful and therefore satisfied people have little time at their hands (Levine, 1997). \n\nThis study is embedded in an experiment investigating the meaning of valence concerning the reminiscence heuristic (e.g., Kosak, Kuhbandner, &amp; Hilbert, 2019). The preregistration of this study is available under https://osf.io/v2ujc."}, "q4": {"extra": [], "value": "H1a: Satisfaction with life is associated with faster passage of time judgements.\nH1b: The affect-balance (i.e., positive minus negative trait affect) is associated with faster passage of time judgements.\n\nH2: The relation between SWB and passage of time judgments is mediated by the reported level of protestant work ethics."}, "q5": {"extra": [], "value": "Observational Study - Data is collected from study subjects that are not randomly assigned to a treatment. This includes surveys, \u201cnatural experiments,\u201d and regression discontinuity designs."}, "q6": {"extra": [], "value": ["No blinding is involved in this study."]}, "q7": {"extra": [], "value": ""}, "q8": {"value": {"question": {"extra": [], "value": "See image attached.\n\nFor this particular research questions, there is no manipulation necessary. However, this research is embedded in an experiment investigating the influence of valence of activated autobiographical memories on passage of time judgements with a between-subject manipulation. Therefore, we describe the whole procedure of that study (see also preregistration https://osf.io/v2ujc):\n\nA between-design with one factor and two levels (valence of autobiographical memories: positive vs. negative) is used. All participants start by filling out the SWLS- (Glaesmer, Grande, Braehler, &amp; Roth, 2011) and the PANAS-Questionnaire (Krohne, Egloff, Kohlmann, &amp; Tausch, 1996) before being randomly assigned to the two reminiscence groups. Depending on the group participants are asked to either retrieve five positive or negative life events. Then, they judge the passage of time for the last five and one year(s) on seperate pages. Next, participants are asked to describe their thoughts when giving their passage of time judgements, before they retrieve another 5 memories, this time the opposite valence than before. Afterwards participants fill out a modified version (focusing on time) of the Protestant Work Ethics Scale (McHoske, 1994) and the Time Pressure Questionnaire (Friedmann &amp; Janssen, 2010), followed by some demographic questions (age, gender, occupation and population of hometown).\n"}, "uploader": {"extra": [{"data": {"name": "Design.jpg"}, "nodeId": "habrz", "sha256": "b97fd7a8b0527259df73fc8699f69ab6f79e798bae847824caa7945a8633d315", "viewUrl": "/project/ceh7y/files/osfstorage/5e1d878a6822bd0113ff04f8/", "selectedFileName": "Design.jpg"}], "value": ""}}}, "q9": {"extra": [], "value": ""}, "q10": {"extra": [], "value": "Registration prior to creation of data"}, "q11": {"extra": [], "value": ""}, "q12": {"value": {"question": {"extra": [], "value": "Participants will be recruited via advertisments at our university, the website of 'Psychologie Heute', facebook-groups as well as via private contacts. Participants having had a posttraumatic stress disorder or extremely burdensome experiences throughout the last five years are not allowed to take part in the study."}, "uploader": {"extra": [], "value": ""}}}, "q13": {"extra": [], "value": "Our target sample size is 260."}, "q14": {"extra": [], "value": "As preregistered at https://osf.io/v2ujc, the sample size was determined based on a power analysis with G*Power, aiming for a Power of 80% with an expected effect of d=.35 (p &lt; .05)."}, "q15": {"extra": [], "value": ""}, "q16": {"value": {"question": {"extra": [], "value": "This part of the study is correlational and therefore not based on a manipulation of variables. However, since this research is embedded in another project, there is a manipulation involved in the design (valence of memories recalled before judging the passage of time, positive vs. negative, see Study Design or https://osf.io/v2ujc for a detailed description), which has to be controlled for in the analyses. "}, "uploader": {"extra": [], "value": ""}}}, "q17": {"value": {"question": {"extra": [], "value": "Passage of time judgements will be measured by asking participants \"When you look back: How did the last 5 years (1 year) pass by for you?\". Answers are given on a 7-point-Likert-Scale ranging from very slow to very fast.\n\nSubjective Well Being will be measured with the Satisfaction With Life Scale (SWLS; Glaesmer, Grande, Braehler, &amp; Roth, 2011) and the Positive and Negative Affect Scale (PANAS; Krohne, Egloff, Kohlmann, &amp; Tausch, 1996).\nThe Protestand Work Ethics Scale (McHoske, 1994; with some Items changed in order to capture more time relevant information) will be measured by using the respective questionnaire. \nThe Time Pressure-Scale will be used as used in Friedmann &amp; Janssen (2010). \n\nThe PANAS-Instructions aim for a general emotion-balance by asking how often one experiences these emotions usually.\n\nAdditionally we will try to capture the heuristics, that participants use to form their POTJ. Therfore we ask them with an open question about what they were thinking about and/or what came to their mind, when they gave their judgement. "}, "uploader": {"extra": [], "value": ""}}}, "q18": {"value": {"question": {"extra": [], "value": "We will calculate an affect-balance-score by subtracting the mean ratings for negative affect items from the mean ratings for positive affect items."}, "uploader": {"extra": [], "value": ""}}}, "q19": {"value": {"question": {"extra": [], "value": "Spearman Correlations will be calculated to test the relation between passage of time judgements, SWLS, and the affect-balance score (PANAS).\n\nTo control for a possible effect of the valence-manipulation on Passage of Time Judgements (see Preregistration under https://osf.io/v2ujc), we will run a multiple hierarchical regression analysis including experimental group in block 1 (control), and SWLS (model A) / affect-balance score (PANAS; model B) in block 2.\n\nIn addition, we will run similar analyses to control for possible effects of time pressure and/or possible age effects.\n\nFinally we will analyse whether Protestant Work Ethic mediates the relation between SWLS/PANAS and POTJ by using the Process-Plugin for SPSS by Hayes (2019). Specifically, we will determine:\n \n(1) the effect of SWLS/PANAS on PWES\n(2) the direct effect of SWLS/PANAS on POTJ and \n(3) the indirect effect of SWLS/PANAS on POTJ (via PWES)\n\nThis anlyses will also be performed including only items of the PWES that directly point to the availability of time (i.e. \u201cLife  would  be  more  meaningful  if  we  had  more  leisure  time\u201d).\n\nAdditionally, we will controll for the effects of the experimental group (valence of memories activated, see Pre-Registration https://osf.io/v2ujc), for time pressure, and age (adding as covariates). \n\n"}, "uploader": {"extra": [], "value": ""}}}, "q20": {"extra": [], "value": "The open question regarding the heuristics used to male POTJ will be processed in a manual coding process. Our fundamental assumption is that participants will mostly refer to memories when derieving POTJs. Therefore, this will be dummy-coded as 0 = reference to memories / 1 = other strategy."}, "q21": {"extra": [], "value": "p &lt; .05"}, "q22": {"extra": [], "value": ""}, "q23": {"extra": [], "value": ""}, "q24": {"extra": [], "value": ""}, "q25": {"extra": [], "value": ""}}, "registration_responses": {"q1": "The faster time passes, the happier? Investigating a surprising relationship.", "q2": "Ferdinand Kosak, Christof Kuhbandner", "q3": "In exploratory analyses of data from previous studies (e.g., Kosak, Kuhbandner, &amp; Hilbert, 2019), we found a small but positive correlation between Subjective Well Being (SWB) and Passage of Time Judgements, suggesting that people reporting time to pass by fast report higher well-being. The aim of this study is to validate this finding. \n\nFurthermore, we want to investigate whether a strong belief in norms, subsumed under a protestant work ethic, may help to explain this relation since previous literature suggests that unemployment (i.e., having little to do) mitigates SWB, particularly for people with a strong protestant work ethic (e.g., van Hoorn &amp; Maseland, 2013). This might imply that in particular people with a strong identification with protestant work ethic believe that successful and therefore satisfied people have little time at their hands (Levine, 1997). \n\nThis study is embedded in an experiment investigating the meaning of valence concerning the reminiscence heuristic (e.g., Kosak, Kuhbandner, &amp; Hilbert, 2019). The preregistration of this study is available under https://osf.io/v2ujc.", "q4": "H1a: Satisfaction with life is associated with faster passage of time judgements.\nH1b: The affect-balance (i.e., positive minus negative trait affect) is associated with faster passage of time judgements.\n\nH2: The relation between SWB and passage of time judgments is mediated by the reported level of protestant work ethics.", "q5": "Observational Study - Data is collected from study subjects that are not randomly assigned to a treatment. This includes surveys, \u201cnatural experiments,\u201d and regression discontinuity designs.", "q6": ["No blinding is involved in this study."], "q7": "", "q9": "", "q10": "Registration prior to creation of data", "q11": "", "q13": "Our target sample size is 260.", "q14": "As preregistered at https://osf.io/v2ujc, the sample size was determined based on a power analysis with G*Power, aiming for a Power of 80% with an expected effect of d=.35 (p &lt; .05).", "q15": "", "q20": "The open question regarding the heuristics used to male POTJ will be processed in a manual coding process. Our fundamental assumption is that participants will mostly refer to memories when derieving POTJs. Therefore, this will be dummy-coded as 0 = reference to memories / 1 = other strategy.", "q21": "p &lt; .05", "q22": "", "q23": "", "q24": "", "q25": "", "q8.question": "See image attached.\n\nFor this particular research questions, there is no manipulation necessary. However, this research is embedded in an experiment investigating the influence of valence of activated autobiographical memories on passage of time judgements with a between-subject manipulation. Therefore, we describe the whole procedure of that study (see also preregistration https://osf.io/v2ujc):\n\nA between-design with one factor and two levels (valence of autobiographical memories: positive vs. negative) is used. All participants start by filling out the SWLS- (Glaesmer, Grande, Braehler, &amp; Roth, 2011) and the PANAS-Questionnaire (Krohne, Egloff, Kohlmann, &amp; Tausch, 1996) before being randomly assigned to the two reminiscence groups. Depending on the group participants are asked to either retrieve five positive or negative life events. Then, they judge the passage of time for the last five and one year(s) on seperate pages. Next, participants are asked to describe their thoughts when giving their passage of time judgements, before they retrieve another 5 memories, this time the opposite valence than before. Afterwards participants fill out a modified version (focusing on time) of the Protestant Work Ethics Scale (McHoske, 1994) and the Time Pressure Questionnaire (Friedmann &amp; Janssen, 2010), followed by some demographic questions (age, gender, occupation and population of hometown).\n", "q8.uploader": [{"file_id": "5e1d878a6822bd0113ff04f8", "file_name": "Design.jpg", "file_urls": {"html": "https://osf.io/project/ceh7y/files/osfstorage/5e1d878a6822bd0113ff04f8", "download": "https://osf.io/download/5e1d878a6822bd0113ff04f8"}, "file_hashes": {"sha256": "b97fd7a8b0527259df73fc8699f69ab6f79e798bae847824caa7945a8633d315"}}], "q12.question": "Participants will be recruited via advertisments at our university, the website of 'Psychologie Heute', facebook-groups as well as via private contacts. Participants having had a posttraumatic stress disorder or extremely burdensome experiences throughout the last five years are not allowed to take part in the study.", "q12.uploader": [], "q16.question": "This part of the study is correlational and therefore not based on a manipulation of variables. However, since this research is embedded in another project, there is a manipulation involved in the design (valence of memories recalled before judging the passage of time, positive vs. negative, see Study Design or https://osf.io/v2ujc for a detailed description), which has to be controlled for in the analyses. ", "q16.uploader": [], "q17.question": "Passage of time judgements will be measured by asking participants \"When you look back: How did the last 5 years (1 year) pass by for you?\". Answers are given on a 7-point-Likert-Scale ranging from very slow to very fast.\n\nSubjective Well Being will be measured with the Satisfaction With Life Scale (SWLS; Glaesmer, Grande, Braehler, &amp; Roth, 2011) and the Positive and Negative Affect Scale (PANAS; Krohne, Egloff, Kohlmann, &amp; Tausch, 1996).\nThe Protestand Work Ethics Scale (McHoske, 1994; with some Items changed in order to capture more time relevant information) will be measured by using the respective questionnaire. \nThe Time Pressure-Scale will be used as used in Friedmann &amp; Janssen (2010). \n\nThe PANAS-Instructions aim for a general emotion-balance by asking how often one experiences these emotions usually.\n\nAdditionally we will try to capture the heuristics, that participants use to form their POTJ. Therfore we ask them with an open question about what they were thinking about and/or what came to their mind, when they gave their judgement. ", "q17.uploader": [], "q18.question": "We will calculate an affect-balance-score by subtracting the mean ratings for negative affect items from the mean ratings for positive affect items.", "q18.uploader": [], "q19.question": "Spearman Correlations will be calculated to test the relation between passage of time judgements, SWLS, and the affect-balance score (PANAS).\n\nTo control for a possible effect of the valence-manipulation on Passage of Time Judgements (see Preregistration under https://osf.io/v2ujc), we will run a multiple hierarchical regression analysis including experimental group in block 1 (control), and SWLS (model A) / affect-balance score (PANAS; model B) in block 2.\n\nIn addition, we will run similar analyses to control for possible effects of time pressure and/or possible age effects.\n\nFinally we will analyse whether Protestant Work Ethic mediates the relation between SWLS/PANAS and POTJ by using the Process-Plugin for SPSS by Hayes (2019). Specifically, we will determine:\n \n(1) the effect of SWLS/PANAS on PWES\n(2) the direct effect of SWLS/PANAS on POTJ and \n(3) the indirect effect of SWLS/PANAS on POTJ (via PWES)\n\nThis anlyses will also be performed including only items of the PWES that directly point to the availability of time (i.e. \u201cLife  would  be  more  meaningful  if  we  had  more  leisure  time\u201d).\n\nAdditionally, we will controll for the effects of the experimental group (valence of memories activated, see Pre-Registration https://osf.io/v2ujc), for time pressure, and age (adding as covariates). \n\n", "q19.uploader": []}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ceh7y/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ceh7y/comments/?format=json&filter%5Btarget%5D=ceh7y", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ceh7y/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ceh7y/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ceh7y/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ceh7y/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ceh7y/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ceh7y/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ceh7y/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ceh7y/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ceh7y/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ceh7y/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ceh7y/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/ceh7y/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/de-1/?format=json", "meta": {}}}, "data": {"id": "de-1", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ceh7y/?format=json", "meta": {}}}, "data": {"id": "ceh7y", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ceh7y/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ceh7y/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/ceh7y/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ceh7y/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/ceh7y/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ceh7y/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ceh7y/citation/?format=json", "meta": {}}}, "data": {"id": "ceh7y", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/vmpbj/?format=json", "meta": {}}}, "data": {"id": "vmpbj", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/habrz/?format=json", "meta": {}}}, "data": {"id": "habrz", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5c08457ed283380029cf73bf/?format=json", "meta": {}}}, "data": {"id": "5c08457ed283380029cf73bf", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/ceh7y/", "self": "https://api.osf.io/v2/registrations/ceh7y/"}}, {"id": "82mtx", "type": "registrations", "attributes": {"title": "Selective Scientific Reasoning", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-01-17T00:17:13.690415", "date_modified": "2020-01-17T00:16:55.869262", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "33965de5247dcb36e8e37bf6336d13916087ba4c2cfe865d2d2f6eea19276a8f6a6ee03c45abeb3324f2d36c43d3fb2a8b5feb1e3e1f14464ba01087836ae294062591b00b75226a7546005d0aace9a693ed19c3d7681c40770fc2d46afac81a0c95df4f12eee11e6a4074e85c056ba5db90c9769152f9c79218f72801a7cc3206272298907b5dd28d032a60801769bf", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-17T00:17:13.668146", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Open-Ended Registration", "registered_meta": {"summary": {"extra": [], "value": "Preregistration Document for Study 2 is attached."}, "uploader": {"extra": [{"data": {"name": "Preregistration011720.docx"}, "nodeId": "a9cdz", "sha256": "5bca41d1f723186263ccb00835c7083e0a51a5631a07830352366a1c643e7419", "viewUrl": "/project/a9cdz/files/osfstorage/5e20fcf7675e0e002d6b5a4f", "selectedFileName": "Preregistration011720.docx"}], "value": ""}}, "registration_responses": {"summary": "Preregistration Document for Study 2 is attached.", "uploader": [{"file_id": "5e20fcf7675e0e002d6b5a4f", "file_name": "Preregistration011720.docx", "file_urls": {"html": "https://osf.io/a9cdz/files/osfstorage/5e20fcf7675e0e002d6b5a4f", "download": "https://osf.io/download/qjfsu/"}, "file_hashes": {"sha256": "5bca41d1f723186263ccb00835c7083e0a51a5631a07830352366a1c643e7419"}}]}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/82mtx/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/82mtx/comments/?format=json&filter%5Btarget%5D=82mtx", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/82mtx/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/82mtx/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/82mtx/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/82mtx/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/82mtx/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/82mtx/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/82mtx/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/82mtx/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/82mtx/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/82mtx/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/82mtx/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/82mtx/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/82mtx/?format=json", "meta": {}}}, "data": {"id": "82mtx", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/82mtx/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/82mtx/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/82mtx/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/82mtx/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/82mtx/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/82mtx/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/82mtx/citation/?format=json", "meta": {}}}, "data": {"id": "82mtx", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/wqa94/?format=json", "meta": {}}}, "data": {"id": "wqa94", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/a9cdz/?format=json", "meta": {}}}, "data": {"id": "a9cdz", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5df83f7dd28338001ac0ab0d/?format=json", "meta": {}}}, "data": {"id": "5df83f7dd28338001ac0ab0d", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/82mtx/", "self": "https://api.osf.io/v2/registrations/82mtx/"}}, {"id": "m2ebs", "type": "registrations", "attributes": {"title": "Implicit vs. explicit risk attitude in predicting stigmatized risk taking", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-01-16T22:53:09.036035", "date_modified": "2020-01-16T22:54:22.272880", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "e080c678c5d68eae36669ebc1d9243df9192592521fb688e87c73d56e61d3d1a40024fbf520e63ec7145e773e65c86b7767e1730706844eebf9924202cb3976fd9cc9b89b2f5c37bf5b74a0819d616d44be91702b03ea932f2374e2320d5448a842c79b9431c5719890e2edc1a961267bca334b81d964c194fc2f142cd2512accbf5647012df59f6131843b0cdc267e6", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-16T22:53:09.015116", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Preregistration Template from AsPredicted.org", "registered_meta": {"data": {"extra": [], "value": "No, no data have been collected for this study yet."}, "name": {"extra": [], "value": "Implicit vs. explicit risk attitude in predicting stigmatized risk taking"}, "other": {"extra": [], "value": ""}, "sample": {"extra": [], "value": "120"}, "analyses": {"extra": [], "value": "regression model explaining DV by:\n- implicit risk attitude (IAT measure; Traczyk, J., &amp; Zaleskiewicz, T. (2015).\n- explicit risk attitude (set of questions related to different gambling activities) \nand their interaction with manipulation (gambling stigma vs. no stigma)"}, "outliers": {"extra": [], "value": "Standard data cleaning procedure for IAT studies (as deleting subjects for whom more than 10% of trials have latency less than 300 ms) described in Lane, K. A., Banaji, M. R., Nosek, B. A., &amp; Greenwald, A. G., 2007)."}, "dependent": {"extra": [], "value": "In modified \"Game of Dice Task\" (Brand, M., Greco, R., Schuster, A., Kalbe, E., Fujiwara, E., Markowitsch, H.J. &amp; Kessler, J., 2002) participants attempt to predict the outcome of a dice roll by selecting among different options ranging from options with high-probability but low payoff to options with low probability but high payoff. DV is the number of risky choices"}, "conditions": {"extra": [], "value": "2 conditions: experimental group (gambling stigmatized) and control (no gambling stigma)"}, "hypothesis": {"extra": [], "value": "Risk-taking stigmatization will influence the effect of explicit risk attitude on risk-taking, but no such interaction is going to be observed for the implicit risk attitude effect on risk-taking"}, "study_type": {"extra": [], "value": "Experiment"}, "study_type_other": {"extra": [], "value": ""}}, "registration_responses": {"data": "No, no data have been collected for this study yet.", "name": "Implicit vs. explicit risk attitude in predicting stigmatized risk taking", "other": "", "sample": "120", "analyses": "regression model explaining DV by:\n- implicit risk attitude (IAT measure; Traczyk, J., &amp; Zaleskiewicz, T. (2015).\n- explicit risk attitude (set of questions related to different gambling activities) \nand their interaction with manipulation (gambling stigma vs. no stigma)", "outliers": "Standard data cleaning procedure for IAT studies (as deleting subjects for whom more than 10% of trials have latency less than 300 ms) described in Lane, K. A., Banaji, M. R., Nosek, B. A., &amp; Greenwald, A. G., 2007).", "dependent": "In modified \"Game of Dice Task\" (Brand, M., Greco, R., Schuster, A., Kalbe, E., Fujiwara, E., Markowitsch, H.J. &amp; Kessler, J., 2002) participants attempt to predict the outcome of a dice roll by selecting among different options ranging from options with high-probability but low payoff to options with low probability but high payoff. DV is the number of risky choices", "conditions": "2 conditions: experimental group (gambling stigmatized) and control (no gambling stigma)", "hypothesis": "Risk-taking stigmatization will influence the effect of explicit risk attitude on risk-taking, but no such interaction is going to be observed for the implicit risk attitude effect on risk-taking", "study_type": "Experiment", "study_type_other": ""}, "subjects": [[{"id": "584240da54be81056cecac48", "text": "Social and Behavioral Sciences"}]]}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m2ebs/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m2ebs/comments/?format=json&filter%5Btarget%5D=m2ebs", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m2ebs/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m2ebs/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m2ebs/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m2ebs/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m2ebs/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m2ebs/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m2ebs/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m2ebs/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m2ebs/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m2ebs/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m2ebs/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/m2ebs/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/de-1/?format=json", "meta": {}}}, "data": {"id": "de-1", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m2ebs/?format=json", "meta": {}}}, "data": {"id": "m2ebs", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m2ebs/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m2ebs/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/m2ebs/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m2ebs/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/m2ebs/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m2ebs/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m2ebs/citation/?format=json", "meta": {}}}, "data": {"id": "m2ebs", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/9rdqx/?format=json", "meta": {}}}, "data": {"id": "9rdqx", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/23d5n/?format=json", "meta": {}}}, "data": {"id": "23d5n", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5d2d2268d28338002c2432d2/?format=json", "meta": {}}}, "data": {"id": "5d2d2268d28338002c2432d2", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/m2ebs/", "self": "https://api.osf.io/v2/registrations/m2ebs/"}}, {"id": "3dz54", "type": "registrations", "attributes": {"title": "MIDLA", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-01-16T20:00:03.207219", "date_modified": "2019-12-17T16:01:20.519559", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "48829f93635ec0f7d3805cf91874a7809b0d755eb07851d5d1e973fb95420e7a29158c12a1f14880ce91976e71424c311bc2fc54bb94d8d139c658da5801e356a04f3956eb88e2cac6db084d801bbcb4081ebc8a9045e942e1bbabe3f663abca9ba1d7386400ba39a90d8f06be26c291c9ce6421404dcd7626148d1fd8492f9b59b77191018a57e993329197575633a7", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-16T20:00:03.172637", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "OSF Preregistration", "registered_meta": {"q1": {"extra": [], "value": "Additional registration notes for: MID longitudinal review update, metaanalytic approach"}, "q2": {"extra": [], "value": "Dylan Nielson, Hanna Keren, Georgia O'Callaghan, Sarah M. Jackson, Dipta Saha, Chris C Camp, Lisa S. Gorham, Argyris Stringaris"}, "q3": {"extra": [], "value": "This note provides greater detail about the analytical approach we will take in our metaanalysis of longitudinal fmri and eeg measures of reward processing and depression. We have completed title and abstract screening and full text review of studies as described in the previous registrations. When combined with the papers from Keren et al., 2018, we have 22 fMRI studies and 11 EEG studies. Of the fMRI studies, 10 are treatment studies where fMRI is evaluated as a predictor of outcomes and 12 are observational where fMRI is used to predict symptom severity or dichotomous relapse, for the EEG studies, 3 are treatment and 8 are observational. Since we do not have 17 studies in any fMRI category, we will not conduct an ALE review. We will conduct random effects meta-analyses for each of the above categories that have more than 5 studies.\n"}, "q4": {"extra": [], "value": "Each of these analyses will only be evaluated if more than 5 studies relevant to that hypothesis are available.\n\nFeedback negativity will be predictive of future depressive symptoms in longitudinal observational EEG studies.\n\nSome EEG signal will be predictive of future depressive symptoms in longitudinal observational EEG studies.\n\nFeedback negativity will predict treatment response in depression treatment studies that include EEG.\n\nSome EEG signal will predict treatment response in depression treatment studies that include EEG.\n\nSome striatal, reward related signal, will predict future depressive symptoms in longitudinal observational fMRI studies.\n\nA neural signal related to reward will predict future depressive symptoms in longitudinal observational fMRI studies.\n\nSome striatal, reward related signal, will predict treatment response in depression treatment studies that include fMRI.\n\nA neural signal related to reward will predict future depressive symptoms in depression treatment studies that include fMRI."}, "q5": {"extra": [], "value": "Meta-Analysis - A systematic review of published studies."}, "q6": {"extra": [], "value": ["No blinding is involved in this study."]}, "q7": {"extra": [], "value": ""}, "q8": {"value": {"question": {"extra": [], "value": "The goal of our study is to evaluate the use of neural signals of reward processing for predicting future depressive symptoms or response to treatment. We are using the longitudinal studies previously identified in Keren et al., 2018 in combination with additional studies identified in a literature review of results published in the intermeaning time. Keren et al. identified 9 longitudinal fMRI studies (5 treatment, 4 observational) and 3 observational longitudinal eeg studies.\n\nWe will use random effects metaanalysis to estimate the mean effect sizes of the populations of predictive performances for each hypothesis. Our initial tests will be as inclusive of relevant neural signals as possible given the relatively small sample sizes. For example, we will include studies that used connectivity measures as well as studies that used activity measures in the relevant fMRI analyses. Subsequent analyses will exclude less common approaches to evaluate more uniform effects as long as there are at least 5 longitudinal predictions that use that approach. We will use the predictive effect size of the reward related signals specifically in the cases in which multivariate predictive models were fit and the information required to estimate these effects is provided. \n"}, "uploader": {"extra": [], "value": ""}}}, "q9": {"extra": [], "value": ""}, "q10": {"extra": [], "value": "Registration prior to analysis of the data"}, "q11": {"extra": [], "value": "We are using the longitudinal studies previously identified in Keren et al., 2018 in combination with additional studies identified in a literature review of results published in the intermeaning time. Keren et al. identified 9 longitudinal fMRI studies (5 treatment, 4 observational) and 3 observational longitudinal eeg studies.\n\nThe studies identified by Keren et al. were described in the supplemental findings of that paper and we are familiar with these studies. Additionally, we are broadly familiar with the findings of many of the papers identified in our updated literature search. We have conducted one round of title and abstract screening and full text screening on the papers identified in this initial round of screening. We have identified 13 new longitudinal fMRI papers (5 treatment, 8 observational) and 8 new longitudinal EEG papers (3 treatment, 5 observational). While we have reviewed the full text of these papers, we have not evaluated the quality of these papers or extracted relevant information. We are conducting a second round of title and abstract screening on the papers deemed irrelevant in the first round of screening and will include any additional relevant papers after full text review.\n"}, "q12": {"value": {"question": {"extra": [], "value": "Literature search and screening approach were described in our previous registrations for this review. We have added an additional round of title and abstract screening to reduce the likelihood of inappropriately excluding any publications.\n\nWe will only evaluate one prediction for each set of study participants. If multiple predictions are reported for the same set of subjects we will pick the prediction over the longest time period, if multiple predictions are made with the same time period, we will pick the highest quality prediction which uses the most participants.\nWe will first rate the quality of each longitudinal prediction based on the criteria put forward in Poldrack et al., 2019. Specifically:\nReporting of out of sample model fit indices\nCross-validation procedure that encompasses all analytical manipulations\nSample size (ideally greater than several hundred observations)\nReporting multiple measures of model fit\nCalculating coefficient of determination via sum-of-squares formulation\nUse of k-fold or shuffle-split cross validation\nIn addition, we will evaluate the open science practices of the publication on the following criteria:\nUse of preregistration\nPublicly releasing code or scripts used in analysis\nPublicly releasing data used in analysis\nEach criteria will be rated on a scale of 0 for least risk of bias to 2 for high risk of bias, or N/A, for example the K-fold criteria in the case that no cross-validation was performed. Quality will be evaluated by two separate raters, conflicts will be reconciled in person and reported.\n\nTwo raters will independently extract the information described below from each longitudinal prediction.\n"}, "uploader": {"extra": [], "value": ""}}}, "q13": {"extra": [], "value": "Our minimum sample size is five distinct longitudinal predictions per hypothesis.\n"}, "q14": {"extra": [], "value": "Our minimum sample size is five distinct longitudinal predictions per hypothesis. At this size, we will be underpowered, but the metaanalytic confidence intervals will help us understand the range of potential values for the effects of interest based on the currently available literature."}, "q15": {"extra": [], "value": ""}, "q16": {"value": {"question": {"extra": [], "value": ""}, "uploader": {"extra": [], "value": ""}}}, "q17": {"value": {"question": {"extra": [], "value": "Prediction quality assessments:\nReporting of out of sample model fit indices\nCross-validation procedure that encompasses all analytical manipulations\nSample size (ideally greater than several hundred observations)\nReporting multiple measures of model fit\nCalculating coefficient of determination via sum-of-squares formulation\nUse of k-fold or shuffle-split cross validation\n\nOpen science assessments:\nUse of preregistration\nPublicly releasing code or scripts used in analysis\nPublicly releasing data used in analysis\n\nEach of the above criteria will be rated on a scale of 0 for least risk of bias to 2 for high risk of bias, or N/A, for example the K-fold criteria in the case that no cross-validation was performed.\n\nFor each longitudinal prediction the following information will be extracted:\nObservational or treatment\nStudy in which source data were first described\nNature of each group (healthy, at risk (defined as the presence of either MDD in a parent, high depression scale scores in the absence of MDD diagnosis, or remitted MDD, depressed), participants with another disorder)\nCriteria used for diagnosis if relevant\nSample size of each group\nPercentage of females in each group\nPercentage of medicated individuals in each group\nMean, SD, and range of ages in each group\nNeural measure: EEG, functional connectivity, fMRI\nDepression measure\nReward task\nType of reward (monetary, affective, or primary)\nContrast used (if any)\nPrediction interval in time\nTerms used in the predictive model\nLink to preregistration\nLink to code\nLink to data\nTreatment type\nSpecific treatment\n\nFor fMRI studies we will separately extract information for the location/connection providing the best predictive performance across the entire brain and the striatal location/connection with the best predictive performance:\nDirection of effect\nReported statistic\nPredictive effect size uniquely contributed by the neural information\nOverall predictive effect size\nTemplate space of reported components\nCoordinates of effect\nConnections\n\nFor EEG studies we will extract information for both the most predictive component of the EEG signal and for the feedback negativity. We will extract the following information:\nElectrodes sampled from\nType of signal extracted (FRN, RewP, etc.)\nSampling method (mean aplitude, peak, etc.)\nWindow for sampling\nHigh and low pass filter applied\nReference electrode\nType of eeg net used\nDirection of effect\nReported statistic\nPredictive effect size uniquely contributed by the neural information\nOverall predictive effect size\n"}, "uploader": {"extra": [], "value": ""}}}, "q18": {"value": {"question": {"extra": [], "value": "Reported effect sizes will be transformed to have a uniform direction of effect and converted to uniform effect size statistic."}, "uploader": {"extra": [], "value": ""}}}, "q19": {"value": {"question": {"extra": [], "value": "We will analyze the effect sizes relevant to each hypothesis with a random effects meta-analysis. If a significant portion of the papers (&gt; 20%) report non-significant results without accompanying effects sizes we will attempt to conduct the meta-analysis with MetaNSUE to appropriately adjust the effect size. "}, "uploader": {"extra": [], "value": ""}}}, "q20": {"extra": [], "value": "Reported effect sizes will be transformed to have a uniform direction of effect and converted to uniform effect size statistic, with preference for the partial correlation coefficient related to the neural data, however, if this is not possible, Cohen\u2019s d will be used instead."}, "q21": {"extra": [], "value": "We will use the standard p &lt; 0.05 criteria for each hypothesis tested in  two tailed manner. Even in the event that the test is not significant, the 95% confidence interval for each hypothesis may be used for exploratory estimation of the clinical predictive utility and causal evidence. \n"}, "q22": {"extra": [], "value": "Longitudinal predictions may be excluded if insufficient information is provided to derive comparable effect sizes. We will only evaluate one prediction for each set of study participants. If multiple predictions are reported for the same set of subjects we will pick the prediction over the longest time period, if multiple predictions are made with the same time period, we will pick the highest quality prediction which uses the most participants."}, "q23": {"extra": [], "value": ""}, "q24": {"extra": [], "value": ""}, "q25": {"extra": [], "value": ""}}, "registration_responses": {"q1": "Additional registration notes for: MID longitudinal review update, metaanalytic approach", "q2": "Dylan Nielson, Hanna Keren, Georgia O'Callaghan, Sarah M. Jackson, Dipta Saha, Chris C Camp, Lisa S. Gorham, Argyris Stringaris", "q3": "This note provides greater detail about the analytical approach we will take in our metaanalysis of longitudinal fmri and eeg measures of reward processing and depression. We have completed title and abstract screening and full text review of studies as described in the previous registrations. When combined with the papers from Keren et al., 2018, we have 22 fMRI studies and 11 EEG studies. Of the fMRI studies, 10 are treatment studies where fMRI is evaluated as a predictor of outcomes and 12 are observational where fMRI is used to predict symptom severity or dichotomous relapse, for the EEG studies, 3 are treatment and 8 are observational. Since we do not have 17 studies in any fMRI category, we will not conduct an ALE review. We will conduct random effects meta-analyses for each of the above categories that have more than 5 studies.\n", "q4": "Each of these analyses will only be evaluated if more than 5 studies relevant to that hypothesis are available.\n\nFeedback negativity will be predictive of future depressive symptoms in longitudinal observational EEG studies.\n\nSome EEG signal will be predictive of future depressive symptoms in longitudinal observational EEG studies.\n\nFeedback negativity will predict treatment response in depression treatment studies that include EEG.\n\nSome EEG signal will predict treatment response in depression treatment studies that include EEG.\n\nSome striatal, reward related signal, will predict future depressive symptoms in longitudinal observational fMRI studies.\n\nA neural signal related to reward will predict future depressive symptoms in longitudinal observational fMRI studies.\n\nSome striatal, reward related signal, will predict treatment response in depression treatment studies that include fMRI.\n\nA neural signal related to reward will predict future depressive symptoms in depression treatment studies that include fMRI.", "q5": "Meta-Analysis - A systematic review of published studies.", "q6": ["No blinding is involved in this study."], "q7": "", "q9": "", "q10": "Registration prior to analysis of the data", "q11": "We are using the longitudinal studies previously identified in Keren et al., 2018 in combination with additional studies identified in a literature review of results published in the intermeaning time. Keren et al. identified 9 longitudinal fMRI studies (5 treatment, 4 observational) and 3 observational longitudinal eeg studies.\n\nThe studies identified by Keren et al. were described in the supplemental findings of that paper and we are familiar with these studies. Additionally, we are broadly familiar with the findings of many of the papers identified in our updated literature search. We have conducted one round of title and abstract screening and full text screening on the papers identified in this initial round of screening. We have identified 13 new longitudinal fMRI papers (5 treatment, 8 observational) and 8 new longitudinal EEG papers (3 treatment, 5 observational). While we have reviewed the full text of these papers, we have not evaluated the quality of these papers or extracted relevant information. We are conducting a second round of title and abstract screening on the papers deemed irrelevant in the first round of screening and will include any additional relevant papers after full text review.\n", "q13": "Our minimum sample size is five distinct longitudinal predictions per hypothesis.\n", "q14": "Our minimum sample size is five distinct longitudinal predictions per hypothesis. At this size, we will be underpowered, but the metaanalytic confidence intervals will help us understand the range of potential values for the effects of interest based on the currently available literature.", "q15": "", "q20": "Reported effect sizes will be transformed to have a uniform direction of effect and converted to uniform effect size statistic, with preference for the partial correlation coefficient related to the neural data, however, if this is not possible, Cohen\u2019s d will be used instead.", "q21": "We will use the standard p &lt; 0.05 criteria for each hypothesis tested in  two tailed manner. Even in the event that the test is not significant, the 95% confidence interval for each hypothesis may be used for exploratory estimation of the clinical predictive utility and causal evidence. \n", "q22": "Longitudinal predictions may be excluded if insufficient information is provided to derive comparable effect sizes. We will only evaluate one prediction for each set of study participants. If multiple predictions are reported for the same set of subjects we will pick the prediction over the longest time period, if multiple predictions are made with the same time period, we will pick the highest quality prediction which uses the most participants.", "q23": "", "q24": "", "q25": "", "q8.question": "The goal of our study is to evaluate the use of neural signals of reward processing for predicting future depressive symptoms or response to treatment. We are using the longitudinal studies previously identified in Keren et al., 2018 in combination with additional studies identified in a literature review of results published in the intermeaning time. Keren et al. identified 9 longitudinal fMRI studies (5 treatment, 4 observational) and 3 observational longitudinal eeg studies.\n\nWe will use random effects metaanalysis to estimate the mean effect sizes of the populations of predictive performances for each hypothesis. Our initial tests will be as inclusive of relevant neural signals as possible given the relatively small sample sizes. For example, we will include studies that used connectivity measures as well as studies that used activity measures in the relevant fMRI analyses. Subsequent analyses will exclude less common approaches to evaluate more uniform effects as long as there are at least 5 longitudinal predictions that use that approach. We will use the predictive effect size of the reward related signals specifically in the cases in which multivariate predictive models were fit and the information required to estimate these effects is provided. \n", "q8.uploader": [], "q12.question": "Literature search and screening approach were described in our previous registrations for this review. We have added an additional round of title and abstract screening to reduce the likelihood of inappropriately excluding any publications.\n\nWe will only evaluate one prediction for each set of study participants. If multiple predictions are reported for the same set of subjects we will pick the prediction over the longest time period, if multiple predictions are made with the same time period, we will pick the highest quality prediction which uses the most participants.\nWe will first rate the quality of each longitudinal prediction based on the criteria put forward in Poldrack et al., 2019. Specifically:\nReporting of out of sample model fit indices\nCross-validation procedure that encompasses all analytical manipulations\nSample size (ideally greater than several hundred observations)\nReporting multiple measures of model fit\nCalculating coefficient of determination via sum-of-squares formulation\nUse of k-fold or shuffle-split cross validation\nIn addition, we will evaluate the open science practices of the publication on the following criteria:\nUse of preregistration\nPublicly releasing code or scripts used in analysis\nPublicly releasing data used in analysis\nEach criteria will be rated on a scale of 0 for least risk of bias to 2 for high risk of bias, or N/A, for example the K-fold criteria in the case that no cross-validation was performed. Quality will be evaluated by two separate raters, conflicts will be reconciled in person and reported.\n\nTwo raters will independently extract the information described below from each longitudinal prediction.\n", "q12.uploader": [], "q16.question": "", "q16.uploader": [], "q17.question": "Prediction quality assessments:\nReporting of out of sample model fit indices\nCross-validation procedure that encompasses all analytical manipulations\nSample size (ideally greater than several hundred observations)\nReporting multiple measures of model fit\nCalculating coefficient of determination via sum-of-squares formulation\nUse of k-fold or shuffle-split cross validation\n\nOpen science assessments:\nUse of preregistration\nPublicly releasing code or scripts used in analysis\nPublicly releasing data used in analysis\n\nEach of the above criteria will be rated on a scale of 0 for least risk of bias to 2 for high risk of bias, or N/A, for example the K-fold criteria in the case that no cross-validation was performed.\n\nFor each longitudinal prediction the following information will be extracted:\nObservational or treatment\nStudy in which source data were first described\nNature of each group (healthy, at risk (defined as the presence of either MDD in a parent, high depression scale scores in the absence of MDD diagnosis, or remitted MDD, depressed), participants with another disorder)\nCriteria used for diagnosis if relevant\nSample size of each group\nPercentage of females in each group\nPercentage of medicated individuals in each group\nMean, SD, and range of ages in each group\nNeural measure: EEG, functional connectivity, fMRI\nDepression measure\nReward task\nType of reward (monetary, affective, or primary)\nContrast used (if any)\nPrediction interval in time\nTerms used in the predictive model\nLink to preregistration\nLink to code\nLink to data\nTreatment type\nSpecific treatment\n\nFor fMRI studies we will separately extract information for the location/connection providing the best predictive performance across the entire brain and the striatal location/connection with the best predictive performance:\nDirection of effect\nReported statistic\nPredictive effect size uniquely contributed by the neural information\nOverall predictive effect size\nTemplate space of reported components\nCoordinates of effect\nConnections\n\nFor EEG studies we will extract information for both the most predictive component of the EEG signal and for the feedback negativity. We will extract the following information:\nElectrodes sampled from\nType of signal extracted (FRN, RewP, etc.)\nSampling method (mean aplitude, peak, etc.)\nWindow for sampling\nHigh and low pass filter applied\nReference electrode\nType of eeg net used\nDirection of effect\nReported statistic\nPredictive effect size uniquely contributed by the neural information\nOverall predictive effect size\n", "q17.uploader": [], "q18.question": "Reported effect sizes will be transformed to have a uniform direction of effect and converted to uniform effect size statistic.", "q18.uploader": [], "q19.question": "We will analyze the effect sizes relevant to each hypothesis with a random effects meta-analysis. If a significant portion of the papers (&gt; 20%) report non-significant results without accompanying effects sizes we will attempt to conduct the meta-analysis with MetaNSUE to appropriately adjust the effect size. ", "q19.uploader": []}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3dz54/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3dz54/comments/?format=json&filter%5Btarget%5D=3dz54", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3dz54/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3dz54/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3dz54/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3dz54/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3dz54/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3dz54/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3dz54/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3dz54/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3dz54/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3dz54/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3dz54/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/3dz54/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3dz54/?format=json", "meta": {}}}, "data": {"id": "3dz54", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3dz54/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3dz54/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/3dz54/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3dz54/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/3dz54/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3dz54/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3dz54/citation/?format=json", "meta": {}}}, "data": {"id": "3dz54", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/gzdr5/?format=json", "meta": {}}}, "data": {"id": "gzdr5", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/whvam/?format=json", "meta": {}}}, "data": {"id": "whvam", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5c08457ed283380029cf73bf/?format=json", "meta": {}}}, "data": {"id": "5c08457ed283380029cf73bf", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/3dz54/", "self": "https://api.osf.io/v2/registrations/3dz54/"}}], "links": {"first": "https://api.osf.io/v2/registrations/?filter%5Bdate_created%5D%5Bgt%5D=2019-12-31&format=json", "last": "https://api.osf.io/v2/registrations/?filter%5Bdate_created%5D%5Bgt%5D=2019-12-31&format=json&page=547", "prev": "https://api.osf.io/v2/registrations/?filter%5Bdate_created%5D%5Bgt%5D=2019-12-31&format=json&page=515", "next": "https://api.osf.io/v2/registrations/?filter%5Bdate_created%5D%5Bgt%5D=2019-12-31&format=json&page=517", "meta": {"total": 5469, "per_page": 10}}}