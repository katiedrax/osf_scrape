{"data": [{"id": "akp5s", "type": "registrations", "attributes": {"title": "OSF Pre-Registration: Directed Forgetting of Stimulus\u2013Classification Associations", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-01-20T18:13:35.076800", "date_modified": "2020-01-20T18:08:28.636362", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "0c6f2c6a11521a9fe5f4951f0319f2be4b839fcbdb0816c233c4e59def638103a0bd695b98f863899eb7647de2aee0d49dd42fcd7a6dd100fda5f4d1f21708ae3658a4003e21c5c8e08d92d369b36496cff31cdacf094b8bae4269fc6f461cf6296180ad04e16d3af16c4592cf93c8c747c76c2462afcaf3ec0038caf9db71db9958e0a8a23ce727a83b3b3cb500001c", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-20T18:13:35.060893", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "OSF Preregistration", "registered_meta": {"q1": {"extra": [], "value": "Directed Forgetting of Stimulus\u2013 Classification Associations"}, "q2": {"extra": [], "value": "Hannah Dames, Lars Link, Andrea Kiesel, Christina U. Pfeuffer, Marco Ragni"}, "q3": {"extra": [], "value": "Humans are able to intentionally forget previously learned information: In the list-method of DF (for an overview see Past\u00f6tter, Tempel, &amp; B\u00e4uml, 2017), for instance, participants are instructed to sequentially learn two lists of items. After learning the first list (referred to as L1), participants are either instructed to forget or to continue remembering this list before learning list 2 (L2). In a memory test for both lists, two findings can be observed: Participants in the forget condition recall fewer L1 items (L1 forgetting) and more L2 items (L2 enhancement) as compared to the remember condition.\n\nWhereas various studies have already demonstrated that humans are able to intentionally forget previously learned information (as often measured using the directed forgetting, short DF, paradigm, for an overview see Past\u00f6tter, Tempel, &amp; B\u00e4uml, 2017), only few studies have investigated how DF affects stimulus-response (S-R) associations (Dreisbach &amp; B\u00e4uml, 2014) or incidentally learned information (e.g., Hockley, Ahmad, &amp; Nicholson, 2016; Jou, 2010). \n\nS-R associations are formed when stimuli and responses repeatedly co-occur and thus bind together \u2013 a notion that is supported by (item-specific) repetition priming effects (see Logan, 1988, 1990). Here, participants\u2019 responses are, for instance, generally faster for items that require the same as opposed to a different, previously executed response. Such item-specific S-R effects are in turn composed of item-specific stimulus\u2013action (S-A) and stimulus\u2013classification (S-C) effects: In general, S-R associations can be divided into two components, S-A associations between stimuli and motor outputs and S-C associations between stimuli and their task-specific semantic classifications (see Hsu &amp; Waszak, 2012; Moutsopoulou et al., 2015). These two components of S-R associations are assumed to be independent (e.g., Pfeuffer, Moutsopoulou, Waszak, &amp; Kiesel, 2019). \n\nWhile to the best of our knowledge only one study has demonstrated that people are able to intentionally forget S-R associations (here, S-A associations), no study has systematically investigated how DF affects S-C associations \u2013 something we aim to investigate in the present study. \n\nA promising hint, that people may be able to intentionally forget S-C associations, is delivered by  recent studies providing first evidence that effects of DF for categorized word lists can extend beyond the individual study items to the level of category information (see Montagliani &amp; Hockley, 2019). The current study aims to gain a deeper understanding of the mechanisms underlying the DF effect on not explicitly instructed and implicitly tested associations between a stimulus and its task-specific classification. For this, we will apply the DF list-method on learned stimulus-classification (S-C) associations drawing on an item-specific priming paradigm (see below and also Hsu &amp; Waszak, 2012; Moutsopoulou, Yang, Desantis, &amp; Waszak., 2015).\n\nOn S\u2013C associations (see Hsu &amp; Waszak, 2012; Moutsopoulou et al., 2015): In an experimental setting, S-C associations are learned when, for instance, participants classify a stimulus according to a classification task (e.g., size \u2013 small/large; mechanism \u2013 mechanic/non-mechanic). S-C associations therefore refer to associations between a stimulus and its task-specific sematic classification. \n\nUsing an item-specific priming paradigm, we will investigate how a DF instruction affects the encoding/retrieval of such S-C associations. For this, we will investigate whether (not explicitly instructed) learned S-C associations can be intentionally forgotten by employing a DF paradigm that allows the simultaneous measurement of S-C retrieval. \n\nShort introduction of and information on the task and study design\n\nIn this study, we are extending the DF paradigm to S-C mappings by drawing on an item-specific priming paradigm (e.g., Hsu &amp; Waszak, 2012; Moutsopoulou, Yang, Desantis, &amp; Waszak, 2015; Pfeuffer, Moutsopoulou, Pfister, Waszak, &amp; Kiesel, 2017) that will allow us to assess the encoding/retrieval of S-C associations (according to the terminology provided by Moutsopoulou et al., 2015).  Our study will consist of three major phases: A learning phase, a distraction phase, and a test phase. \n\nDuring the learning phase, participants categorize images of objects of two lists (L1 and L2) either according to their size or as containing a mechanism or not. By actively classifying objects pressing a left/right key, participants will form S-C associations. Additionally, they will be instructed to remember the objects. \n\nAn equal number of object images will fall into the four possible category combinations (size: small/large X mechanism: mechanic/non-mechanic). Importantly, the required classification task for an object (mechanic/not-mechanic vs. large/small) will differ between the stimuli. Item-specific task cues at the beginning of a trial inform the participant what type of classification should be used, and also which action is required to classify an object accordingly. For example, the task cue \u201cM + N\u201d indicates that an object image has to be classified as being either mechanic or not. At the same time, the task cue informs the participants that the object can be classified as mechanic by pressing a left key and a right key for the classification \u201cnon-mechanic\u201d. Conversely, the task cue \u201cN + M\u201d indicates that a right key press is required for mechanic objects and a left key press for non-mechanic ones. Instead, the task cues \u201cG + K\u201d or \u201cK + G\u201d (G for German \u201cgro\u00df\u201d = large, K for German \u201cklein\u201d = small) indicate that an object image has to be classified according to its size. \n\nBetween L1 and L2, half of the participants will be instructed to forget the objects of L1 using a cover-story (forget condition). The other half of the participants will be told to continue remembering the objects and to proceed to the second list (remember condition).\nAfter the learning phase of L1 and L2, participants will perform a visual working memory task for three minutes to purge short-term memory.\n\nIn the test phase, participants will be presented with all the object images from the learning phase (L1 and L2) and new object images. Participants will again be instructed to classify objects either according to their size or as containing a mechanism or not. \nImportantly, for half of the objects presented in the learning phase, the S-C mappings will be the same as in the learning phase (i.e., again size classification; item-specific classification repetition). For the other half of the old objects, the S-C mappings will switch (i.e., switch from size to mechanism classification; item-specific classification switches). \n\nClassification switches are therefore defined as item-specific switches of the S-C mappings between the learning (e.g., object should be classified according to its size in the learning phase) and the test phase (e.g., object should be classified as containing a mechanisms or not in the test phase). Classification repetitions are in turn defined as item-specific repetitions between the learning (object should be classified according to its size in the learning phase) and the test phase (object should also be classified according to its size in the test phase), respectively. \n\nTypically, RTs and error rates for item-specific classification repetitions between learning phase and test phase trials decrease as compared to classification switches (increase for classification switches). As a result, for trials in the test phase, RTs and error rates for item-specific classification switches are generally higher as compared to RTs for item-specific classification repetitions. We refer to these effects as item-specific S-C effects. Item-specific S-A effects describe a decrease in RTs and error rates for item-specific action repetitions as compared to classification switches in test trials, respectively. \n\nHow we aim to measure a DF effect on S-R associations\n\nWe use the difference in response times, RTs, and error rates between trials that require a classification switch and a classification repetition to determine a DF. In other words, we measure the strength of item-specific S-C effects in the forget as compared to the remember condition.\nIn a typical memory test for L1 and L2 in the list-method of DF, two findings can be observed: Participants in the forget condition recall fewer L1 items (L1 forgetting) and more L2 items (L2 enhancement) as compared to the remember condition.\nApplying these observations to the context of S-C associations we expect the following observations: If DF influences the retrieval of S-C associations, the performance difference between classification repetition and switch trials (see Hypotheses section) should be smaller in the forget as compared to the remember condition for L1 items (L1 forgetting). If DF enhances the learning of novel S-C associations, the performance difference between classification repetition and switch trials should be larger in the forget as compared to the remember condition for L2 items (L2 enhancement).\n\nPlease see the attached file for a PDF version of this pre-registration."}, "q4": {"extra": [], "value": "In the present study, item-specific S-C (or S-A) effects refer to a decrease in RTs and error rates for item-specific classification (or action) repetitions as compared to classification (or action) switches in test trials. If item-specific S-C associations are formed during the learning phase and are automatically retrieved in the corresponding test trial, responses during the test phase should be slower and less accurate for classification switches as compared to classification repetitions. However, we expect, that in the forget condition, these item-specific S-C effects are reduced for items from the to-be-forgotten list 1 (L1) and increased for list 2 (L2):\n\nH1a (L1 forgetting): The item-specific S-C effect in RTs (increased RTs for classification switches as compared to classification repetitions in the test phase) for L1 stimuli is smaller in the forget condition as compared with the remember condition. \n\nH1b (L1 forgetting): The item-specific S-C effect in error rates for L1 stimuli (increased error rates for classification switches as compared to classification repetitions in the test phase) is smaller in the forget condition as compared with the remember condition. \n\nH2a (L2 enhancement): The item-specific S-C effect of RTs in the test phase for L2 stimuli is stronger in the forget as compared to the remember condition. \n\nH2b (L2 enhancement): The item-specific S-C effect of error rates in the test phase for L2 associations is stronger in the forget as compared to the remember condition.\n\nFurthermore, despite not the main focus of the current study, we assume that DF also affects the retrieval/encoding of S-A associations (see detailed study details below): First, we hypothesize that the item-specific S-A effect in RTs for L1 stimuli is smaller in the forget condition as compared with the remember condition. Second, we predict that the item-specific S-A effect of RTs in the test phase for L2 stimuli is stronger in the forget as compared to the remember condition (as well as the corresponding effects for the error rates). A potential interaction between S-C and S-A effects and the forget/remember instruction is exploratively investigated.\n"}, "q5": {"extra": [], "value": "Experiment - A researcher randomly assigns treatments to study subjects, this includes field or lab experiments. This is also known as an intervention experiment and includes randomized controlled trials."}, "q6": {"extra": [], "value": ["For studies that involve human subjects, they will not know the treatment group to which they have been assigned."]}, "q7": {"extra": [], "value": ""}, "q8": {"value": {"question": {"extra": [], "value": "The experiment has a 2 x 2 x 2 design with item-specific stimulus-classification (short: classification; repetition vs. switch between learning and test) and item-specific stimulus-action (short: action; repetition vs. switch between learning and test) manipulated within participants and instruction (remember vs. forget condition) manipulated between participants. \n\nStimuli and Task\n\nThe experiment will be conducted in German. Images of objects serve as stimuli and depict everyday objects. Images of objects are drawn from a pool of 256 images that contains 64 stimuli of small and mechanical objects, 64 stimuli of large and mechanical objects, 64 stimuli of small and nonmechanical objects, and 64 stimuli of large and nonmechanical objects (256 pixels X 256 pixels, about 8\u00b0 visual angle). The participants\u2019 task is to classify the stimuli either as containing a mechanism or not (\u201cmechanisch\u201d, Engl. mechanic and \u201cnicht-mechanisch\u201d, Engl. Non-mechanic) or according to their size (\u201cGro\u00df\u201d, Engl. large and \u201cKlein\u201d, Engl. small) using a left or right response key. The trial structure is as follows: First, a task-cue is presented for 700 ms that indicates how to classify an object (mechanism or size) and as well as the classification-action mapping (e.g., left response for small, right response for large). For example, the task cue \u201cM + N\u201d indicates that an object image has to be classified as being either mechanic or not. At the same time, the task cue informs the participants that a left key press is required for mechanic objects and a right key press for non-mechanic ones. Conversely, the task cue \u201cN + M\u201d indicates that a right key press is required for mechanic objects and a left key press for non-mechanic ones. Instead, the task cues \u201cG + K\u201d or \u201cK + G\u201d (G for German \u201cgro\u00df\u201d = large, K for German \u201cklein\u201d = small) indicate that an object image has to be classified according to its size. \n\nThen, the stimulus (the image of an object) follows and the participants classify the stimulus using left or right key presses according to the class and action mapping provided by the preceding task-cue. Objects are displayed until a response (classifications via left/right key presses) is given or for a maximum of 2000 ms. Next, a feedback screen is presented  for 500 ms stating \u201crichtig!\u201d/ Eng: \u201ccorrect!\u201d for correct responses; \u201cFehler!\u201d/ Eng.: \u201cerror!\u201d for incorrect responses or  \u201czu langsam!\u201d/ Eng: \u201ctoo slow!\u201d in case of response omissions (responses outside the response frame).\n\nAs a result,  participants learn item-specific associations between the stimulus (object image) and the corresponding classification (size vs. mechanism; S-C associations) as well as between the stimulus and the corresponding action (left/right key press; S-A associations; see Moutsopoulou et al., 2015).\n\nProcedure\n\nParticipants are randomly assigned to either the remember condition or the forget condition (38 each). As described, there are three major phases: A learning phase (consisting of L1 and L2 as well as the remember/ forget instruction in-between L1 and L2), a distraction phase, and a test phase.  \n\nInstructions are given on the screen and summarized by an experimenter. After receiving the instructions regarding the classification task (see task description), participants are told to also remember the images of objects they classify. Crucially, participants are not instructed to learn any associations between the images, the classification, and their responses.\n\nIn a practice block consisting of eight additional object images, participants are familiarized with the task.\n\nLearning phase. The learning phase consists of two lists, list 1 (L1) and list 2 (L2) in which participants learn (not explicitly instructed) stimulus-classification (S-C) associations. \n\nIn total, they respond to 64 objects in L1 (presented 2 times, thus, 128 trials), and 64 different objects in L2 (presented 2 times, thus, 128 trials). In order to build stronger S-C associations, in L1 and L2, each stimulus is presented two times with the exact same S C mapping and S-A mapping (i.e., the same task cue): L1 and L2 each consist of two blocks and in each block the stimuli of the corresponding list are presented once (and thus two times in total). \n\nFirst, participants respond to all items in L1 in the two corresponding blocks. After L1, half of the participants are either instructed to forget or to remember L1. Then L2 follows. Thus, for participants in the forget condition, L1 consists of to-be-forgotten items (to measure L1 forgetting) and L2 of to-be-remembered items (to measure L2 enhancement; note, participants are not instructed to remember S-C associations but only the object images). For the remember condition, both L1 and L2 consist of to-be-remembered items. \n\nForget-condition: After L1 is learned, participants in the forget condition are instructed to forget the so-far-presented items. For this, after L1, a computer screen gives an arbitrary overview of the participant\u2019s performance and the current condition group the experiment was in. The participants are asked to go to the experimenter in order to continue the experiment in the next condition group. The experimenter then steps in, reads over the summary and apologizes for having accidentally started the experiment in the incorrect condition group. Thereupon, the experimenter leaves the room pretending to ask the leading researcher what to do next. The experimenter re-enters the room and informs the participants that they could restart the experiment in the correct condition group. The participants are kindly asked to start over again with the correct condition group. The participants are casually told to try to forget what they had just done (i.e., to forget the images but importantly no instruction is given on the S-C or S-A mappings). The experiment is restarted and the participants are again instructed to forget everything they have previously learned. The instruction emphasizes the importance of trying to forget the previously presented objects and only to concentrate on the subsequently to-be-categorized objects. The practice trials are skipped by the experimenter. \n\nRemember-condition. After L1 is learned, a screen is presented providing participants with the same arbitrary experimental overview as in the forget condition. Again, the experimenter has to enter the room to continue the experiment. In contrast to the forget condition, however, this time the participants are simply told that they finished the first part of the learning phase and are going to continue with the second part.\n\nBoth groups then respond to all items in L2 in the two corresponding blocks.\n\nDistractor phase. In a following distractor phase intended to purge short-term memory, participants solve a visual working memory task for three minutes. \n\nTest phase. In the test phase, participants are then presented with all objects from the learning phase (L1 and L2 regardless for both the remember or forget condition, thus, 128 old objects) and 128 new objects (total of 256 trials) over four blocks (64 trials each). Object order is randomized. Again, participants are instructed to classify the objects either according to their size or as containing a mechanism or not by pressing a left/right key.\nPer list of old items, L1 and L2, in the test phase, for half of the stimuli the required classification is the same as in the learning phase (classification repetition; see introduction), whereas it switches for the other half of the objects (classification switches). Importantly, to balance participants\u00b4 responses and possible influences of S-A associations, the required response (left/right key press) additionally repeat/switch between the learning and test instances of an object image in half of the trials per item-specific S-C repeat/switch condition. That is, there are four item-specific switch conditions between learning and test: full repetition: S-C and S-A repetition, action switch: S-C repetition and S-A switch, classification switch: S-C switch and S-A repetition, full switch: S-C and S-A switch. \n\nItems in the test phase are presented once. \n\nUsing post-experimental questions, we will check whether participants had any suspicion about the restart of the experiment. Participants are properly debriefed about the simulated experiment restart and the reason behind this deception. Last, they are asked not to tell friends and colleagues about the simulated experiment restart.\n"}, "uploader": {"extra": [{"data": {"name": "PreReg_DF_SC.pdf"}, "nodeId": "3cypq", "sha256": "95727f3e9a8c8f984784b486b6b585c4791c01113b6b15fb885c7fa0c83ab287", "viewUrl": "/project/akp5s/files/osfstorage/5e25edd2675e0e01796b4a51/", "selectedFileName": "PreReg_DF_SC.pdf"}], "value": ""}}}, "q9": {"extra": [], "value": "Participants are randomly assigned to either the remember condition or the forget condition (n = 38 each). \n\nFor the presentation of stimuli, for each participant three lists are randomly drawn from the pool of 256 stimuli without replacement: \n\n-\tone list of items for L1 (learning phase) containing 64 different objects with 16 objects of each stimulus category combination: mechanic and small, mechanic and large, non-mechanic and small, non-mechanic and large objects. Within each stimulus category combination, four objects are randomly allocated to each of the four item-specific classification-action switch conditions (i.e. per stimulus category combination, each possible task cue is realized once). Simultaneously, this balances the number of left/right responses per condition combination.\n\n-\tone list of items for L2 (learning phase) containing 64 different objects (different objects than in L1) with 16 objects of each stimulus category combination of which in turn four objects are randomly allocated to each of the four item-specific classification-action switch conditions (see description for L1 above). \n\n-\tone list of items for the test phase consisting of all old objects (L1 and L2, 128 objects) as well as 128 additional, novel objects (32 for each category combination; total of 256 objects). Novel stimuli introduced in the test phase again feature the four stimulus category combinations and per stimulus category combination both classification tasks, the possible task cues, and the two possible required responses occur equally often. \n\nAs described, in L1 as well as L2, each stimulus is paired with the same corresponding classification and action two times: L1 and L2 each consist of two blocks and in each block the stimuli of the corresponding list are presented once (and thus two times in total). While the required classification and action for each stimulus remains the same across the two repetition blocks for the stimuli in L1 as well as across the two repetition blocks for the stimuli in L2, the order of presented stimuli is independently randomized in each block. \nIn sum, in the test phase, for old items of L1 and L2, each of the four item-specific switch conditions occurs equally often and per item-specific switch condition, each possible task cue and key press required for a correct response occur equally often. The order of the presented stimuli (old and new) in the test-phase is randomized trial-by-trial across blocks for every participant.\n\nTherefore, the design is fully matched and participants cannot make any predictions about the test phase.\n"}, "q10": {"extra": [], "value": "Registration prior to creation of data"}, "q11": {"extra": [], "value": ""}, "q12": {"value": {"question": {"extra": [], "value": "Participants will be recruited via a local web-based study participation platform where participants can sign up for studies they qualify for on the system. In exchange for their participation, participants will receive monetary compensation (the expected duration is 45 minutes, 6 EUR). "}, "uploader": {"extra": [], "value": ""}}}, "q13": {"extra": [], "value": "76"}, "q14": {"extra": [], "value": "In two experiments conducted by Dreisbach and B\u00e4uml (2014), which is the only study which partly mirrors our design (though for S-A associations and not S-C associations), a partial eta squared of \u03b7p2 = .14 and \u03b7p2 = .06 was observed for the critical interaction between instruction (forget vs. remember) and item-specific compatibility (in the current study: item-specific classification, repetition vs. switch) in the RT analyses (see analysis plan). Power analyses using G*Power (Faul, Erdfelder, Lang, &amp; Buchner, 2007) on the mean \u03b7p2 = .10 suggested a sample size of N=76 to detect a significant effect (with \u03b1 = .05 with 1-\u03b2 = .80)."}, "q15": {"extra": [], "value": ""}, "q16": {"value": {"question": {"extra": [], "value": "Item-specific classification (repetition vs. switch between learning and test phase) and item-specific action (repetition vs. switch between learning and test phase) manipulated within participants, forget vs. remember condition (between), list (L1 vs. L2)"}, "uploader": {"extra": [], "value": ""}}}, "q17": {"value": {"question": {"extra": [], "value": "We will measure reaction times and error rates of items from L1 and L2 in the test phase.\n\nIn addition, we will collect some demographic data (e.g., age, gender) and information on participants\u2019 motivation at the end of the experiment. However, we will not use these measures in confirmatory analyses. Last, using post-experimental questions, we will assess whether participants had any suspicion about the restart of the experiment.\n"}, "uploader": {"extra": [], "value": ""}}}, "q18": {"value": {"question": {"extra": [], "value": "For a descriptive analysis, we will calculate the percentage of correct responses and mean reaction time for all design cells separately for L1 and L2."}, "uploader": {"extra": [], "value": ""}}}, "q19": {"value": {"question": {"extra": [], "value": "For the RTs analysis, for L1 and L2 items separately, we will fit a linear mixed model (LMM) on participants\u2019 RTs in the test phase with item-specific classification (repetition vs. switch, within), action (repetition vs. switch, within),  and instruction (remember vs. forget condition, between) as well as the corresponding interaction between instruction and action as well as classification as fixed effects and the maximal random effects structure . The maximal random effects structure for our design is given by random intercepts for participants and objects and by-participant random slopes for classification (repetition vs. switch) as well as action (repetition vs. switch) including their interaction and by object random slopes for classification, action, and instruction (and their interaction). In case the models do not converge, we will first remove the correlation among random slopes and then stepwise remove random slopes (beginning with by-object random slopes; then the highest-order interaction term, the second lowest interaction term, and so on \u2013 the same procedure for by-participant random slopes) until the models converge. For the analyses of errors, we will fit a generalized mixed model (GLMM) on participants\u2019 responses\u2019 correctness in the test phase with item-specific classification (repetition vs. switch, within), action (repetition vs. switch, within),  and instruction (remember vs. forget condition, between) as well as the corresponding interaction as fixed effects separated for L1 and L2 items with binomial errors distribution and a logistic linking function. Otherwise, the procedure will be the same as for the RT analyses."}, "uploader": {"extra": [], "value": ""}}}, "q20": {"extra": [], "value": ""}, "q21": {"extra": [], "value": "For the RT analysis and the LMM, we will evaluate the significance of the fixed effect using the Kenward-Roger approximation to estimate the denominator degrees of freedom with the standard p &lt; .05 criterion. For the GLMM and the error analyses, we will use parametric bootstrap comparisons."}, "q22": {"extra": [], "value": "The following exclusion criteria on a participant level (participants who will be completely excluded from the analysis) will be applied: First, participants who report that they did not follow the instructions (e.g., using only one instead of both hands to respond) will not be considered in the analyses. Second, participants will be excluded from all analyses when they committed errors or response omissions in more than 30% of the trials in the learning or test phase. All these participants will be replaced by new ones. On a trial level (trials that will be excluded but the participants remain for the analysis) the following data will be excluded: First, trials with response omissions will be discarded. Second, for the analyses of trials in the test phase only the trials with correct responses in the corresponding trials in the learning phase will be used. In addition, the trials from the practice blocks will be removed. Third, trials with exceptionally high or low RTs that is, trials with RTs above/below 3SD from the individual cell mean will be discarded. Participants who then have less than six observations per cell will also be excluded from the analyses and will be replaced. Using post-experimental questions, we will check whether participants had any suspicion about the restart of the experiment. Participants who report having suspected that the restart was an experimental manipulation will be replaced. All participants excluded by the means of these exclusion criteria will be directly replaced."}, "q23": {"extra": [], "value": "Participants who do not complete the whole experiment will be excluded and directly replaced. "}, "q24": {"extra": [], "value": "In explorative analyses, for both the model of RTs and error rates, we will investigate a potential three-way interaction between action, classification, instruction."}, "q25": {"extra": [], "value": "Please see the attached file for a PDF version of this pre-registration.\n\nReferences\n\nDreisbach, G., &amp; B\u00e4uml, K. H. T. (2014). Don\u2019t do it again! Directed forgetting of habits. Psychological Science, 25(6), 1242\u20131248. https://doi.org/10.1177/0956797614526063 \n\nHockley, W. E., Ahmad, F. N., &amp; Nicholson, R. (2016). Intentional and incidental encoding of item and associative information in the directed forgetting procedure. Memory &amp; Cognition, 44(2), 220\u2013228. https://doi.org/10.3758/s13421-015-0557-8 \n\nHsu, Y. F., &amp; Waszak, F. (2012). Stimulus-classification traces are dominant in response learning. International Journal of Psychophysiology, 86(3), 262\u2013268. https://doi.org/10.1016/j.ijpsycho.2012.10.002\n\nJou, J. (2010). Can associative information be strategically separated from item information in word-pair recognition? Psychonomic Bulletin &amp; Review, 17(6), 778\u2013783. https://doi.org/10.3758/PBR.17.6.778 \n\nLogan, G. D. (1988). Toward an instance theory of automatization. Psychological Review, 95, 492\u2013527. http://dx.doi.org/10.1037/0033-295X.95.4.492\n\nLogan, G. D. (1990). Repetition priming and automaticity: Common underlying mechanisms? Cognitive Psychology, 22, 1\u201335. http://dx.doi.org/10.1016/0010-0285(90)90002-L\n\nMontagliani, A., &amp; Hockley, W. E. (2019). Item-based directed forgetting for categorized lists: Forgetting of words that were not presented. Canadian Journal of Experimental Psychology/Revue Canadienne de Psychologie Exp\u00e9rimentale, 73(3), 135-143.\n\nMoutsopoulou, K., Yang, Q., Desantis, A., &amp; Waszak, F. (2015). Stimulus\u2013classification and stimulus\u2013action associations: Effects of repetition learning and durability. The Quarterly Journal of Experimental Psychology, 68(9), 1744\u20131757. https://doi.org/10.1080/17470218.2014.984232\n\nPast\u00f6tter, B., Tempel, T., &amp; B\u00e4uml, K. H. T. (2017). Long-term memory updating: The reset-of-encoding hypothesis in list-method directed forgetting. Frontiers in Psychology, 8, 2076. https://doi.org/10.3389/fpsyg.2017.02076 \n\nPfeuffer, C. U., Moutsopoulou, K., Pfister, R., Waszak, F., &amp; Kiesel, A. (2017). The power of words: On item-specific stimulus\u2013response associations formed in the absence of action. Journal of Experimental Psychology: Human Perception and Performance, 43(2), 328\u2013347. https://doi.org/10.1037/xhp0000317\n\nPfeuffer, C. U., Moutsopoulou, K., Waszak, F., &amp; Kiesel, A. (2019). Execution-based and verbal code-based stimulus\u2013response associations: Proportion manipulations reveal conflict adaptation processes in item-specific priming. Psychological Research, 1-24. doi:10.1007/s00426-019-01220-3\n"}}, "registration_responses": {"q1": "Directed Forgetting of Stimulus\u2013 Classification Associations", "q2": "Hannah Dames, Lars Link, Andrea Kiesel, Christina U. Pfeuffer, Marco Ragni", "q3": "Humans are able to intentionally forget previously learned information: In the list-method of DF (for an overview see Past\u00f6tter, Tempel, &amp; B\u00e4uml, 2017), for instance, participants are instructed to sequentially learn two lists of items. After learning the first list (referred to as L1), participants are either instructed to forget or to continue remembering this list before learning list 2 (L2). In a memory test for both lists, two findings can be observed: Participants in the forget condition recall fewer L1 items (L1 forgetting) and more L2 items (L2 enhancement) as compared to the remember condition.\n\nWhereas various studies have already demonstrated that humans are able to intentionally forget previously learned information (as often measured using the directed forgetting, short DF, paradigm, for an overview see Past\u00f6tter, Tempel, &amp; B\u00e4uml, 2017), only few studies have investigated how DF affects stimulus-response (S-R) associations (Dreisbach &amp; B\u00e4uml, 2014) or incidentally learned information (e.g., Hockley, Ahmad, &amp; Nicholson, 2016; Jou, 2010). \n\nS-R associations are formed when stimuli and responses repeatedly co-occur and thus bind together \u2013 a notion that is supported by (item-specific) repetition priming effects (see Logan, 1988, 1990). Here, participants\u2019 responses are, for instance, generally faster for items that require the same as opposed to a different, previously executed response. Such item-specific S-R effects are in turn composed of item-specific stimulus\u2013action (S-A) and stimulus\u2013classification (S-C) effects: In general, S-R associations can be divided into two components, S-A associations between stimuli and motor outputs and S-C associations between stimuli and their task-specific semantic classifications (see Hsu &amp; Waszak, 2012; Moutsopoulou et al., 2015). These two components of S-R associations are assumed to be independent (e.g., Pfeuffer, Moutsopoulou, Waszak, &amp; Kiesel, 2019). \n\nWhile to the best of our knowledge only one study has demonstrated that people are able to intentionally forget S-R associations (here, S-A associations), no study has systematically investigated how DF affects S-C associations \u2013 something we aim to investigate in the present study. \n\nA promising hint, that people may be able to intentionally forget S-C associations, is delivered by  recent studies providing first evidence that effects of DF for categorized word lists can extend beyond the individual study items to the level of category information (see Montagliani &amp; Hockley, 2019). The current study aims to gain a deeper understanding of the mechanisms underlying the DF effect on not explicitly instructed and implicitly tested associations between a stimulus and its task-specific classification. For this, we will apply the DF list-method on learned stimulus-classification (S-C) associations drawing on an item-specific priming paradigm (see below and also Hsu &amp; Waszak, 2012; Moutsopoulou, Yang, Desantis, &amp; Waszak., 2015).\n\nOn S\u2013C associations (see Hsu &amp; Waszak, 2012; Moutsopoulou et al., 2015): In an experimental setting, S-C associations are learned when, for instance, participants classify a stimulus according to a classification task (e.g., size \u2013 small/large; mechanism \u2013 mechanic/non-mechanic). S-C associations therefore refer to associations between a stimulus and its task-specific sematic classification. \n\nUsing an item-specific priming paradigm, we will investigate how a DF instruction affects the encoding/retrieval of such S-C associations. For this, we will investigate whether (not explicitly instructed) learned S-C associations can be intentionally forgotten by employing a DF paradigm that allows the simultaneous measurement of S-C retrieval. \n\nShort introduction of and information on the task and study design\n\nIn this study, we are extending the DF paradigm to S-C mappings by drawing on an item-specific priming paradigm (e.g., Hsu &amp; Waszak, 2012; Moutsopoulou, Yang, Desantis, &amp; Waszak, 2015; Pfeuffer, Moutsopoulou, Pfister, Waszak, &amp; Kiesel, 2017) that will allow us to assess the encoding/retrieval of S-C associations (according to the terminology provided by Moutsopoulou et al., 2015).  Our study will consist of three major phases: A learning phase, a distraction phase, and a test phase. \n\nDuring the learning phase, participants categorize images of objects of two lists (L1 and L2) either according to their size or as containing a mechanism or not. By actively classifying objects pressing a left/right key, participants will form S-C associations. Additionally, they will be instructed to remember the objects. \n\nAn equal number of object images will fall into the four possible category combinations (size: small/large X mechanism: mechanic/non-mechanic). Importantly, the required classification task for an object (mechanic/not-mechanic vs. large/small) will differ between the stimuli. Item-specific task cues at the beginning of a trial inform the participant what type of classification should be used, and also which action is required to classify an object accordingly. For example, the task cue \u201cM + N\u201d indicates that an object image has to be classified as being either mechanic or not. At the same time, the task cue informs the participants that the object can be classified as mechanic by pressing a left key and a right key for the classification \u201cnon-mechanic\u201d. Conversely, the task cue \u201cN + M\u201d indicates that a right key press is required for mechanic objects and a left key press for non-mechanic ones. Instead, the task cues \u201cG + K\u201d or \u201cK + G\u201d (G for German \u201cgro\u00df\u201d = large, K for German \u201cklein\u201d = small) indicate that an object image has to be classified according to its size. \n\nBetween L1 and L2, half of the participants will be instructed to forget the objects of L1 using a cover-story (forget condition). The other half of the participants will be told to continue remembering the objects and to proceed to the second list (remember condition).\nAfter the learning phase of L1 and L2, participants will perform a visual working memory task for three minutes to purge short-term memory.\n\nIn the test phase, participants will be presented with all the object images from the learning phase (L1 and L2) and new object images. Participants will again be instructed to classify objects either according to their size or as containing a mechanism or not. \nImportantly, for half of the objects presented in the learning phase, the S-C mappings will be the same as in the learning phase (i.e., again size classification; item-specific classification repetition). For the other half of the old objects, the S-C mappings will switch (i.e., switch from size to mechanism classification; item-specific classification switches). \n\nClassification switches are therefore defined as item-specific switches of the S-C mappings between the learning (e.g., object should be classified according to its size in the learning phase) and the test phase (e.g., object should be classified as containing a mechanisms or not in the test phase). Classification repetitions are in turn defined as item-specific repetitions between the learning (object should be classified according to its size in the learning phase) and the test phase (object should also be classified according to its size in the test phase), respectively. \n\nTypically, RTs and error rates for item-specific classification repetitions between learning phase and test phase trials decrease as compared to classification switches (increase for classification switches). As a result, for trials in the test phase, RTs and error rates for item-specific classification switches are generally higher as compared to RTs for item-specific classification repetitions. We refer to these effects as item-specific S-C effects. Item-specific S-A effects describe a decrease in RTs and error rates for item-specific action repetitions as compared to classification switches in test trials, respectively. \n\nHow we aim to measure a DF effect on S-R associations\n\nWe use the difference in response times, RTs, and error rates between trials that require a classification switch and a classification repetition to determine a DF. In other words, we measure the strength of item-specific S-C effects in the forget as compared to the remember condition.\nIn a typical memory test for L1 and L2 in the list-method of DF, two findings can be observed: Participants in the forget condition recall fewer L1 items (L1 forgetting) and more L2 items (L2 enhancement) as compared to the remember condition.\nApplying these observations to the context of S-C associations we expect the following observations: If DF influences the retrieval of S-C associations, the performance difference between classification repetition and switch trials (see Hypotheses section) should be smaller in the forget as compared to the remember condition for L1 items (L1 forgetting). If DF enhances the learning of novel S-C associations, the performance difference between classification repetition and switch trials should be larger in the forget as compared to the remember condition for L2 items (L2 enhancement).\n\nPlease see the attached file for a PDF version of this pre-registration.", "q4": "In the present study, item-specific S-C (or S-A) effects refer to a decrease in RTs and error rates for item-specific classification (or action) repetitions as compared to classification (or action) switches in test trials. If item-specific S-C associations are formed during the learning phase and are automatically retrieved in the corresponding test trial, responses during the test phase should be slower and less accurate for classification switches as compared to classification repetitions. However, we expect, that in the forget condition, these item-specific S-C effects are reduced for items from the to-be-forgotten list 1 (L1) and increased for list 2 (L2):\n\nH1a (L1 forgetting): The item-specific S-C effect in RTs (increased RTs for classification switches as compared to classification repetitions in the test phase) for L1 stimuli is smaller in the forget condition as compared with the remember condition. \n\nH1b (L1 forgetting): The item-specific S-C effect in error rates for L1 stimuli (increased error rates for classification switches as compared to classification repetitions in the test phase) is smaller in the forget condition as compared with the remember condition. \n\nH2a (L2 enhancement): The item-specific S-C effect of RTs in the test phase for L2 stimuli is stronger in the forget as compared to the remember condition. \n\nH2b (L2 enhancement): The item-specific S-C effect of error rates in the test phase for L2 associations is stronger in the forget as compared to the remember condition.\n\nFurthermore, despite not the main focus of the current study, we assume that DF also affects the retrieval/encoding of S-A associations (see detailed study details below): First, we hypothesize that the item-specific S-A effect in RTs for L1 stimuli is smaller in the forget condition as compared with the remember condition. Second, we predict that the item-specific S-A effect of RTs in the test phase for L2 stimuli is stronger in the forget as compared to the remember condition (as well as the corresponding effects for the error rates). A potential interaction between S-C and S-A effects and the forget/remember instruction is exploratively investigated.\n", "q5": "Experiment - A researcher randomly assigns treatments to study subjects, this includes field or lab experiments. This is also known as an intervention experiment and includes randomized controlled trials.", "q6": ["For studies that involve human subjects, they will not know the treatment group to which they have been assigned."], "q7": "", "q9": "Participants are randomly assigned to either the remember condition or the forget condition (n = 38 each). \n\nFor the presentation of stimuli, for each participant three lists are randomly drawn from the pool of 256 stimuli without replacement: \n\n-\tone list of items for L1 (learning phase) containing 64 different objects with 16 objects of each stimulus category combination: mechanic and small, mechanic and large, non-mechanic and small, non-mechanic and large objects. Within each stimulus category combination, four objects are randomly allocated to each of the four item-specific classification-action switch conditions (i.e. per stimulus category combination, each possible task cue is realized once). Simultaneously, this balances the number of left/right responses per condition combination.\n\n-\tone list of items for L2 (learning phase) containing 64 different objects (different objects than in L1) with 16 objects of each stimulus category combination of which in turn four objects are randomly allocated to each of the four item-specific classification-action switch conditions (see description for L1 above). \n\n-\tone list of items for the test phase consisting of all old objects (L1 and L2, 128 objects) as well as 128 additional, novel objects (32 for each category combination; total of 256 objects). Novel stimuli introduced in the test phase again feature the four stimulus category combinations and per stimulus category combination both classification tasks, the possible task cues, and the two possible required responses occur equally often. \n\nAs described, in L1 as well as L2, each stimulus is paired with the same corresponding classification and action two times: L1 and L2 each consist of two blocks and in each block the stimuli of the corresponding list are presented once (and thus two times in total). While the required classification and action for each stimulus remains the same across the two repetition blocks for the stimuli in L1 as well as across the two repetition blocks for the stimuli in L2, the order of presented stimuli is independently randomized in each block. \nIn sum, in the test phase, for old items of L1 and L2, each of the four item-specific switch conditions occurs equally often and per item-specific switch condition, each possible task cue and key press required for a correct response occur equally often. The order of the presented stimuli (old and new) in the test-phase is randomized trial-by-trial across blocks for every participant.\n\nTherefore, the design is fully matched and participants cannot make any predictions about the test phase.\n", "q10": "Registration prior to creation of data", "q11": "", "q13": "76", "q14": "In two experiments conducted by Dreisbach and B\u00e4uml (2014), which is the only study which partly mirrors our design (though for S-A associations and not S-C associations), a partial eta squared of \u03b7p2 = .14 and \u03b7p2 = .06 was observed for the critical interaction between instruction (forget vs. remember) and item-specific compatibility (in the current study: item-specific classification, repetition vs. switch) in the RT analyses (see analysis plan). Power analyses using G*Power (Faul, Erdfelder, Lang, &amp; Buchner, 2007) on the mean \u03b7p2 = .10 suggested a sample size of N=76 to detect a significant effect (with \u03b1 = .05 with 1-\u03b2 = .80).", "q15": "", "q20": "", "q21": "For the RT analysis and the LMM, we will evaluate the significance of the fixed effect using the Kenward-Roger approximation to estimate the denominator degrees of freedom with the standard p &lt; .05 criterion. For the GLMM and the error analyses, we will use parametric bootstrap comparisons.", "q22": "The following exclusion criteria on a participant level (participants who will be completely excluded from the analysis) will be applied: First, participants who report that they did not follow the instructions (e.g., using only one instead of both hands to respond) will not be considered in the analyses. Second, participants will be excluded from all analyses when they committed errors or response omissions in more than 30% of the trials in the learning or test phase. All these participants will be replaced by new ones. On a trial level (trials that will be excluded but the participants remain for the analysis) the following data will be excluded: First, trials with response omissions will be discarded. Second, for the analyses of trials in the test phase only the trials with correct responses in the corresponding trials in the learning phase will be used. In addition, the trials from the practice blocks will be removed. Third, trials with exceptionally high or low RTs that is, trials with RTs above/below 3SD from the individual cell mean will be discarded. Participants who then have less than six observations per cell will also be excluded from the analyses and will be replaced. Using post-experimental questions, we will check whether participants had any suspicion about the restart of the experiment. Participants who report having suspected that the restart was an experimental manipulation will be replaced. All participants excluded by the means of these exclusion criteria will be directly replaced.", "q23": "Participants who do not complete the whole experiment will be excluded and directly replaced. ", "q24": "In explorative analyses, for both the model of RTs and error rates, we will investigate a potential three-way interaction between action, classification, instruction.", "q25": "Please see the attached file for a PDF version of this pre-registration.\n\nReferences\n\nDreisbach, G., &amp; B\u00e4uml, K. H. T. (2014). Don\u2019t do it again! Directed forgetting of habits. Psychological Science, 25(6), 1242\u20131248. https://doi.org/10.1177/0956797614526063 \n\nHockley, W. E., Ahmad, F. N., &amp; Nicholson, R. (2016). Intentional and incidental encoding of item and associative information in the directed forgetting procedure. Memory &amp; Cognition, 44(2), 220\u2013228. https://doi.org/10.3758/s13421-015-0557-8 \n\nHsu, Y. F., &amp; Waszak, F. (2012). Stimulus-classification traces are dominant in response learning. International Journal of Psychophysiology, 86(3), 262\u2013268. https://doi.org/10.1016/j.ijpsycho.2012.10.002\n\nJou, J. (2010). Can associative information be strategically separated from item information in word-pair recognition? Psychonomic Bulletin &amp; Review, 17(6), 778\u2013783. https://doi.org/10.3758/PBR.17.6.778 \n\nLogan, G. D. (1988). Toward an instance theory of automatization. Psychological Review, 95, 492\u2013527. http://dx.doi.org/10.1037/0033-295X.95.4.492\n\nLogan, G. D. (1990). Repetition priming and automaticity: Common underlying mechanisms? Cognitive Psychology, 22, 1\u201335. http://dx.doi.org/10.1016/0010-0285(90)90002-L\n\nMontagliani, A., &amp; Hockley, W. E. (2019). Item-based directed forgetting for categorized lists: Forgetting of words that were not presented. Canadian Journal of Experimental Psychology/Revue Canadienne de Psychologie Exp\u00e9rimentale, 73(3), 135-143.\n\nMoutsopoulou, K., Yang, Q., Desantis, A., &amp; Waszak, F. (2015). Stimulus\u2013classification and stimulus\u2013action associations: Effects of repetition learning and durability. The Quarterly Journal of Experimental Psychology, 68(9), 1744\u20131757. https://doi.org/10.1080/17470218.2014.984232\n\nPast\u00f6tter, B., Tempel, T., &amp; B\u00e4uml, K. H. T. (2017). Long-term memory updating: The reset-of-encoding hypothesis in list-method directed forgetting. Frontiers in Psychology, 8, 2076. https://doi.org/10.3389/fpsyg.2017.02076 \n\nPfeuffer, C. U., Moutsopoulou, K., Pfister, R., Waszak, F., &amp; Kiesel, A. (2017). The power of words: On item-specific stimulus\u2013response associations formed in the absence of action. Journal of Experimental Psychology: Human Perception and Performance, 43(2), 328\u2013347. https://doi.org/10.1037/xhp0000317\n\nPfeuffer, C. U., Moutsopoulou, K., Waszak, F., &amp; Kiesel, A. (2019). Execution-based and verbal code-based stimulus\u2013response associations: Proportion manipulations reveal conflict adaptation processes in item-specific priming. Psychological Research, 1-24. doi:10.1007/s00426-019-01220-3\n", "q8.question": "The experiment has a 2 x 2 x 2 design with item-specific stimulus-classification (short: classification; repetition vs. switch between learning and test) and item-specific stimulus-action (short: action; repetition vs. switch between learning and test) manipulated within participants and instruction (remember vs. forget condition) manipulated between participants. \n\nStimuli and Task\n\nThe experiment will be conducted in German. Images of objects serve as stimuli and depict everyday objects. Images of objects are drawn from a pool of 256 images that contains 64 stimuli of small and mechanical objects, 64 stimuli of large and mechanical objects, 64 stimuli of small and nonmechanical objects, and 64 stimuli of large and nonmechanical objects (256 pixels X 256 pixels, about 8\u00b0 visual angle). The participants\u2019 task is to classify the stimuli either as containing a mechanism or not (\u201cmechanisch\u201d, Engl. mechanic and \u201cnicht-mechanisch\u201d, Engl. Non-mechanic) or according to their size (\u201cGro\u00df\u201d, Engl. large and \u201cKlein\u201d, Engl. small) using a left or right response key. The trial structure is as follows: First, a task-cue is presented for 700 ms that indicates how to classify an object (mechanism or size) and as well as the classification-action mapping (e.g., left response for small, right response for large). For example, the task cue \u201cM + N\u201d indicates that an object image has to be classified as being either mechanic or not. At the same time, the task cue informs the participants that a left key press is required for mechanic objects and a right key press for non-mechanic ones. Conversely, the task cue \u201cN + M\u201d indicates that a right key press is required for mechanic objects and a left key press for non-mechanic ones. Instead, the task cues \u201cG + K\u201d or \u201cK + G\u201d (G for German \u201cgro\u00df\u201d = large, K for German \u201cklein\u201d = small) indicate that an object image has to be classified according to its size. \n\nThen, the stimulus (the image of an object) follows and the participants classify the stimulus using left or right key presses according to the class and action mapping provided by the preceding task-cue. Objects are displayed until a response (classifications via left/right key presses) is given or for a maximum of 2000 ms. Next, a feedback screen is presented  for 500 ms stating \u201crichtig!\u201d/ Eng: \u201ccorrect!\u201d for correct responses; \u201cFehler!\u201d/ Eng.: \u201cerror!\u201d for incorrect responses or  \u201czu langsam!\u201d/ Eng: \u201ctoo slow!\u201d in case of response omissions (responses outside the response frame).\n\nAs a result,  participants learn item-specific associations between the stimulus (object image) and the corresponding classification (size vs. mechanism; S-C associations) as well as between the stimulus and the corresponding action (left/right key press; S-A associations; see Moutsopoulou et al., 2015).\n\nProcedure\n\nParticipants are randomly assigned to either the remember condition or the forget condition (38 each). As described, there are three major phases: A learning phase (consisting of L1 and L2 as well as the remember/ forget instruction in-between L1 and L2), a distraction phase, and a test phase.  \n\nInstructions are given on the screen and summarized by an experimenter. After receiving the instructions regarding the classification task (see task description), participants are told to also remember the images of objects they classify. Crucially, participants are not instructed to learn any associations between the images, the classification, and their responses.\n\nIn a practice block consisting of eight additional object images, participants are familiarized with the task.\n\nLearning phase. The learning phase consists of two lists, list 1 (L1) and list 2 (L2) in which participants learn (not explicitly instructed) stimulus-classification (S-C) associations. \n\nIn total, they respond to 64 objects in L1 (presented 2 times, thus, 128 trials), and 64 different objects in L2 (presented 2 times, thus, 128 trials). In order to build stronger S-C associations, in L1 and L2, each stimulus is presented two times with the exact same S C mapping and S-A mapping (i.e., the same task cue): L1 and L2 each consist of two blocks and in each block the stimuli of the corresponding list are presented once (and thus two times in total). \n\nFirst, participants respond to all items in L1 in the two corresponding blocks. After L1, half of the participants are either instructed to forget or to remember L1. Then L2 follows. Thus, for participants in the forget condition, L1 consists of to-be-forgotten items (to measure L1 forgetting) and L2 of to-be-remembered items (to measure L2 enhancement; note, participants are not instructed to remember S-C associations but only the object images). For the remember condition, both L1 and L2 consist of to-be-remembered items. \n\nForget-condition: After L1 is learned, participants in the forget condition are instructed to forget the so-far-presented items. For this, after L1, a computer screen gives an arbitrary overview of the participant\u2019s performance and the current condition group the experiment was in. The participants are asked to go to the experimenter in order to continue the experiment in the next condition group. The experimenter then steps in, reads over the summary and apologizes for having accidentally started the experiment in the incorrect condition group. Thereupon, the experimenter leaves the room pretending to ask the leading researcher what to do next. The experimenter re-enters the room and informs the participants that they could restart the experiment in the correct condition group. The participants are kindly asked to start over again with the correct condition group. The participants are casually told to try to forget what they had just done (i.e., to forget the images but importantly no instruction is given on the S-C or S-A mappings). The experiment is restarted and the participants are again instructed to forget everything they have previously learned. The instruction emphasizes the importance of trying to forget the previously presented objects and only to concentrate on the subsequently to-be-categorized objects. The practice trials are skipped by the experimenter. \n\nRemember-condition. After L1 is learned, a screen is presented providing participants with the same arbitrary experimental overview as in the forget condition. Again, the experimenter has to enter the room to continue the experiment. In contrast to the forget condition, however, this time the participants are simply told that they finished the first part of the learning phase and are going to continue with the second part.\n\nBoth groups then respond to all items in L2 in the two corresponding blocks.\n\nDistractor phase. In a following distractor phase intended to purge short-term memory, participants solve a visual working memory task for three minutes. \n\nTest phase. In the test phase, participants are then presented with all objects from the learning phase (L1 and L2 regardless for both the remember or forget condition, thus, 128 old objects) and 128 new objects (total of 256 trials) over four blocks (64 trials each). Object order is randomized. Again, participants are instructed to classify the objects either according to their size or as containing a mechanism or not by pressing a left/right key.\nPer list of old items, L1 and L2, in the test phase, for half of the stimuli the required classification is the same as in the learning phase (classification repetition; see introduction), whereas it switches for the other half of the objects (classification switches). Importantly, to balance participants\u00b4 responses and possible influences of S-A associations, the required response (left/right key press) additionally repeat/switch between the learning and test instances of an object image in half of the trials per item-specific S-C repeat/switch condition. That is, there are four item-specific switch conditions between learning and test: full repetition: S-C and S-A repetition, action switch: S-C repetition and S-A switch, classification switch: S-C switch and S-A repetition, full switch: S-C and S-A switch. \n\nItems in the test phase are presented once. \n\nUsing post-experimental questions, we will check whether participants had any suspicion about the restart of the experiment. Participants are properly debriefed about the simulated experiment restart and the reason behind this deception. Last, they are asked not to tell friends and colleagues about the simulated experiment restart.\n", "q8.uploader": [{"file_id": "5e25edd2675e0e01796b4a51", "file_name": "PreReg_DF_SC.pdf", "file_urls": {"html": "https://osf.io/project/akp5s/files/osfstorage/5e25edd2675e0e01796b4a51", "download": "https://osf.io/download/5e25edd2675e0e01796b4a51"}, "file_hashes": {"sha256": "95727f3e9a8c8f984784b486b6b585c4791c01113b6b15fb885c7fa0c83ab287"}}], "q12.question": "Participants will be recruited via a local web-based study participation platform where participants can sign up for studies they qualify for on the system. In exchange for their participation, participants will receive monetary compensation (the expected duration is 45 minutes, 6 EUR). ", "q12.uploader": [], "q16.question": "Item-specific classification (repetition vs. switch between learning and test phase) and item-specific action (repetition vs. switch between learning and test phase) manipulated within participants, forget vs. remember condition (between), list (L1 vs. L2)", "q16.uploader": [], "q17.question": "We will measure reaction times and error rates of items from L1 and L2 in the test phase.\n\nIn addition, we will collect some demographic data (e.g., age, gender) and information on participants\u2019 motivation at the end of the experiment. However, we will not use these measures in confirmatory analyses. Last, using post-experimental questions, we will assess whether participants had any suspicion about the restart of the experiment.\n", "q17.uploader": [], "q18.question": "For a descriptive analysis, we will calculate the percentage of correct responses and mean reaction time for all design cells separately for L1 and L2.", "q18.uploader": [], "q19.question": "For the RTs analysis, for L1 and L2 items separately, we will fit a linear mixed model (LMM) on participants\u2019 RTs in the test phase with item-specific classification (repetition vs. switch, within), action (repetition vs. switch, within),  and instruction (remember vs. forget condition, between) as well as the corresponding interaction between instruction and action as well as classification as fixed effects and the maximal random effects structure . The maximal random effects structure for our design is given by random intercepts for participants and objects and by-participant random slopes for classification (repetition vs. switch) as well as action (repetition vs. switch) including their interaction and by object random slopes for classification, action, and instruction (and their interaction). In case the models do not converge, we will first remove the correlation among random slopes and then stepwise remove random slopes (beginning with by-object random slopes; then the highest-order interaction term, the second lowest interaction term, and so on \u2013 the same procedure for by-participant random slopes) until the models converge. For the analyses of errors, we will fit a generalized mixed model (GLMM) on participants\u2019 responses\u2019 correctness in the test phase with item-specific classification (repetition vs. switch, within), action (repetition vs. switch, within),  and instruction (remember vs. forget condition, between) as well as the corresponding interaction as fixed effects separated for L1 and L2 items with binomial errors distribution and a logistic linking function. Otherwise, the procedure will be the same as for the RT analyses.", "q19.uploader": []}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/akp5s/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/akp5s/comments/?format=json&filter%5Btarget%5D=akp5s", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/akp5s/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/akp5s/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/akp5s/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/akp5s/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/akp5s/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/akp5s/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/akp5s/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/akp5s/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/akp5s/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/akp5s/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/akp5s/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/akp5s/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/de-1/?format=json", "meta": {}}}, "data": {"id": "de-1", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/akp5s/?format=json", "meta": {}}}, "data": {"id": "akp5s", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/akp5s/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/akp5s/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/akp5s/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/akp5s/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/akp5s/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/akp5s/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/akp5s/citation/?format=json", "meta": {}}}, "data": {"id": "akp5s", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/sqn4s/?format=json", "meta": {}}}, "data": {"id": "sqn4s", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/3cypq/?format=json", "meta": {}}}, "data": {"id": "3cypq", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5c08457ed283380029cf73bf/?format=json", "meta": {}}}, "data": {"id": "5c08457ed283380029cf73bf", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/akp5s/", "self": "https://api.osf.io/v2/registrations/akp5s/"}}, {"id": "dqs49", "type": "registrations", "attributes": {"title": "MYSTAT Potentiostat/Galvanostat", "description": "Contains design files for the USB Potentiostat/Galvanostat described in \"MYSTAT: A compact potentiostat/galvanostat for general electrochemistry measurements.\"", "category": "project", "custom_citation": "", "date_created": "2020-01-20T01:54:22.615926", "date_modified": "2020-01-21T05:31:28.235270", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": {"copyright_holders": [""], "year": "2019"}, "analytics_key": "574d729dced6dfbcab28bd34be4b18c9ff1c801ef53c147c4f5f479859cde600c2bc989ff2e70b700e0a09774bb3f3b65cd75dab5b5271723772e259d04174a7fcf5416afcef42592dec8dbca0419d9a77f1a424145c259f56313213864d56080c360759378f912a05f3b8ec2be27664aec2d19bb5995c6deba3a23025204cc0ca1fdd84cc9b9c31bc442eacd59cca5e", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-20T01:54:22.585955", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Open-Ended Registration", "registered_meta": {"summary": {"extra": [], "value": "This is a registration of the MYSTAT design files to be published in \"MYSTAT: A compact potentiostat/galvanostat for general electrochemistry measurements.\""}, "uploader": {"extra": [{"data": {"name": "kicad.zip"}, "nodeId": "s2qam", "sha256": "a1b9781059e2f11e8cd904866164c4d24c811fc0ee60d66b8e804eb8d05c8588", "viewUrl": "/project/s2qam/files/osfstorage/5de0a53f84c479000c72473a", "selectedFileName": "kicad.zip"}, {"data": {"name": "kicad_backpanel.zip"}, "nodeId": "s2qam", "sha256": "e6eedbb3cda7fe7e8b3c510de1d5e9b2bb6044026baac0a02c361d85a0e631e1", "viewUrl": "/project/s2qam/files/osfstorage/5de0a545fbde36000c977f77", "selectedFileName": "kicad_backpanel.zip"}, {"data": {"name": "kicad_frontpanel.zip"}, "nodeId": "s2qam", "sha256": "4decc3b5ad2184386547603311debf11be48cc184631abab06196039a288beb8", "viewUrl": "/project/s2qam/files/osfstorage/5de0a54f84c479000a70d62b", "selectedFileName": "kicad_frontpanel.zip"}, {"data": {"name": "python.zip"}, "nodeId": "s2qam", "sha256": "96774b4a7aec9d2dbce1fe00f78aa3145ae9d222f13708ab26acd876bba81d5b", "viewUrl": "/project/s2qam/files/osfstorage/5de0a55984c479000970c2f0", "selectedFileName": "python.zip"}, {"data": {"name": "firmware.zip"}, "nodeId": "s2qam", "sha256": "a69eb1cc9a7ef67877bccace4b438a3cf2fa84f16d9e1de4a46365936951ba27", "viewUrl": "/project/s2qam/files/osfstorage/5e21db29675e0e008a6b6024", "selectedFileName": "firmware.zip"}], "value": ""}}, "registration_responses": {"summary": "This is a registration of the MYSTAT design files to be published in \"MYSTAT: A compact potentiostat/galvanostat for general electrochemistry measurements.\"", "uploader": [{"file_id": "5de0a53f84c479000c72473a", "file_name": "kicad.zip", "file_urls": {"html": "https://osf.io/s2qam/files/osfstorage/5de0a53f84c479000c72473a", "download": "https://osf.io/download/kr6as/"}, "file_hashes": {"sha256": "a1b9781059e2f11e8cd904866164c4d24c811fc0ee60d66b8e804eb8d05c8588"}}, {"file_id": "5de0a545fbde36000c977f77", "file_name": "kicad_backpanel.zip", "file_urls": {"html": "https://osf.io/s2qam/files/osfstorage/5de0a545fbde36000c977f77", "download": "https://osf.io/download/ct9hu/"}, "file_hashes": {"sha256": "e6eedbb3cda7fe7e8b3c510de1d5e9b2bb6044026baac0a02c361d85a0e631e1"}}, {"file_id": "5de0a54f84c479000a70d62b", "file_name": "kicad_frontpanel.zip", "file_urls": {"html": "https://osf.io/s2qam/files/osfstorage/5de0a54f84c479000a70d62b", "download": "https://osf.io/download/2bytu/"}, "file_hashes": {"sha256": "4decc3b5ad2184386547603311debf11be48cc184631abab06196039a288beb8"}}, {"file_id": "5de0a55984c479000970c2f0", "file_name": "python.zip", "file_urls": {"html": "https://osf.io/s2qam/files/osfstorage/5de0a55984c479000970c2f0", "download": "https://osf.io/download/tg24a/"}, "file_hashes": {"sha256": "96774b4a7aec9d2dbce1fe00f78aa3145ae9d222f13708ab26acd876bba81d5b"}}, {"file_id": "5e21db29675e0e008a6b6024", "file_name": "firmware.zip", "file_urls": {"html": "https://osf.io/s2qam/files/osfstorage/5e21db29675e0e008a6b6024", "download": "https://osf.io/download/zcsja/"}, "file_hashes": {"sha256": "a69eb1cc9a7ef67877bccace4b438a3cf2fa84f16d9e1de4a46365936951ba27"}}]}, "subjects": []}, "relationships": {"license": {"links": {"related": {"href": "https://api.osf.io/v2/licenses/563c1cf88c5e4a3877f9e973/?format=json", "meta": {}}}, "data": {"id": "563c1cf88c5e4a3877f9e973", "type": "licenses"}}, "children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dqs49/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dqs49/comments/?format=json&filter%5Btarget%5D=dqs49", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dqs49/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dqs49/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dqs49/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dqs49/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dqs49/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dqs49/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dqs49/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dqs49/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dqs49/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dqs49/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dqs49/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/dqs49/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dqs49/?format=json", "meta": {}}}, "data": {"id": "dqs49", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dqs49/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dqs49/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/dqs49/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dqs49/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/dqs49/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dqs49/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/dqs49/citation/?format=json", "meta": {}}}, "data": {"id": "dqs49", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/ucz6m/?format=json", "meta": {}}}, "data": {"id": "ucz6m", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/s2qam/?format=json", "meta": {}}}, "data": {"id": "s2qam", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5df83f7dd28338001ac0ab0d/?format=json", "meta": {}}}, "data": {"id": "5df83f7dd28338001ac0ab0d", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/dqs49/", "self": "https://api.osf.io/v2/registrations/dqs49/"}}, {"id": "47ne5", "type": "registrations", "attributes": {"title": "Types of integration perceptions and their relationship with party ID", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-01-18T06:17:45.376332", "date_modified": "2019-12-09T10:34:06.661227", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "4ff43a254f4ead378f58d8eb772285f337b1af49cd5383aa7c529767b07b701ba7d9544ca8af372e85e77773770563bb150c3a05b91e997412ebabb1190bc71b9c953ab5f9bde1698c4af76d846f1b444304ca0cb0edb47142211c28ac831807aa7cf283a08ff581fc53b2814ea7eb02cf22dd414aa703d9fe707cb018ac15eda93f9cb7d839bb75c12f870488e4a3dd", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-18T06:17:45.354618", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "OSF Preregistration", "registered_meta": {"q1": {"extra": [], "value": "What affects (paradox) perceptions of integration among party supporters"}, "q2": {"extra": [], "value": "Sabrina Jasmin Mayer, Stephanie M\u00fcssig"}, "q3": {"extra": [], "value": "Our research projects looks at different types of integration perceptions and analyses what affects belonging to one of these types. Our data set is based on answers from ~2,500 respondents from YouGov, that took part in a survey funded by the University of Duisburg-Essen, which Sabrina acquired. The questionnaire took 20 minutes in total. About 750 Germans without migration background (who themselves and their parents were born in Germany) from East and West Germany each as well as 1,000 Germans with migration background in the first and second generation (born abroad or at least one of their parents were born abroad) were surveyed.\n\nBased on an open-ended question what respondents mean when they think about integration, two research assistants coded the answers based on a deductively developed coding scheme. The question wording was \u201cViele Politiker und Medien in Deutschland verwenden den Begriff \"Integration\" um \u00fcber das Zusammenleben mit Menschen ausl\u00e4ndischer Herkunft zu sprechen. Dabei ist nicht klar, ob alle das Gleiche unter \"Integration\" verstehen.  K\u00f6nnen Sie uns bitte sagen, was Sie selbst unter dem Begriff \"Integration\" verstehen?\u201d So far, we have the codings from one of the assistants. After merging categories with less than 5 answers, we used Latent Class Analyse to determine the number of types. We found seven types (based on AIC and theoretical considerations) of integration perceptions which we heuristicly recoded into four classes. We coded each participant as belonging to the class he/she has the highest probability of belonging. About 1,730 of the ~2,500 participants provided at least on valid answers. Furthermore, we asked participants afterwards the closed-ended question how the evaluate the term integration (\u201dUnd wie bewerten Sie den Begriff \"Integration\"? Ist dieser Begriff f\u00fcr Sie... 1 negatively evaluated to 5 positively evaluated).\n\nWe have several broad research questions concerning this specific study:\n- What types of integration perception exist within the general population? How do types of integration perception correlate with the evaluation of integration?\n- How are integration types distributed between the different party identifier groups?\n- What is key for a negative conception of integration across supporters of all parties?\n- What individual traits and contextual experiences do adherents of different parties have in common when they share the same view on integration? "}, "q4": {"extra": [], "value": "We also have the following research questions for correlations:\nH1: Those that belong to an assimilation and/or negatively connotated integration perception-class do also evaluate integration more negatively in general.\n\nH2a: A strong identification with one\u2019s in-group (either national or subnational identity, resp. ethnic identity for immigrant-origin citizens) furthers a negative conception of integration across supporters of all parties. \nH2b: A strong identification with one\u2019s in-group furthers a negative conception of integration among supporters of parties other than the populist right only when it is combined with with feelings of deprivation/discrimination. \n\nH3: Additionally, across all party families young men (without immigrant background)  with a low SES should be more likely to support a negative conception of integration than other population groups. \n\nH4: Supporters of the populist right without a negative conception of integration are different in such as they lack the feeling of deprivation, have a high SES and are older than their party fellows.\n\nH5: Supporters of the populist right without a negative conception of integration are similar to their party fellows in such as they hold a strong identification with their in-group,  are dissatisfied with democracy and politicians, and have less trust in institutions of the political systems and in politicians.\n"}, "q5": {"extra": [], "value": "Observational Study - Data is collected from study subjects that are not randomly assigned to a treatment. This includes surveys, \u201cnatural experiments,\u201d and regression discontinuity designs."}, "q6": {"extra": [], "value": ["No blinding is involved in this study."]}, "q7": {"extra": [], "value": ""}, "q8": {"value": {"question": {"extra": [], "value": " Our data set is based on answers from ~2,500 respondents from YouGov, that took part in a survey funded by the University of Duisburg-Essen, which Sabrina Mayer acquired. The questionnaire took 20 minutes in total. About 750 Germans without migration background (who themselves and their parents were born in Germany) from East and West Germany each as well as 1,000 Germans with migration background in the first and second generation (born abroad or at least one of their parents were born abroad) were surveyed.\n"}, "uploader": {"extra": [], "value": ""}}}, "q9": {"extra": [], "value": ""}, "q10": {"extra": [], "value": "Registration prior to analysis of the data"}, "q11": {"extra": [], "value": "Did not analyse any correlations of the class variable with other variables."}, "q12": {"value": {"question": {"extra": [], "value": "Online-Access Panel conducted by YouGov"}, "uploader": {"extra": [], "value": ""}}}, "q13": {"extra": [], "value": "2,500 but only ~1,730 took part in the core question about the perception of integration"}, "q14": {"extra": [], "value": ""}, "q15": {"extra": [], "value": ""}, "q16": {"value": {"question": {"extra": [], "value": ""}, "uploader": {"extra": [], "value": ""}}}, "q17": {"value": {"question": {"extra": [], "value": "Identity = Single Item question"}, "uploader": {"extra": [], "value": ""}}}, "q18": {"value": {"question": {"extra": [], "value": ""}, "uploader": {"extra": [], "value": ""}}}, "q19": {"value": {"question": {"extra": [], "value": "We will look at correlations or multivariate mulinomial/logistic regressions on class membership and how they are affected by the different variables."}, "uploader": {"extra": [], "value": ""}}}, "q20": {"extra": [], "value": ""}, "q21": {"extra": [], "value": "p &lt; 0.05"}, "q22": {"extra": [], "value": ""}, "q23": {"extra": [], "value": "exclude"}, "q24": {"extra": [], "value": ""}, "q25": {"extra": [], "value": ""}}, "registration_responses": {"q1": "What affects (paradox) perceptions of integration among party supporters", "q2": "Sabrina Jasmin Mayer, Stephanie M\u00fcssig", "q3": "Our research projects looks at different types of integration perceptions and analyses what affects belonging to one of these types. Our data set is based on answers from ~2,500 respondents from YouGov, that took part in a survey funded by the University of Duisburg-Essen, which Sabrina acquired. The questionnaire took 20 minutes in total. About 750 Germans without migration background (who themselves and their parents were born in Germany) from East and West Germany each as well as 1,000 Germans with migration background in the first and second generation (born abroad or at least one of their parents were born abroad) were surveyed.\n\nBased on an open-ended question what respondents mean when they think about integration, two research assistants coded the answers based on a deductively developed coding scheme. The question wording was \u201cViele Politiker und Medien in Deutschland verwenden den Begriff \"Integration\" um \u00fcber das Zusammenleben mit Menschen ausl\u00e4ndischer Herkunft zu sprechen. Dabei ist nicht klar, ob alle das Gleiche unter \"Integration\" verstehen.  K\u00f6nnen Sie uns bitte sagen, was Sie selbst unter dem Begriff \"Integration\" verstehen?\u201d So far, we have the codings from one of the assistants. After merging categories with less than 5 answers, we used Latent Class Analyse to determine the number of types. We found seven types (based on AIC and theoretical considerations) of integration perceptions which we heuristicly recoded into four classes. We coded each participant as belonging to the class he/she has the highest probability of belonging. About 1,730 of the ~2,500 participants provided at least on valid answers. Furthermore, we asked participants afterwards the closed-ended question how the evaluate the term integration (\u201dUnd wie bewerten Sie den Begriff \"Integration\"? Ist dieser Begriff f\u00fcr Sie... 1 negatively evaluated to 5 positively evaluated).\n\nWe have several broad research questions concerning this specific study:\n- What types of integration perception exist within the general population? How do types of integration perception correlate with the evaluation of integration?\n- How are integration types distributed between the different party identifier groups?\n- What is key for a negative conception of integration across supporters of all parties?\n- What individual traits and contextual experiences do adherents of different parties have in common when they share the same view on integration? ", "q4": "We also have the following research questions for correlations:\nH1: Those that belong to an assimilation and/or negatively connotated integration perception-class do also evaluate integration more negatively in general.\n\nH2a: A strong identification with one\u2019s in-group (either national or subnational identity, resp. ethnic identity for immigrant-origin citizens) furthers a negative conception of integration across supporters of all parties. \nH2b: A strong identification with one\u2019s in-group furthers a negative conception of integration among supporters of parties other than the populist right only when it is combined with with feelings of deprivation/discrimination. \n\nH3: Additionally, across all party families young men (without immigrant background)  with a low SES should be more likely to support a negative conception of integration than other population groups. \n\nH4: Supporters of the populist right without a negative conception of integration are different in such as they lack the feeling of deprivation, have a high SES and are older than their party fellows.\n\nH5: Supporters of the populist right without a negative conception of integration are similar to their party fellows in such as they hold a strong identification with their in-group,  are dissatisfied with democracy and politicians, and have less trust in institutions of the political systems and in politicians.\n", "q5": "Observational Study - Data is collected from study subjects that are not randomly assigned to a treatment. This includes surveys, \u201cnatural experiments,\u201d and regression discontinuity designs.", "q6": ["No blinding is involved in this study."], "q7": "", "q9": "", "q10": "Registration prior to analysis of the data", "q11": "Did not analyse any correlations of the class variable with other variables.", "q13": "2,500 but only ~1,730 took part in the core question about the perception of integration", "q14": "", "q15": "", "q20": "", "q21": "p &lt; 0.05", "q22": "", "q23": "exclude", "q24": "", "q25": "", "q8.question": " Our data set is based on answers from ~2,500 respondents from YouGov, that took part in a survey funded by the University of Duisburg-Essen, which Sabrina Mayer acquired. The questionnaire took 20 minutes in total. About 750 Germans without migration background (who themselves and their parents were born in Germany) from East and West Germany each as well as 1,000 Germans with migration background in the first and second generation (born abroad or at least one of their parents were born abroad) were surveyed.\n", "q8.uploader": [], "q12.question": "Online-Access Panel conducted by YouGov", "q12.uploader": [], "q16.question": "", "q16.uploader": [], "q17.question": "Identity = Single Item question", "q17.uploader": [], "q18.question": "", "q18.uploader": [], "q19.question": "We will look at correlations or multivariate mulinomial/logistic regressions on class membership and how they are affected by the different variables.", "q19.uploader": []}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/47ne5/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/47ne5/comments/?format=json&filter%5Btarget%5D=47ne5", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/47ne5/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/47ne5/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/47ne5/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/47ne5/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/47ne5/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/47ne5/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/47ne5/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/47ne5/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/47ne5/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/47ne5/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/47ne5/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/47ne5/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/de-1/?format=json", "meta": {}}}, "data": {"id": "de-1", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/47ne5/?format=json", "meta": {}}}, "data": {"id": "47ne5", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/47ne5/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/47ne5/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/47ne5/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/47ne5/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/47ne5/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/47ne5/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/47ne5/citation/?format=json", "meta": {}}}, "data": {"id": "47ne5", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/6ghtr/?format=json", "meta": {}}}, "data": {"id": "6ghtr", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/f93nh/?format=json", "meta": {}}}, "data": {"id": "f93nh", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5c08457ed283380029cf73bf/?format=json", "meta": {}}}, "data": {"id": "5c08457ed283380029cf73bf", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/47ne5/", "self": "https://api.osf.io/v2/registrations/47ne5/"}}, {"id": "w76bk", "type": "registrations", "attributes": {"title": "Relative disadvantage and prosocial behavior", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-01-18T12:21:40.562896", "date_modified": "2020-01-17T06:07:09.629282", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "0f1c44661f32e61f41ebb1f169b50090569d87df8b169d6f44ab2200efbd6bf67d7aacc7c4fb0b1d9705cce0fe7eee57855cf1163840043e77b5b9b99234d23a6005ea8b9f12aef60f1971cf811794b486d9c49a741106fab57f5feaedb5e7ca3b37e0b2679d6c988268cf278c7c64e294f71221f8022efe396ef0623a5d45538604da594a5c90dce9027d2b29191345", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-18T12:21:40.545264", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Pre-Registration in Social Psychology (van 't Veer & Giner-Sorolla, 2016): Pre-Registration", "registered_meta": {"looked": {"extra": [], "value": "No"}, "datacompletion": {"extra": [], "value": "Yes, data collection is underway or complete"}, "additionalComments": {"extra": [], "value": ""}, "dataCollectionDates": {"extra": [], "value": "16.1.20 - 23.1.20"}, "description-methods": {"value": {"design": {"value": {"question2a": {"extra": [], "value": "This is a between-participants design.\nIV1: status (high, medium, low) \nIV2: motivation (prosocial, pro-self, neutral) \n"}, "question2b": {"extra": [], "value": "DV: donation of points to another participant in the game."}, "question3b": {"extra": [], "value": "N/A"}}}, "procedure": {"value": {"question10b": {"extra": [], "value": "First, participants learn that they are about to take part in a game in the beginning of which they will receive either 50, 100 or 150 points. At the end of the study 10 participants will be randomly selected to receive a cash prize which will be equivalent to the amount of points they have at the end of the game. They are asked to choose a picture of a mythical creature that will determine their initial amount of points. Participants are then randomly assigned to either high (150 points), medium (100 points) or low status (50 points) conditions. In the second part of the experiment participants learn that another participant who initially received 50 points has lost 40 points and now has only 10 points. Participants are asked if they would like to share some of their points with that participant (the DV). At this stage participants are again randomly assigned to one of three experimental conditions. In the prosocial motivation condition participant read a message stating that receiving help from others make people feel good, and see a picture of a smiling gift receiver. In the pro-self motivation condition participants read a message stating that assisting others makes people feel good, and see a picture of a smiling gift giver. In the neutral condition there is no additional information and participants see a similar picture without a smile. After deciding about the donation, participants are asked to fill in demographic data (age, gender, native language, university) and then the questionnaire ends. "}}}, "planned-sample": {"value": {"question4b": {"extra": [], "value": "N/A"}, "question5b": {"extra": [], "value": "Students from the Hebrew University and Ben-Gurion University."}, "question6b": {"extra": [], "value": "540 participants."}, "question7b": {"extra": [], "value": "Data collection will be terminated once we reach the planned sample size."}, "question6b-upload": {"extra": [], "value": ""}}}, "exclusion-criteria": {"value": {"question8b": {"extra": [], "value": "Participants who will indicate a donation amount that is higher than the amount of points they have in the game will be excluded from data analysis. "}}}}}, "recommended-methods": {"value": {"procedure": {"value": {"question9b": {"extra": [], "value": ""}, "question9b-file": {"extra": [], "value": ""}}}}}, "recommended-analysis": {"value": {"specify": {"value": {"question6c": {"extra": [], "value": ""}, "question7c": {"extra": [], "value": ""}, "question8c": {"extra": [], "value": ""}, "question9c": {"extra": [], "value": ""}, "question10c": {"extra": [], "value": ""}, "question11c": {"extra": [], "value": ""}}}}}, "description-hypothesis": {"value": {"question1a": {"extra": [], "value": "1. Financially better off participants (ones who have the higher amount of points in the game) will donate a lower percentage of their points to another participant, than the worse-off participants (who have a low or medium amount of points). 2. Participants in the prosocial motivation condition will contribute a higher percentage of their points than participants in the pro-self motivation and the control conditions. 3. There will be an interaction between financial status and motivation to share points."}, "question2a": {"extra": [], "value": "When the motivation is prosocial, we expect lower status participants to share a higher percentage of their resources than the higher status participants. When the motivation is pro-self, we expect the higher status participants to share a larger percentage of their resources, than the lower status participants. "}, "question3a": {"extra": [], "value": "We did not include a manipulation check since  it may affect the experimental manipulation. "}}}, "recommended-hypothesis": {"value": {"question4a": {"extra": [], "value": ""}, "question5a": {"extra": [], "value": ""}, "question6a": {"extra": [], "value": ""}}}, "confirmatory-analyses-first": {"value": {"first": {"value": {"question1c": {"extra": [], "value": "The DV - donation to other participant, will be calculated as a percent of participants' donation. "}, "question2c": {"extra": [], "value": "We will perform an ANOVA and simple effects analyses "}, "question3c": {"extra": [], "value": "N/A"}, "question4c": {"extra": [], "value": "N/A"}, "question5c": {"extra": [], "value": "N/A"}}}}}, "confirmatory-analyses-third": {"value": {"third": {"value": {"question1c": {"extra": [], "value": ""}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}, "confirmatory-analyses-fourth": {"value": {"fourth": {"value": {"question1c": {"extra": [], "value": ""}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}, "confirmatory-analyses-second": {"value": {"second": {"value": {"question1c": {"extra": [], "value": ""}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}, "confirmatory-analyses-further": {"value": {"further": {"value": {"question1c": {"extra": [], "value": ""}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}}, "registration_responses": {"looked": "No", "datacompletion": "Yes, data collection is underway or complete", "additionalComments": "", "dataCollectionDates": "16.1.20 - 23.1.20", "description-hypothesis.question1a": "1. Financially better off participants (ones who have the higher amount of points in the game) will donate a lower percentage of their points to another participant, than the worse-off participants (who have a low or medium amount of points). 2. Participants in the prosocial motivation condition will contribute a higher percentage of their points than participants in the pro-self motivation and the control conditions. 3. There will be an interaction between financial status and motivation to share points.", "description-hypothesis.question2a": "When the motivation is prosocial, we expect lower status participants to share a higher percentage of their resources than the higher status participants. When the motivation is pro-self, we expect the higher status participants to share a larger percentage of their resources, than the lower status participants. ", "description-hypothesis.question3a": "We did not include a manipulation check since  it may affect the experimental manipulation. ", "recommended-hypothesis.question4a": [], "recommended-hypothesis.question5a": "", "recommended-hypothesis.question6a": "", "description-methods.design.question2a": "This is a between-participants design.\nIV1: status (high, medium, low) \nIV2: motivation (prosocial, pro-self, neutral) \n", "description-methods.design.question2b": "DV: donation of points to another participant in the game.", "description-methods.design.question3b": "N/A", "recommended-analysis.specify.question6c": "", "recommended-analysis.specify.question7c": "", "recommended-analysis.specify.question8c": "", "recommended-analysis.specify.question9c": "", "recommended-analysis.specify.question10c": "", "recommended-analysis.specify.question11c": [], "recommended-methods.procedure.question9b": "", "description-methods.procedure.question10b": "First, participants learn that they are about to take part in a game in the beginning of which they will receive either 50, 100 or 150 points. At the end of the study 10 participants will be randomly selected to receive a cash prize which will be equivalent to the amount of points they have at the end of the game. They are asked to choose a picture of a mythical creature that will determine their initial amount of points. Participants are then randomly assigned to either high (150 points), medium (100 points) or low status (50 points) conditions. In the second part of the experiment participants learn that another participant who initially received 50 points has lost 40 points and now has only 10 points. Participants are asked if they would like to share some of their points with that participant (the DV). At this stage participants are again randomly assigned to one of three experimental conditions. In the prosocial motivation condition participant read a message stating that receiving help from others make people feel good, and see a picture of a smiling gift receiver. In the pro-self motivation condition participants read a message stating that assisting others makes people feel good, and see a picture of a smiling gift giver. In the neutral condition there is no additional information and participants see a similar picture without a smile. After deciding about the donation, participants are asked to fill in demographic data (age, gender, native language, university) and then the questionnaire ends. ", "confirmatory-analyses-first.first.question1c": "The DV - donation to other participant, will be calculated as a percent of participants' donation. ", "confirmatory-analyses-first.first.question2c": "We will perform an ANOVA and simple effects analyses ", "confirmatory-analyses-first.first.question3c": "N/A", "confirmatory-analyses-first.first.question4c": "N/A", "confirmatory-analyses-first.first.question5c": "N/A", "confirmatory-analyses-third.third.question1c": "", "confirmatory-analyses-third.third.question2c": "", "confirmatory-analyses-third.third.question3c": "", "confirmatory-analyses-third.third.question4c": "", "confirmatory-analyses-third.third.question5c": "", "description-methods.planned-sample.question4b": "N/A", "description-methods.planned-sample.question5b": "Students from the Hebrew University and Ben-Gurion University.", "description-methods.planned-sample.question6b": "540 participants.", "description-methods.planned-sample.question7b": "Data collection will be terminated once we reach the planned sample size.", "recommended-methods.procedure.question9b-file": [], "confirmatory-analyses-fourth.fourth.question1c": "", "confirmatory-analyses-fourth.fourth.question2c": "", "confirmatory-analyses-fourth.fourth.question3c": "", "confirmatory-analyses-fourth.fourth.question4c": "", "confirmatory-analyses-fourth.fourth.question5c": "", "confirmatory-analyses-second.second.question1c": "", "confirmatory-analyses-second.second.question2c": "", "confirmatory-analyses-second.second.question3c": "", "confirmatory-analyses-second.second.question4c": "", "confirmatory-analyses-second.second.question5c": "", "confirmatory-analyses-further.further.question1c": "", "confirmatory-analyses-further.further.question2c": "", "confirmatory-analyses-further.further.question3c": "", "confirmatory-analyses-further.further.question4c": "", "confirmatory-analyses-further.further.question5c": "", "description-methods.exclusion-criteria.question8b": "Participants who will indicate a donation amount that is higher than the amount of points they have in the game will be excluded from data analysis. ", "description-methods.planned-sample.question6b-upload": []}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/w76bk/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/w76bk/comments/?format=json&filter%5Btarget%5D=w76bk", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/w76bk/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/w76bk/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/w76bk/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/w76bk/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/w76bk/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/w76bk/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/w76bk/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/w76bk/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/w76bk/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/w76bk/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/w76bk/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/w76bk/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/w76bk/?format=json", "meta": {}}}, "data": {"id": "w76bk", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/w76bk/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/w76bk/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/w76bk/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/w76bk/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/w76bk/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/w76bk/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/w76bk/citation/?format=json", "meta": {}}}, "data": {"id": "w76bk", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/znhs3/?format=json", "meta": {}}}, "data": {"id": "znhs3", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/sd6mv/?format=json", "meta": {}}}, "data": {"id": "sd6mv", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5730e99a9ad5a102c5745a8a/?format=json", "meta": {}}}, "data": {"id": "5730e99a9ad5a102c5745a8a", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/w76bk/", "self": "https://api.osf.io/v2/registrations/w76bk/"}}, {"id": "sq3kx", "type": "registrations", "attributes": {"title": "Impact of Native Advertising on News Credibility", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-01-14T14:54:53.452702", "date_modified": "2020-01-21T05:00:08.542193", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "de9d5bf95cfbb27a5ec979661be65f4a84c966296a91bb2e4b9bd06c8d7645d38ffd12ab8ec8f32aa4e4ce23f40b8b09451b269dc5b39bb4575a53be1e69a900bca92fa82b81f5edce156f8c0829a3e7e67698ed5bdd0fd574df76ca5a8ba22f27daa64da79e92b2c5be184c5d9bceebbc53ab8ee7dc869c488d5c49192043994cc7d5ca2cf0407e3979adfe4ef0333d", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-14T14:54:53.425082", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "OSF Preregistration", "registered_meta": {"q1": {"extra": [], "value": "Impact of Native Advertising on News Credibility "}, "q2": {"extra": [], "value": "Manon Revel, Dean Eckles, adam berinsky"}, "q3": {"extra": [], "value": "What effects do native ads have on perception of news credibility? Following a previous study, we aim to examine heterogeneity in these effects for ads of varied topics and quality and for different sources, especially according to how familiar those sources are."}, "q4": {"extra": [], "value": "Hypothesis 1: Ad quality affects perception of news credibility?\n\nQuality-specific questions: \nWe use the \u201cno ads\u201d condition as our control condition. With respect to this baseline:\nlow quality ads decrease news\u2019 credibility (measured by our index)\nhigh quality ads increase news\u2019 credibility (measured by our index)  \n\nWe expect these results to vary based on (i) the popularity of the publishers, (ii) the level of familiarity of the audience with the publishers, (iii) the subjects\u2019 political leaning. \nSpecifically, we will cluster publishers in three groups (high_familiarity, medium_familiarity, low_familiarity) and expect: \nthe effect of ads quality to be greater for low familiarity publishers\nFurther, we will measure the effects among familiar audience and non-familiar audience, and we expect: \nthe effect of low quality ads in decreasing trust to be greater among familiar audience \nthe effect of high quality ads in increasing trust to be greater among non-familiar audience \nFinally, we will cluster subjects based on their political leanings, and we expect: \nthe effect of low quality ads in decreasing trust to be greater among subjects\u2019 with a political leaning that differs from the publisher\u2019s.   \n\n\nHypothesis 2: Is it not in the publishers\u2019 interest to embed ads with a leaning that differ from theirs?\n\nWe use the \u201cneutral high quality\u201d condition as our control condition. With respect to this baseline:\nhigh quality left-leaning political ads decrease trust in right-wing publishers. \nhigh quality right-leaning political ads decrease trust in left-wing publishers. "}, "q5": {"extra": [], "value": "Experiment - A researcher randomly assigns treatments to study subjects, this includes field or lab experiments. This is also known as an intervention experiment and includes randomized controlled trials."}, "q6": {"extra": [], "value": ["For studies that involve human subjects, they will not know the treatment group to which they have been assigned.", "Personnel who interact directly with the study subjects (either human or non-human subjects) will not be aware of the assigned treatments. (Commonly known as \u201cdouble blind\u201d)"]}, "q7": {"extra": [], "value": ""}, "q8": {"value": {"question": {"extra": [], "value": "Within subject design, each subject read 6 articles with different ads conditions (2 no ads, 1 high quality general, 1 low quality general, 1 high quality political, 1 low quality political)."}, "uploader": {"extra": [{"data": {"name": "Pre-registration.pdf"}, "nodeId": "48w6s", "sha256": "a05bb997ee457137dce476a9b76bfb01e821cb1be793c46ff05c0485873c85b6", "viewUrl": "/project/sq3kx/files/osfstorage/5e1dd640855d4c0140b6fba1/", "selectedFileName": "Pre-registration.pdf"}], "value": ""}}}, "q9": {"extra": [], "value": "Each participant will read 6 articles randomly chosen among all the article-publishers pair created, the ads conditions are randomly assigned to these 6 articles, respecting the number of ads type explained in the Study Design block. "}, "q10": {"extra": [], "value": "Registration prior to creation of data"}, "q11": {"extra": [], "value": ""}, "q12": {"value": {"question": {"extra": [], "value": "Data collected through a third-party company among a group of people representative of the US population. "}, "uploader": {"extra": [], "value": ""}}}, "q13": {"extra": [], "value": "Our target is 5000 participants. "}, "q14": {"extra": [], "value": ""}, "q15": {"extra": [], "value": ""}, "q16": {"value": {"question": {"extra": [], "value": ""}, "uploader": {"extra": [], "value": ""}}}, "q17": {"value": {"question": {"extra": [], "value": "We are studying the effects of native ads (shown as part of \"content recommendation networks\", CRNs) on a subject i\u2019s perception of {trustworthiness, bias, falseness, newsworthiness and credibility} (outcome) one has in articles k (Articlek) and publishers j (Publisherj). \nVariables: trustworthiness, bias, falseness, newsworthiness and credibility"}, "uploader": {"extra": [], "value": ""}}}, "q18": {"value": {"question": {"extra": [], "value": "outcomeijk is an index combining the 5 articles\u2019 descriptors we gather along the survey. This index will depend on either two factors (trustworthy, newsworthy and credible combined in one factor, biased and false combined in another factor) or one factor (all five descriptors combined with biased and false reversed).\n"}, "uploader": {"extra": [], "value": ""}}}, "q19": {"value": {"question": {"extra": [], "value": "Random effect models for: \n\nGeneral Model: \noutcomeijk = \t(1|Article)k + (1|Publisher)j \n+ (1ISubject)i + Political_Interesti + familiarityij \n+ Political_leaningi \n+ Publisher:familiarity + Publisher:familiarity:CRN\n\nHypothesis 1:\noutcome = \u2026 + Publisher_familiarity:familiarity:CRN_quality\noutcome = \u2026 + Publisher_leaning:leaning:CRN_quality\n\nHypothesis 2: \noutcome = \u2026 + Publisher_leaning:CRN_leaning"}, "uploader": {"extra": [], "value": ""}}}, "q20": {"extra": [], "value": ""}, "q21": {"extra": [], "value": ""}, "q22": {"extra": [], "value": "We will verify that each subject answered correctly the attention check questions. "}, "q23": {"extra": [], "value": ""}, "q24": {"extra": [], "value": "We aim at studying the complementary questions that could help us understand if native ads have significantly different effects within different groups.\nAge: \nOlder subjects are more likely to perceive a decrease in the news\u2019 credibility when native ads are displayed.\nEducation: \nMore educated subjects are more likely to perceive a decrease in the news\u2019 credibility when native ads are displayed. \nCognition: \nDifferent cognition level might imply different perception.  \nAds recognition: \nRecognizing the ads decreases the perceived credibility of the news. \n"}, "q25": {"extra": [], "value": ""}}, "registration_responses": {"q1": "Impact of Native Advertising on News Credibility ", "q2": "Manon Revel, Dean Eckles, adam berinsky", "q3": "What effects do native ads have on perception of news credibility? Following a previous study, we aim to examine heterogeneity in these effects for ads of varied topics and quality and for different sources, especially according to how familiar those sources are.", "q4": "Hypothesis 1: Ad quality affects perception of news credibility?\n\nQuality-specific questions: \nWe use the \u201cno ads\u201d condition as our control condition. With respect to this baseline:\nlow quality ads decrease news\u2019 credibility (measured by our index)\nhigh quality ads increase news\u2019 credibility (measured by our index)  \n\nWe expect these results to vary based on (i) the popularity of the publishers, (ii) the level of familiarity of the audience with the publishers, (iii) the subjects\u2019 political leaning. \nSpecifically, we will cluster publishers in three groups (high_familiarity, medium_familiarity, low_familiarity) and expect: \nthe effect of ads quality to be greater for low familiarity publishers\nFurther, we will measure the effects among familiar audience and non-familiar audience, and we expect: \nthe effect of low quality ads in decreasing trust to be greater among familiar audience \nthe effect of high quality ads in increasing trust to be greater among non-familiar audience \nFinally, we will cluster subjects based on their political leanings, and we expect: \nthe effect of low quality ads in decreasing trust to be greater among subjects\u2019 with a political leaning that differs from the publisher\u2019s.   \n\n\nHypothesis 2: Is it not in the publishers\u2019 interest to embed ads with a leaning that differ from theirs?\n\nWe use the \u201cneutral high quality\u201d condition as our control condition. With respect to this baseline:\nhigh quality left-leaning political ads decrease trust in right-wing publishers. \nhigh quality right-leaning political ads decrease trust in left-wing publishers. ", "q5": "Experiment - A researcher randomly assigns treatments to study subjects, this includes field or lab experiments. This is also known as an intervention experiment and includes randomized controlled trials.", "q6": ["For studies that involve human subjects, they will not know the treatment group to which they have been assigned.", "Personnel who interact directly with the study subjects (either human or non-human subjects) will not be aware of the assigned treatments. (Commonly known as \u201cdouble blind\u201d)"], "q7": "", "q9": "Each participant will read 6 articles randomly chosen among all the article-publishers pair created, the ads conditions are randomly assigned to these 6 articles, respecting the number of ads type explained in the Study Design block. ", "q10": "Registration prior to creation of data", "q11": "", "q13": "Our target is 5000 participants. ", "q14": "", "q15": "", "q20": "", "q21": "", "q22": "We will verify that each subject answered correctly the attention check questions. ", "q23": "", "q24": "We aim at studying the complementary questions that could help us understand if native ads have significantly different effects within different groups.\nAge: \nOlder subjects are more likely to perceive a decrease in the news\u2019 credibility when native ads are displayed.\nEducation: \nMore educated subjects are more likely to perceive a decrease in the news\u2019 credibility when native ads are displayed. \nCognition: \nDifferent cognition level might imply different perception.  \nAds recognition: \nRecognizing the ads decreases the perceived credibility of the news. \n", "q25": "", "q8.question": "Within subject design, each subject read 6 articles with different ads conditions (2 no ads, 1 high quality general, 1 low quality general, 1 high quality political, 1 low quality political).", "q8.uploader": [{"file_id": "5e1dd640855d4c0140b6fba1", "file_name": "Pre-registration.pdf", "file_urls": {"html": "https://osf.io/project/sq3kx/files/osfstorage/5e1dd640855d4c0140b6fba1", "download": "https://osf.io/download/5e1dd640855d4c0140b6fba1"}, "file_hashes": {"sha256": "a05bb997ee457137dce476a9b76bfb01e821cb1be793c46ff05c0485873c85b6"}}], "q12.question": "Data collected through a third-party company among a group of people representative of the US population. ", "q12.uploader": [], "q16.question": "", "q16.uploader": [], "q17.question": "We are studying the effects of native ads (shown as part of \"content recommendation networks\", CRNs) on a subject i\u2019s perception of {trustworthiness, bias, falseness, newsworthiness and credibility} (outcome) one has in articles k (Articlek) and publishers j (Publisherj). \nVariables: trustworthiness, bias, falseness, newsworthiness and credibility", "q17.uploader": [], "q18.question": "outcomeijk is an index combining the 5 articles\u2019 descriptors we gather along the survey. This index will depend on either two factors (trustworthy, newsworthy and credible combined in one factor, biased and false combined in another factor) or one factor (all five descriptors combined with biased and false reversed).\n", "q18.uploader": [], "q19.question": "Random effect models for: \n\nGeneral Model: \noutcomeijk = \t(1|Article)k + (1|Publisher)j \n+ (1ISubject)i + Political_Interesti + familiarityij \n+ Political_leaningi \n+ Publisher:familiarity + Publisher:familiarity:CRN\n\nHypothesis 1:\noutcome = \u2026 + Publisher_familiarity:familiarity:CRN_quality\noutcome = \u2026 + Publisher_leaning:leaning:CRN_quality\n\nHypothesis 2: \noutcome = \u2026 + Publisher_leaning:CRN_leaning", "q19.uploader": []}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/sq3kx/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/sq3kx/comments/?format=json&filter%5Btarget%5D=sq3kx", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/sq3kx/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/sq3kx/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/sq3kx/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/sq3kx/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/sq3kx/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/sq3kx/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/sq3kx/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/sq3kx/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/sq3kx/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/sq3kx/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/sq3kx/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/sq3kx/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/sq3kx/?format=json", "meta": {}}}, "data": {"id": "sq3kx", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/sq3kx/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/sq3kx/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/sq3kx/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/sq3kx/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/sq3kx/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/sq3kx/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/sq3kx/citation/?format=json", "meta": {}}}, "data": {"id": "sq3kx", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/zkatx/?format=json", "meta": {}}}, "data": {"id": "zkatx", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/48w6s/?format=json", "meta": {}}}, "data": {"id": "48w6s", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5c08457ed283380029cf73bf/?format=json", "meta": {}}}, "data": {"id": "5c08457ed283380029cf73bf", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/sq3kx/", "self": "https://api.osf.io/v2/registrations/sq3kx/"}}, {"id": "5x6eq", "type": "registrations", "attributes": {"title": "A Exploratory Factor Model with Ordinal Paired Comparison Indicators", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-01-18T12:03:48.009982", "date_modified": "2020-01-18T12:01:13.332178", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "4eb1a6304c59f64ba5870c46be1c2a9797a79cf30a5de8c759a4f04d94a2eb89193104a48f06c28bd2d9dc2753b75fe6bf5ebfeef9089b4fab38cb25d9628d81692d2db2da38c2536c7971bf0f4e018559efd4ff7bb015476f93a7fb2616fd7d62d5c8450eafb26e068c5f6ac89a0fa04918cd0b2c9be676646bcf328e6a49157f12e34c4dcb4dc5ce513f22c77d5970", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-18T12:03:47.994472", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Open-Ended Registration", "registered_meta": {"summary": {"extra": [], "value": "Better separation of location and scale distributions in the factor model"}, "uploader": {"extra": [], "value": ""}}, "registration_responses": {"summary": "Better separation of location and scale distributions in the factor model"}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5x6eq/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5x6eq/comments/?format=json&filter%5Btarget%5D=5x6eq", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5x6eq/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5x6eq/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5x6eq/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5x6eq/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5x6eq/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5x6eq/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5x6eq/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5x6eq/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5x6eq/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5x6eq/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5x6eq/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/5x6eq/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5x6eq/?format=json", "meta": {}}}, "data": {"id": "5x6eq", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5x6eq/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5x6eq/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/5x6eq/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5x6eq/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/5x6eq/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5x6eq/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/5x6eq/citation/?format=json", "meta": {}}}, "data": {"id": "5x6eq", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/bwypp/?format=json", "meta": {}}}, "data": {"id": "bwypp", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/6e4jt/?format=json", "meta": {}}}, "data": {"id": "6e4jt", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5df83f7dd28338001ac0ab0d/?format=json", "meta": {}}}, "data": {"id": "5df83f7dd28338001ac0ab0d", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/5x6eq/", "self": "https://api.osf.io/v2/registrations/5x6eq/"}}, {"id": "s3wex", "type": "registrations", "attributes": {"title": "Project Part 1 (redirects to: Change over time &amp; Conflict of interest)", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-01-20T20:11:29.842534", "date_modified": "2020-01-04T17:25:47.075675", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "020f5c039e36bd2f755b79d742a80586541fb504b029905d720a7239089480489edcedc6eec31ba53bd14187f22fa0c46c811b31c751195592dd7700b9cb30a96e7e1aaf0d596c4295eb977a7fd223f197d8bc705f589512134cdd68c8da3e0fc14ef068e81666f585d4477a15a06ffcc473ad7ad4aae7aecf6f565c8a5363427140ddcda9c65b804581035f2638246a", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-20T20:11:29.807714", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "OSF Preregistration", "registered_meta": {"q1": {"extra": [], "value": "Publication bias in psychology : Evaluating the robustness of meta-analytic effects"}, "q2": {"extra": [], "value": "Martina Sladekova"}, "q3": {"extra": [], "value": "***Due to OSF formatting settings, some sections of this form may be difficult to read. The attached document titled \"preregistration_v.2.0.pdf\" contains a formatted and otherwise identical version of this preregistration. The document can also be found in the OSF repository https://osf.io/k9hqm/***\n\nPublication bias is an ongoing problem affecting meta-analytic estimates of effect sizes. A number of methods correcting for small study effects and publication bias have been developed over the years, however these methods tend to be applied without the regard for optimal performance conditions of each method. \nThe aim of this study is to investigate:\n\na)\tThe extent to which meta-analysts in psychology attend to publication bias\nb)\tHow the published effect sizes change when the data are re-analysed with a publication bias correction method that has been found to perform well given specific conditions of each study. These conditions refer to heterogeneity of primary effect sizes, number of primary effects included in the meta-analysis, expected level of publication bias, and expected population effect size. \n\nBecause the level of publication bias and population effect size are unknown, changes in publication bias will be investigated separately within 4 conditions that assume: \n\n1.\tMedium publication bias and population effect size of \u03b4 = 0.2 (Condition 1)\n2.\tHigh publication bias and population effect size of \u03b4 = 0.2 (Condition 2)\n3.\tMedium publication bias and population effect size of \u03b4 = 0.5 (Condition 3)\n4.\tHigh publication bias and population effect size of \u03b4 = 0.5 (Condition 4)\n\nSee *Variables* and *Analysis Plan* sections for details. \n"}, "q4": {"extra": [], "value": "Objectives\n\nThe key objective is to estimate: \n\n(1)\tthe typical attenuation in published meta-analytic effect sizes after the application of publication bias correcting methods. \n(2)\tthe plausible range of this attenuation using 95% highest posterior density intervals. \n(3)\tthe plausible limits of variation in the effect size attenuation across different bias correcting methods\n\nThe analysis will be performed separately for the specific combinations of the level of publication bias and the population effect size, as specified above.  \n"}, "q5": {"extra": [], "value": "Other"}, "q6": {"extra": [], "value": ["No blinding is involved in this study."]}, "q7": {"extra": [], "value": ""}, "q8": {"value": {"question": {"extra": [], "value": "The final data will have 3-level hierarchical structure. Models will be fitted for each of the 4 conditions separately. Level 1 predictor (effect size estimator) is a factor with 2 levels (original uncorrected estimator vs bias-corrected estimate); outcome is the effect size (continuous variable). See *Variables* and *Analysis Plan* for details. "}, "uploader": {"extra": [{"data": {"name": "preregistration_v.2.0.pdf"}, "nodeId": "k9hqm", "sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91", "viewUrl": "/project/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "selectedFileName": "preregistration_v.2.0.pdf"}], "value": ""}}}, "q9": {"extra": [], "value": ""}, "q10": {"extra": [], "value": "Registration prior to accessing the data"}, "q11": {"extra": [], "value": "Data were collected in two parts. \n\nPart 1 included random selection of meta-analyses published in 2008 and 2018, and subsequent coding of meta-analytic practices in these papers using a coding scheme. This phase of data collection lasted from February 2019 to June 2019. Authors of the present study were involved in the coding scheme development and data collection. Exact details of the coding scheme as well as analyses run on this dataset so far can be found at https://osf.io/ruvhd/ . No items from this dataset will be inferentially tested as outcome variables in the present study. \n\nPart 2 involves collection of raw data used in meta-analyses that were coded in Part 1. At the time of registration, raw data available in supplemental materials online have been downloaded. Data extraction directly from journal articles has begun, with the first dataset extracted on 03/09/2019. Additionally, 118 authors have been e-mailed with request for their data (first request sent on 10/10/2019), out of which 23 made their data available, 24 confirmed that they no longer have access to the data, with remaining 71 requests pending on 27/12/19. \n\nNo data that have been downloaded, extracted, or received from the authors has been in any way transformed or analysed. No additional variables have been computed for any of the datasets at time of the registration. Some authors of the meta-analyses included in the sample have sent their datasets with a computed variance measure; however, no additional analyses were performed on said datasets. As such the main outcome measure for this study has not yet been obtained for any of the studies. \n"}, "q12": {"value": {"question": {"extra": [], "value": "Details of study selection, inclusion/exclusion criteria and coding procedures for Part 1 can be found at https://osf.io/ruvhd/ . \n\nAs detailed above, data for Part 2 are being obtained via the following means: \n\u2022\tDownloading supplemental materials linked to the published papers\n\u2022\tExtracting data from tables and forest plots published within journal articles\n\u2022\tE-mailing the authors of the meta-analyses with requests for their data\n\nData collection will finish after the last author has responded, expected no later than 31/01/2020. \n\nInclusion criteria: \ni.\tStudy was included in Part 1 of this project. \ni.\tData for the study is accessible or made available by the authors \nii.\tStudy reports effect sizes in form of Cohen\u2019s d or provides parameters that enable transformation into Cohen\u2019s d.\niii.\tStudy provides the information necessary for computation or estimation of variance of the primary studies, and the t statistic where relevant for the appropriate publication bias correction method (see Variables and Analysis Plan for details.)\n\nExclusion criteria:\nIn addition to failing to meet the above inclusion criteria, studies will be excluded if: \ni.\tStudy is a meta-meta-analysis or a meta-analysis using internal databases as opposed to published research papers, as the nature of publication bias in these types of samples is different to the publication bias investigated in the present study. \nii.\tData are insufficient to reproduce the original analysis and the attempts to consult with the author of the paper are unsuccessful. \n"}, "uploader": {"extra": [{"data": {"name": "preregistration_v.2.0.pdf"}, "nodeId": "k9hqm", "sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91", "viewUrl": "/project/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "selectedFileName": "preregistration_v.2.0.pdf"}], "value": ""}}}, "q13": {"extra": [], "value": "Attempt will be made to obtain raw data for every single meta-analysis included in Part 1 (spreadsheet with all the studies included in Part 1 can be found at https://osf.io/ruvhd/). Should this effort be successful, and all the studies are found to be eligible, this will result in the inclusion of 170 published papers (level 3 units), containing 1242 individual meta-analyses (level 2 units), each containing uncorrected and corrected effect size estimates (resulting in 2484 level 1 units within each of the 4 conditions). This is the maximum upper boundary of the sample size, however at the time of registration, the expected sample size is 107 published papers containing 478 individual meta-analysis, each containing uncorrected and correct effect size estimates and therefore 956 level 1 units within each of the 4 conditions. "}, "q14": {"extra": [], "value": "Sample size for Part 1 was determined by time constraints of the project with the aim to code as many studies as possible. Sample size for this part of the project will be determined by data availability and alignment with inclusion/exclusion criteria outlined above. "}, "q15": {"extra": [], "value": ""}, "q16": {"value": {"question": {"extra": [], "value": ""}, "uploader": {"extra": [], "value": ""}}}, "q17": {"value": {"question": {"extra": [], "value": "Variables collected in Part 1 which will be summarised using only descriptive statistics without inferential tests: \n\n\n\n\u2022\tNumber of unpublished studies included in the meta-analysis\n\u2022\tMethod used to obtain unpublished studies [multiple selection from: Undisclosed; Unpublished studies not included on purpose; Contact - first authors; Contact - authors from the reference list; Internet search of databases (such as OSF); Search of dissertation archives; Search of conference proceedings; Other - text box]\n\u2022\tResponse rate when contacting authors about unpublished studies [Authors contacted - integer; Authors responded - integer]\n\u2022\tMethod of addressing publication bias [Not applicable (publication bias not found); Trim-and-fill; Inclusion of unpublished studies; Weight function models (Vevea &amp; Hedges); Egger (regression); Egger-var (regression); Harbord (regression); Peters (regression); WLS; WAAP-WLS; PET-PEESE; Bayesian methods; Other - text box]\n\u2022\tMethod used to check for the presence of publication bias [Undisclosed; Visual - funnel plot; Visual - p-curve; Trim-and-fill (sensitivity analysis); Rosenthal\u2019s fail-safe N; Orwin\u2019s fail-safe N; Reverse correlation between effect sizes and sample sizes; Funnel asymmetry test; Precision effect test; Ioannidis &amp; Trikalinos (2007) publication bias test; Other - text box]\n\u2022\tAuthors\u2019 conclusion about the presence of publication bias in the meta-analytic sample [Present; Not present; Not reported]\n\nOutcome variables computed for Part 2 of the project: \n\nEach meta-analysis (level 2 unit) will contain 2 effect sizes (level 1 units), which is the primary outcome of this study. These effect sizes are: \n\n1.\tOriginal uncorrected effect size as published in the paper\n2.\tEffect size corrected by a publication bias correction method. Performance of a correction method is affected by the study\u2019s sample size and heterogeneity of primary effect sizes (defined by \u03c42), as well as unknown factors such as the level of publication bias and the population effect size. Therefore, for each meta-analysis, 4 additional effect sizes will be computed using a publication bias correction method that performs well given the study\u2019s sample size and heterogeneity (see below), as well as the level of publication bias and population effect size which have to be assumed. Assuming these unknown parameters will create 4 separate conditions within which to perform the analysis: \n\n1.\tMedium publication bias and population effect size of \u03b4 = 0.2 (Condition 1)\n2.\tHigh publication bias and population effect size of \u03b4 = 0.2 (Condition 2)\n3.\tMedium publication bias and population effect size of \u03b4 = 0.5 (Condition 3)\n4.\tHigh publication bias and population effect size of \u03b4 = 0.5 (Condition 4)\n\nEach of the 4 corrected effect sizes will be computed using one of the following publication bias correction methods: \n\u2022\tPrecision-effect test (PET) \n\u2022\tPrecision-effect estimate with standard error (PEESE)\n\u2022\tPET-PEESE\n\u2022\tWeighted average of the adequately powered - weighted least squares (WAAP-WLS)\n\u2022\tTrim-and-fill \n\u2022\tp-curve\n\u2022\tp-uniform\n\u2022\tSelection model with 3 parameters (3PSM; \u201cweight function model\u201d)\n\u2022\tSelection model with 4 parameters (4PSM; \u201cweight function model\u201d)\n\nAny adjustments that were applied for each meta-analysis prior to the estimation of the final effect size (i.e. dealing with dependent effect sizes, addressing with outliers, artefact corrections, or any other data transformations, excluding publication bias corrections) will be applied in the current study prior to calculating the corrected estimates. Therefore, the baseline uncorrected estimate will match the estimate that was published in the paper. \n\nDecisions regarding the selection of appropriate correction method for each individual meta-analysis across each of the four conditions outlined above will be modelled according to a recent simulation study by Carter et al. (2019) who have published detailed results of their simulations in an online R Shiny app Meta-Showdown Explorer (http://shinyapps.org/apps/metaExplorer/). As some methods perform equally well or similarly well with other methods under specific combinations of the conditions, data from the \u201cEstimation\u201d section have been downloaded and transformed into an R function which selects the appropriate correction method using pre-defined criteria which take into account the mean error, root mean squared error, and, where relevant, coverage.\n\nCriteria for deciding which correction method to use: \n\n\u2022\tOut of the 9 correction methods, the method that is eventually selected has to have the smallest summary value for mean error and root mean squared error. \n\u2022\tSome methods (namely 3PSM, 4 PSM, p-curve and p-uniform) require p-values in order to be performed. If a p-value based method is evaluated as the best method and the p-values are available for a given meta-analysis, the p-value based method will be preferred. If p-values are not available, the second best performing method will be selected. \n\u2022\tIn cases where 3PSM and 4PSM are evaluated as the best and equally well performing, 4PSM will be selected as it accounts for more realistic conditions regarding significance values than 3PSM. If the data available are not suitable for 4PSM, the analysis will fall back to 3PSM. \n\u2022\tIf PET and PEESE are evaluated as the best and equally well performing, PET-PEESE will be selected as this method takes both PET and PEESE into account. \n\u2022\tIf PET and PET-PEESE are evaluated as the best and equally well performing, PET will be selected. PET-PEESE uses conditional probability of PET to decide whether to use PET or PEESE as the final estimate. Given that PEESE was not highlighted as well performing under the conditions of the meta-analysis that is being re-analysed, the estimate from this method is likely to be more biased, and so would potentially be the final estimate of PET-PEESE. \n\u2022\tSame logic as outlined in the point above applies to the situation where the decision between PET and PET-PEESE has to be made. \n\u2022\tIf there is a tie in the summary value between any other methods not specified in the previous points, coverage is used as the deciding factor - the method with coverage closest to nominal .95 will be selected. \nThe R project containing the selection function is attached (note: the R project will also be made available directly within the OSF repository with additional files used in later stages of the project. There is no intention to further modify this function past the registration point. However, should minor error fixes or adjustments be found necessary, these will be clearly outlined within the R script). \n\nExample:\n\nIt is not the case that a single one of these methods is always assigned to any of the 4 conditions defined by level of publication bias and population effect size. For example, for a study with a sample size k = 34 and \u03c42 = 0.2, the estimators that are evaluated being likely the least biased ones are 4PSM for condition 1, PET for condition 2, 3PSM for condition 3, and PEESE for condition 4. On the other hand, for a study with k = 14 and \u03c42 = 0.09, the estimators are 4PSM (condition 1), 4PSM (condition 2), 3PSM (condition 3), and WAAP-WLS (condition 4). Therefore, for the whole sample, corrected effect sizes will not necessarily be obtained by the same estimator within a single condition. \n"}, "uploader": {"extra": [{"data": {"name": "preregistration_v.2.0.pdf"}, "nodeId": "k9hqm", "sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91", "viewUrl": "/project/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "selectedFileName": "preregistration_v.2.0.pdf"}, {"data": {"name": "pb_correction_selection.zip"}, "nodeId": "k9hqm", "sha256": "74ae0fdd0623640e307936b29f4be14d4c4a21ccb6a03a77a778e4a126f66e07", "viewUrl": "/project/k9hqm/files/osfstorage/5e2608fa675e0e017c6b7551", "selectedFileName": "pb_correction_selection.zip"}], "value": ""}}}, "q18": {"value": {"question": {"extra": [], "value": ""}, "uploader": {"extra": [], "value": ""}}}, "q19": {"value": {"question": {"extra": [], "value": "For each of the 4 conditions, a separate 3-level Bayesian hierarchical model will be fitted (resulting in 4 models in total). Because published meta-analytic papers typically report multiple meta-analyses, effect sizes (level 1) are nested within meta-analyses (level 2) which themselves are nested within published papers (level 3). The form the model will take is specified in the attached document.  \n\nThe model predicts the effect size from the estimator type (factor with 2 levels: original uncorrected estimate vs corrected estimate). Additionally, crossed effect of the bias correction method will be modelled at level 2. Random effects will be fitted for the estimator, correction method, and the interaction between the estimator and the correction method.\n\nIt is possible that after the re-analysis, the number of values in each of the cells for the correction method will be insufficient to model the crossed effect. In such case, a simplified model without the cross-level interaction (specified in the attached document)\n\nIn either of the cases outlined above, model for each of the 4 conditions will be fitted using the brms R package for Bayesian multilevel modelling (B\u00fcrkner, 2017), with default uninformative priors. 95% highest posterior density intervals will subsequently be extracted from the models as the indicator of the plausible range of the attenuation in the effect sizes after the application of bias correcting methods. \n"}, "uploader": {"extra": [{"data": {"name": "preregistration_v.2.0.pdf"}, "nodeId": "k9hqm", "sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91", "viewUrl": "/project/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "selectedFileName": "preregistration_v.2.0.pdf"}], "value": ""}}}, "q20": {"extra": [], "value": "Where possible, the steps of the original analysis will be followed without additional data transformations. Because the majority of the coded papers report their effect sizes as Cohen\u2019s d, this will be the target metric. Data that use alternative effect size metrics (correlation coefficient r or odds ratio) will be converted into d using the formulae (from Borenstein et al., 2009) specified in the attached document."}, "q21": {"extra": [], "value": "Inferential tests will not be performed as part of the analysis. As the mathematical properties of the bias correcting methods will inevitably reduce the original effect sizes in the presence of publication bias, the analysis will focus on the estimates of the extent of this reduction.  "}, "q22": {"extra": [], "value": "No data are expected to be excluded on the basis of presence of outliers or violations of other model assumptions. To address potential issues, the original model will be compared to a robust model fitted using the brms R package as a form of sensitivity analysis. Should the original estimate substantially differ, the robust estimate will be interpreted instead. "}, "q23": {"extra": [], "value": "It is possible that some data will not be suitable for analysis with any of the well performing correction methods corresponding to one of the 4 conditions. In such cases, the data in question will be excluded for the condition where re-analysis is not possible but retained for the remaining conditions. "}, "q24": {"extra": [], "value": "Some meta-analyses may have used publication bias correction methods and reported the corrected estimates as well as the uncorrected ones. If this is found to be the case for a sufficient number of analyses, analyses that originally report corrected estimates will be grouped and analysed separately to see if the original corrected effect sizes differ from effect sizes computed using correction methods identified as suitable using the criteria employed in this study. "}, "q25": {"extra": [], "value": "***References***\n\nB\u00fcrkner, P. C. (2017). Advanced Bayesian multilevel modelling with the R package brms. arXiv preprint arXiv:1705.11123.\n\nCarter, E. C., Sch\u00f6nbrodt, F. D., Gervais, W. M., &amp; Hilgard, J. (2019). Correcting for bias in psychology: A comparison of meta-analytic methods. Advances in Methods and Practices in Psychological Science, 2(2), 115-144.\n\nBorenstein, M., Hedges, L. V., Higgins, J. P., &amp; Rothstein, H. R. (2009). Introduction to meta-analysis. John Wiley &amp; Sons.\n"}}, "registration_responses": {"q1": "Publication bias in psychology : Evaluating the robustness of meta-analytic effects", "q2": "Martina Sladekova", "q3": "***Due to OSF formatting settings, some sections of this form may be difficult to read. The attached document titled \"preregistration_v.2.0.pdf\" contains a formatted and otherwise identical version of this preregistration. The document can also be found in the OSF repository https://osf.io/k9hqm/***\n\nPublication bias is an ongoing problem affecting meta-analytic estimates of effect sizes. A number of methods correcting for small study effects and publication bias have been developed over the years, however these methods tend to be applied without the regard for optimal performance conditions of each method. \nThe aim of this study is to investigate:\n\na)\tThe extent to which meta-analysts in psychology attend to publication bias\nb)\tHow the published effect sizes change when the data are re-analysed with a publication bias correction method that has been found to perform well given specific conditions of each study. These conditions refer to heterogeneity of primary effect sizes, number of primary effects included in the meta-analysis, expected level of publication bias, and expected population effect size. \n\nBecause the level of publication bias and population effect size are unknown, changes in publication bias will be investigated separately within 4 conditions that assume: \n\n1.\tMedium publication bias and population effect size of \u03b4 = 0.2 (Condition 1)\n2.\tHigh publication bias and population effect size of \u03b4 = 0.2 (Condition 2)\n3.\tMedium publication bias and population effect size of \u03b4 = 0.5 (Condition 3)\n4.\tHigh publication bias and population effect size of \u03b4 = 0.5 (Condition 4)\n\nSee *Variables* and *Analysis Plan* sections for details. \n", "q4": "Objectives\n\nThe key objective is to estimate: \n\n(1)\tthe typical attenuation in published meta-analytic effect sizes after the application of publication bias correcting methods. \n(2)\tthe plausible range of this attenuation using 95% highest posterior density intervals. \n(3)\tthe plausible limits of variation in the effect size attenuation across different bias correcting methods\n\nThe analysis will be performed separately for the specific combinations of the level of publication bias and the population effect size, as specified above.  \n", "q5": "Other", "q6": ["No blinding is involved in this study."], "q7": "", "q9": "", "q10": "Registration prior to accessing the data", "q11": "Data were collected in two parts. \n\nPart 1 included random selection of meta-analyses published in 2008 and 2018, and subsequent coding of meta-analytic practices in these papers using a coding scheme. This phase of data collection lasted from February 2019 to June 2019. Authors of the present study were involved in the coding scheme development and data collection. Exact details of the coding scheme as well as analyses run on this dataset so far can be found at https://osf.io/ruvhd/ . No items from this dataset will be inferentially tested as outcome variables in the present study. \n\nPart 2 involves collection of raw data used in meta-analyses that were coded in Part 1. At the time of registration, raw data available in supplemental materials online have been downloaded. Data extraction directly from journal articles has begun, with the first dataset extracted on 03/09/2019. Additionally, 118 authors have been e-mailed with request for their data (first request sent on 10/10/2019), out of which 23 made their data available, 24 confirmed that they no longer have access to the data, with remaining 71 requests pending on 27/12/19. \n\nNo data that have been downloaded, extracted, or received from the authors has been in any way transformed or analysed. No additional variables have been computed for any of the datasets at time of the registration. Some authors of the meta-analyses included in the sample have sent their datasets with a computed variance measure; however, no additional analyses were performed on said datasets. As such the main outcome measure for this study has not yet been obtained for any of the studies. \n", "q13": "Attempt will be made to obtain raw data for every single meta-analysis included in Part 1 (spreadsheet with all the studies included in Part 1 can be found at https://osf.io/ruvhd/). Should this effort be successful, and all the studies are found to be eligible, this will result in the inclusion of 170 published papers (level 3 units), containing 1242 individual meta-analyses (level 2 units), each containing uncorrected and corrected effect size estimates (resulting in 2484 level 1 units within each of the 4 conditions). This is the maximum upper boundary of the sample size, however at the time of registration, the expected sample size is 107 published papers containing 478 individual meta-analysis, each containing uncorrected and correct effect size estimates and therefore 956 level 1 units within each of the 4 conditions. ", "q14": "Sample size for Part 1 was determined by time constraints of the project with the aim to code as many studies as possible. Sample size for this part of the project will be determined by data availability and alignment with inclusion/exclusion criteria outlined above. ", "q15": "", "q20": "Where possible, the steps of the original analysis will be followed without additional data transformations. Because the majority of the coded papers report their effect sizes as Cohen\u2019s d, this will be the target metric. Data that use alternative effect size metrics (correlation coefficient r or odds ratio) will be converted into d using the formulae (from Borenstein et al., 2009) specified in the attached document.", "q21": "Inferential tests will not be performed as part of the analysis. As the mathematical properties of the bias correcting methods will inevitably reduce the original effect sizes in the presence of publication bias, the analysis will focus on the estimates of the extent of this reduction.  ", "q22": "No data are expected to be excluded on the basis of presence of outliers or violations of other model assumptions. To address potential issues, the original model will be compared to a robust model fitted using the brms R package as a form of sensitivity analysis. Should the original estimate substantially differ, the robust estimate will be interpreted instead. ", "q23": "It is possible that some data will not be suitable for analysis with any of the well performing correction methods corresponding to one of the 4 conditions. In such cases, the data in question will be excluded for the condition where re-analysis is not possible but retained for the remaining conditions. ", "q24": "Some meta-analyses may have used publication bias correction methods and reported the corrected estimates as well as the uncorrected ones. If this is found to be the case for a sufficient number of analyses, analyses that originally report corrected estimates will be grouped and analysed separately to see if the original corrected effect sizes differ from effect sizes computed using correction methods identified as suitable using the criteria employed in this study. ", "q25": "***References***\n\nB\u00fcrkner, P. C. (2017). Advanced Bayesian multilevel modelling with the R package brms. arXiv preprint arXiv:1705.11123.\n\nCarter, E. C., Sch\u00f6nbrodt, F. D., Gervais, W. M., &amp; Hilgard, J. (2019). Correcting for bias in psychology: A comparison of meta-analytic methods. Advances in Methods and Practices in Psychological Science, 2(2), 115-144.\n\nBorenstein, M., Hedges, L. V., Higgins, J. P., &amp; Rothstein, H. R. (2009). Introduction to meta-analysis. John Wiley &amp; Sons.\n", "q8.question": "The final data will have 3-level hierarchical structure. Models will be fitted for each of the 4 conditions separately. Level 1 predictor (effect size estimator) is a factor with 2 levels (original uncorrected estimator vs bias-corrected estimate); outcome is the effect size (continuous variable). See *Variables* and *Analysis Plan* for details. ", "q8.uploader": [{"file_id": "5e2608e9edceab019882e23c", "file_name": "preregistration_v.2.0.pdf", "file_urls": {"html": "https://osf.io/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "download": "https://osf.io/download/q4nhf/"}, "file_hashes": {"sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91"}}], "q12.question": "Details of study selection, inclusion/exclusion criteria and coding procedures for Part 1 can be found at https://osf.io/ruvhd/ . \n\nAs detailed above, data for Part 2 are being obtained via the following means: \n\u2022\tDownloading supplemental materials linked to the published papers\n\u2022\tExtracting data from tables and forest plots published within journal articles\n\u2022\tE-mailing the authors of the meta-analyses with requests for their data\n\nData collection will finish after the last author has responded, expected no later than 31/01/2020. \n\nInclusion criteria: \ni.\tStudy was included in Part 1 of this project. \ni.\tData for the study is accessible or made available by the authors \nii.\tStudy reports effect sizes in form of Cohen\u2019s d or provides parameters that enable transformation into Cohen\u2019s d.\niii.\tStudy provides the information necessary for computation or estimation of variance of the primary studies, and the t statistic where relevant for the appropriate publication bias correction method (see Variables and Analysis Plan for details.)\n\nExclusion criteria:\nIn addition to failing to meet the above inclusion criteria, studies will be excluded if: \ni.\tStudy is a meta-meta-analysis or a meta-analysis using internal databases as opposed to published research papers, as the nature of publication bias in these types of samples is different to the publication bias investigated in the present study. \nii.\tData are insufficient to reproduce the original analysis and the attempts to consult with the author of the paper are unsuccessful. \n", "q12.uploader": [{"file_id": "5e2608e9edceab019882e23c", "file_name": "preregistration_v.2.0.pdf", "file_urls": {"html": "https://osf.io/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "download": "https://osf.io/download/q4nhf/"}, "file_hashes": {"sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91"}}], "q16.question": "", "q16.uploader": [], "q17.question": "Variables collected in Part 1 which will be summarised using only descriptive statistics without inferential tests: \n\n\n\n\u2022\tNumber of unpublished studies included in the meta-analysis\n\u2022\tMethod used to obtain unpublished studies [multiple selection from: Undisclosed; Unpublished studies not included on purpose; Contact - first authors; Contact - authors from the reference list; Internet search of databases (such as OSF); Search of dissertation archives; Search of conference proceedings; Other - text box]\n\u2022\tResponse rate when contacting authors about unpublished studies [Authors contacted - integer; Authors responded - integer]\n\u2022\tMethod of addressing publication bias [Not applicable (publication bias not found); Trim-and-fill; Inclusion of unpublished studies; Weight function models (Vevea &amp; Hedges); Egger (regression); Egger-var (regression); Harbord (regression); Peters (regression); WLS; WAAP-WLS; PET-PEESE; Bayesian methods; Other - text box]\n\u2022\tMethod used to check for the presence of publication bias [Undisclosed; Visual - funnel plot; Visual - p-curve; Trim-and-fill (sensitivity analysis); Rosenthal\u2019s fail-safe N; Orwin\u2019s fail-safe N; Reverse correlation between effect sizes and sample sizes; Funnel asymmetry test; Precision effect test; Ioannidis &amp; Trikalinos (2007) publication bias test; Other - text box]\n\u2022\tAuthors\u2019 conclusion about the presence of publication bias in the meta-analytic sample [Present; Not present; Not reported]\n\nOutcome variables computed for Part 2 of the project: \n\nEach meta-analysis (level 2 unit) will contain 2 effect sizes (level 1 units), which is the primary outcome of this study. These effect sizes are: \n\n1.\tOriginal uncorrected effect size as published in the paper\n2.\tEffect size corrected by a publication bias correction method. Performance of a correction method is affected by the study\u2019s sample size and heterogeneity of primary effect sizes (defined by \u03c42), as well as unknown factors such as the level of publication bias and the population effect size. Therefore, for each meta-analysis, 4 additional effect sizes will be computed using a publication bias correction method that performs well given the study\u2019s sample size and heterogeneity (see below), as well as the level of publication bias and population effect size which have to be assumed. Assuming these unknown parameters will create 4 separate conditions within which to perform the analysis: \n\n1.\tMedium publication bias and population effect size of \u03b4 = 0.2 (Condition 1)\n2.\tHigh publication bias and population effect size of \u03b4 = 0.2 (Condition 2)\n3.\tMedium publication bias and population effect size of \u03b4 = 0.5 (Condition 3)\n4.\tHigh publication bias and population effect size of \u03b4 = 0.5 (Condition 4)\n\nEach of the 4 corrected effect sizes will be computed using one of the following publication bias correction methods: \n\u2022\tPrecision-effect test (PET) \n\u2022\tPrecision-effect estimate with standard error (PEESE)\n\u2022\tPET-PEESE\n\u2022\tWeighted average of the adequately powered - weighted least squares (WAAP-WLS)\n\u2022\tTrim-and-fill \n\u2022\tp-curve\n\u2022\tp-uniform\n\u2022\tSelection model with 3 parameters (3PSM; \u201cweight function model\u201d)\n\u2022\tSelection model with 4 parameters (4PSM; \u201cweight function model\u201d)\n\nAny adjustments that were applied for each meta-analysis prior to the estimation of the final effect size (i.e. dealing with dependent effect sizes, addressing with outliers, artefact corrections, or any other data transformations, excluding publication bias corrections) will be applied in the current study prior to calculating the corrected estimates. Therefore, the baseline uncorrected estimate will match the estimate that was published in the paper. \n\nDecisions regarding the selection of appropriate correction method for each individual meta-analysis across each of the four conditions outlined above will be modelled according to a recent simulation study by Carter et al. (2019) who have published detailed results of their simulations in an online R Shiny app Meta-Showdown Explorer (http://shinyapps.org/apps/metaExplorer/). As some methods perform equally well or similarly well with other methods under specific combinations of the conditions, data from the \u201cEstimation\u201d section have been downloaded and transformed into an R function which selects the appropriate correction method using pre-defined criteria which take into account the mean error, root mean squared error, and, where relevant, coverage.\n\nCriteria for deciding which correction method to use: \n\n\u2022\tOut of the 9 correction methods, the method that is eventually selected has to have the smallest summary value for mean error and root mean squared error. \n\u2022\tSome methods (namely 3PSM, 4 PSM, p-curve and p-uniform) require p-values in order to be performed. If a p-value based method is evaluated as the best method and the p-values are available for a given meta-analysis, the p-value based method will be preferred. If p-values are not available, the second best performing method will be selected. \n\u2022\tIn cases where 3PSM and 4PSM are evaluated as the best and equally well performing, 4PSM will be selected as it accounts for more realistic conditions regarding significance values than 3PSM. If the data available are not suitable for 4PSM, the analysis will fall back to 3PSM. \n\u2022\tIf PET and PEESE are evaluated as the best and equally well performing, PET-PEESE will be selected as this method takes both PET and PEESE into account. \n\u2022\tIf PET and PET-PEESE are evaluated as the best and equally well performing, PET will be selected. PET-PEESE uses conditional probability of PET to decide whether to use PET or PEESE as the final estimate. Given that PEESE was not highlighted as well performing under the conditions of the meta-analysis that is being re-analysed, the estimate from this method is likely to be more biased, and so would potentially be the final estimate of PET-PEESE. \n\u2022\tSame logic as outlined in the point above applies to the situation where the decision between PET and PET-PEESE has to be made. \n\u2022\tIf there is a tie in the summary value between any other methods not specified in the previous points, coverage is used as the deciding factor - the method with coverage closest to nominal .95 will be selected. \nThe R project containing the selection function is attached (note: the R project will also be made available directly within the OSF repository with additional files used in later stages of the project. There is no intention to further modify this function past the registration point. However, should minor error fixes or adjustments be found necessary, these will be clearly outlined within the R script). \n\nExample:\n\nIt is not the case that a single one of these methods is always assigned to any of the 4 conditions defined by level of publication bias and population effect size. For example, for a study with a sample size k = 34 and \u03c42 = 0.2, the estimators that are evaluated being likely the least biased ones are 4PSM for condition 1, PET for condition 2, 3PSM for condition 3, and PEESE for condition 4. On the other hand, for a study with k = 14 and \u03c42 = 0.09, the estimators are 4PSM (condition 1), 4PSM (condition 2), 3PSM (condition 3), and WAAP-WLS (condition 4). Therefore, for the whole sample, corrected effect sizes will not necessarily be obtained by the same estimator within a single condition. \n", "q17.uploader": [{"file_id": "5e2608e9edceab019882e23c", "file_name": "preregistration_v.2.0.pdf", "file_urls": {"html": "https://osf.io/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "download": "https://osf.io/download/q4nhf/"}, "file_hashes": {"sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91"}}, {"file_id": "5e2608fa675e0e017c6b7551", "file_name": "pb_correction_selection.zip", "file_urls": {"html": "https://osf.io/k9hqm/files/osfstorage/5e2608fa675e0e017c6b7551", "download": "https://osf.io/download/5v6eu/"}, "file_hashes": {"sha256": "74ae0fdd0623640e307936b29f4be14d4c4a21ccb6a03a77a778e4a126f66e07"}}], "q18.question": "", "q18.uploader": [], "q19.question": "For each of the 4 conditions, a separate 3-level Bayesian hierarchical model will be fitted (resulting in 4 models in total). Because published meta-analytic papers typically report multiple meta-analyses, effect sizes (level 1) are nested within meta-analyses (level 2) which themselves are nested within published papers (level 3). The form the model will take is specified in the attached document.  \n\nThe model predicts the effect size from the estimator type (factor with 2 levels: original uncorrected estimate vs corrected estimate). Additionally, crossed effect of the bias correction method will be modelled at level 2. Random effects will be fitted for the estimator, correction method, and the interaction between the estimator and the correction method.\n\nIt is possible that after the re-analysis, the number of values in each of the cells for the correction method will be insufficient to model the crossed effect. In such case, a simplified model without the cross-level interaction (specified in the attached document)\n\nIn either of the cases outlined above, model for each of the 4 conditions will be fitted using the brms R package for Bayesian multilevel modelling (B\u00fcrkner, 2017), with default uninformative priors. 95% highest posterior density intervals will subsequently be extracted from the models as the indicator of the plausible range of the attenuation in the effect sizes after the application of bias correcting methods. \n", "q19.uploader": [{"file_id": "5e2608e9edceab019882e23c", "file_name": "preregistration_v.2.0.pdf", "file_urls": {"html": "https://osf.io/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "download": "https://osf.io/download/q4nhf/"}, "file_hashes": {"sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91"}}]}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/s3wex/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/s3wex/comments/?format=json&filter%5Btarget%5D=s3wex", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/s3wex/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/s3wex/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/s3wex/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/s3wex/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/s3wex/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/s3wex/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/s3wex/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/s3wex/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/s3wex/linked_by_registrations/?format=json", "meta": {}}}}, "parent": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/?format=json", "meta": {}}}, "data": {"id": "kxjs3", "type": "registrations"}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/s3wex/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/s3wex/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/s3wex/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/?format=json", "meta": {}}}, "data": {"id": "kxjs3", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/s3wex/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/s3wex/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/s3wex/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/s3wex/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/s3wex/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/s3wex/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/s3wex/citation/?format=json", "meta": {}}}, "data": {"id": "s3wex", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/vq6rm/?format=json", "meta": {}}}, "data": {"id": "vq6rm", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/pzv42/?format=json", "meta": {}}}, "data": {"id": "pzv42", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5c08457ed283380029cf73bf/?format=json", "meta": {}}}, "data": {"id": "5c08457ed283380029cf73bf", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/s3wex/", "self": "https://api.osf.io/v2/registrations/s3wex/"}}, {"id": "y6bng", "type": "registrations", "attributes": {"title": "Preregistration", "description": "", "category": "hypothesis", "custom_citation": "", "date_created": "2020-01-20T20:11:29.139259", "date_modified": "2020-01-20T20:05:22.758831", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "00465e094ab56c66919902515bf2b9efaecf4aa9bc8cfac9be5cbf810184e6ce368cdb4d0fadab31fda40273d614f49964c4161e3ed9267a2561eaeda5c0e65373581a4b67a5e606f67ceefa87b126ba1bf9efe664dabebc302c5531306abe68295d981eb575447a6195f9ef64fd94724795cc03bc25cdada819cadb25270d2f1b0d6435e5ea041ed5b8b22c08343a18", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-20T20:11:29.119688", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "OSF Preregistration", "registered_meta": {"q1": {"extra": [], "value": "Publication bias in psychology : Evaluating the robustness of meta-analytic effects"}, "q2": {"extra": [], "value": "Martina Sladekova"}, "q3": {"extra": [], "value": "***Due to OSF formatting settings, some sections of this form may be difficult to read. The attached document titled \"preregistration_v.2.0.pdf\" contains a formatted and otherwise identical version of this preregistration. The document can also be found in the OSF repository https://osf.io/k9hqm/***\n\nPublication bias is an ongoing problem affecting meta-analytic estimates of effect sizes. A number of methods correcting for small study effects and publication bias have been developed over the years, however these methods tend to be applied without the regard for optimal performance conditions of each method. \nThe aim of this study is to investigate:\n\na)\tThe extent to which meta-analysts in psychology attend to publication bias\nb)\tHow the published effect sizes change when the data are re-analysed with a publication bias correction method that has been found to perform well given specific conditions of each study. These conditions refer to heterogeneity of primary effect sizes, number of primary effects included in the meta-analysis, expected level of publication bias, and expected population effect size. \n\nBecause the level of publication bias and population effect size are unknown, changes in publication bias will be investigated separately within 4 conditions that assume: \n\n1.\tMedium publication bias and population effect size of \u03b4 = 0.2 (Condition 1)\n2.\tHigh publication bias and population effect size of \u03b4 = 0.2 (Condition 2)\n3.\tMedium publication bias and population effect size of \u03b4 = 0.5 (Condition 3)\n4.\tHigh publication bias and population effect size of \u03b4 = 0.5 (Condition 4)\n\nSee *Variables* and *Analysis Plan* sections for details. \n"}, "q4": {"extra": [], "value": "Objectives\n\nThe key objective is to estimate: \n\n(1)\tthe typical attenuation in published meta-analytic effect sizes after the application of publication bias correcting methods. \n(2)\tthe plausible range of this attenuation using 95% highest posterior density intervals. \n(3)\tthe plausible limits of variation in the effect size attenuation across different bias correcting methods\n\nThe analysis will be performed separately for the specific combinations of the level of publication bias and the population effect size, as specified above.  \n"}, "q5": {"extra": [], "value": "Other"}, "q6": {"extra": [], "value": ["No blinding is involved in this study."]}, "q7": {"extra": [], "value": ""}, "q8": {"value": {"question": {"extra": [], "value": "The final data will have 3-level hierarchical structure. Models will be fitted for each of the 4 conditions separately. Level 1 predictor (effect size estimator) is a factor with 2 levels (original uncorrected estimator vs bias-corrected estimate); outcome is the effect size (continuous variable). See *Variables* and *Analysis Plan* for details. "}, "uploader": {"extra": [{"data": {"name": "preregistration_v.2.0.pdf"}, "nodeId": "k9hqm", "sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91", "viewUrl": "/project/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "selectedFileName": "preregistration_v.2.0.pdf"}], "value": ""}}}, "q9": {"extra": [], "value": ""}, "q10": {"extra": [], "value": "Registration prior to accessing the data"}, "q11": {"extra": [], "value": "Data were collected in two parts. \n\nPart 1 included random selection of meta-analyses published in 2008 and 2018, and subsequent coding of meta-analytic practices in these papers using a coding scheme. This phase of data collection lasted from February 2019 to June 2019. Authors of the present study were involved in the coding scheme development and data collection. Exact details of the coding scheme as well as analyses run on this dataset so far can be found at https://osf.io/ruvhd/ . No items from this dataset will be inferentially tested as outcome variables in the present study. \n\nPart 2 involves collection of raw data used in meta-analyses that were coded in Part 1. At the time of registration, raw data available in supplemental materials online have been downloaded. Data extraction directly from journal articles has begun, with the first dataset extracted on 03/09/2019. Additionally, 118 authors have been e-mailed with request for their data (first request sent on 10/10/2019), out of which 23 made their data available, 24 confirmed that they no longer have access to the data, with remaining 71 requests pending on 27/12/19. \n\nNo data that have been downloaded, extracted, or received from the authors has been in any way transformed or analysed. No additional variables have been computed for any of the datasets at time of the registration. Some authors of the meta-analyses included in the sample have sent their datasets with a computed variance measure; however, no additional analyses were performed on said datasets. As such the main outcome measure for this study has not yet been obtained for any of the studies. \n"}, "q12": {"value": {"question": {"extra": [], "value": "Details of study selection, inclusion/exclusion criteria and coding procedures for Part 1 can be found at https://osf.io/ruvhd/ . \n\nAs detailed above, data for Part 2 are being obtained via the following means: \n\u2022\tDownloading supplemental materials linked to the published papers\n\u2022\tExtracting data from tables and forest plots published within journal articles\n\u2022\tE-mailing the authors of the meta-analyses with requests for their data\n\nData collection will finish after the last author has responded, expected no later than 31/01/2020. \n\nInclusion criteria: \ni.\tStudy was included in Part 1 of this project. \ni.\tData for the study is accessible or made available by the authors \nii.\tStudy reports effect sizes in form of Cohen\u2019s d or provides parameters that enable transformation into Cohen\u2019s d.\niii.\tStudy provides the information necessary for computation or estimation of variance of the primary studies, and the t statistic where relevant for the appropriate publication bias correction method (see Variables and Analysis Plan for details.)\n\nExclusion criteria:\nIn addition to failing to meet the above inclusion criteria, studies will be excluded if: \ni.\tStudy is a meta-meta-analysis or a meta-analysis using internal databases as opposed to published research papers, as the nature of publication bias in these types of samples is different to the publication bias investigated in the present study. \nii.\tData are insufficient to reproduce the original analysis and the attempts to consult with the author of the paper are unsuccessful. \n"}, "uploader": {"extra": [{"data": {"name": "preregistration_v.2.0.pdf"}, "nodeId": "k9hqm", "sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91", "viewUrl": "/project/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "selectedFileName": "preregistration_v.2.0.pdf"}], "value": ""}}}, "q13": {"extra": [], "value": "Attempt will be made to obtain raw data for every single meta-analysis included in Part 1 (spreadsheet with all the studies included in Part 1 can be found at https://osf.io/ruvhd/). Should this effort be successful, and all the studies are found to be eligible, this will result in the inclusion of 170 published papers (level 3 units), containing 1242 individual meta-analyses (level 2 units), each containing uncorrected and corrected effect size estimates (resulting in 2484 level 1 units within each of the 4 conditions). This is the maximum upper boundary of the sample size, however at the time of registration, the expected sample size is 107 published papers containing 478 individual meta-analysis, each containing uncorrected and correct effect size estimates and therefore 956 level 1 units within each of the 4 conditions. "}, "q14": {"extra": [], "value": "Sample size for Part 1 was determined by time constraints of the project with the aim to code as many studies as possible. Sample size for this part of the project will be determined by data availability and alignment with inclusion/exclusion criteria outlined above. "}, "q15": {"extra": [], "value": ""}, "q16": {"value": {"question": {"extra": [], "value": ""}, "uploader": {"extra": [], "value": ""}}}, "q17": {"value": {"question": {"extra": [], "value": "Variables collected in Part 1 which will be summarised using only descriptive statistics without inferential tests: \n\n\n\n\u2022\tNumber of unpublished studies included in the meta-analysis\n\u2022\tMethod used to obtain unpublished studies [multiple selection from: Undisclosed; Unpublished studies not included on purpose; Contact - first authors; Contact - authors from the reference list; Internet search of databases (such as OSF); Search of dissertation archives; Search of conference proceedings; Other - text box]\n\u2022\tResponse rate when contacting authors about unpublished studies [Authors contacted - integer; Authors responded - integer]\n\u2022\tMethod of addressing publication bias [Not applicable (publication bias not found); Trim-and-fill; Inclusion of unpublished studies; Weight function models (Vevea &amp; Hedges); Egger (regression); Egger-var (regression); Harbord (regression); Peters (regression); WLS; WAAP-WLS; PET-PEESE; Bayesian methods; Other - text box]\n\u2022\tMethod used to check for the presence of publication bias [Undisclosed; Visual - funnel plot; Visual - p-curve; Trim-and-fill (sensitivity analysis); Rosenthal\u2019s fail-safe N; Orwin\u2019s fail-safe N; Reverse correlation between effect sizes and sample sizes; Funnel asymmetry test; Precision effect test; Ioannidis &amp; Trikalinos (2007) publication bias test; Other - text box]\n\u2022\tAuthors\u2019 conclusion about the presence of publication bias in the meta-analytic sample [Present; Not present; Not reported]\n\nOutcome variables computed for Part 2 of the project: \n\nEach meta-analysis (level 2 unit) will contain 2 effect sizes (level 1 units), which is the primary outcome of this study. These effect sizes are: \n\n1.\tOriginal uncorrected effect size as published in the paper\n2.\tEffect size corrected by a publication bias correction method. Performance of a correction method is affected by the study\u2019s sample size and heterogeneity of primary effect sizes (defined by \u03c42), as well as unknown factors such as the level of publication bias and the population effect size. Therefore, for each meta-analysis, 4 additional effect sizes will be computed using a publication bias correction method that performs well given the study\u2019s sample size and heterogeneity (see below), as well as the level of publication bias and population effect size which have to be assumed. Assuming these unknown parameters will create 4 separate conditions within which to perform the analysis: \n\n1.\tMedium publication bias and population effect size of \u03b4 = 0.2 (Condition 1)\n2.\tHigh publication bias and population effect size of \u03b4 = 0.2 (Condition 2)\n3.\tMedium publication bias and population effect size of \u03b4 = 0.5 (Condition 3)\n4.\tHigh publication bias and population effect size of \u03b4 = 0.5 (Condition 4)\n\nEach of the 4 corrected effect sizes will be computed using one of the following publication bias correction methods: \n\u2022\tPrecision-effect test (PET) \n\u2022\tPrecision-effect estimate with standard error (PEESE)\n\u2022\tPET-PEESE\n\u2022\tWeighted average of the adequately powered - weighted least squares (WAAP-WLS)\n\u2022\tTrim-and-fill \n\u2022\tp-curve\n\u2022\tp-uniform\n\u2022\tSelection model with 3 parameters (3PSM; \u201cweight function model\u201d)\n\u2022\tSelection model with 4 parameters (4PSM; \u201cweight function model\u201d)\n\nAny adjustments that were applied for each meta-analysis prior to the estimation of the final effect size (i.e. dealing with dependent effect sizes, addressing with outliers, artefact corrections, or any other data transformations, excluding publication bias corrections) will be applied in the current study prior to calculating the corrected estimates. Therefore, the baseline uncorrected estimate will match the estimate that was published in the paper. \n\nDecisions regarding the selection of appropriate correction method for each individual meta-analysis across each of the four conditions outlined above will be modelled according to a recent simulation study by Carter et al. (2019) who have published detailed results of their simulations in an online R Shiny app Meta-Showdown Explorer (http://shinyapps.org/apps/metaExplorer/). As some methods perform equally well or similarly well with other methods under specific combinations of the conditions, data from the \u201cEstimation\u201d section have been downloaded and transformed into an R function which selects the appropriate correction method using pre-defined criteria which take into account the mean error, root mean squared error, and, where relevant, coverage.\n\nCriteria for deciding which correction method to use: \n\n\u2022\tOut of the 9 correction methods, the method that is eventually selected has to have the smallest summary value for mean error and root mean squared error. \n\u2022\tSome methods (namely 3PSM, 4 PSM, p-curve and p-uniform) require p-values in order to be performed. If a p-value based method is evaluated as the best method and the p-values are available for a given meta-analysis, the p-value based method will be preferred. If p-values are not available, the second best performing method will be selected. \n\u2022\tIn cases where 3PSM and 4PSM are evaluated as the best and equally well performing, 4PSM will be selected as it accounts for more realistic conditions regarding significance values than 3PSM. If the data available are not suitable for 4PSM, the analysis will fall back to 3PSM. \n\u2022\tIf PET and PEESE are evaluated as the best and equally well performing, PET-PEESE will be selected as this method takes both PET and PEESE into account. \n\u2022\tIf PET and PET-PEESE are evaluated as the best and equally well performing, PET will be selected. PET-PEESE uses conditional probability of PET to decide whether to use PET or PEESE as the final estimate. Given that PEESE was not highlighted as well performing under the conditions of the meta-analysis that is being re-analysed, the estimate from this method is likely to be more biased, and so would potentially be the final estimate of PET-PEESE. \n\u2022\tSame logic as outlined in the point above applies to the situation where the decision between PET and PET-PEESE has to be made. \n\u2022\tIf there is a tie in the summary value between any other methods not specified in the previous points, coverage is used as the deciding factor - the method with coverage closest to nominal .95 will be selected. \nThe R project containing the selection function is attached (note: the R project will also be made available directly within the OSF repository with additional files used in later stages of the project. There is no intention to further modify this function past the registration point. However, should minor error fixes or adjustments be found necessary, these will be clearly outlined within the R script). \n\nExample:\n\nIt is not the case that a single one of these methods is always assigned to any of the 4 conditions defined by level of publication bias and population effect size. For example, for a study with a sample size k = 34 and \u03c42 = 0.2, the estimators that are evaluated being likely the least biased ones are 4PSM for condition 1, PET for condition 2, 3PSM for condition 3, and PEESE for condition 4. On the other hand, for a study with k = 14 and \u03c42 = 0.09, the estimators are 4PSM (condition 1), 4PSM (condition 2), 3PSM (condition 3), and WAAP-WLS (condition 4). Therefore, for the whole sample, corrected effect sizes will not necessarily be obtained by the same estimator within a single condition. \n"}, "uploader": {"extra": [{"data": {"name": "preregistration_v.2.0.pdf"}, "nodeId": "k9hqm", "sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91", "viewUrl": "/project/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "selectedFileName": "preregistration_v.2.0.pdf"}, {"data": {"name": "pb_correction_selection.zip"}, "nodeId": "k9hqm", "sha256": "74ae0fdd0623640e307936b29f4be14d4c4a21ccb6a03a77a778e4a126f66e07", "viewUrl": "/project/k9hqm/files/osfstorage/5e2608fa675e0e017c6b7551", "selectedFileName": "pb_correction_selection.zip"}], "value": ""}}}, "q18": {"value": {"question": {"extra": [], "value": ""}, "uploader": {"extra": [], "value": ""}}}, "q19": {"value": {"question": {"extra": [], "value": "For each of the 4 conditions, a separate 3-level Bayesian hierarchical model will be fitted (resulting in 4 models in total). Because published meta-analytic papers typically report multiple meta-analyses, effect sizes (level 1) are nested within meta-analyses (level 2) which themselves are nested within published papers (level 3). The form the model will take is specified in the attached document.  \n\nThe model predicts the effect size from the estimator type (factor with 2 levels: original uncorrected estimate vs corrected estimate). Additionally, crossed effect of the bias correction method will be modelled at level 2. Random effects will be fitted for the estimator, correction method, and the interaction between the estimator and the correction method.\n\nIt is possible that after the re-analysis, the number of values in each of the cells for the correction method will be insufficient to model the crossed effect. In such case, a simplified model without the cross-level interaction (specified in the attached document)\n\nIn either of the cases outlined above, model for each of the 4 conditions will be fitted using the brms R package for Bayesian multilevel modelling (B\u00fcrkner, 2017), with default uninformative priors. 95% highest posterior density intervals will subsequently be extracted from the models as the indicator of the plausible range of the attenuation in the effect sizes after the application of bias correcting methods. \n"}, "uploader": {"extra": [{"data": {"name": "preregistration_v.2.0.pdf"}, "nodeId": "k9hqm", "sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91", "viewUrl": "/project/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "selectedFileName": "preregistration_v.2.0.pdf"}], "value": ""}}}, "q20": {"extra": [], "value": "Where possible, the steps of the original analysis will be followed without additional data transformations. Because the majority of the coded papers report their effect sizes as Cohen\u2019s d, this will be the target metric. Data that use alternative effect size metrics (correlation coefficient r or odds ratio) will be converted into d using the formulae (from Borenstein et al., 2009) specified in the attached document."}, "q21": {"extra": [], "value": "Inferential tests will not be performed as part of the analysis. As the mathematical properties of the bias correcting methods will inevitably reduce the original effect sizes in the presence of publication bias, the analysis will focus on the estimates of the extent of this reduction.  "}, "q22": {"extra": [], "value": "No data are expected to be excluded on the basis of presence of outliers or violations of other model assumptions. To address potential issues, the original model will be compared to a robust model fitted using the brms R package as a form of sensitivity analysis. Should the original estimate substantially differ, the robust estimate will be interpreted instead. "}, "q23": {"extra": [], "value": "It is possible that some data will not be suitable for analysis with any of the well performing correction methods corresponding to one of the 4 conditions. In such cases, the data in question will be excluded for the condition where re-analysis is not possible but retained for the remaining conditions. "}, "q24": {"extra": [], "value": "Some meta-analyses may have used publication bias correction methods and reported the corrected estimates as well as the uncorrected ones. If this is found to be the case for a sufficient number of analyses, analyses that originally report corrected estimates will be grouped and analysed separately to see if the original corrected effect sizes differ from effect sizes computed using correction methods identified as suitable using the criteria employed in this study. "}, "q25": {"extra": [], "value": "***References***\n\nB\u00fcrkner, P. C. (2017). Advanced Bayesian multilevel modelling with the R package brms. arXiv preprint arXiv:1705.11123.\n\nCarter, E. C., Sch\u00f6nbrodt, F. D., Gervais, W. M., &amp; Hilgard, J. (2019). Correcting for bias in psychology: A comparison of meta-analytic methods. Advances in Methods and Practices in Psychological Science, 2(2), 115-144.\n\nBorenstein, M., Hedges, L. V., Higgins, J. P., &amp; Rothstein, H. R. (2009). Introduction to meta-analysis. John Wiley &amp; Sons.\n"}}, "registration_responses": {"q1": "Publication bias in psychology : Evaluating the robustness of meta-analytic effects", "q2": "Martina Sladekova", "q3": "***Due to OSF formatting settings, some sections of this form may be difficult to read. The attached document titled \"preregistration_v.2.0.pdf\" contains a formatted and otherwise identical version of this preregistration. The document can also be found in the OSF repository https://osf.io/k9hqm/***\n\nPublication bias is an ongoing problem affecting meta-analytic estimates of effect sizes. A number of methods correcting for small study effects and publication bias have been developed over the years, however these methods tend to be applied without the regard for optimal performance conditions of each method. \nThe aim of this study is to investigate:\n\na)\tThe extent to which meta-analysts in psychology attend to publication bias\nb)\tHow the published effect sizes change when the data are re-analysed with a publication bias correction method that has been found to perform well given specific conditions of each study. These conditions refer to heterogeneity of primary effect sizes, number of primary effects included in the meta-analysis, expected level of publication bias, and expected population effect size. \n\nBecause the level of publication bias and population effect size are unknown, changes in publication bias will be investigated separately within 4 conditions that assume: \n\n1.\tMedium publication bias and population effect size of \u03b4 = 0.2 (Condition 1)\n2.\tHigh publication bias and population effect size of \u03b4 = 0.2 (Condition 2)\n3.\tMedium publication bias and population effect size of \u03b4 = 0.5 (Condition 3)\n4.\tHigh publication bias and population effect size of \u03b4 = 0.5 (Condition 4)\n\nSee *Variables* and *Analysis Plan* sections for details. \n", "q4": "Objectives\n\nThe key objective is to estimate: \n\n(1)\tthe typical attenuation in published meta-analytic effect sizes after the application of publication bias correcting methods. \n(2)\tthe plausible range of this attenuation using 95% highest posterior density intervals. \n(3)\tthe plausible limits of variation in the effect size attenuation across different bias correcting methods\n\nThe analysis will be performed separately for the specific combinations of the level of publication bias and the population effect size, as specified above.  \n", "q5": "Other", "q6": ["No blinding is involved in this study."], "q7": "", "q9": "", "q10": "Registration prior to accessing the data", "q11": "Data were collected in two parts. \n\nPart 1 included random selection of meta-analyses published in 2008 and 2018, and subsequent coding of meta-analytic practices in these papers using a coding scheme. This phase of data collection lasted from February 2019 to June 2019. Authors of the present study were involved in the coding scheme development and data collection. Exact details of the coding scheme as well as analyses run on this dataset so far can be found at https://osf.io/ruvhd/ . No items from this dataset will be inferentially tested as outcome variables in the present study. \n\nPart 2 involves collection of raw data used in meta-analyses that were coded in Part 1. At the time of registration, raw data available in supplemental materials online have been downloaded. Data extraction directly from journal articles has begun, with the first dataset extracted on 03/09/2019. Additionally, 118 authors have been e-mailed with request for their data (first request sent on 10/10/2019), out of which 23 made their data available, 24 confirmed that they no longer have access to the data, with remaining 71 requests pending on 27/12/19. \n\nNo data that have been downloaded, extracted, or received from the authors has been in any way transformed or analysed. No additional variables have been computed for any of the datasets at time of the registration. Some authors of the meta-analyses included in the sample have sent their datasets with a computed variance measure; however, no additional analyses were performed on said datasets. As such the main outcome measure for this study has not yet been obtained for any of the studies. \n", "q13": "Attempt will be made to obtain raw data for every single meta-analysis included in Part 1 (spreadsheet with all the studies included in Part 1 can be found at https://osf.io/ruvhd/). Should this effort be successful, and all the studies are found to be eligible, this will result in the inclusion of 170 published papers (level 3 units), containing 1242 individual meta-analyses (level 2 units), each containing uncorrected and corrected effect size estimates (resulting in 2484 level 1 units within each of the 4 conditions). This is the maximum upper boundary of the sample size, however at the time of registration, the expected sample size is 107 published papers containing 478 individual meta-analysis, each containing uncorrected and correct effect size estimates and therefore 956 level 1 units within each of the 4 conditions. ", "q14": "Sample size for Part 1 was determined by time constraints of the project with the aim to code as many studies as possible. Sample size for this part of the project will be determined by data availability and alignment with inclusion/exclusion criteria outlined above. ", "q15": "", "q20": "Where possible, the steps of the original analysis will be followed without additional data transformations. Because the majority of the coded papers report their effect sizes as Cohen\u2019s d, this will be the target metric. Data that use alternative effect size metrics (correlation coefficient r or odds ratio) will be converted into d using the formulae (from Borenstein et al., 2009) specified in the attached document.", "q21": "Inferential tests will not be performed as part of the analysis. As the mathematical properties of the bias correcting methods will inevitably reduce the original effect sizes in the presence of publication bias, the analysis will focus on the estimates of the extent of this reduction.  ", "q22": "No data are expected to be excluded on the basis of presence of outliers or violations of other model assumptions. To address potential issues, the original model will be compared to a robust model fitted using the brms R package as a form of sensitivity analysis. Should the original estimate substantially differ, the robust estimate will be interpreted instead. ", "q23": "It is possible that some data will not be suitable for analysis with any of the well performing correction methods corresponding to one of the 4 conditions. In such cases, the data in question will be excluded for the condition where re-analysis is not possible but retained for the remaining conditions. ", "q24": "Some meta-analyses may have used publication bias correction methods and reported the corrected estimates as well as the uncorrected ones. If this is found to be the case for a sufficient number of analyses, analyses that originally report corrected estimates will be grouped and analysed separately to see if the original corrected effect sizes differ from effect sizes computed using correction methods identified as suitable using the criteria employed in this study. ", "q25": "***References***\n\nB\u00fcrkner, P. C. (2017). Advanced Bayesian multilevel modelling with the R package brms. arXiv preprint arXiv:1705.11123.\n\nCarter, E. C., Sch\u00f6nbrodt, F. D., Gervais, W. M., &amp; Hilgard, J. (2019). Correcting for bias in psychology: A comparison of meta-analytic methods. Advances in Methods and Practices in Psychological Science, 2(2), 115-144.\n\nBorenstein, M., Hedges, L. V., Higgins, J. P., &amp; Rothstein, H. R. (2009). Introduction to meta-analysis. John Wiley &amp; Sons.\n", "q8.question": "The final data will have 3-level hierarchical structure. Models will be fitted for each of the 4 conditions separately. Level 1 predictor (effect size estimator) is a factor with 2 levels (original uncorrected estimator vs bias-corrected estimate); outcome is the effect size (continuous variable). See *Variables* and *Analysis Plan* for details. ", "q8.uploader": [{"file_id": "5e2608e9edceab019882e23c", "file_name": "preregistration_v.2.0.pdf", "file_urls": {"html": "https://osf.io/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "download": "https://osf.io/download/q4nhf/"}, "file_hashes": {"sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91"}}], "q12.question": "Details of study selection, inclusion/exclusion criteria and coding procedures for Part 1 can be found at https://osf.io/ruvhd/ . \n\nAs detailed above, data for Part 2 are being obtained via the following means: \n\u2022\tDownloading supplemental materials linked to the published papers\n\u2022\tExtracting data from tables and forest plots published within journal articles\n\u2022\tE-mailing the authors of the meta-analyses with requests for their data\n\nData collection will finish after the last author has responded, expected no later than 31/01/2020. \n\nInclusion criteria: \ni.\tStudy was included in Part 1 of this project. \ni.\tData for the study is accessible or made available by the authors \nii.\tStudy reports effect sizes in form of Cohen\u2019s d or provides parameters that enable transformation into Cohen\u2019s d.\niii.\tStudy provides the information necessary for computation or estimation of variance of the primary studies, and the t statistic where relevant for the appropriate publication bias correction method (see Variables and Analysis Plan for details.)\n\nExclusion criteria:\nIn addition to failing to meet the above inclusion criteria, studies will be excluded if: \ni.\tStudy is a meta-meta-analysis or a meta-analysis using internal databases as opposed to published research papers, as the nature of publication bias in these types of samples is different to the publication bias investigated in the present study. \nii.\tData are insufficient to reproduce the original analysis and the attempts to consult with the author of the paper are unsuccessful. \n", "q12.uploader": [{"file_id": "5e2608e9edceab019882e23c", "file_name": "preregistration_v.2.0.pdf", "file_urls": {"html": "https://osf.io/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "download": "https://osf.io/download/q4nhf/"}, "file_hashes": {"sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91"}}], "q16.question": "", "q16.uploader": [], "q17.question": "Variables collected in Part 1 which will be summarised using only descriptive statistics without inferential tests: \n\n\n\n\u2022\tNumber of unpublished studies included in the meta-analysis\n\u2022\tMethod used to obtain unpublished studies [multiple selection from: Undisclosed; Unpublished studies not included on purpose; Contact - first authors; Contact - authors from the reference list; Internet search of databases (such as OSF); Search of dissertation archives; Search of conference proceedings; Other - text box]\n\u2022\tResponse rate when contacting authors about unpublished studies [Authors contacted - integer; Authors responded - integer]\n\u2022\tMethod of addressing publication bias [Not applicable (publication bias not found); Trim-and-fill; Inclusion of unpublished studies; Weight function models (Vevea &amp; Hedges); Egger (regression); Egger-var (regression); Harbord (regression); Peters (regression); WLS; WAAP-WLS; PET-PEESE; Bayesian methods; Other - text box]\n\u2022\tMethod used to check for the presence of publication bias [Undisclosed; Visual - funnel plot; Visual - p-curve; Trim-and-fill (sensitivity analysis); Rosenthal\u2019s fail-safe N; Orwin\u2019s fail-safe N; Reverse correlation between effect sizes and sample sizes; Funnel asymmetry test; Precision effect test; Ioannidis &amp; Trikalinos (2007) publication bias test; Other - text box]\n\u2022\tAuthors\u2019 conclusion about the presence of publication bias in the meta-analytic sample [Present; Not present; Not reported]\n\nOutcome variables computed for Part 2 of the project: \n\nEach meta-analysis (level 2 unit) will contain 2 effect sizes (level 1 units), which is the primary outcome of this study. These effect sizes are: \n\n1.\tOriginal uncorrected effect size as published in the paper\n2.\tEffect size corrected by a publication bias correction method. Performance of a correction method is affected by the study\u2019s sample size and heterogeneity of primary effect sizes (defined by \u03c42), as well as unknown factors such as the level of publication bias and the population effect size. Therefore, for each meta-analysis, 4 additional effect sizes will be computed using a publication bias correction method that performs well given the study\u2019s sample size and heterogeneity (see below), as well as the level of publication bias and population effect size which have to be assumed. Assuming these unknown parameters will create 4 separate conditions within which to perform the analysis: \n\n1.\tMedium publication bias and population effect size of \u03b4 = 0.2 (Condition 1)\n2.\tHigh publication bias and population effect size of \u03b4 = 0.2 (Condition 2)\n3.\tMedium publication bias and population effect size of \u03b4 = 0.5 (Condition 3)\n4.\tHigh publication bias and population effect size of \u03b4 = 0.5 (Condition 4)\n\nEach of the 4 corrected effect sizes will be computed using one of the following publication bias correction methods: \n\u2022\tPrecision-effect test (PET) \n\u2022\tPrecision-effect estimate with standard error (PEESE)\n\u2022\tPET-PEESE\n\u2022\tWeighted average of the adequately powered - weighted least squares (WAAP-WLS)\n\u2022\tTrim-and-fill \n\u2022\tp-curve\n\u2022\tp-uniform\n\u2022\tSelection model with 3 parameters (3PSM; \u201cweight function model\u201d)\n\u2022\tSelection model with 4 parameters (4PSM; \u201cweight function model\u201d)\n\nAny adjustments that were applied for each meta-analysis prior to the estimation of the final effect size (i.e. dealing with dependent effect sizes, addressing with outliers, artefact corrections, or any other data transformations, excluding publication bias corrections) will be applied in the current study prior to calculating the corrected estimates. Therefore, the baseline uncorrected estimate will match the estimate that was published in the paper. \n\nDecisions regarding the selection of appropriate correction method for each individual meta-analysis across each of the four conditions outlined above will be modelled according to a recent simulation study by Carter et al. (2019) who have published detailed results of their simulations in an online R Shiny app Meta-Showdown Explorer (http://shinyapps.org/apps/metaExplorer/). As some methods perform equally well or similarly well with other methods under specific combinations of the conditions, data from the \u201cEstimation\u201d section have been downloaded and transformed into an R function which selects the appropriate correction method using pre-defined criteria which take into account the mean error, root mean squared error, and, where relevant, coverage.\n\nCriteria for deciding which correction method to use: \n\n\u2022\tOut of the 9 correction methods, the method that is eventually selected has to have the smallest summary value for mean error and root mean squared error. \n\u2022\tSome methods (namely 3PSM, 4 PSM, p-curve and p-uniform) require p-values in order to be performed. If a p-value based method is evaluated as the best method and the p-values are available for a given meta-analysis, the p-value based method will be preferred. If p-values are not available, the second best performing method will be selected. \n\u2022\tIn cases where 3PSM and 4PSM are evaluated as the best and equally well performing, 4PSM will be selected as it accounts for more realistic conditions regarding significance values than 3PSM. If the data available are not suitable for 4PSM, the analysis will fall back to 3PSM. \n\u2022\tIf PET and PEESE are evaluated as the best and equally well performing, PET-PEESE will be selected as this method takes both PET and PEESE into account. \n\u2022\tIf PET and PET-PEESE are evaluated as the best and equally well performing, PET will be selected. PET-PEESE uses conditional probability of PET to decide whether to use PET or PEESE as the final estimate. Given that PEESE was not highlighted as well performing under the conditions of the meta-analysis that is being re-analysed, the estimate from this method is likely to be more biased, and so would potentially be the final estimate of PET-PEESE. \n\u2022\tSame logic as outlined in the point above applies to the situation where the decision between PET and PET-PEESE has to be made. \n\u2022\tIf there is a tie in the summary value between any other methods not specified in the previous points, coverage is used as the deciding factor - the method with coverage closest to nominal .95 will be selected. \nThe R project containing the selection function is attached (note: the R project will also be made available directly within the OSF repository with additional files used in later stages of the project. There is no intention to further modify this function past the registration point. However, should minor error fixes or adjustments be found necessary, these will be clearly outlined within the R script). \n\nExample:\n\nIt is not the case that a single one of these methods is always assigned to any of the 4 conditions defined by level of publication bias and population effect size. For example, for a study with a sample size k = 34 and \u03c42 = 0.2, the estimators that are evaluated being likely the least biased ones are 4PSM for condition 1, PET for condition 2, 3PSM for condition 3, and PEESE for condition 4. On the other hand, for a study with k = 14 and \u03c42 = 0.09, the estimators are 4PSM (condition 1), 4PSM (condition 2), 3PSM (condition 3), and WAAP-WLS (condition 4). Therefore, for the whole sample, corrected effect sizes will not necessarily be obtained by the same estimator within a single condition. \n", "q17.uploader": [{"file_id": "5e2608e9edceab019882e23c", "file_name": "preregistration_v.2.0.pdf", "file_urls": {"html": "https://osf.io/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "download": "https://osf.io/download/q4nhf/"}, "file_hashes": {"sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91"}}, {"file_id": "5e2608fa675e0e017c6b7551", "file_name": "pb_correction_selection.zip", "file_urls": {"html": "https://osf.io/k9hqm/files/osfstorage/5e2608fa675e0e017c6b7551", "download": "https://osf.io/download/5v6eu/"}, "file_hashes": {"sha256": "74ae0fdd0623640e307936b29f4be14d4c4a21ccb6a03a77a778e4a126f66e07"}}], "q18.question": "", "q18.uploader": [], "q19.question": "For each of the 4 conditions, a separate 3-level Bayesian hierarchical model will be fitted (resulting in 4 models in total). Because published meta-analytic papers typically report multiple meta-analyses, effect sizes (level 1) are nested within meta-analyses (level 2) which themselves are nested within published papers (level 3). The form the model will take is specified in the attached document.  \n\nThe model predicts the effect size from the estimator type (factor with 2 levels: original uncorrected estimate vs corrected estimate). Additionally, crossed effect of the bias correction method will be modelled at level 2. Random effects will be fitted for the estimator, correction method, and the interaction between the estimator and the correction method.\n\nIt is possible that after the re-analysis, the number of values in each of the cells for the correction method will be insufficient to model the crossed effect. In such case, a simplified model without the cross-level interaction (specified in the attached document)\n\nIn either of the cases outlined above, model for each of the 4 conditions will be fitted using the brms R package for Bayesian multilevel modelling (B\u00fcrkner, 2017), with default uninformative priors. 95% highest posterior density intervals will subsequently be extracted from the models as the indicator of the plausible range of the attenuation in the effect sizes after the application of bias correcting methods. \n", "q19.uploader": [{"file_id": "5e2608e9edceab019882e23c", "file_name": "preregistration_v.2.0.pdf", "file_urls": {"html": "https://osf.io/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "download": "https://osf.io/download/q4nhf/"}, "file_hashes": {"sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91"}}]}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y6bng/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y6bng/comments/?format=json&filter%5Btarget%5D=y6bng", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y6bng/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y6bng/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y6bng/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y6bng/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y6bng/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y6bng/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y6bng/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y6bng/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y6bng/linked_by_registrations/?format=json", "meta": {}}}}, "parent": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3q6tw/?format=json", "meta": {}}}, "data": {"id": "3q6tw", "type": "registrations"}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y6bng/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y6bng/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/y6bng/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/?format=json", "meta": {}}}, "data": {"id": "kxjs3", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y6bng/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y6bng/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/y6bng/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y6bng/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/y6bng/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y6bng/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/y6bng/citation/?format=json", "meta": {}}}, "data": {"id": "y6bng", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/vq6rm/?format=json", "meta": {}}}, "data": {"id": "vq6rm", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/r98v4/?format=json", "meta": {}}}, "data": {"id": "r98v4", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5c08457ed283380029cf73bf/?format=json", "meta": {}}}, "data": {"id": "5c08457ed283380029cf73bf", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/y6bng/", "self": "https://api.osf.io/v2/registrations/y6bng/"}}, {"id": "3q6tw", "type": "registrations", "attributes": {"title": "Project Part 2 (Publication Bias)", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-01-20T20:11:28.735709", "date_modified": "2020-01-20T19:34:50.514833", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "1a6c0518a9e01cede78181e9e763b4761f7c494ff1de18ed5568047b6e8f9b31ac044fd44be5f38898ec79cf456d0451fbb5c13b110607e6817455bd2a70f94eb23060d4471a2dc90fdc6a753b8ce391a2b9d64beded551626b91a1110e42e40462ca8132acbb15bcefc14de55ef7e7f45099cf5a5035a5c6161c9096802f5804e4ca78aeaed6b2c674283ab76904ae2", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-20T20:11:28.718789", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "OSF Preregistration", "registered_meta": {"q1": {"extra": [], "value": "Publication bias in psychology : Evaluating the robustness of meta-analytic effects"}, "q2": {"extra": [], "value": "Martina Sladekova"}, "q3": {"extra": [], "value": "***Due to OSF formatting settings, some sections of this form may be difficult to read. The attached document titled \"preregistration_v.2.0.pdf\" contains a formatted and otherwise identical version of this preregistration. The document can also be found in the OSF repository https://osf.io/k9hqm/***\n\nPublication bias is an ongoing problem affecting meta-analytic estimates of effect sizes. A number of methods correcting for small study effects and publication bias have been developed over the years, however these methods tend to be applied without the regard for optimal performance conditions of each method. \nThe aim of this study is to investigate:\n\na)\tThe extent to which meta-analysts in psychology attend to publication bias\nb)\tHow the published effect sizes change when the data are re-analysed with a publication bias correction method that has been found to perform well given specific conditions of each study. These conditions refer to heterogeneity of primary effect sizes, number of primary effects included in the meta-analysis, expected level of publication bias, and expected population effect size. \n\nBecause the level of publication bias and population effect size are unknown, changes in publication bias will be investigated separately within 4 conditions that assume: \n\n1.\tMedium publication bias and population effect size of \u03b4 = 0.2 (Condition 1)\n2.\tHigh publication bias and population effect size of \u03b4 = 0.2 (Condition 2)\n3.\tMedium publication bias and population effect size of \u03b4 = 0.5 (Condition 3)\n4.\tHigh publication bias and population effect size of \u03b4 = 0.5 (Condition 4)\n\nSee *Variables* and *Analysis Plan* sections for details. \n"}, "q4": {"extra": [], "value": "Objectives\n\nThe key objective is to estimate: \n\n(1)\tthe typical attenuation in published meta-analytic effect sizes after the application of publication bias correcting methods. \n(2)\tthe plausible range of this attenuation using 95% highest posterior density intervals. \n(3)\tthe plausible limits of variation in the effect size attenuation across different bias correcting methods\n\nThe analysis will be performed separately for the specific combinations of the level of publication bias and the population effect size, as specified above.  \n"}, "q5": {"extra": [], "value": "Other"}, "q6": {"extra": [], "value": ["No blinding is involved in this study."]}, "q7": {"extra": [], "value": ""}, "q8": {"value": {"question": {"extra": [], "value": "The final data will have 3-level hierarchical structure. Models will be fitted for each of the 4 conditions separately. Level 1 predictor (effect size estimator) is a factor with 2 levels (original uncorrected estimator vs bias-corrected estimate); outcome is the effect size (continuous variable). See *Variables* and *Analysis Plan* for details. "}, "uploader": {"extra": [{"data": {"name": "preregistration_v.2.0.pdf"}, "nodeId": "k9hqm", "sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91", "viewUrl": "/project/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "selectedFileName": "preregistration_v.2.0.pdf"}], "value": ""}}}, "q9": {"extra": [], "value": ""}, "q10": {"extra": [], "value": "Registration prior to accessing the data"}, "q11": {"extra": [], "value": "Data were collected in two parts. \n\nPart 1 included random selection of meta-analyses published in 2008 and 2018, and subsequent coding of meta-analytic practices in these papers using a coding scheme. This phase of data collection lasted from February 2019 to June 2019. Authors of the present study were involved in the coding scheme development and data collection. Exact details of the coding scheme as well as analyses run on this dataset so far can be found at https://osf.io/ruvhd/ . No items from this dataset will be inferentially tested as outcome variables in the present study. \n\nPart 2 involves collection of raw data used in meta-analyses that were coded in Part 1. At the time of registration, raw data available in supplemental materials online have been downloaded. Data extraction directly from journal articles has begun, with the first dataset extracted on 03/09/2019. Additionally, 118 authors have been e-mailed with request for their data (first request sent on 10/10/2019), out of which 23 made their data available, 24 confirmed that they no longer have access to the data, with remaining 71 requests pending on 27/12/19. \n\nNo data that have been downloaded, extracted, or received from the authors has been in any way transformed or analysed. No additional variables have been computed for any of the datasets at time of the registration. Some authors of the meta-analyses included in the sample have sent their datasets with a computed variance measure; however, no additional analyses were performed on said datasets. As such the main outcome measure for this study has not yet been obtained for any of the studies. \n"}, "q12": {"value": {"question": {"extra": [], "value": "Details of study selection, inclusion/exclusion criteria and coding procedures for Part 1 can be found at https://osf.io/ruvhd/ . \n\nAs detailed above, data for Part 2 are being obtained via the following means: \n\u2022\tDownloading supplemental materials linked to the published papers\n\u2022\tExtracting data from tables and forest plots published within journal articles\n\u2022\tE-mailing the authors of the meta-analyses with requests for their data\n\nData collection will finish after the last author has responded, expected no later than 31/01/2020. \n\nInclusion criteria: \ni.\tStudy was included in Part 1 of this project. \ni.\tData for the study is accessible or made available by the authors \nii.\tStudy reports effect sizes in form of Cohen\u2019s d or provides parameters that enable transformation into Cohen\u2019s d.\niii.\tStudy provides the information necessary for computation or estimation of variance of the primary studies, and the t statistic where relevant for the appropriate publication bias correction method (see Variables and Analysis Plan for details.)\n\nExclusion criteria:\nIn addition to failing to meet the above inclusion criteria, studies will be excluded if: \ni.\tStudy is a meta-meta-analysis or a meta-analysis using internal databases as opposed to published research papers, as the nature of publication bias in these types of samples is different to the publication bias investigated in the present study. \nii.\tData are insufficient to reproduce the original analysis and the attempts to consult with the author of the paper are unsuccessful. \n"}, "uploader": {"extra": [{"data": {"name": "preregistration_v.2.0.pdf"}, "nodeId": "k9hqm", "sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91", "viewUrl": "/project/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "selectedFileName": "preregistration_v.2.0.pdf"}], "value": ""}}}, "q13": {"extra": [], "value": "Attempt will be made to obtain raw data for every single meta-analysis included in Part 1 (spreadsheet with all the studies included in Part 1 can be found at https://osf.io/ruvhd/). Should this effort be successful, and all the studies are found to be eligible, this will result in the inclusion of 170 published papers (level 3 units), containing 1242 individual meta-analyses (level 2 units), each containing uncorrected and corrected effect size estimates (resulting in 2484 level 1 units within each of the 4 conditions). This is the maximum upper boundary of the sample size, however at the time of registration, the expected sample size is 107 published papers containing 478 individual meta-analysis, each containing uncorrected and correct effect size estimates and therefore 956 level 1 units within each of the 4 conditions. "}, "q14": {"extra": [], "value": "Sample size for Part 1 was determined by time constraints of the project with the aim to code as many studies as possible. Sample size for this part of the project will be determined by data availability and alignment with inclusion/exclusion criteria outlined above. "}, "q15": {"extra": [], "value": ""}, "q16": {"value": {"question": {"extra": [], "value": ""}, "uploader": {"extra": [], "value": ""}}}, "q17": {"value": {"question": {"extra": [], "value": "Variables collected in Part 1 which will be summarised using only descriptive statistics without inferential tests: \n\n\n\n\u2022\tNumber of unpublished studies included in the meta-analysis\n\u2022\tMethod used to obtain unpublished studies [multiple selection from: Undisclosed; Unpublished studies not included on purpose; Contact - first authors; Contact - authors from the reference list; Internet search of databases (such as OSF); Search of dissertation archives; Search of conference proceedings; Other - text box]\n\u2022\tResponse rate when contacting authors about unpublished studies [Authors contacted - integer; Authors responded - integer]\n\u2022\tMethod of addressing publication bias [Not applicable (publication bias not found); Trim-and-fill; Inclusion of unpublished studies; Weight function models (Vevea &amp; Hedges); Egger (regression); Egger-var (regression); Harbord (regression); Peters (regression); WLS; WAAP-WLS; PET-PEESE; Bayesian methods; Other - text box]\n\u2022\tMethod used to check for the presence of publication bias [Undisclosed; Visual - funnel plot; Visual - p-curve; Trim-and-fill (sensitivity analysis); Rosenthal\u2019s fail-safe N; Orwin\u2019s fail-safe N; Reverse correlation between effect sizes and sample sizes; Funnel asymmetry test; Precision effect test; Ioannidis &amp; Trikalinos (2007) publication bias test; Other - text box]\n\u2022\tAuthors\u2019 conclusion about the presence of publication bias in the meta-analytic sample [Present; Not present; Not reported]\n\nOutcome variables computed for Part 2 of the project: \n\nEach meta-analysis (level 2 unit) will contain 2 effect sizes (level 1 units), which is the primary outcome of this study. These effect sizes are: \n\n1.\tOriginal uncorrected effect size as published in the paper\n2.\tEffect size corrected by a publication bias correction method. Performance of a correction method is affected by the study\u2019s sample size and heterogeneity of primary effect sizes (defined by \u03c42), as well as unknown factors such as the level of publication bias and the population effect size. Therefore, for each meta-analysis, 4 additional effect sizes will be computed using a publication bias correction method that performs well given the study\u2019s sample size and heterogeneity (see below), as well as the level of publication bias and population effect size which have to be assumed. Assuming these unknown parameters will create 4 separate conditions within which to perform the analysis: \n\n1.\tMedium publication bias and population effect size of \u03b4 = 0.2 (Condition 1)\n2.\tHigh publication bias and population effect size of \u03b4 = 0.2 (Condition 2)\n3.\tMedium publication bias and population effect size of \u03b4 = 0.5 (Condition 3)\n4.\tHigh publication bias and population effect size of \u03b4 = 0.5 (Condition 4)\n\nEach of the 4 corrected effect sizes will be computed using one of the following publication bias correction methods: \n\u2022\tPrecision-effect test (PET) \n\u2022\tPrecision-effect estimate with standard error (PEESE)\n\u2022\tPET-PEESE\n\u2022\tWeighted average of the adequately powered - weighted least squares (WAAP-WLS)\n\u2022\tTrim-and-fill \n\u2022\tp-curve\n\u2022\tp-uniform\n\u2022\tSelection model with 3 parameters (3PSM; \u201cweight function model\u201d)\n\u2022\tSelection model with 4 parameters (4PSM; \u201cweight function model\u201d)\n\nAny adjustments that were applied for each meta-analysis prior to the estimation of the final effect size (i.e. dealing with dependent effect sizes, addressing with outliers, artefact corrections, or any other data transformations, excluding publication bias corrections) will be applied in the current study prior to calculating the corrected estimates. Therefore, the baseline uncorrected estimate will match the estimate that was published in the paper. \n\nDecisions regarding the selection of appropriate correction method for each individual meta-analysis across each of the four conditions outlined above will be modelled according to a recent simulation study by Carter et al. (2019) who have published detailed results of their simulations in an online R Shiny app Meta-Showdown Explorer (http://shinyapps.org/apps/metaExplorer/). As some methods perform equally well or similarly well with other methods under specific combinations of the conditions, data from the \u201cEstimation\u201d section have been downloaded and transformed into an R function which selects the appropriate correction method using pre-defined criteria which take into account the mean error, root mean squared error, and, where relevant, coverage.\n\nCriteria for deciding which correction method to use: \n\n\u2022\tOut of the 9 correction methods, the method that is eventually selected has to have the smallest summary value for mean error and root mean squared error. \n\u2022\tSome methods (namely 3PSM, 4 PSM, p-curve and p-uniform) require p-values in order to be performed. If a p-value based method is evaluated as the best method and the p-values are available for a given meta-analysis, the p-value based method will be preferred. If p-values are not available, the second best performing method will be selected. \n\u2022\tIn cases where 3PSM and 4PSM are evaluated as the best and equally well performing, 4PSM will be selected as it accounts for more realistic conditions regarding significance values than 3PSM. If the data available are not suitable for 4PSM, the analysis will fall back to 3PSM. \n\u2022\tIf PET and PEESE are evaluated as the best and equally well performing, PET-PEESE will be selected as this method takes both PET and PEESE into account. \n\u2022\tIf PET and PET-PEESE are evaluated as the best and equally well performing, PET will be selected. PET-PEESE uses conditional probability of PET to decide whether to use PET or PEESE as the final estimate. Given that PEESE was not highlighted as well performing under the conditions of the meta-analysis that is being re-analysed, the estimate from this method is likely to be more biased, and so would potentially be the final estimate of PET-PEESE. \n\u2022\tSame logic as outlined in the point above applies to the situation where the decision between PET and PET-PEESE has to be made. \n\u2022\tIf there is a tie in the summary value between any other methods not specified in the previous points, coverage is used as the deciding factor - the method with coverage closest to nominal .95 will be selected. \nThe R project containing the selection function is attached (note: the R project will also be made available directly within the OSF repository with additional files used in later stages of the project. There is no intention to further modify this function past the registration point. However, should minor error fixes or adjustments be found necessary, these will be clearly outlined within the R script). \n\nExample:\n\nIt is not the case that a single one of these methods is always assigned to any of the 4 conditions defined by level of publication bias and population effect size. For example, for a study with a sample size k = 34 and \u03c42 = 0.2, the estimators that are evaluated being likely the least biased ones are 4PSM for condition 1, PET for condition 2, 3PSM for condition 3, and PEESE for condition 4. On the other hand, for a study with k = 14 and \u03c42 = 0.09, the estimators are 4PSM (condition 1), 4PSM (condition 2), 3PSM (condition 3), and WAAP-WLS (condition 4). Therefore, for the whole sample, corrected effect sizes will not necessarily be obtained by the same estimator within a single condition. \n"}, "uploader": {"extra": [{"data": {"name": "preregistration_v.2.0.pdf"}, "nodeId": "k9hqm", "sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91", "viewUrl": "/project/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "selectedFileName": "preregistration_v.2.0.pdf"}, {"data": {"name": "pb_correction_selection.zip"}, "nodeId": "k9hqm", "sha256": "74ae0fdd0623640e307936b29f4be14d4c4a21ccb6a03a77a778e4a126f66e07", "viewUrl": "/project/k9hqm/files/osfstorage/5e2608fa675e0e017c6b7551", "selectedFileName": "pb_correction_selection.zip"}], "value": ""}}}, "q18": {"value": {"question": {"extra": [], "value": ""}, "uploader": {"extra": [], "value": ""}}}, "q19": {"value": {"question": {"extra": [], "value": "For each of the 4 conditions, a separate 3-level Bayesian hierarchical model will be fitted (resulting in 4 models in total). Because published meta-analytic papers typically report multiple meta-analyses, effect sizes (level 1) are nested within meta-analyses (level 2) which themselves are nested within published papers (level 3). The form the model will take is specified in the attached document.  \n\nThe model predicts the effect size from the estimator type (factor with 2 levels: original uncorrected estimate vs corrected estimate). Additionally, crossed effect of the bias correction method will be modelled at level 2. Random effects will be fitted for the estimator, correction method, and the interaction between the estimator and the correction method.\n\nIt is possible that after the re-analysis, the number of values in each of the cells for the correction method will be insufficient to model the crossed effect. In such case, a simplified model without the cross-level interaction (specified in the attached document)\n\nIn either of the cases outlined above, model for each of the 4 conditions will be fitted using the brms R package for Bayesian multilevel modelling (B\u00fcrkner, 2017), with default uninformative priors. 95% highest posterior density intervals will subsequently be extracted from the models as the indicator of the plausible range of the attenuation in the effect sizes after the application of bias correcting methods. \n"}, "uploader": {"extra": [{"data": {"name": "preregistration_v.2.0.pdf"}, "nodeId": "k9hqm", "sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91", "viewUrl": "/project/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "selectedFileName": "preregistration_v.2.0.pdf"}], "value": ""}}}, "q20": {"extra": [], "value": "Where possible, the steps of the original analysis will be followed without additional data transformations. Because the majority of the coded papers report their effect sizes as Cohen\u2019s d, this will be the target metric. Data that use alternative effect size metrics (correlation coefficient r or odds ratio) will be converted into d using the formulae (from Borenstein et al., 2009) specified in the attached document."}, "q21": {"extra": [], "value": "Inferential tests will not be performed as part of the analysis. As the mathematical properties of the bias correcting methods will inevitably reduce the original effect sizes in the presence of publication bias, the analysis will focus on the estimates of the extent of this reduction.  "}, "q22": {"extra": [], "value": "No data are expected to be excluded on the basis of presence of outliers or violations of other model assumptions. To address potential issues, the original model will be compared to a robust model fitted using the brms R package as a form of sensitivity analysis. Should the original estimate substantially differ, the robust estimate will be interpreted instead. "}, "q23": {"extra": [], "value": "It is possible that some data will not be suitable for analysis with any of the well performing correction methods corresponding to one of the 4 conditions. In such cases, the data in question will be excluded for the condition where re-analysis is not possible but retained for the remaining conditions. "}, "q24": {"extra": [], "value": "Some meta-analyses may have used publication bias correction methods and reported the corrected estimates as well as the uncorrected ones. If this is found to be the case for a sufficient number of analyses, analyses that originally report corrected estimates will be grouped and analysed separately to see if the original corrected effect sizes differ from effect sizes computed using correction methods identified as suitable using the criteria employed in this study. "}, "q25": {"extra": [], "value": "***References***\n\nB\u00fcrkner, P. C. (2017). Advanced Bayesian multilevel modelling with the R package brms. arXiv preprint arXiv:1705.11123.\n\nCarter, E. C., Sch\u00f6nbrodt, F. D., Gervais, W. M., &amp; Hilgard, J. (2019). Correcting for bias in psychology: A comparison of meta-analytic methods. Advances in Methods and Practices in Psychological Science, 2(2), 115-144.\n\nBorenstein, M., Hedges, L. V., Higgins, J. P., &amp; Rothstein, H. R. (2009). Introduction to meta-analysis. John Wiley &amp; Sons.\n"}}, "registration_responses": {"q1": "Publication bias in psychology : Evaluating the robustness of meta-analytic effects", "q2": "Martina Sladekova", "q3": "***Due to OSF formatting settings, some sections of this form may be difficult to read. The attached document titled \"preregistration_v.2.0.pdf\" contains a formatted and otherwise identical version of this preregistration. The document can also be found in the OSF repository https://osf.io/k9hqm/***\n\nPublication bias is an ongoing problem affecting meta-analytic estimates of effect sizes. A number of methods correcting for small study effects and publication bias have been developed over the years, however these methods tend to be applied without the regard for optimal performance conditions of each method. \nThe aim of this study is to investigate:\n\na)\tThe extent to which meta-analysts in psychology attend to publication bias\nb)\tHow the published effect sizes change when the data are re-analysed with a publication bias correction method that has been found to perform well given specific conditions of each study. These conditions refer to heterogeneity of primary effect sizes, number of primary effects included in the meta-analysis, expected level of publication bias, and expected population effect size. \n\nBecause the level of publication bias and population effect size are unknown, changes in publication bias will be investigated separately within 4 conditions that assume: \n\n1.\tMedium publication bias and population effect size of \u03b4 = 0.2 (Condition 1)\n2.\tHigh publication bias and population effect size of \u03b4 = 0.2 (Condition 2)\n3.\tMedium publication bias and population effect size of \u03b4 = 0.5 (Condition 3)\n4.\tHigh publication bias and population effect size of \u03b4 = 0.5 (Condition 4)\n\nSee *Variables* and *Analysis Plan* sections for details. \n", "q4": "Objectives\n\nThe key objective is to estimate: \n\n(1)\tthe typical attenuation in published meta-analytic effect sizes after the application of publication bias correcting methods. \n(2)\tthe plausible range of this attenuation using 95% highest posterior density intervals. \n(3)\tthe plausible limits of variation in the effect size attenuation across different bias correcting methods\n\nThe analysis will be performed separately for the specific combinations of the level of publication bias and the population effect size, as specified above.  \n", "q5": "Other", "q6": ["No blinding is involved in this study."], "q7": "", "q9": "", "q10": "Registration prior to accessing the data", "q11": "Data were collected in two parts. \n\nPart 1 included random selection of meta-analyses published in 2008 and 2018, and subsequent coding of meta-analytic practices in these papers using a coding scheme. This phase of data collection lasted from February 2019 to June 2019. Authors of the present study were involved in the coding scheme development and data collection. Exact details of the coding scheme as well as analyses run on this dataset so far can be found at https://osf.io/ruvhd/ . No items from this dataset will be inferentially tested as outcome variables in the present study. \n\nPart 2 involves collection of raw data used in meta-analyses that were coded in Part 1. At the time of registration, raw data available in supplemental materials online have been downloaded. Data extraction directly from journal articles has begun, with the first dataset extracted on 03/09/2019. Additionally, 118 authors have been e-mailed with request for their data (first request sent on 10/10/2019), out of which 23 made their data available, 24 confirmed that they no longer have access to the data, with remaining 71 requests pending on 27/12/19. \n\nNo data that have been downloaded, extracted, or received from the authors has been in any way transformed or analysed. No additional variables have been computed for any of the datasets at time of the registration. Some authors of the meta-analyses included in the sample have sent their datasets with a computed variance measure; however, no additional analyses were performed on said datasets. As such the main outcome measure for this study has not yet been obtained for any of the studies. \n", "q13": "Attempt will be made to obtain raw data for every single meta-analysis included in Part 1 (spreadsheet with all the studies included in Part 1 can be found at https://osf.io/ruvhd/). Should this effort be successful, and all the studies are found to be eligible, this will result in the inclusion of 170 published papers (level 3 units), containing 1242 individual meta-analyses (level 2 units), each containing uncorrected and corrected effect size estimates (resulting in 2484 level 1 units within each of the 4 conditions). This is the maximum upper boundary of the sample size, however at the time of registration, the expected sample size is 107 published papers containing 478 individual meta-analysis, each containing uncorrected and correct effect size estimates and therefore 956 level 1 units within each of the 4 conditions. ", "q14": "Sample size for Part 1 was determined by time constraints of the project with the aim to code as many studies as possible. Sample size for this part of the project will be determined by data availability and alignment with inclusion/exclusion criteria outlined above. ", "q15": "", "q20": "Where possible, the steps of the original analysis will be followed without additional data transformations. Because the majority of the coded papers report their effect sizes as Cohen\u2019s d, this will be the target metric. Data that use alternative effect size metrics (correlation coefficient r or odds ratio) will be converted into d using the formulae (from Borenstein et al., 2009) specified in the attached document.", "q21": "Inferential tests will not be performed as part of the analysis. As the mathematical properties of the bias correcting methods will inevitably reduce the original effect sizes in the presence of publication bias, the analysis will focus on the estimates of the extent of this reduction.  ", "q22": "No data are expected to be excluded on the basis of presence of outliers or violations of other model assumptions. To address potential issues, the original model will be compared to a robust model fitted using the brms R package as a form of sensitivity analysis. Should the original estimate substantially differ, the robust estimate will be interpreted instead. ", "q23": "It is possible that some data will not be suitable for analysis with any of the well performing correction methods corresponding to one of the 4 conditions. In such cases, the data in question will be excluded for the condition where re-analysis is not possible but retained for the remaining conditions. ", "q24": "Some meta-analyses may have used publication bias correction methods and reported the corrected estimates as well as the uncorrected ones. If this is found to be the case for a sufficient number of analyses, analyses that originally report corrected estimates will be grouped and analysed separately to see if the original corrected effect sizes differ from effect sizes computed using correction methods identified as suitable using the criteria employed in this study. ", "q25": "***References***\n\nB\u00fcrkner, P. C. (2017). Advanced Bayesian multilevel modelling with the R package brms. arXiv preprint arXiv:1705.11123.\n\nCarter, E. C., Sch\u00f6nbrodt, F. D., Gervais, W. M., &amp; Hilgard, J. (2019). Correcting for bias in psychology: A comparison of meta-analytic methods. Advances in Methods and Practices in Psychological Science, 2(2), 115-144.\n\nBorenstein, M., Hedges, L. V., Higgins, J. P., &amp; Rothstein, H. R. (2009). Introduction to meta-analysis. John Wiley &amp; Sons.\n", "q8.question": "The final data will have 3-level hierarchical structure. Models will be fitted for each of the 4 conditions separately. Level 1 predictor (effect size estimator) is a factor with 2 levels (original uncorrected estimator vs bias-corrected estimate); outcome is the effect size (continuous variable). See *Variables* and *Analysis Plan* for details. ", "q8.uploader": [{"file_id": "5e2608e9edceab019882e23c", "file_name": "preregistration_v.2.0.pdf", "file_urls": {"html": "https://osf.io/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "download": "https://osf.io/download/q4nhf/"}, "file_hashes": {"sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91"}}], "q12.question": "Details of study selection, inclusion/exclusion criteria and coding procedures for Part 1 can be found at https://osf.io/ruvhd/ . \n\nAs detailed above, data for Part 2 are being obtained via the following means: \n\u2022\tDownloading supplemental materials linked to the published papers\n\u2022\tExtracting data from tables and forest plots published within journal articles\n\u2022\tE-mailing the authors of the meta-analyses with requests for their data\n\nData collection will finish after the last author has responded, expected no later than 31/01/2020. \n\nInclusion criteria: \ni.\tStudy was included in Part 1 of this project. \ni.\tData for the study is accessible or made available by the authors \nii.\tStudy reports effect sizes in form of Cohen\u2019s d or provides parameters that enable transformation into Cohen\u2019s d.\niii.\tStudy provides the information necessary for computation or estimation of variance of the primary studies, and the t statistic where relevant for the appropriate publication bias correction method (see Variables and Analysis Plan for details.)\n\nExclusion criteria:\nIn addition to failing to meet the above inclusion criteria, studies will be excluded if: \ni.\tStudy is a meta-meta-analysis or a meta-analysis using internal databases as opposed to published research papers, as the nature of publication bias in these types of samples is different to the publication bias investigated in the present study. \nii.\tData are insufficient to reproduce the original analysis and the attempts to consult with the author of the paper are unsuccessful. \n", "q12.uploader": [{"file_id": "5e2608e9edceab019882e23c", "file_name": "preregistration_v.2.0.pdf", "file_urls": {"html": "https://osf.io/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "download": "https://osf.io/download/q4nhf/"}, "file_hashes": {"sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91"}}], "q16.question": "", "q16.uploader": [], "q17.question": "Variables collected in Part 1 which will be summarised using only descriptive statistics without inferential tests: \n\n\n\n\u2022\tNumber of unpublished studies included in the meta-analysis\n\u2022\tMethod used to obtain unpublished studies [multiple selection from: Undisclosed; Unpublished studies not included on purpose; Contact - first authors; Contact - authors from the reference list; Internet search of databases (such as OSF); Search of dissertation archives; Search of conference proceedings; Other - text box]\n\u2022\tResponse rate when contacting authors about unpublished studies [Authors contacted - integer; Authors responded - integer]\n\u2022\tMethod of addressing publication bias [Not applicable (publication bias not found); Trim-and-fill; Inclusion of unpublished studies; Weight function models (Vevea &amp; Hedges); Egger (regression); Egger-var (regression); Harbord (regression); Peters (regression); WLS; WAAP-WLS; PET-PEESE; Bayesian methods; Other - text box]\n\u2022\tMethod used to check for the presence of publication bias [Undisclosed; Visual - funnel plot; Visual - p-curve; Trim-and-fill (sensitivity analysis); Rosenthal\u2019s fail-safe N; Orwin\u2019s fail-safe N; Reverse correlation between effect sizes and sample sizes; Funnel asymmetry test; Precision effect test; Ioannidis &amp; Trikalinos (2007) publication bias test; Other - text box]\n\u2022\tAuthors\u2019 conclusion about the presence of publication bias in the meta-analytic sample [Present; Not present; Not reported]\n\nOutcome variables computed for Part 2 of the project: \n\nEach meta-analysis (level 2 unit) will contain 2 effect sizes (level 1 units), which is the primary outcome of this study. These effect sizes are: \n\n1.\tOriginal uncorrected effect size as published in the paper\n2.\tEffect size corrected by a publication bias correction method. Performance of a correction method is affected by the study\u2019s sample size and heterogeneity of primary effect sizes (defined by \u03c42), as well as unknown factors such as the level of publication bias and the population effect size. Therefore, for each meta-analysis, 4 additional effect sizes will be computed using a publication bias correction method that performs well given the study\u2019s sample size and heterogeneity (see below), as well as the level of publication bias and population effect size which have to be assumed. Assuming these unknown parameters will create 4 separate conditions within which to perform the analysis: \n\n1.\tMedium publication bias and population effect size of \u03b4 = 0.2 (Condition 1)\n2.\tHigh publication bias and population effect size of \u03b4 = 0.2 (Condition 2)\n3.\tMedium publication bias and population effect size of \u03b4 = 0.5 (Condition 3)\n4.\tHigh publication bias and population effect size of \u03b4 = 0.5 (Condition 4)\n\nEach of the 4 corrected effect sizes will be computed using one of the following publication bias correction methods: \n\u2022\tPrecision-effect test (PET) \n\u2022\tPrecision-effect estimate with standard error (PEESE)\n\u2022\tPET-PEESE\n\u2022\tWeighted average of the adequately powered - weighted least squares (WAAP-WLS)\n\u2022\tTrim-and-fill \n\u2022\tp-curve\n\u2022\tp-uniform\n\u2022\tSelection model with 3 parameters (3PSM; \u201cweight function model\u201d)\n\u2022\tSelection model with 4 parameters (4PSM; \u201cweight function model\u201d)\n\nAny adjustments that were applied for each meta-analysis prior to the estimation of the final effect size (i.e. dealing with dependent effect sizes, addressing with outliers, artefact corrections, or any other data transformations, excluding publication bias corrections) will be applied in the current study prior to calculating the corrected estimates. Therefore, the baseline uncorrected estimate will match the estimate that was published in the paper. \n\nDecisions regarding the selection of appropriate correction method for each individual meta-analysis across each of the four conditions outlined above will be modelled according to a recent simulation study by Carter et al. (2019) who have published detailed results of their simulations in an online R Shiny app Meta-Showdown Explorer (http://shinyapps.org/apps/metaExplorer/). As some methods perform equally well or similarly well with other methods under specific combinations of the conditions, data from the \u201cEstimation\u201d section have been downloaded and transformed into an R function which selects the appropriate correction method using pre-defined criteria which take into account the mean error, root mean squared error, and, where relevant, coverage.\n\nCriteria for deciding which correction method to use: \n\n\u2022\tOut of the 9 correction methods, the method that is eventually selected has to have the smallest summary value for mean error and root mean squared error. \n\u2022\tSome methods (namely 3PSM, 4 PSM, p-curve and p-uniform) require p-values in order to be performed. If a p-value based method is evaluated as the best method and the p-values are available for a given meta-analysis, the p-value based method will be preferred. If p-values are not available, the second best performing method will be selected. \n\u2022\tIn cases where 3PSM and 4PSM are evaluated as the best and equally well performing, 4PSM will be selected as it accounts for more realistic conditions regarding significance values than 3PSM. If the data available are not suitable for 4PSM, the analysis will fall back to 3PSM. \n\u2022\tIf PET and PEESE are evaluated as the best and equally well performing, PET-PEESE will be selected as this method takes both PET and PEESE into account. \n\u2022\tIf PET and PET-PEESE are evaluated as the best and equally well performing, PET will be selected. PET-PEESE uses conditional probability of PET to decide whether to use PET or PEESE as the final estimate. Given that PEESE was not highlighted as well performing under the conditions of the meta-analysis that is being re-analysed, the estimate from this method is likely to be more biased, and so would potentially be the final estimate of PET-PEESE. \n\u2022\tSame logic as outlined in the point above applies to the situation where the decision between PET and PET-PEESE has to be made. \n\u2022\tIf there is a tie in the summary value between any other methods not specified in the previous points, coverage is used as the deciding factor - the method with coverage closest to nominal .95 will be selected. \nThe R project containing the selection function is attached (note: the R project will also be made available directly within the OSF repository with additional files used in later stages of the project. There is no intention to further modify this function past the registration point. However, should minor error fixes or adjustments be found necessary, these will be clearly outlined within the R script). \n\nExample:\n\nIt is not the case that a single one of these methods is always assigned to any of the 4 conditions defined by level of publication bias and population effect size. For example, for a study with a sample size k = 34 and \u03c42 = 0.2, the estimators that are evaluated being likely the least biased ones are 4PSM for condition 1, PET for condition 2, 3PSM for condition 3, and PEESE for condition 4. On the other hand, for a study with k = 14 and \u03c42 = 0.09, the estimators are 4PSM (condition 1), 4PSM (condition 2), 3PSM (condition 3), and WAAP-WLS (condition 4). Therefore, for the whole sample, corrected effect sizes will not necessarily be obtained by the same estimator within a single condition. \n", "q17.uploader": [{"file_id": "5e2608e9edceab019882e23c", "file_name": "preregistration_v.2.0.pdf", "file_urls": {"html": "https://osf.io/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "download": "https://osf.io/download/q4nhf/"}, "file_hashes": {"sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91"}}, {"file_id": "5e2608fa675e0e017c6b7551", "file_name": "pb_correction_selection.zip", "file_urls": {"html": "https://osf.io/k9hqm/files/osfstorage/5e2608fa675e0e017c6b7551", "download": "https://osf.io/download/5v6eu/"}, "file_hashes": {"sha256": "74ae0fdd0623640e307936b29f4be14d4c4a21ccb6a03a77a778e4a126f66e07"}}], "q18.question": "", "q18.uploader": [], "q19.question": "For each of the 4 conditions, a separate 3-level Bayesian hierarchical model will be fitted (resulting in 4 models in total). Because published meta-analytic papers typically report multiple meta-analyses, effect sizes (level 1) are nested within meta-analyses (level 2) which themselves are nested within published papers (level 3). The form the model will take is specified in the attached document.  \n\nThe model predicts the effect size from the estimator type (factor with 2 levels: original uncorrected estimate vs corrected estimate). Additionally, crossed effect of the bias correction method will be modelled at level 2. Random effects will be fitted for the estimator, correction method, and the interaction between the estimator and the correction method.\n\nIt is possible that after the re-analysis, the number of values in each of the cells for the correction method will be insufficient to model the crossed effect. In such case, a simplified model without the cross-level interaction (specified in the attached document)\n\nIn either of the cases outlined above, model for each of the 4 conditions will be fitted using the brms R package for Bayesian multilevel modelling (B\u00fcrkner, 2017), with default uninformative priors. 95% highest posterior density intervals will subsequently be extracted from the models as the indicator of the plausible range of the attenuation in the effect sizes after the application of bias correcting methods. \n", "q19.uploader": [{"file_id": "5e2608e9edceab019882e23c", "file_name": "preregistration_v.2.0.pdf", "file_urls": {"html": "https://osf.io/k9hqm/files/osfstorage/5e2608e9edceab019882e23c", "download": "https://osf.io/download/q4nhf/"}, "file_hashes": {"sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91"}}]}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3q6tw/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3q6tw/comments/?format=json&filter%5Btarget%5D=3q6tw", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3q6tw/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3q6tw/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3q6tw/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3q6tw/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3q6tw/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3q6tw/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3q6tw/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3q6tw/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3q6tw/linked_by_registrations/?format=json", "meta": {}}}}, "parent": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/?format=json", "meta": {}}}, "data": {"id": "kxjs3", "type": "registrations"}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3q6tw/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3q6tw/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/3q6tw/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/?format=json", "meta": {}}}, "data": {"id": "kxjs3", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3q6tw/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3q6tw/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/3q6tw/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3q6tw/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/3q6tw/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3q6tw/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/3q6tw/citation/?format=json", "meta": {}}}, "data": {"id": "3q6tw", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/vq6rm/?format=json", "meta": {}}}, "data": {"id": "vq6rm", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/8a9pt/?format=json", "meta": {}}}, "data": {"id": "8a9pt", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5c08457ed283380029cf73bf/?format=json", "meta": {}}}, "data": {"id": "5c08457ed283380029cf73bf", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/3q6tw/", "self": "https://api.osf.io/v2/registrations/3q6tw/"}}, {"id": "kxjs3", "type": "registrations", "attributes": {"title": "Publication bias in psychology : Evaluating the robustness of meta-analytic effects", "description": "This project is a sister project linked to the OSF repository \"Meta-Analyses in Psychology - A Systematic Review\" by Avery, Kamar, Sladekova, and Field (https://osf.io/ruvhd/). The present study goes beyond the data originally coded in the first part of the project by looking at raw data and investigating how changes in methodological choices regarding publication bias correction change conclusions of individual studies.", "category": "project", "custom_citation": "", "date_created": "2020-01-20T20:11:28.413114", "date_modified": "2020-01-20T20:09:30.851765", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "0bc67aec4dfef944d5e1112ddbcc56fcaccf0ed07613bf65c2e6037dc3829b49690b24dfb6918a4ebb418bcf28e91a5c0f90a3edf88fe5dc95ac7252b1a204a13daa71c062d295003424d9d5a32afea872dd94594e8002c98b8c4c80d576ba798a7da2f49c670e3f50a97c8e604ada7aa568bd4ca6dfdc8104a517514939f3459cfe23abddac0f2fde4314c4ccc39386", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-20T20:11:28.397579", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "OSF Preregistration", "registered_meta": {"q1": {"extra": [], "value": "Publication bias in psychology : Evaluating the robustness of meta-analytic effects"}, "q2": {"extra": [], "value": "Martina Sladekova"}, "q3": {"extra": [], "value": "***Due to OSF formatting settings, some sections of this form may be difficult to read. The attached document titled \"preregistration_v.2.0.pdf\" contains a formatted and otherwise identical version of this preregistration. The document can also be found in the OSF repository https://osf.io/k9hqm/***\n\nPublication bias is an ongoing problem affecting meta-analytic estimates of effect sizes. A number of methods correcting for small study effects and publication bias have been developed over the years, however these methods tend to be applied without the regard for optimal performance conditions of each method. \nThe aim of this study is to investigate:\n\na)\tThe extent to which meta-analysts in psychology attend to publication bias\nb)\tHow the published effect sizes change when the data are re-analysed with a publication bias correction method that has been found to perform well given specific conditions of each study. These conditions refer to heterogeneity of primary effect sizes, number of primary effects included in the meta-analysis, expected level of publication bias, and expected population effect size. \n\nBecause the level of publication bias and population effect size are unknown, changes in publication bias will be investigated separately within 4 conditions that assume: \n\n1.\tMedium publication bias and population effect size of \u03b4 = 0.2 (Condition 1)\n2.\tHigh publication bias and population effect size of \u03b4 = 0.2 (Condition 2)\n3.\tMedium publication bias and population effect size of \u03b4 = 0.5 (Condition 3)\n4.\tHigh publication bias and population effect size of \u03b4 = 0.5 (Condition 4)\n\nSee *Variables* and *Analysis Plan* sections for details. \n"}, "q4": {"extra": [], "value": "Objectives\n\nThe key objective is to estimate: \n\n(1)\tthe typical attenuation in published meta-analytic effect sizes after the application of publication bias correcting methods. \n(2)\tthe plausible range of this attenuation using 95% highest posterior density intervals. \n(3)\tthe plausible limits of variation in the effect size attenuation across different bias correcting methods\n\nThe analysis will be performed separately for the specific combinations of the level of publication bias and the population effect size, as specified above.  \n"}, "q5": {"extra": [], "value": "Other"}, "q6": {"extra": [], "value": ["No blinding is involved in this study."]}, "q7": {"extra": [], "value": ""}, "q8": {"value": {"question": {"extra": [], "value": "The final data will have 3-level hierarchical structure. Models will be fitted for each of the 4 conditions separately. Level 1 predictor (effect size estimator) is a factor with 2 levels (original uncorrected estimator vs bias-corrected estimate); outcome is the effect size (continuous variable). See *Variables* and *Analysis Plan* for details. "}, "uploader": {"extra": [{"data": {"name": "preregistration_v.2.0.pdf"}, "nodeId": "k9hqm", "sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91", "viewUrl": "/project/kxjs3/files/osfstorage/5e260977edceab019882e2dc/", "selectedFileName": "preregistration_v.2.0.pdf"}], "value": ""}}}, "q9": {"extra": [], "value": ""}, "q10": {"extra": [], "value": "Registration prior to accessing the data"}, "q11": {"extra": [], "value": "Data were collected in two parts. \n\nPart 1 included random selection of meta-analyses published in 2008 and 2018, and subsequent coding of meta-analytic practices in these papers using a coding scheme. This phase of data collection lasted from February 2019 to June 2019. Authors of the present study were involved in the coding scheme development and data collection. Exact details of the coding scheme as well as analyses run on this dataset so far can be found at https://osf.io/ruvhd/ . No items from this dataset will be inferentially tested as outcome variables in the present study. \n\nPart 2 involves collection of raw data used in meta-analyses that were coded in Part 1. At the time of registration, raw data available in supplemental materials online have been downloaded. Data extraction directly from journal articles has begun, with the first dataset extracted on 03/09/2019. Additionally, 118 authors have been e-mailed with request for their data (first request sent on 10/10/2019), out of which 23 made their data available, 24 confirmed that they no longer have access to the data, with remaining 71 requests pending on 27/12/19. \n\nNo data that have been downloaded, extracted, or received from the authors has been in any way transformed or analysed. No additional variables have been computed for any of the datasets at time of the registration. Some authors of the meta-analyses included in the sample have sent their datasets with a computed variance measure; however, no additional analyses were performed on said datasets. As such the main outcome measure for this study has not yet been obtained for any of the studies. \n"}, "q12": {"value": {"question": {"extra": [], "value": "Details of study selection, inclusion/exclusion criteria and coding procedures for Part 1 can be found at https://osf.io/ruvhd/ . \n\nAs detailed above, data for Part 2 are being obtained via the following means: \n\u2022\tDownloading supplemental materials linked to the published papers\n\u2022\tExtracting data from tables and forest plots published within journal articles\n\u2022\tE-mailing the authors of the meta-analyses with requests for their data\n\nData collection will finish after the last author has responded, expected no later than 31/01/2020. \n\nInclusion criteria: \ni.\tStudy was included in Part 1 of this project. \ni.\tData for the study is accessible or made available by the authors \nii.\tStudy reports effect sizes in form of Cohen\u2019s d or provides parameters that enable transformation into Cohen\u2019s d.\niii.\tStudy provides the information necessary for computation or estimation of variance of the primary studies, and the t statistic where relevant for the appropriate publication bias correction method (see Variables and Analysis Plan for details.)\n\nExclusion criteria:\nIn addition to failing to meet the above inclusion criteria, studies will be excluded if: \ni.\tStudy is a meta-meta-analysis or a meta-analysis using internal databases as opposed to published research papers, as the nature of publication bias in these types of samples is different to the publication bias investigated in the present study. \nii.\tData are insufficient to reproduce the original analysis and the attempts to consult with the author of the paper are unsuccessful. \n"}, "uploader": {"extra": [{"data": {"name": "preregistration_v.2.0.pdf"}, "nodeId": "k9hqm", "sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91", "viewUrl": "/project/kxjs3/files/osfstorage/5e260977edceab019882e2dc/", "selectedFileName": "preregistration_v.2.0.pdf"}], "value": ""}}}, "q13": {"extra": [], "value": "Attempt will be made to obtain raw data for every single meta-analysis included in Part 1 (spreadsheet with all the studies included in Part 1 can be found at https://osf.io/ruvhd/). Should this effort be successful, and all the studies are found to be eligible, this will result in the inclusion of 170 published papers (level 3 units), containing 1242 individual meta-analyses (level 2 units), each containing uncorrected and corrected effect size estimates (resulting in 2484 level 1 units within each of the 4 conditions). This is the maximum upper boundary of the sample size, however at the time of registration, the expected sample size is 107 published papers containing 478 individual meta-analysis, each containing uncorrected and correct effect size estimates and therefore 956 level 1 units within each of the 4 conditions. "}, "q14": {"extra": [], "value": "Sample size for Part 1 was determined by time constraints of the project with the aim to code as many studies as possible. Sample size for this part of the project will be determined by data availability and alignment with inclusion/exclusion criteria outlined above. "}, "q15": {"extra": [], "value": ""}, "q16": {"value": {"question": {"extra": [], "value": ""}, "uploader": {"extra": [], "value": ""}}}, "q17": {"value": {"question": {"extra": [], "value": "Variables collected in Part 1 which will be summarised using only descriptive statistics without inferential tests: \n\n\n\n\u2022\tNumber of unpublished studies included in the meta-analysis\n\u2022\tMethod used to obtain unpublished studies [multiple selection from: Undisclosed; Unpublished studies not included on purpose; Contact - first authors; Contact - authors from the reference list; Internet search of databases (such as OSF); Search of dissertation archives; Search of conference proceedings; Other - text box]\n\u2022\tResponse rate when contacting authors about unpublished studies [Authors contacted - integer; Authors responded - integer]\n\u2022\tMethod of addressing publication bias [Not applicable (publication bias not found); Trim-and-fill; Inclusion of unpublished studies; Weight function models (Vevea &amp; Hedges); Egger (regression); Egger-var (regression); Harbord (regression); Peters (regression); WLS; WAAP-WLS; PET-PEESE; Bayesian methods; Other - text box]\n\u2022\tMethod used to check for the presence of publication bias [Undisclosed; Visual - funnel plot; Visual - p-curve; Trim-and-fill (sensitivity analysis); Rosenthal\u2019s fail-safe N; Orwin\u2019s fail-safe N; Reverse correlation between effect sizes and sample sizes; Funnel asymmetry test; Precision effect test; Ioannidis &amp; Trikalinos (2007) publication bias test; Other - text box]\n\u2022\tAuthors\u2019 conclusion about the presence of publication bias in the meta-analytic sample [Present; Not present; Not reported]\n\nOutcome variables computed for Part 2 of the project: \n\nEach meta-analysis (level 2 unit) will contain 2 effect sizes (level 1 units), which is the primary outcome of this study. These effect sizes are: \n\n1.\tOriginal uncorrected effect size as published in the paper\n2.\tEffect size corrected by a publication bias correction method. Performance of a correction method is affected by the study\u2019s sample size and heterogeneity of primary effect sizes (defined by \u03c42), as well as unknown factors such as the level of publication bias and the population effect size. Therefore, for each meta-analysis, 4 additional effect sizes will be computed using a publication bias correction method that performs well given the study\u2019s sample size and heterogeneity (see below), as well as the level of publication bias and population effect size which have to be assumed. Assuming these unknown parameters will create 4 separate conditions within which to perform the analysis: \n\n1.\tMedium publication bias and population effect size of \u03b4 = 0.2 (Condition 1)\n2.\tHigh publication bias and population effect size of \u03b4 = 0.2 (Condition 2)\n3.\tMedium publication bias and population effect size of \u03b4 = 0.5 (Condition 3)\n4.\tHigh publication bias and population effect size of \u03b4 = 0.5 (Condition 4)\n\nEach of the 4 corrected effect sizes will be computed using one of the following publication bias correction methods: \n\u2022\tPrecision-effect test (PET) \n\u2022\tPrecision-effect estimate with standard error (PEESE)\n\u2022\tPET-PEESE\n\u2022\tWeighted average of the adequately powered - weighted least squares (WAAP-WLS)\n\u2022\tTrim-and-fill \n\u2022\tp-curve\n\u2022\tp-uniform\n\u2022\tSelection model with 3 parameters (3PSM; \u201cweight function model\u201d)\n\u2022\tSelection model with 4 parameters (4PSM; \u201cweight function model\u201d)\n\nAny adjustments that were applied for each meta-analysis prior to the estimation of the final effect size (i.e. dealing with dependent effect sizes, addressing with outliers, artefact corrections, or any other data transformations, excluding publication bias corrections) will be applied in the current study prior to calculating the corrected estimates. Therefore, the baseline uncorrected estimate will match the estimate that was published in the paper. \n\nDecisions regarding the selection of appropriate correction method for each individual meta-analysis across each of the four conditions outlined above will be modelled according to a recent simulation study by Carter et al. (2019) who have published detailed results of their simulations in an online R Shiny app Meta-Showdown Explorer (http://shinyapps.org/apps/metaExplorer/). As some methods perform equally well or similarly well with other methods under specific combinations of the conditions, data from the \u201cEstimation\u201d section have been downloaded and transformed into an R function which selects the appropriate correction method using pre-defined criteria which take into account the mean error, root mean squared error, and, where relevant, coverage.\n\nCriteria for deciding which correction method to use: \n\n\u2022\tOut of the 9 correction methods, the method that is eventually selected has to have the smallest summary value for mean error and root mean squared error. \n\u2022\tSome methods (namely 3PSM, 4 PSM, p-curve and p-uniform) require p-values in order to be performed. If a p-value based method is evaluated as the best method and the p-values are available for a given meta-analysis, the p-value based method will be preferred. If p-values are not available, the second best performing method will be selected. \n\u2022\tIn cases where 3PSM and 4PSM are evaluated as the best and equally well performing, 4PSM will be selected as it accounts for more realistic conditions regarding significance values than 3PSM. If the data available are not suitable for 4PSM, the analysis will fall back to 3PSM. \n\u2022\tIf PET and PEESE are evaluated as the best and equally well performing, PET-PEESE will be selected as this method takes both PET and PEESE into account. \n\u2022\tIf PET and PET-PEESE are evaluated as the best and equally well performing, PET will be selected. PET-PEESE uses conditional probability of PET to decide whether to use PET or PEESE as the final estimate. Given that PEESE was not highlighted as well performing under the conditions of the meta-analysis that is being re-analysed, the estimate from this method is likely to be more biased, and so would potentially be the final estimate of PET-PEESE. \n\u2022\tSame logic as outlined in the point above applies to the situation where the decision between PET and PET-PEESE has to be made. \n\u2022\tIf there is a tie in the summary value between any other methods not specified in the previous points, coverage is used as the deciding factor - the method with coverage closest to nominal .95 will be selected. \nThe R project containing the selection function is attached (note: the R project will also be made available directly within the OSF repository with additional files used in later stages of the project. There is no intention to further modify this function past the registration point. However, should minor error fixes or adjustments be found necessary, these will be clearly outlined within the R script). \n\nExample:\n\nIt is not the case that a single one of these methods is always assigned to any of the 4 conditions defined by level of publication bias and population effect size. For example, for a study with a sample size k = 34 and \u03c42 = 0.2, the estimators that are evaluated being likely the least biased ones are 4PSM for condition 1, PET for condition 2, 3PSM for condition 3, and PEESE for condition 4. On the other hand, for a study with k = 14 and \u03c42 = 0.09, the estimators are 4PSM (condition 1), 4PSM (condition 2), 3PSM (condition 3), and WAAP-WLS (condition 4). Therefore, for the whole sample, corrected effect sizes will not necessarily be obtained by the same estimator within a single condition. \n"}, "uploader": {"extra": [{"data": {"name": "preregistration_v.2.0.pdf"}, "nodeId": "k9hqm", "sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91", "viewUrl": "/project/kxjs3/files/osfstorage/5e260977edceab019882e2dc/", "selectedFileName": "preregistration_v.2.0.pdf"}, {"data": {"name": "pb_correction_selection.zip"}, "nodeId": "k9hqm", "sha256": "74ae0fdd0623640e307936b29f4be14d4c4a21ccb6a03a77a778e4a126f66e07", "viewUrl": "/project/kxjs3/files/osfstorage/5e260977edceab019882e2da/", "selectedFileName": "pb_correction_selection.zip"}], "value": ""}}}, "q18": {"value": {"question": {"extra": [], "value": ""}, "uploader": {"extra": [], "value": ""}}}, "q19": {"value": {"question": {"extra": [], "value": "For each of the 4 conditions, a separate 3-level Bayesian hierarchical model will be fitted (resulting in 4 models in total). Because published meta-analytic papers typically report multiple meta-analyses, effect sizes (level 1) are nested within meta-analyses (level 2) which themselves are nested within published papers (level 3). The form the model will take is specified in the attached document.  \n\nThe model predicts the effect size from the estimator type (factor with 2 levels: original uncorrected estimate vs corrected estimate). Additionally, crossed effect of the bias correction method will be modelled at level 2. Random effects will be fitted for the estimator, correction method, and the interaction between the estimator and the correction method.\n\nIt is possible that after the re-analysis, the number of values in each of the cells for the correction method will be insufficient to model the crossed effect. In such case, a simplified model without the cross-level interaction (specified in the attached document)\n\nIn either of the cases outlined above, model for each of the 4 conditions will be fitted using the brms R package for Bayesian multilevel modelling (B\u00fcrkner, 2017), with default uninformative priors. 95% highest posterior density intervals will subsequently be extracted from the models as the indicator of the plausible range of the attenuation in the effect sizes after the application of bias correcting methods. \n"}, "uploader": {"extra": [{"data": {"name": "preregistration_v.2.0.pdf"}, "nodeId": "k9hqm", "sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91", "viewUrl": "/project/kxjs3/files/osfstorage/5e260977edceab019882e2dc/", "selectedFileName": "preregistration_v.2.0.pdf"}], "value": ""}}}, "q20": {"extra": [], "value": "Where possible, the steps of the original analysis will be followed without additional data transformations. Because the majority of the coded papers report their effect sizes as Cohen\u2019s d, this will be the target metric. Data that use alternative effect size metrics (correlation coefficient r or odds ratio) will be converted into d using the formulae (from Borenstein et al., 2009) specified in the attached document."}, "q21": {"extra": [], "value": "Inferential tests will not be performed as part of the analysis. As the mathematical properties of the bias correcting methods will inevitably reduce the original effect sizes in the presence of publication bias, the analysis will focus on the estimates of the extent of this reduction.  "}, "q22": {"extra": [], "value": "No data are expected to be excluded on the basis of presence of outliers or violations of other model assumptions. To address potential issues, the original model will be compared to a robust model fitted using the brms R package as a form of sensitivity analysis. Should the original estimate substantially differ, the robust estimate will be interpreted instead. "}, "q23": {"extra": [], "value": "It is possible that some data will not be suitable for analysis with any of the well performing correction methods corresponding to one of the 4 conditions. In such cases, the data in question will be excluded for the condition where re-analysis is not possible but retained for the remaining conditions. "}, "q24": {"extra": [], "value": "Some meta-analyses may have used publication bias correction methods and reported the corrected estimates as well as the uncorrected ones. If this is found to be the case for a sufficient number of analyses, analyses that originally report corrected estimates will be grouped and analysed separately to see if the original corrected effect sizes differ from effect sizes computed using correction methods identified as suitable using the criteria employed in this study. "}, "q25": {"extra": [], "value": "***References***\n\nB\u00fcrkner, P. C. (2017). Advanced Bayesian multilevel modelling with the R package brms. arXiv preprint arXiv:1705.11123.\n\nCarter, E. C., Sch\u00f6nbrodt, F. D., Gervais, W. M., &amp; Hilgard, J. (2019). Correcting for bias in psychology: A comparison of meta-analytic methods. Advances in Methods and Practices in Psychological Science, 2(2), 115-144.\n\nBorenstein, M., Hedges, L. V., Higgins, J. P., &amp; Rothstein, H. R. (2009). Introduction to meta-analysis. John Wiley &amp; Sons.\n"}}, "registration_responses": {"q1": "Publication bias in psychology : Evaluating the robustness of meta-analytic effects", "q2": "Martina Sladekova", "q3": "***Due to OSF formatting settings, some sections of this form may be difficult to read. The attached document titled \"preregistration_v.2.0.pdf\" contains a formatted and otherwise identical version of this preregistration. The document can also be found in the OSF repository https://osf.io/k9hqm/***\n\nPublication bias is an ongoing problem affecting meta-analytic estimates of effect sizes. A number of methods correcting for small study effects and publication bias have been developed over the years, however these methods tend to be applied without the regard for optimal performance conditions of each method. \nThe aim of this study is to investigate:\n\na)\tThe extent to which meta-analysts in psychology attend to publication bias\nb)\tHow the published effect sizes change when the data are re-analysed with a publication bias correction method that has been found to perform well given specific conditions of each study. These conditions refer to heterogeneity of primary effect sizes, number of primary effects included in the meta-analysis, expected level of publication bias, and expected population effect size. \n\nBecause the level of publication bias and population effect size are unknown, changes in publication bias will be investigated separately within 4 conditions that assume: \n\n1.\tMedium publication bias and population effect size of \u03b4 = 0.2 (Condition 1)\n2.\tHigh publication bias and population effect size of \u03b4 = 0.2 (Condition 2)\n3.\tMedium publication bias and population effect size of \u03b4 = 0.5 (Condition 3)\n4.\tHigh publication bias and population effect size of \u03b4 = 0.5 (Condition 4)\n\nSee *Variables* and *Analysis Plan* sections for details. \n", "q4": "Objectives\n\nThe key objective is to estimate: \n\n(1)\tthe typical attenuation in published meta-analytic effect sizes after the application of publication bias correcting methods. \n(2)\tthe plausible range of this attenuation using 95% highest posterior density intervals. \n(3)\tthe plausible limits of variation in the effect size attenuation across different bias correcting methods\n\nThe analysis will be performed separately for the specific combinations of the level of publication bias and the population effect size, as specified above.  \n", "q5": "Other", "q6": ["No blinding is involved in this study."], "q7": "", "q9": "", "q10": "Registration prior to accessing the data", "q11": "Data were collected in two parts. \n\nPart 1 included random selection of meta-analyses published in 2008 and 2018, and subsequent coding of meta-analytic practices in these papers using a coding scheme. This phase of data collection lasted from February 2019 to June 2019. Authors of the present study were involved in the coding scheme development and data collection. Exact details of the coding scheme as well as analyses run on this dataset so far can be found at https://osf.io/ruvhd/ . No items from this dataset will be inferentially tested as outcome variables in the present study. \n\nPart 2 involves collection of raw data used in meta-analyses that were coded in Part 1. At the time of registration, raw data available in supplemental materials online have been downloaded. Data extraction directly from journal articles has begun, with the first dataset extracted on 03/09/2019. Additionally, 118 authors have been e-mailed with request for their data (first request sent on 10/10/2019), out of which 23 made their data available, 24 confirmed that they no longer have access to the data, with remaining 71 requests pending on 27/12/19. \n\nNo data that have been downloaded, extracted, or received from the authors has been in any way transformed or analysed. No additional variables have been computed for any of the datasets at time of the registration. Some authors of the meta-analyses included in the sample have sent their datasets with a computed variance measure; however, no additional analyses were performed on said datasets. As such the main outcome measure for this study has not yet been obtained for any of the studies. \n", "q13": "Attempt will be made to obtain raw data for every single meta-analysis included in Part 1 (spreadsheet with all the studies included in Part 1 can be found at https://osf.io/ruvhd/). Should this effort be successful, and all the studies are found to be eligible, this will result in the inclusion of 170 published papers (level 3 units), containing 1242 individual meta-analyses (level 2 units), each containing uncorrected and corrected effect size estimates (resulting in 2484 level 1 units within each of the 4 conditions). This is the maximum upper boundary of the sample size, however at the time of registration, the expected sample size is 107 published papers containing 478 individual meta-analysis, each containing uncorrected and correct effect size estimates and therefore 956 level 1 units within each of the 4 conditions. ", "q14": "Sample size for Part 1 was determined by time constraints of the project with the aim to code as many studies as possible. Sample size for this part of the project will be determined by data availability and alignment with inclusion/exclusion criteria outlined above. ", "q15": "", "q20": "Where possible, the steps of the original analysis will be followed without additional data transformations. Because the majority of the coded papers report their effect sizes as Cohen\u2019s d, this will be the target metric. Data that use alternative effect size metrics (correlation coefficient r or odds ratio) will be converted into d using the formulae (from Borenstein et al., 2009) specified in the attached document.", "q21": "Inferential tests will not be performed as part of the analysis. As the mathematical properties of the bias correcting methods will inevitably reduce the original effect sizes in the presence of publication bias, the analysis will focus on the estimates of the extent of this reduction.  ", "q22": "No data are expected to be excluded on the basis of presence of outliers or violations of other model assumptions. To address potential issues, the original model will be compared to a robust model fitted using the brms R package as a form of sensitivity analysis. Should the original estimate substantially differ, the robust estimate will be interpreted instead. ", "q23": "It is possible that some data will not be suitable for analysis with any of the well performing correction methods corresponding to one of the 4 conditions. In such cases, the data in question will be excluded for the condition where re-analysis is not possible but retained for the remaining conditions. ", "q24": "Some meta-analyses may have used publication bias correction methods and reported the corrected estimates as well as the uncorrected ones. If this is found to be the case for a sufficient number of analyses, analyses that originally report corrected estimates will be grouped and analysed separately to see if the original corrected effect sizes differ from effect sizes computed using correction methods identified as suitable using the criteria employed in this study. ", "q25": "***References***\n\nB\u00fcrkner, P. C. (2017). Advanced Bayesian multilevel modelling with the R package brms. arXiv preprint arXiv:1705.11123.\n\nCarter, E. C., Sch\u00f6nbrodt, F. D., Gervais, W. M., &amp; Hilgard, J. (2019). Correcting for bias in psychology: A comparison of meta-analytic methods. Advances in Methods and Practices in Psychological Science, 2(2), 115-144.\n\nBorenstein, M., Hedges, L. V., Higgins, J. P., &amp; Rothstein, H. R. (2009). Introduction to meta-analysis. John Wiley &amp; Sons.\n", "q8.question": "The final data will have 3-level hierarchical structure. Models will be fitted for each of the 4 conditions separately. Level 1 predictor (effect size estimator) is a factor with 2 levels (original uncorrected estimator vs bias-corrected estimate); outcome is the effect size (continuous variable). See *Variables* and *Analysis Plan* for details. ", "q8.uploader": [{"file_id": "5e260977edceab019882e2dc", "file_name": "preregistration_v.2.0.pdf", "file_urls": {"html": "https://osf.io/project/kxjs3/files/osfstorage/5e260977edceab019882e2dc", "download": "https://osf.io/download/5e260977edceab019882e2dc"}, "file_hashes": {"sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91"}}], "q12.question": "Details of study selection, inclusion/exclusion criteria and coding procedures for Part 1 can be found at https://osf.io/ruvhd/ . \n\nAs detailed above, data for Part 2 are being obtained via the following means: \n\u2022\tDownloading supplemental materials linked to the published papers\n\u2022\tExtracting data from tables and forest plots published within journal articles\n\u2022\tE-mailing the authors of the meta-analyses with requests for their data\n\nData collection will finish after the last author has responded, expected no later than 31/01/2020. \n\nInclusion criteria: \ni.\tStudy was included in Part 1 of this project. \ni.\tData for the study is accessible or made available by the authors \nii.\tStudy reports effect sizes in form of Cohen\u2019s d or provides parameters that enable transformation into Cohen\u2019s d.\niii.\tStudy provides the information necessary for computation or estimation of variance of the primary studies, and the t statistic where relevant for the appropriate publication bias correction method (see Variables and Analysis Plan for details.)\n\nExclusion criteria:\nIn addition to failing to meet the above inclusion criteria, studies will be excluded if: \ni.\tStudy is a meta-meta-analysis or a meta-analysis using internal databases as opposed to published research papers, as the nature of publication bias in these types of samples is different to the publication bias investigated in the present study. \nii.\tData are insufficient to reproduce the original analysis and the attempts to consult with the author of the paper are unsuccessful. \n", "q12.uploader": [{"file_id": "5e260977edceab019882e2dc", "file_name": "preregistration_v.2.0.pdf", "file_urls": {"html": "https://osf.io/project/kxjs3/files/osfstorage/5e260977edceab019882e2dc", "download": "https://osf.io/download/5e260977edceab019882e2dc"}, "file_hashes": {"sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91"}}], "q16.question": "", "q16.uploader": [], "q17.question": "Variables collected in Part 1 which will be summarised using only descriptive statistics without inferential tests: \n\n\n\n\u2022\tNumber of unpublished studies included in the meta-analysis\n\u2022\tMethod used to obtain unpublished studies [multiple selection from: Undisclosed; Unpublished studies not included on purpose; Contact - first authors; Contact - authors from the reference list; Internet search of databases (such as OSF); Search of dissertation archives; Search of conference proceedings; Other - text box]\n\u2022\tResponse rate when contacting authors about unpublished studies [Authors contacted - integer; Authors responded - integer]\n\u2022\tMethod of addressing publication bias [Not applicable (publication bias not found); Trim-and-fill; Inclusion of unpublished studies; Weight function models (Vevea &amp; Hedges); Egger (regression); Egger-var (regression); Harbord (regression); Peters (regression); WLS; WAAP-WLS; PET-PEESE; Bayesian methods; Other - text box]\n\u2022\tMethod used to check for the presence of publication bias [Undisclosed; Visual - funnel plot; Visual - p-curve; Trim-and-fill (sensitivity analysis); Rosenthal\u2019s fail-safe N; Orwin\u2019s fail-safe N; Reverse correlation between effect sizes and sample sizes; Funnel asymmetry test; Precision effect test; Ioannidis &amp; Trikalinos (2007) publication bias test; Other - text box]\n\u2022\tAuthors\u2019 conclusion about the presence of publication bias in the meta-analytic sample [Present; Not present; Not reported]\n\nOutcome variables computed for Part 2 of the project: \n\nEach meta-analysis (level 2 unit) will contain 2 effect sizes (level 1 units), which is the primary outcome of this study. These effect sizes are: \n\n1.\tOriginal uncorrected effect size as published in the paper\n2.\tEffect size corrected by a publication bias correction method. Performance of a correction method is affected by the study\u2019s sample size and heterogeneity of primary effect sizes (defined by \u03c42), as well as unknown factors such as the level of publication bias and the population effect size. Therefore, for each meta-analysis, 4 additional effect sizes will be computed using a publication bias correction method that performs well given the study\u2019s sample size and heterogeneity (see below), as well as the level of publication bias and population effect size which have to be assumed. Assuming these unknown parameters will create 4 separate conditions within which to perform the analysis: \n\n1.\tMedium publication bias and population effect size of \u03b4 = 0.2 (Condition 1)\n2.\tHigh publication bias and population effect size of \u03b4 = 0.2 (Condition 2)\n3.\tMedium publication bias and population effect size of \u03b4 = 0.5 (Condition 3)\n4.\tHigh publication bias and population effect size of \u03b4 = 0.5 (Condition 4)\n\nEach of the 4 corrected effect sizes will be computed using one of the following publication bias correction methods: \n\u2022\tPrecision-effect test (PET) \n\u2022\tPrecision-effect estimate with standard error (PEESE)\n\u2022\tPET-PEESE\n\u2022\tWeighted average of the adequately powered - weighted least squares (WAAP-WLS)\n\u2022\tTrim-and-fill \n\u2022\tp-curve\n\u2022\tp-uniform\n\u2022\tSelection model with 3 parameters (3PSM; \u201cweight function model\u201d)\n\u2022\tSelection model with 4 parameters (4PSM; \u201cweight function model\u201d)\n\nAny adjustments that were applied for each meta-analysis prior to the estimation of the final effect size (i.e. dealing with dependent effect sizes, addressing with outliers, artefact corrections, or any other data transformations, excluding publication bias corrections) will be applied in the current study prior to calculating the corrected estimates. Therefore, the baseline uncorrected estimate will match the estimate that was published in the paper. \n\nDecisions regarding the selection of appropriate correction method for each individual meta-analysis across each of the four conditions outlined above will be modelled according to a recent simulation study by Carter et al. (2019) who have published detailed results of their simulations in an online R Shiny app Meta-Showdown Explorer (http://shinyapps.org/apps/metaExplorer/). As some methods perform equally well or similarly well with other methods under specific combinations of the conditions, data from the \u201cEstimation\u201d section have been downloaded and transformed into an R function which selects the appropriate correction method using pre-defined criteria which take into account the mean error, root mean squared error, and, where relevant, coverage.\n\nCriteria for deciding which correction method to use: \n\n\u2022\tOut of the 9 correction methods, the method that is eventually selected has to have the smallest summary value for mean error and root mean squared error. \n\u2022\tSome methods (namely 3PSM, 4 PSM, p-curve and p-uniform) require p-values in order to be performed. If a p-value based method is evaluated as the best method and the p-values are available for a given meta-analysis, the p-value based method will be preferred. If p-values are not available, the second best performing method will be selected. \n\u2022\tIn cases where 3PSM and 4PSM are evaluated as the best and equally well performing, 4PSM will be selected as it accounts for more realistic conditions regarding significance values than 3PSM. If the data available are not suitable for 4PSM, the analysis will fall back to 3PSM. \n\u2022\tIf PET and PEESE are evaluated as the best and equally well performing, PET-PEESE will be selected as this method takes both PET and PEESE into account. \n\u2022\tIf PET and PET-PEESE are evaluated as the best and equally well performing, PET will be selected. PET-PEESE uses conditional probability of PET to decide whether to use PET or PEESE as the final estimate. Given that PEESE was not highlighted as well performing under the conditions of the meta-analysis that is being re-analysed, the estimate from this method is likely to be more biased, and so would potentially be the final estimate of PET-PEESE. \n\u2022\tSame logic as outlined in the point above applies to the situation where the decision between PET and PET-PEESE has to be made. \n\u2022\tIf there is a tie in the summary value between any other methods not specified in the previous points, coverage is used as the deciding factor - the method with coverage closest to nominal .95 will be selected. \nThe R project containing the selection function is attached (note: the R project will also be made available directly within the OSF repository with additional files used in later stages of the project. There is no intention to further modify this function past the registration point. However, should minor error fixes or adjustments be found necessary, these will be clearly outlined within the R script). \n\nExample:\n\nIt is not the case that a single one of these methods is always assigned to any of the 4 conditions defined by level of publication bias and population effect size. For example, for a study with a sample size k = 34 and \u03c42 = 0.2, the estimators that are evaluated being likely the least biased ones are 4PSM for condition 1, PET for condition 2, 3PSM for condition 3, and PEESE for condition 4. On the other hand, for a study with k = 14 and \u03c42 = 0.09, the estimators are 4PSM (condition 1), 4PSM (condition 2), 3PSM (condition 3), and WAAP-WLS (condition 4). Therefore, for the whole sample, corrected effect sizes will not necessarily be obtained by the same estimator within a single condition. \n", "q17.uploader": [{"file_id": "5e260977edceab019882e2dc", "file_name": "preregistration_v.2.0.pdf", "file_urls": {"html": "https://osf.io/project/kxjs3/files/osfstorage/5e260977edceab019882e2dc", "download": "https://osf.io/download/5e260977edceab019882e2dc"}, "file_hashes": {"sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91"}}, {"file_id": "5e260977edceab019882e2da", "file_name": "pb_correction_selection.zip", "file_urls": {"html": "https://osf.io/project/kxjs3/files/osfstorage/5e260977edceab019882e2da", "download": "https://osf.io/download/5e260977edceab019882e2da"}, "file_hashes": {"sha256": "74ae0fdd0623640e307936b29f4be14d4c4a21ccb6a03a77a778e4a126f66e07"}}], "q18.question": "", "q18.uploader": [], "q19.question": "For each of the 4 conditions, a separate 3-level Bayesian hierarchical model will be fitted (resulting in 4 models in total). Because published meta-analytic papers typically report multiple meta-analyses, effect sizes (level 1) are nested within meta-analyses (level 2) which themselves are nested within published papers (level 3). The form the model will take is specified in the attached document.  \n\nThe model predicts the effect size from the estimator type (factor with 2 levels: original uncorrected estimate vs corrected estimate). Additionally, crossed effect of the bias correction method will be modelled at level 2. Random effects will be fitted for the estimator, correction method, and the interaction between the estimator and the correction method.\n\nIt is possible that after the re-analysis, the number of values in each of the cells for the correction method will be insufficient to model the crossed effect. In such case, a simplified model without the cross-level interaction (specified in the attached document)\n\nIn either of the cases outlined above, model for each of the 4 conditions will be fitted using the brms R package for Bayesian multilevel modelling (B\u00fcrkner, 2017), with default uninformative priors. 95% highest posterior density intervals will subsequently be extracted from the models as the indicator of the plausible range of the attenuation in the effect sizes after the application of bias correcting methods. \n", "q19.uploader": [{"file_id": "5e260977edceab019882e2dc", "file_name": "preregistration_v.2.0.pdf", "file_urls": {"html": "https://osf.io/project/kxjs3/files/osfstorage/5e260977edceab019882e2dc", "download": "https://osf.io/download/5e260977edceab019882e2dc"}, "file_hashes": {"sha256": "1feadfe40619813c6cc1f3b2350c0591f3ab4bacc8a6995e6b3829e46916fb91"}}]}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/comments/?format=json&filter%5Btarget%5D=kxjs3", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/kxjs3/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/?format=json", "meta": {}}}, "data": {"id": "kxjs3", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/kxjs3/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/kxjs3/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/kxjs3/citation/?format=json", "meta": {}}}, "data": {"id": "kxjs3", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/vq6rm/?format=json", "meta": {}}}, "data": {"id": "vq6rm", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/k9hqm/?format=json", "meta": {}}}, "data": {"id": "k9hqm", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5c08457ed283380029cf73bf/?format=json", "meta": {}}}, "data": {"id": "5c08457ed283380029cf73bf", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/kxjs3/", "self": "https://api.osf.io/v2/registrations/kxjs3/"}}], "links": {"first": "https://api.osf.io/v2/registrations/?filter%5Bdate_created%5D%5Bgt%5D=2019-12-31&format=json", "last": "https://api.osf.io/v2/registrations/?filter%5Bdate_created%5D%5Bgt%5D=2019-12-31&format=json&page=547", "prev": "https://api.osf.io/v2/registrations/?filter%5Bdate_created%5D%5Bgt%5D=2019-12-31&format=json&page=506", "next": "https://api.osf.io/v2/registrations/?filter%5Bdate_created%5D%5Bgt%5D=2019-12-31&format=json&page=508", "meta": {"total": 5469, "per_page": 10}}}