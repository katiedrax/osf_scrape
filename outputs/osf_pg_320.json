{"data": [{"id": "m9puw", "type": "registrations", "attributes": {"title": "Purpose of Project", "description": "", "category": "", "custom_citation": "", "date_created": "2020-02-11T16:27:32.438088", "date_modified": "2020-02-09T19:27:54.186085", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "17fa9ba3948a6ac33d6db5f35d919f7f230b1ec72824dc6f1ba855683b56e88580abe97f9fd31d9d746184b0abbeacf74e2ab2aaf59a334d7db01b8ab88d6d1b63b811ade1e310f0a7635b2ca632eb2f873f50e6d47282e7c136de968bc095de94c4707575226e545d721e68907a7d33c882122a51caae0975ccf5ae23dd5a2361e2b820373ef9bfe5ec72e1c85598f8", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-02-11T16:27:32.419966", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Pre-Registration in Social Psychology (van 't Veer & Giner-Sorolla, 2016): Pre-Registration", "registered_meta": {"looked": {"extra": [], "value": "No"}, "datacompletion": {"extra": [], "value": "No, data collection has not begun"}, "additionalComments": {"extra": [], "value": "Citations: \n\nHuart, J., Corneille, O., &amp; Becquart, E. (2005). Face-based categorization, context-based categorization, and distortions in the recollection of gender-ambiguous faces. Journal of Experimental Social Psychology, 41(6), 598-608. doi:10.1016/j.jesp.2004.10.007\n\nMapstone, L. (2015). Rihanna hides away under oversized gothic hoodie and baggy trousers for low-key arrival in Los Angeles after Paris love-in with Travis Scott [Online image]. MailOnline. Retrieved from: http://www.dailymail.co.uk/tvshowbiz/article-3262964/Rihanna-hides-away-oversized-gothic-hoodie-baggy-trousers-low-key-arrival-Los-Angeles-Paris-love-Travis-Scott.html "}, "dataCollectionDates": {"extra": [], "value": "February 2020 - February 2023\n"}, "description-methods": {"value": {"design": {"value": {"question2a": {"extra": [], "value": "This is a 2 Gendered-clothing (male clothing [MC] or female clothing [FC]) x 2 Gender-ambiguous face (Face 1 or Face 2) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) between-subjects factorial design. This is an orthogonal study design.\n"}, "question2b": {"extra": [], "value": "Dependent Variables: \n\n1. Demographic judgments of the individual in the image: categorical gender judgment (M or F), and continuous estimations of weight (open-ended), height (open-ended), and age (open-ended).\n\n2. Judgement of the social features of the individual in the image: level of aggression on a 9-point Likert scale (0 = \"Not aggressive\", 9 = \"Highly Aggressive\").\n\n3. Metacognitive judgment of the viewers experience: participant\u2019s confidence in their judgments (0 = \u201cNot Confident At All\u201d to 100 = \u201cExtremely Confident\u201d), the speed at which they made the gender judgment (open-ended), quality of the view of the individual\u2019s face (1 = \u201cVery Poor\u201d, 7 = \u201cVery Good\u201d), which factors the participant took into consideration when determining gender (open-ended), and how order of responding affected judgment (open-ended)."}, "question3b": {"extra": [], "value": "We do not anticipate using any covariate. However, it is possible that we may use reported age as a covariate if we are seeking to understand our findings on the demographic measures for those in the MC and FC.   "}}}, "procedure": {"value": {"question10b": {"extra": [], "value": "Manipulations and Measures\n\nThis is a 2 Gendered-clothing (male clothing [MC] or female clothing [FC]) x 2 Gender-ambiguous face (Face 1 or Face 2) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) between-subjects factorial design. \n\nDependent Variables\n\n1. Demographic judgments of the individual in the image: categorical gender judgment (M or F), and continuous estimations of weight (open-ended), height, (open-ended) and age (open-ended). \n\n2. Judgement on the social features of the individual in the image: level of aggression on a 9-point Likert scale (0 = \"Not aggressive\", 9 = \"Highly Aggressive\"). \n\n3. Metacognitive judgment of the viewers experience: (i) participant\u2019s confidence in each one of their demographic judgments (gender, weight, height, age) and aggression judgment, (ii) the estimated speed at which they made their gender judgment, (iii) quality of the view of the individual\u2019s face, (iv) which factors the participant took into consideration when determining the gender of the individual and (v) if they believe that the order that they answered the demographic questions could have affected their judgments. \n\nMaterials\n\nFace: Two gender-ambiguous faces were selected from a continuum of morphed male/female faces developed by Huart et al. (2005). Our Face 1 stimulus is a blend of 50% male and 50% female face (named \u201cMoprh 10-050\u201d in original paper; Huart et al., 2005), and our Face 2 stimulus is a blend of 70% female\u201330% male moderately ambiguous face (named \u201cMorph 7-030\u201d in original paper). \n\nClothing: We modified a single image by changing the colour and the logo on the clothing to make it either more \u201cmasculine\u201d or \u201cfeminine.\u201d The image was an anterior view of a person (the pop singer Rhianna) wearing a hooded sweatshirt and a pair of baggy pants (image retrieved from Google Image; Mapstone, 2015). The baggy clothing obscured the physique of the person. Photo editing software was used to alter the logo on the sweatshirt and the clothing colour. \n\nWe conducted a pilot study with four clothing stimuli to test their levels of perceived masculinity and femininity. Sixty undergraduate students (49 females, 11 males) participated in the study and were asked to rate on a 9-point Likert scale (1 = \u201cOnly Women\u201d; 9 = \u201cOnly Men\u201d) on whether men or women are more likely to wear the outfit presented. Descriptive results revealed two outfits were rated as relatively equal in magnitude; one on the quality of \u201cfeminine\u201d and one on the quality of \u201cmasculine\u201d while maintaining low variances. The feminine outfit selected was an entirely pink outfit with an image of a pair of red lips above the letters \u201cXOXO\u201d on the sweater (M = 2.88, SD = 1.42). The masculine outfit selected was black pants and a brown sweatshirt with an image of a woman in lingerie (M = 6.38, SD = 1.59). \n\nFinal stimuli: Photo editing software was used to incorporate each of the two faces (Face 1 and Face 2) with the masculine (i.e., black pants and a brown sweatshirt with an image of a woman in lingerie) and feminine (i.e., pink pants and a pink sweatshirt with an image of a pair of red lips above \u201cXOXO\u201d) outfits. A fringe of gender-neutral hair was added to the forehead area of each image to make the final images of the people appear more realistic. \n\nProcedure\n\nParticipants will use either a laptop or a computer to participate \u2013 attempting to use any cellular devices will result in automatic termination of the survey (ballot box stuffing disabled).\n\nScreen 1: Consent form \u2013 participants who click the \u201cyes, I would like to participate\u201d to continue and those who click \u201cNo, I do not consent to participating in this study\u201d will be brought to the end of the survey. All participants receive credit regardless of if they complete the survey.\n\nScreen 2: Participants are instructed to: \u201cPay attention to the images you are about to see, and answer the following questions about the image as quickly and honestly as possible.\u201d\n\nScreens 3-14: Participants make judgements on twelve filler task questions. These tasks require participants to make judgments on visual stimuli. For instance, how many red jelly beans are there in a jar of beans or what was the colour of horses seen in an image. The filler tasks are included to prevent participants from being overly vigilant in our activity of interest, which will be the final task.\n\nScreens 15-25: Participants make demographic and character judgments of a person who has a gender-ambiguous face (F1 or F4) is wearing clothing that has been modified to be either female (FC) or male (MC). Importantly the image of the person will remain on the screen while participants make all of the demographic judgments, their aggression judgment, as well as, their confidence judgments:\n\n*Half of participants will receive the gender question as the first judgment they make of the individual in the image; half will be asked to judge gender at the end of the person judgments:\n\nGender Judgment: \u201cPlease select the gender of this person:\u201d Screen presents a centered image of a person in either the MC or FC with one of the two gender-neutral faces (F1 or F4). There is a forced-choice option underneath for participants to select either \u201cMale\u201d or \u201cFemale\u201d.\n\nParticipants will receive one of two presentation options: Order1: male option on the left and female option on the right OR Order2: female option on the left and male option on the right.\n\nFollowing the gender judgment, a new screen asks participants to rate their confidence about their gender judgment while the image of the person remains on screen (0 = \"Not Confident At All\" to 100 = \"Extremely Confident\"). Their gender selection is not visible on the confidence screen.\n\nContinuous Demographic and Character Judgements (the order of the four questions will be randomly presented to participants): \n      a). Weight: \u201cPlease estimate the weight of the person in the image (in pounds/lbs)\u201d (Open-ended)\n      b). Height: \u201cPlease estimate the height of the person in the image (in ft and inches)\u201d (Open-ended)\n      c). Age: \u201cPlease estimate the age of the person in the image (in years)\u201d (Open-ended)\n      d). Aggression: \u201cRate how aggressive the person in the image seems\u201d (0 = \"Not aggressive\", 9 = \"Highly Aggressive\")\n\nFollowing each of the four judgements, a new screen will ask participants to rate their confidence about their judgement while the image of the person remains on screen (0 = \"Not Confident At All\", 100 = \"Extremely Confident\"). However, their response to the question is not visible to participants when they rate their confidence in their response. \n \n*The half of participants who did not receive the gender question at the outset of this task are asked the gender question at this point. \n\n*For each of the questions from screens 3-25, including confidence, participants are given a maximum of 10 minutes to respond, but they are allowed to respond and advance to the next question before the timer is up (timer is hidden from participants).\n\nScreens 26-29: Participants are asked follow-up questions regarding the image they saw.\n\nMetacognitive Questions (the order of the three questions will be counterbalanced between participants):\n     a). View of face: \u201cHow good of a view did you get of the person in the image?\u201d (Likert scale between 1-7 with 1 = Very Poor, 7 = Very Good).\n     b). Self-Reported Speed: \u201cEstimate how quickly you answered the question about the person\u2019s gender (in seconds):\u201d (Open-ended)\n     c). Factors the participant took into consideration when determining gender: \u201cWhat did you look in the image to determine the gender of the person (please be specific)?\u201d (Open-ended)\n     d). If the participant was aware of how order could affect their responding: \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) about the individual in the image could have affected your judgments?\u201d (Yes/No). If yes, \u201cYou answered yes, please answer how your judgments could have been affected by the order you received the questions?\u201d (open-ended)\n\nScreens 30-31: Manipulation Checks: \u201cWhat was the colour of the sweatshirt?\u201d (open-ended) and \u201cWhat was the logo on the sweatshirt?\u201d (open-ended)\n\nScreens 32-35: Demographics. Each question will be presented on separate screens (with the exception of the two questions about gender): \n1. \u201cWhat is your age?\u201d (Open-ended) \n2. \u201cAre you currently the same gender you were assigned at birth?\u201d (Open-ended) and \u201cWhat is your gender?\u201d (Options: Male/Female/Other [Please specify])\n3. \u201cDo you suffer from colour blindness?\u201d (Yes/No). If participant answers \"YES\", then they are prompted to answer a follow-up question: \u201cPlease list the colours that you cannot see:\u201d (Open-ended) \n4. \u201cMy ethnicity is (if mixed, select more than one or specify under \"other\")\u2026\u201d (Multiple Choice) \n\nScreen 36: Debriefing form outlining the purpose of the study and researchers\u2019 contact information. The following is placed at the end of the debriefing form: \"Thank you for participating in our study! We value your participation greatly. However, if you feel uncomfortable about your participation in the study today and would like your data removed, please enter 'erase my data'\" (Text box is provided)\n"}}}, "planned-sample": {"value": {"question4b": {"extra": [], "value": "Participants will be randomly allocated into one of the following conditions:\n\nFace 1 and FC\nFace 1 and MC\nFace 2 and FC\nFace 2 and MC\n\nHalf of the participants within each condition above will also be sorted into the following DV orders:\n\nOrder 1: Gender categorization and then Demographic and aggression judgements\nOrder 2: Demographic and aggression judgements and then Gender categorization"}, "question5b": {"extra": [], "value": "Participants will be recruited through the Kwantlen Polytechnic University Psychology Research Pool System and will be granted 0.5% bonus course credit for their time. Subjects who are visually impaired (i.e., blindness or colour blindness) will be excluded from the study. The \u201cmasculine\u201d and \u201cfeminine\u201d clothing is gendered via its colour (e.g., brown for male and pink for female). Thus, participants must have full function of their colour vision or have visual aids such as glasses for proper visual perception. Participants who cannot see colours (or at all) will provide unusable data for the study.\n\nTo prevent participants from being overly vigilant in our activity of interest, the study name advertised on SONA will be \"Judgement of Pictures\".\n\nPotential participants will read: \u201cThe purpose of this research project is to explore people\u2019s judgments of others. This study requires you to USE A PC/LAPTOP! People who are visually impaired (blind or colour blind) may not participate in this study. Sorry for the inconvenience.\u201d\n\nData will be collected through the computerized database in \"Qualtrics\" using only a laptop or PC. If participants attempts to use a cellular device of any kind (e.g., Blackberry, Android, IPad, IPhone, etc.) to partake in the study, Qualtrics will automatically discontinue the study with a message reminder for them to \u201cPLEASE use a laptop or computer for this study!\u201d"}, "question6b": {"extra": [], "value": "Our target sample size is 282 participants. \n\nWe used the software program G*Power to conduct our power analysis. A priori power analysis determined that we require N = 240 to reach statistical significance for a medium-sized effect with power (1 - \u00df) set at 0.80 at the standard .05 alpha error probability. However, we will attempt to recruit an additional 15% (n = 42) of our targeted N to account for potential data loss due to manipulation check failures, incompletion, technical difficulties, etc. "}, "question7b": {"extra": [], "value": "If participants attempt to use a cellular device of any kind (e.g., Blackberry, Android, IPad, iPhone, etc.) to partake in the study, Qualtrics will automatically discontinue the study with a message reminder for them to \u201cPLEASE use a laptop or computer for this study!\u201d Participants may restart the survey on either a laptop or computer. "}, "question6b-upload": {"extra": [{"data": {"name": "GPower_Biasing Effects of Expectation on Person Perception 2020.JPG"}, "nodeId": "p2ru3", "sha256": "42191814c3c25b25e72fa8e0d63704b426842d9a2eb4a4f603240a2cd49b3408", "viewUrl": "/project/p2ru3/files/osfstorage/5e3a0be4f1369e001b8af94b", "selectedFileName": "GPower_Biasing Effects of Expectation on Person Perception 2020.JPG"}], "value": ""}}}, "exclusion-criteria": {"value": {"question8b": {"extra": [], "value": "Anticipated data exclusion criteria: \n\na). Participants who spend a disproportionate amount of time (e.g., hours) to complete the 15-minutes study.\nb). Participants who request to have their data deleted. \nc). Participants with incomplete data. \nd). Participants who indicate that they suffer from colour blindness. \ne). Participants who fail the manipulation checks - i.e., do not know the image on the sweatshirt of the individual or the colour of the individual\u2019s outfit. "}}}}}, "recommended-methods": {"value": {"procedure": {"value": {"question9b": {"extra": [], "value": "Participants will use either a laptop or a computer to participate \u2013 attempting to use any cellular devices will result in automatic termination of the survey (ballot box stuffing disabled). "}, "question9b-file": {"extra": [], "value": ""}}}}}, "recommended-analysis": {"value": {"specify": {"value": {"question6c": {"extra": [], "value": ""}, "question7c": {"extra": [], "value": "The data of participants who do not complete the study will not be used in analyses. "}, "question8c": {"extra": [], "value": ""}, "question9c": {"extra": [], "value": "Outlier ratings of continuous DVs may be replaced with the mean rating from the sample. Any manipulation of this kind will be clearly articulated in a manuscript prepared for publication."}, "question10c": {"extra": [], "value": "If assumptions of our parametrics tests are violated we will seek non-parametric options for data analysis. "}, "question11c": {"extra": [], "value": ""}}}}}, "description-hypothesis": {"value": {"question1a": {"extra": [], "value": "Gender-Ambiguous face\n\nTwo gender-ambiguous faces were counterbalanced in this research to enhance the generalizability of our findings. We do not expect any effect of this variable.\nGendered Clothing Manipulation\n\nH1 \u201cGender Judgment\u201d: We predict that pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result participants categorizing the individual in the gender category suggested by the clothing (MC or FC).\n\nH2 \u201cDemographic Judgments\u201d: We predict that a pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result in demographic judgments (height, weight) consistent with the gender category suggested by the clothing (MC or FC).\n\nH2.a: (DV: Height): Participants in the MC condition will estimate the individual to be taller than participants\u2019 estimations of the same individual in the FC condition.\n\nH2.b: (DV: Weight): Participants in the MC condition will estimate the individual to be heavier than participants\u2019 estimations of the same individual in the FC condition.\n\nH3 \u201cAggression Judgment\u201d: We predict that pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result in an aggression judgment consistent with the gender category suggested by the clothing (MC or FC). Specifically, participants in the MC condition would rate the individual to be more aggressive than participants\u2019 estimations of the same individual in the FC condition.\n\nGender Judgment Manipulation\n\nH4: \u201cDemographic and Aggression Judgments\u201d We predict a 2 Gendered-clothing (MC or FC) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) interaction on the height, weight and aggression variables.\n\nSpecifically, participants who are asked to categorize the gender of the individual first, i.e., prior to judging demographic and aggression variables, will provide responses to the demographic and aggression judgments that are more representative of their gender categorization (i.e., male is heavier, taller and more aggressive; female is shorter, lighter and less aggressive) than participants who are asked to gender categorize the individual as their last judgment, i.e., after judging demographics and character variables.\n\nH5 \u201cMetacognitive Judgments of Performance\u201d: We predict that participants will:\n\nH5.a. Be confident in their gender, demographic, and aggression judgments of the individual.\n\nH5.b. Report that they had a good view of the person in the image.\n\nH5.c. Report that they were fast in their categorization of gender regardless of their speed.\n\nH5.d. Be largely unaware that contextual variables \u2013 (i) clothing manipulation and (ii) time of gender judgment - affected their reporting. That is, first, when asked what they considered when categorizing the gender of the person in the image the majority of participants will report that the used biological features of the individual (entire face or facial features, shape and stature of the body) versus reporting contextual information found on the clothing (colour and image). Second, when asked \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) could have affected your judgments? Yes/No, we predict that the majority of participant will respond \u201cNO.\u201d\n\nPossible Exploratory\n\nEx.1 Gender categorization: We may explore if peoples gender categorizations had a relationship with the demographic, aggression and metacognitive variables in our study. This analysis is different than our gender manipulation because it will use gender categorization as the independent variable in our analysis, not gendered-clothing condition.\n\nEx.2 (DV: Age): We will explore if participants who categorize the individual as \u201cMale\u201d will estimate the age of the individual as younger than participants who categorize the individual as \u201cFemale.\u201d\n\nEx.3: We may explore if speed of responding is related to a higher amount of consistency between clothing condition and gender categorization, as well as judgments that are more congruent with the gender category.\n\nEx.4: We may explore the relationship between speed of reporting and metacognitive judgments. Ultimately testing if faster response times resulted in more validating metacognitive reports, i.e. more confident, better view, reporting that they were faster in their identification of gender.\n\nEx.5: We may also explore if the metacognitive judgments of participants who were congruent in their clothing condition/gender categorization varied from those who were incongruent."}, "question2a": {"extra": [], "value": "N/A"}, "question3a": {"extra": [], "value": "We will include two manipulation checks at the end of the study. Participants will be asked 1. \u201cWhat was the colour of the sweatshirt that the individual was wearing?\", and 2. \u201cWhat was the image on the sweatshirt?\u201d to verify that they paid attention to our visual manipulation."}}}, "recommended-hypothesis": {"value": {"question4a": {"extra": [], "value": ""}, "question5a": {"extra": [], "value": ""}, "question6a": {"extra": [], "value": ""}}}, "confirmatory-analyses-first": {"value": {"first": {"value": {"question1c": {"extra": [], "value": "We will use chi-square test for goodness of fit to analyze whether Face 1 and Face 2 performed similarly. We anticipate that they will, and the face variable will be collapsed in all subsequent analyses. \n\nPhi coefficient and the CI for \u0424 will be calculated using Cumming\u2019s Exploratory Software for Confidence Intervals (ESCI). Cohen\u2019s d and the CI of d will be calculated using Cumming\u2019s formulas, d=((M2-M1))/s and  \u2206 =  (\u03bc2- \u03bc1 )/(\u03b4\u221a(1/N1+1/N2)) respectively in ESCI. "}, "question2c": {"extra": [], "value": "See above. "}, "question3c": {"extra": [], "value": "See above. "}, "question4c": {"extra": [], "value": "N/A"}, "question5c": {"extra": [], "value": "N/A"}}}}}, "confirmatory-analyses-third": {"value": {"third": {"value": {"question1c": {"extra": [], "value": "Time of Gender Judgement \n\nH4: Multiple between-subject ANAOVAs will test the relationship between gendered outfit (FC or MC) and time of gender judgment (1st question, last question) on the variables of weight, height, age and aggression. This analysis will test if asking the gender question at the end of the demographic questions helps to mitigate the effect of gender perception on demographic reporting.  "}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}, "confirmatory-analyses-fourth": {"value": {"fourth": {"value": {"question1c": {"extra": [], "value": "Metacognitive Judgments\n\nH5. Confidence: A MANOVA will be used to compare the level of confidence between participants who make gender categorization congruent vs. incongruent to the gender category suggested by the clothing. Alternatively, we may calculate the Cronbach\u2019s alpha of the confidence questions, if internal consistency is high a composite \u201cconfidence\u201d variable will be calculated and used in a t-test analysis (IV: Congruence, DV: Confidence). \n\nH5.a. Confidence (DVs: Gender confidence, height confidence, weight confidence, age confidence, and aggression confidence). Descriptive statistics will be calculated for all the confidence measures. \n\nH5.b., H5.c. Good view and speed of reporting: Two univariate ANOVAs will test the variables of gendered-clothing and time of gender judgment on (i) reported quality of view and (ii) reported speed of reporting. \n\nH5.d. To test if participants were aware that contextual information was affecting their reporting we will code their open-ended responses using the following rubric. To ensure inter-rater reliability, a second coder will independently score 50% of the total self-report Information on the factors that influenced participants gender judgment. This analysis will demonstrate the participants were largely unaware of the effect of context and rather believe they were using features of the person to categorize their gender.  \n\nH5.e. We will calculate the descriptives of the following question: \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) could have affected your judgments?\u201d and show that most participants selected \u201cNO.\u201d We will then code the written responses of those who answered \u201cYES\u201d  to determine how they believed order affected their reporting. "}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}, "confirmatory-analyses-second": {"value": {"second": {"value": {"question1c": {"extra": [], "value": "Demographic and Character Judgements\n\nH1.a: (DV: Gender) We will use Chi-square test for goodness of fit to analyze whether our clothing manipulation influences participants\u2019 gender categorization. \n\nH2.a, H2.b, Ex.2., H3: (DVs: Height, Weight, Aggression) Factorial ANOVAs will be used to analyze participants\u2019 continuous outcome variables. \n\nEx: (DV: Age): T-tests will be used to analyze participants\u2019 estimation of Age. "}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}, "confirmatory-analyses-further": {"value": {"further": {"value": {"question1c": {"extra": [], "value": "Exploratory Analysis\n\n*We would like to mention here that we may or may not look at these aspects of the data. The following are points of interest:\n\nEx.1: Gender selection and demographic reporting. We may divide our sample into participants who selected \u201cmale\u201d and \u201cfemale.\u201d This gender-selected variable may then be used as an IV in our univariate ANOVAs in which we test if people\u2019s selections of gender affect how they report when making demographic and aggression judgments.   \n\nEx.3: If we explore if speed of responding is related to a higher amount of consistency between clothing condition and gender categorization we will use a logistic regression to do so. Pearson correlations will test if there is a relationship between speed of reporting and the demographic and aggression judgments in each of the clothing conditions (MC and FC). \n\nEx.4: If tested, Pearson correlations would be used to explore the relationship between speed of reporting and metacognitive judgments. Ultimately testing if faster response times resulted in more validating metacognitive reports, i.e. more confident, better view, reporting that they were faster in their identification of gender. \n\nEx.5: We may also explore if participants who were congruent in their clothing condition/gender categorization varied from those who were incongruent in their metacognitive reporting. An ANOVAs would be used to explore this relationship with congruency (congruent/incongruent) and time of gender judgment (1st or last) being used as our IVs and confidence, view, and speed reports as our DVs.  "}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}}, "registration_responses": {"looked": "No", "datacompletion": "No, data collection has not begun", "additionalComments": "Citations: \n\nHuart, J., Corneille, O., &amp; Becquart, E. (2005). Face-based categorization, context-based categorization, and distortions in the recollection of gender-ambiguous faces. Journal of Experimental Social Psychology, 41(6), 598-608. doi:10.1016/j.jesp.2004.10.007\n\nMapstone, L. (2015). Rihanna hides away under oversized gothic hoodie and baggy trousers for low-key arrival in Los Angeles after Paris love-in with Travis Scott [Online image]. MailOnline. Retrieved from: http://www.dailymail.co.uk/tvshowbiz/article-3262964/Rihanna-hides-away-oversized-gothic-hoodie-baggy-trousers-low-key-arrival-Los-Angeles-Paris-love-Travis-Scott.html ", "dataCollectionDates": "February 2020 - February 2023\n", "description-hypothesis.question1a": "Gender-Ambiguous face\n\nTwo gender-ambiguous faces were counterbalanced in this research to enhance the generalizability of our findings. We do not expect any effect of this variable.\nGendered Clothing Manipulation\n\nH1 \u201cGender Judgment\u201d: We predict that pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result participants categorizing the individual in the gender category suggested by the clothing (MC or FC).\n\nH2 \u201cDemographic Judgments\u201d: We predict that a pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result in demographic judgments (height, weight) consistent with the gender category suggested by the clothing (MC or FC).\n\nH2.a: (DV: Height): Participants in the MC condition will estimate the individual to be taller than participants\u2019 estimations of the same individual in the FC condition.\n\nH2.b: (DV: Weight): Participants in the MC condition will estimate the individual to be heavier than participants\u2019 estimations of the same individual in the FC condition.\n\nH3 \u201cAggression Judgment\u201d: We predict that pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result in an aggression judgment consistent with the gender category suggested by the clothing (MC or FC). Specifically, participants in the MC condition would rate the individual to be more aggressive than participants\u2019 estimations of the same individual in the FC condition.\n\nGender Judgment Manipulation\n\nH4: \u201cDemographic and Aggression Judgments\u201d We predict a 2 Gendered-clothing (MC or FC) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) interaction on the height, weight and aggression variables.\n\nSpecifically, participants who are asked to categorize the gender of the individual first, i.e., prior to judging demographic and aggression variables, will provide responses to the demographic and aggression judgments that are more representative of their gender categorization (i.e., male is heavier, taller and more aggressive; female is shorter, lighter and less aggressive) than participants who are asked to gender categorize the individual as their last judgment, i.e., after judging demographics and character variables.\n\nH5 \u201cMetacognitive Judgments of Performance\u201d: We predict that participants will:\n\nH5.a. Be confident in their gender, demographic, and aggression judgments of the individual.\n\nH5.b. Report that they had a good view of the person in the image.\n\nH5.c. Report that they were fast in their categorization of gender regardless of their speed.\n\nH5.d. Be largely unaware that contextual variables \u2013 (i) clothing manipulation and (ii) time of gender judgment - affected their reporting. That is, first, when asked what they considered when categorizing the gender of the person in the image the majority of participants will report that the used biological features of the individual (entire face or facial features, shape and stature of the body) versus reporting contextual information found on the clothing (colour and image). Second, when asked \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) could have affected your judgments? Yes/No, we predict that the majority of participant will respond \u201cNO.\u201d\n\nPossible Exploratory\n\nEx.1 Gender categorization: We may explore if peoples gender categorizations had a relationship with the demographic, aggression and metacognitive variables in our study. This analysis is different than our gender manipulation because it will use gender categorization as the independent variable in our analysis, not gendered-clothing condition.\n\nEx.2 (DV: Age): We will explore if participants who categorize the individual as \u201cMale\u201d will estimate the age of the individual as younger than participants who categorize the individual as \u201cFemale.\u201d\n\nEx.3: We may explore if speed of responding is related to a higher amount of consistency between clothing condition and gender categorization, as well as judgments that are more congruent with the gender category.\n\nEx.4: We may explore the relationship between speed of reporting and metacognitive judgments. Ultimately testing if faster response times resulted in more validating metacognitive reports, i.e. more confident, better view, reporting that they were faster in their identification of gender.\n\nEx.5: We may also explore if the metacognitive judgments of participants who were congruent in their clothing condition/gender categorization varied from those who were incongruent.", "description-hypothesis.question2a": "N/A", "description-hypothesis.question3a": "We will include two manipulation checks at the end of the study. Participants will be asked 1. \u201cWhat was the colour of the sweatshirt that the individual was wearing?\", and 2. \u201cWhat was the image on the sweatshirt?\u201d to verify that they paid attention to our visual manipulation.", "description-methods.design.question2a": "This is a 2 Gendered-clothing (male clothing [MC] or female clothing [FC]) x 2 Gender-ambiguous face (Face 1 or Face 2) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) between-subjects factorial design. This is an orthogonal study design.\n", "description-methods.design.question2b": "Dependent Variables: \n\n1. Demographic judgments of the individual in the image: categorical gender judgment (M or F), and continuous estimations of weight (open-ended), height (open-ended), and age (open-ended).\n\n2. Judgement of the social features of the individual in the image: level of aggression on a 9-point Likert scale (0 = \"Not aggressive\", 9 = \"Highly Aggressive\").\n\n3. Metacognitive judgment of the viewers experience: participant\u2019s confidence in their judgments (0 = \u201cNot Confident At All\u201d to 100 = \u201cExtremely Confident\u201d), the speed at which they made the gender judgment (open-ended), quality of the view of the individual\u2019s face (1 = \u201cVery Poor\u201d, 7 = \u201cVery Good\u201d), which factors the participant took into consideration when determining gender (open-ended), and how order of responding affected judgment (open-ended).", "description-methods.design.question3b": "We do not anticipate using any covariate. However, it is possible that we may use reported age as a covariate if we are seeking to understand our findings on the demographic measures for those in the MC and FC.   ", "recommended-analysis.specify.question6c": "", "recommended-analysis.specify.question7c": "The data of participants who do not complete the study will not be used in analyses. ", "recommended-analysis.specify.question8c": "", "recommended-analysis.specify.question9c": "Outlier ratings of continuous DVs may be replaced with the mean rating from the sample. Any manipulation of this kind will be clearly articulated in a manuscript prepared for publication.", "recommended-analysis.specify.question10c": "If assumptions of our parametrics tests are violated we will seek non-parametric options for data analysis. ", "recommended-analysis.specify.question11c": [], "recommended-methods.procedure.question9b": "Participants will use either a laptop or a computer to participate \u2013 attempting to use any cellular devices will result in automatic termination of the survey (ballot box stuffing disabled). ", "description-methods.procedure.question10b": "Manipulations and Measures\n\nThis is a 2 Gendered-clothing (male clothing [MC] or female clothing [FC]) x 2 Gender-ambiguous face (Face 1 or Face 2) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) between-subjects factorial design. \n\nDependent Variables\n\n1. Demographic judgments of the individual in the image: categorical gender judgment (M or F), and continuous estimations of weight (open-ended), height, (open-ended) and age (open-ended). \n\n2. Judgement on the social features of the individual in the image: level of aggression on a 9-point Likert scale (0 = \"Not aggressive\", 9 = \"Highly Aggressive\"). \n\n3. Metacognitive judgment of the viewers experience: (i) participant\u2019s confidence in each one of their demographic judgments (gender, weight, height, age) and aggression judgment, (ii) the estimated speed at which they made their gender judgment, (iii) quality of the view of the individual\u2019s face, (iv) which factors the participant took into consideration when determining the gender of the individual and (v) if they believe that the order that they answered the demographic questions could have affected their judgments. \n\nMaterials\n\nFace: Two gender-ambiguous faces were selected from a continuum of morphed male/female faces developed by Huart et al. (2005). Our Face 1 stimulus is a blend of 50% male and 50% female face (named \u201cMoprh 10-050\u201d in original paper; Huart et al., 2005), and our Face 2 stimulus is a blend of 70% female\u201330% male moderately ambiguous face (named \u201cMorph 7-030\u201d in original paper). \n\nClothing: We modified a single image by changing the colour and the logo on the clothing to make it either more \u201cmasculine\u201d or \u201cfeminine.\u201d The image was an anterior view of a person (the pop singer Rhianna) wearing a hooded sweatshirt and a pair of baggy pants (image retrieved from Google Image; Mapstone, 2015). The baggy clothing obscured the physique of the person. Photo editing software was used to alter the logo on the sweatshirt and the clothing colour. \n\nWe conducted a pilot study with four clothing stimuli to test their levels of perceived masculinity and femininity. Sixty undergraduate students (49 females, 11 males) participated in the study and were asked to rate on a 9-point Likert scale (1 = \u201cOnly Women\u201d; 9 = \u201cOnly Men\u201d) on whether men or women are more likely to wear the outfit presented. Descriptive results revealed two outfits were rated as relatively equal in magnitude; one on the quality of \u201cfeminine\u201d and one on the quality of \u201cmasculine\u201d while maintaining low variances. The feminine outfit selected was an entirely pink outfit with an image of a pair of red lips above the letters \u201cXOXO\u201d on the sweater (M = 2.88, SD = 1.42). The masculine outfit selected was black pants and a brown sweatshirt with an image of a woman in lingerie (M = 6.38, SD = 1.59). \n\nFinal stimuli: Photo editing software was used to incorporate each of the two faces (Face 1 and Face 2) with the masculine (i.e., black pants and a brown sweatshirt with an image of a woman in lingerie) and feminine (i.e., pink pants and a pink sweatshirt with an image of a pair of red lips above \u201cXOXO\u201d) outfits. A fringe of gender-neutral hair was added to the forehead area of each image to make the final images of the people appear more realistic. \n\nProcedure\n\nParticipants will use either a laptop or a computer to participate \u2013 attempting to use any cellular devices will result in automatic termination of the survey (ballot box stuffing disabled).\n\nScreen 1: Consent form \u2013 participants who click the \u201cyes, I would like to participate\u201d to continue and those who click \u201cNo, I do not consent to participating in this study\u201d will be brought to the end of the survey. All participants receive credit regardless of if they complete the survey.\n\nScreen 2: Participants are instructed to: \u201cPay attention to the images you are about to see, and answer the following questions about the image as quickly and honestly as possible.\u201d\n\nScreens 3-14: Participants make judgements on twelve filler task questions. These tasks require participants to make judgments on visual stimuli. For instance, how many red jelly beans are there in a jar of beans or what was the colour of horses seen in an image. The filler tasks are included to prevent participants from being overly vigilant in our activity of interest, which will be the final task.\n\nScreens 15-25: Participants make demographic and character judgments of a person who has a gender-ambiguous face (F1 or F4) is wearing clothing that has been modified to be either female (FC) or male (MC). Importantly the image of the person will remain on the screen while participants make all of the demographic judgments, their aggression judgment, as well as, their confidence judgments:\n\n*Half of participants will receive the gender question as the first judgment they make of the individual in the image; half will be asked to judge gender at the end of the person judgments:\n\nGender Judgment: \u201cPlease select the gender of this person:\u201d Screen presents a centered image of a person in either the MC or FC with one of the two gender-neutral faces (F1 or F4). There is a forced-choice option underneath for participants to select either \u201cMale\u201d or \u201cFemale\u201d.\n\nParticipants will receive one of two presentation options: Order1: male option on the left and female option on the right OR Order2: female option on the left and male option on the right.\n\nFollowing the gender judgment, a new screen asks participants to rate their confidence about their gender judgment while the image of the person remains on screen (0 = \"Not Confident At All\" to 100 = \"Extremely Confident\"). Their gender selection is not visible on the confidence screen.\n\nContinuous Demographic and Character Judgements (the order of the four questions will be randomly presented to participants): \n      a). Weight: \u201cPlease estimate the weight of the person in the image (in pounds/lbs)\u201d (Open-ended)\n      b). Height: \u201cPlease estimate the height of the person in the image (in ft and inches)\u201d (Open-ended)\n      c). Age: \u201cPlease estimate the age of the person in the image (in years)\u201d (Open-ended)\n      d). Aggression: \u201cRate how aggressive the person in the image seems\u201d (0 = \"Not aggressive\", 9 = \"Highly Aggressive\")\n\nFollowing each of the four judgements, a new screen will ask participants to rate their confidence about their judgement while the image of the person remains on screen (0 = \"Not Confident At All\", 100 = \"Extremely Confident\"). However, their response to the question is not visible to participants when they rate their confidence in their response. \n \n*The half of participants who did not receive the gender question at the outset of this task are asked the gender question at this point. \n\n*For each of the questions from screens 3-25, including confidence, participants are given a maximum of 10 minutes to respond, but they are allowed to respond and advance to the next question before the timer is up (timer is hidden from participants).\n\nScreens 26-29: Participants are asked follow-up questions regarding the image they saw.\n\nMetacognitive Questions (the order of the three questions will be counterbalanced between participants):\n     a). View of face: \u201cHow good of a view did you get of the person in the image?\u201d (Likert scale between 1-7 with 1 = Very Poor, 7 = Very Good).\n     b). Self-Reported Speed: \u201cEstimate how quickly you answered the question about the person\u2019s gender (in seconds):\u201d (Open-ended)\n     c). Factors the participant took into consideration when determining gender: \u201cWhat did you look in the image to determine the gender of the person (please be specific)?\u201d (Open-ended)\n     d). If the participant was aware of how order could affect their responding: \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) about the individual in the image could have affected your judgments?\u201d (Yes/No). If yes, \u201cYou answered yes, please answer how your judgments could have been affected by the order you received the questions?\u201d (open-ended)\n\nScreens 30-31: Manipulation Checks: \u201cWhat was the colour of the sweatshirt?\u201d (open-ended) and \u201cWhat was the logo on the sweatshirt?\u201d (open-ended)\n\nScreens 32-35: Demographics. Each question will be presented on separate screens (with the exception of the two questions about gender): \n1. \u201cWhat is your age?\u201d (Open-ended) \n2. \u201cAre you currently the same gender you were assigned at birth?\u201d (Open-ended) and \u201cWhat is your gender?\u201d (Options: Male/Female/Other [Please specify])\n3. \u201cDo you suffer from colour blindness?\u201d (Yes/No). If participant answers \"YES\", then they are prompted to answer a follow-up question: \u201cPlease list the colours that you cannot see:\u201d (Open-ended) \n4. \u201cMy ethnicity is (if mixed, select more than one or specify under \"other\")\u2026\u201d (Multiple Choice) \n\nScreen 36: Debriefing form outlining the purpose of the study and researchers\u2019 contact information. The following is placed at the end of the debriefing form: \"Thank you for participating in our study! We value your participation greatly. However, if you feel uncomfortable about your participation in the study today and would like your data removed, please enter 'erase my data'\" (Text box is provided)\n", "confirmatory-analyses-first.first.question1c": "We will use chi-square test for goodness of fit to analyze whether Face 1 and Face 2 performed similarly. We anticipate that they will, and the face variable will be collapsed in all subsequent analyses. \n\nPhi coefficient and the CI for \u0424 will be calculated using Cumming\u2019s Exploratory Software for Confidence Intervals (ESCI). Cohen\u2019s d and the CI of d will be calculated using Cumming\u2019s formulas, d=((M2-M1))/s and  \u2206 =  (\u03bc2- \u03bc1 )/(\u03b4\u221a(1/N1+1/N2)) respectively in ESCI. ", "confirmatory-analyses-first.first.question2c": "See above. ", "confirmatory-analyses-first.first.question3c": "See above. ", "confirmatory-analyses-first.first.question4c": "N/A", "confirmatory-analyses-first.first.question5c": "N/A", "confirmatory-analyses-third.third.question1c": "Time of Gender Judgement \n\nH4: Multiple between-subject ANAOVAs will test the relationship between gendered outfit (FC or MC) and time of gender judgment (1st question, last question) on the variables of weight, height, age and aggression. This analysis will test if asking the gender question at the end of the demographic questions helps to mitigate the effect of gender perception on demographic reporting.  ", "description-methods.planned-sample.question4b": "Participants will be randomly allocated into one of the following conditions:\n\nFace 1 and FC\nFace 1 and MC\nFace 2 and FC\nFace 2 and MC\n\nHalf of the participants within each condition above will also be sorted into the following DV orders:\n\nOrder 1: Gender categorization and then Demographic and aggression judgements\nOrder 2: Demographic and aggression judgements and then Gender categorization", "description-methods.planned-sample.question5b": "Participants will be recruited through the Kwantlen Polytechnic University Psychology Research Pool System and will be granted 0.5% bonus course credit for their time. Subjects who are visually impaired (i.e., blindness or colour blindness) will be excluded from the study. The \u201cmasculine\u201d and \u201cfeminine\u201d clothing is gendered via its colour (e.g., brown for male and pink for female). Thus, participants must have full function of their colour vision or have visual aids such as glasses for proper visual perception. Participants who cannot see colours (or at all) will provide unusable data for the study.\n\nTo prevent participants from being overly vigilant in our activity of interest, the study name advertised on SONA will be \"Judgement of Pictures\".\n\nPotential participants will read: \u201cThe purpose of this research project is to explore people\u2019s judgments of others. This study requires you to USE A PC/LAPTOP! People who are visually impaired (blind or colour blind) may not participate in this study. Sorry for the inconvenience.\u201d\n\nData will be collected through the computerized database in \"Qualtrics\" using only a laptop or PC. If participants attempts to use a cellular device of any kind (e.g., Blackberry, Android, IPad, IPhone, etc.) to partake in the study, Qualtrics will automatically discontinue the study with a message reminder for them to \u201cPLEASE use a laptop or computer for this study!\u201d", "description-methods.planned-sample.question6b": "Our target sample size is 282 participants. \n\nWe used the software program G*Power to conduct our power analysis. A priori power analysis determined that we require N = 240 to reach statistical significance for a medium-sized effect with power (1 - \u00df) set at 0.80 at the standard .05 alpha error probability. However, we will attempt to recruit an additional 15% (n = 42) of our targeted N to account for potential data loss due to manipulation check failures, incompletion, technical difficulties, etc. ", "description-methods.planned-sample.question7b": "If participants attempt to use a cellular device of any kind (e.g., Blackberry, Android, IPad, iPhone, etc.) to partake in the study, Qualtrics will automatically discontinue the study with a message reminder for them to \u201cPLEASE use a laptop or computer for this study!\u201d Participants may restart the survey on either a laptop or computer. ", "confirmatory-analyses-fourth.fourth.question1c": "Metacognitive Judgments\n\nH5. Confidence: A MANOVA will be used to compare the level of confidence between participants who make gender categorization congruent vs. incongruent to the gender category suggested by the clothing. Alternatively, we may calculate the Cronbach\u2019s alpha of the confidence questions, if internal consistency is high a composite \u201cconfidence\u201d variable will be calculated and used in a t-test analysis (IV: Congruence, DV: Confidence). \n\nH5.a. Confidence (DVs: Gender confidence, height confidence, weight confidence, age confidence, and aggression confidence). Descriptive statistics will be calculated for all the confidence measures. \n\nH5.b., H5.c. Good view and speed of reporting: Two univariate ANOVAs will test the variables of gendered-clothing and time of gender judgment on (i) reported quality of view and (ii) reported speed of reporting. \n\nH5.d. To test if participants were aware that contextual information was affecting their reporting we will code their open-ended responses using the following rubric. To ensure inter-rater reliability, a second coder will independently score 50% of the total self-report Information on the factors that influenced participants gender judgment. This analysis will demonstrate the participants were largely unaware of the effect of context and rather believe they were using features of the person to categorize their gender.  \n\nH5.e. We will calculate the descriptives of the following question: \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) could have affected your judgments?\u201d and show that most participants selected \u201cNO.\u201d We will then code the written responses of those who answered \u201cYES\u201d  to determine how they believed order affected their reporting. ", "confirmatory-analyses-second.second.question1c": "Demographic and Character Judgements\n\nH1.a: (DV: Gender) We will use Chi-square test for goodness of fit to analyze whether our clothing manipulation influences participants\u2019 gender categorization. \n\nH2.a, H2.b, Ex.2., H3: (DVs: Height, Weight, Aggression) Factorial ANOVAs will be used to analyze participants\u2019 continuous outcome variables. \n\nEx: (DV: Age): T-tests will be used to analyze participants\u2019 estimation of Age. ", "confirmatory-analyses-further.further.question1c": "Exploratory Analysis\n\n*We would like to mention here that we may or may not look at these aspects of the data. The following are points of interest:\n\nEx.1: Gender selection and demographic reporting. We may divide our sample into participants who selected \u201cmale\u201d and \u201cfemale.\u201d This gender-selected variable may then be used as an IV in our univariate ANOVAs in which we test if people\u2019s selections of gender affect how they report when making demographic and aggression judgments.   \n\nEx.3: If we explore if speed of responding is related to a higher amount of consistency between clothing condition and gender categorization we will use a logistic regression to do so. Pearson correlations will test if there is a relationship between speed of reporting and the demographic and aggression judgments in each of the clothing conditions (MC and FC). \n\nEx.4: If tested, Pearson correlations would be used to explore the relationship between speed of reporting and metacognitive judgments. Ultimately testing if faster response times resulted in more validating metacognitive reports, i.e. more confident, better view, reporting that they were faster in their identification of gender. \n\nEx.5: We may also explore if participants who were congruent in their clothing condition/gender categorization varied from those who were incongruent in their metacognitive reporting. An ANOVAs would be used to explore this relationship with congruency (congruent/incongruent) and time of gender judgment (1st or last) being used as our IVs and confidence, view, and speed reports as our DVs.  ", "description-methods.exclusion-criteria.question8b": "Anticipated data exclusion criteria: \n\na). Participants who spend a disproportionate amount of time (e.g., hours) to complete the 15-minutes study.\nb). Participants who request to have their data deleted. \nc). Participants with incomplete data. \nd). Participants who indicate that they suffer from colour blindness. \ne). Participants who fail the manipulation checks - i.e., do not know the image on the sweatshirt of the individual or the colour of the individual\u2019s outfit. ", "description-methods.planned-sample.question6b-upload": [{"file_id": "5e3a0be4f1369e001b8af94b", "file_name": "GPower_Biasing Effects of Expectation on Person Perception 2020.JPG", "file_urls": {"html": "https://osf.io/p2ru3/files/osfstorage/5e3a0be4f1369e001b8af94b", "download": "https://osf.io/download/ckjp8/"}, "file_hashes": {"sha256": "42191814c3c25b25e72fa8e0d63704b426842d9a2eb4a4f603240a2cd49b3408"}}]}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m9puw/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m9puw/comments/?format=json&filter%5Btarget%5D=m9puw", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m9puw/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m9puw/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m9puw/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m9puw/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m9puw/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m9puw/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m9puw/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m9puw/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m9puw/linked_by_registrations/?format=json", "meta": {}}}}, "parent": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/?format=json", "meta": {}}}, "data": {"id": "j927s", "type": "registrations"}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m9puw/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m9puw/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/m9puw/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/ca-1/?format=json", "meta": {}}}, "data": {"id": "ca-1", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/?format=json", "meta": {}}}, "data": {"id": "j927s", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m9puw/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m9puw/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/m9puw/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m9puw/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/m9puw/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m9puw/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/m9puw/citation/?format=json", "meta": {}}}, "data": {"id": "m9puw", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/85n6s/?format=json", "meta": {}}}, "data": {"id": "85n6s", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/d9nxz/?format=json", "meta": {}}}, "data": {"id": "d9nxz", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5730e99a9ad5a102c5745a8a/?format=json", "meta": {}}}, "data": {"id": "5730e99a9ad5a102c5745a8a", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/m9puw/", "self": "https://api.osf.io/v2/registrations/m9puw/"}}, {"id": "mb6ut", "type": "registrations", "attributes": {"title": "Hypothesis", "description": "", "category": "hypothesis", "custom_citation": "", "date_created": "2020-02-11T16:27:31.588230", "date_modified": "2020-02-09T18:41:07.271491", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "5a6aee7a599145140383f7d0c719feed306a8c1d34d36562e4df9950fe628c2b4f38411bc9277daaaf479a6b6d8d84b0ef9992a33ee88f0161d5f52c1347992fe3e9aeb3f99257408328ef08302be058463e9a190b73485b7811f3a02da070d0021ff83d1720b5d3698aa2b39c323210d2fc0acd6a1f186548ae7fb273494027593721b6d3c2b29034a709b4abfd1715", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-02-11T16:27:31.563877", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Pre-Registration in Social Psychology (van 't Veer & Giner-Sorolla, 2016): Pre-Registration", "registered_meta": {"looked": {"extra": [], "value": "No"}, "datacompletion": {"extra": [], "value": "No, data collection has not begun"}, "additionalComments": {"extra": [], "value": "Citations: \n\nHuart, J., Corneille, O., &amp; Becquart, E. (2005). Face-based categorization, context-based categorization, and distortions in the recollection of gender-ambiguous faces. Journal of Experimental Social Psychology, 41(6), 598-608. doi:10.1016/j.jesp.2004.10.007\n\nMapstone, L. (2015). Rihanna hides away under oversized gothic hoodie and baggy trousers for low-key arrival in Los Angeles after Paris love-in with Travis Scott [Online image]. MailOnline. Retrieved from: http://www.dailymail.co.uk/tvshowbiz/article-3262964/Rihanna-hides-away-oversized-gothic-hoodie-baggy-trousers-low-key-arrival-Los-Angeles-Paris-love-Travis-Scott.html "}, "dataCollectionDates": {"extra": [], "value": "February 2020 - February 2023\n"}, "description-methods": {"value": {"design": {"value": {"question2a": {"extra": [], "value": "This is a 2 Gendered-clothing (male clothing [MC] or female clothing [FC]) x 2 Gender-ambiguous face (Face 1 or Face 2) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) between-subjects factorial design. This is an orthogonal study design.\n"}, "question2b": {"extra": [], "value": "Dependent Variables: \n\n1. Demographic judgments of the individual in the image: categorical gender judgment (M or F), and continuous estimations of weight (open-ended), height (open-ended), and age (open-ended).\n\n2. Judgement of the social features of the individual in the image: level of aggression on a 9-point Likert scale (0 = \"Not aggressive\", 9 = \"Highly Aggressive\").\n\n3. Metacognitive judgment of the viewers experience: participant\u2019s confidence in their judgments (0 = \u201cNot Confident At All\u201d to 100 = \u201cExtremely Confident\u201d), the speed at which they made the gender judgment (open-ended), quality of the view of the individual\u2019s face (1 = \u201cVery Poor\u201d, 7 = \u201cVery Good\u201d), which factors the participant took into consideration when determining gender (open-ended), and how order of responding affected judgment (open-ended)."}, "question3b": {"extra": [], "value": "We do not anticipate using any covariate. However, it is possible that we may use reported age as a covariate if we are seeking to understand our findings on the demographic measures for those in the MC and FC.   "}}}, "procedure": {"value": {"question10b": {"extra": [], "value": "Manipulations and Measures\n\nThis is a 2 Gendered-clothing (male clothing [MC] or female clothing [FC]) x 2 Gender-ambiguous face (Face 1 or Face 2) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) between-subjects factorial design. \n\nDependent Variables\n\n1. Demographic judgments of the individual in the image: categorical gender judgment (M or F), and continuous estimations of weight (open-ended), height, (open-ended) and age (open-ended). \n\n2. Judgement on the social features of the individual in the image: level of aggression on a 9-point Likert scale (0 = \"Not aggressive\", 9 = \"Highly Aggressive\"). \n\n3. Metacognitive judgment of the viewers experience: (i) participant\u2019s confidence in each one of their demographic judgments (gender, weight, height, age) and aggression judgment, (ii) the estimated speed at which they made their gender judgment, (iii) quality of the view of the individual\u2019s face, (iv) which factors the participant took into consideration when determining the gender of the individual and (v) if they believe that the order that they answered the demographic questions could have affected their judgments. \n\nMaterials\n\nFace: Two gender-ambiguous faces were selected from a continuum of morphed male/female faces developed by Huart et al. (2005). Our Face 1 stimulus is a blend of 50% male and 50% female face (named \u201cMoprh 10-050\u201d in original paper; Huart et al., 2005), and our Face 2 stimulus is a blend of 70% female\u201330% male moderately ambiguous face (named \u201cMorph 7-030\u201d in original paper). \n\nClothing: We modified a single image by changing the colour and the logo on the clothing to make it either more \u201cmasculine\u201d or \u201cfeminine.\u201d The image was an anterior view of a person (the pop singer Rhianna) wearing a hooded sweatshirt and a pair of baggy pants (image retrieved from Google Image; Mapstone, 2015). The baggy clothing obscured the physique of the person. Photo editing software was used to alter the logo on the sweatshirt and the clothing colour. \n\nWe conducted a pilot study with four clothing stimuli to test their levels of perceived masculinity and femininity. Sixty undergraduate students (49 females, 11 males) participated in the study and were asked to rate on a 9-point Likert scale (1 = \u201cOnly Women\u201d; 9 = \u201cOnly Men\u201d) on whether men or women are more likely to wear the outfit presented. Descriptive results revealed two outfits were rated as relatively equal in magnitude; one on the quality of \u201cfeminine\u201d and one on the quality of \u201cmasculine\u201d while maintaining low variances. The feminine outfit selected was an entirely pink outfit with an image of a pair of red lips above the letters \u201cXOXO\u201d on the sweater (M = 2.88, SD = 1.42). The masculine outfit selected was black pants and a brown sweatshirt with an image of a woman in lingerie (M = 6.38, SD = 1.59). \n\nFinal stimuli: Photo editing software was used to incorporate each of the two faces (Face 1 and Face 2) with the masculine (i.e., black pants and a brown sweatshirt with an image of a woman in lingerie) and feminine (i.e., pink pants and a pink sweatshirt with an image of a pair of red lips above \u201cXOXO\u201d) outfits. A fringe of gender-neutral hair was added to the forehead area of each image to make the final images of the people appear more realistic. \n\nProcedure\n\nParticipants will use either a laptop or a computer to participate \u2013 attempting to use any cellular devices will result in automatic termination of the survey (ballot box stuffing disabled).\n\nScreen 1: Consent form \u2013 participants who click the \u201cyes, I would like to participate\u201d to continue and those who click \u201cNo, I do not consent to participating in this study\u201d will be brought to the end of the survey. All participants receive credit regardless of if they complete the survey.\n\nScreen 2: Participants are instructed to: \u201cPay attention to the images you are about to see, and answer the following questions about the image as quickly and honestly as possible.\u201d\n\nScreens 3-14: Participants make judgements on twelve filler task questions. These tasks require participants to make judgments on visual stimuli. For instance, how many red jelly beans are there in a jar of beans or what was the colour of horses seen in an image. The filler tasks are included to prevent participants from being overly vigilant in our activity of interest, which will be the final task.\n\nScreens 15-25: Participants make demographic and character judgments of a person who has a gender-ambiguous face (F1 or F4) is wearing clothing that has been modified to be either female (FC) or male (MC). Importantly the image of the person will remain on the screen while participants make all of the demographic judgments, their aggression judgment, as well as, their confidence judgments:\n\n*Half of participants will receive the gender question as the first judgment they make of the individual in the image; half will be asked to judge gender at the end of the person judgments:\n\nGender Judgment: \u201cPlease select the gender of this person:\u201d Screen presents a centered image of a person in either the MC or FC with one of the two gender-neutral faces (F1 or F4). There is a forced-choice option underneath for participants to select either \u201cMale\u201d or \u201cFemale\u201d.\n\nParticipants will receive one of two presentation options: Order1: male option on the left and female option on the right OR Order2: female option on the left and male option on the right.\n\nFollowing the gender judgment, a new screen asks participants to rate their confidence about their gender judgment while the image of the person remains on screen (0 = \"Not Confident At All\" to 100 = \"Extremely Confident\"). Their gender selection is not visible on the confidence screen.\n\nContinuous Demographic and Character Judgements (the order of the four questions will be randomly presented to participants): \n      a). Weight: \u201cPlease estimate the weight of the person in the image (in pounds/lbs)\u201d (Open-ended)\n      b). Height: \u201cPlease estimate the height of the person in the image (in ft and inches)\u201d (Open-ended)\n      c). Age: \u201cPlease estimate the age of the person in the image (in years)\u201d (Open-ended)\n      d). Aggression: \u201cRate how aggressive the person in the image seems\u201d (0 = \"Not aggressive\", 9 = \"Highly Aggressive\")\n\nFollowing each of the four judgements, a new screen will ask participants to rate their confidence about their judgement while the image of the person remains on screen (0 = \"Not Confident At All\", 100 = \"Extremely Confident\"). However, their response to the question is not visible to participants when they rate their confidence in their response. \n \n*The half of participants who did not receive the gender question at the outset of this task are asked the gender question at this point. \n\n*For each of the questions from screens 3-25, including confidence, participants are given a maximum of 10 minutes to respond, but they are allowed to respond and advance to the next question before the timer is up (timer is hidden from participants).\n\nScreens 26-29: Participants are asked follow-up questions regarding the image they saw.\n\nMetacognitive Questions (the order of the three questions will be counterbalanced between participants):\n     a). View of face: \u201cHow good of a view did you get of the person in the image?\u201d (Likert scale between 1-7 with 1 = Very Poor, 7 = Very Good).\n     b). Self-Reported Speed: \u201cEstimate how quickly you answered the question about the person\u2019s gender (in seconds):\u201d (Open-ended)\n     c). Factors the participant took into consideration when determining gender: \u201cWhat did you look in the image to determine the gender of the person (please be specific)?\u201d (Open-ended)\n     d). If the participant was aware of how order could affect their responding: \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) about the individual in the image could have affected your judgments?\u201d (Yes/No). If yes, \u201cYou answered yes, please answer how your judgments could have been affected by the order you received the questions?\u201d (open-ended)\n\nScreens 30-31: Manipulation Checks: \u201cWhat was the colour of the sweatshirt?\u201d (open-ended) and \u201cWhat was the logo on the sweatshirt?\u201d (open-ended)\n\nScreens 32-35: Demographics. Each question will be presented on separate screens (with the exception of the two questions about gender): \n1. \u201cWhat is your age?\u201d (Open-ended) \n2. \u201cAre you currently the same gender you were assigned at birth?\u201d (Open-ended) and \u201cWhat is your gender?\u201d (Options: Male/Female/Other [Please specify])\n3. \u201cDo you suffer from colour blindness?\u201d (Yes/No). If participant answers \"YES\", then they are prompted to answer a follow-up question: \u201cPlease list the colours that you cannot see:\u201d (Open-ended) \n4. \u201cMy ethnicity is (if mixed, select more than one or specify under \"other\")\u2026\u201d (Multiple Choice) \n\nScreen 36: Debriefing form outlining the purpose of the study and researchers\u2019 contact information. The following is placed at the end of the debriefing form: \"Thank you for participating in our study! We value your participation greatly. However, if you feel uncomfortable about your participation in the study today and would like your data removed, please enter 'erase my data'\" (Text box is provided)\n"}}}, "planned-sample": {"value": {"question4b": {"extra": [], "value": "Participants will be randomly allocated into one of the following conditions:\n\nFace 1 and FC\nFace 1 and MC\nFace 2 and FC\nFace 2 and MC\n\nHalf of the participants within each condition above will also be sorted into the following DV orders:\n\nOrder 1: Gender categorization and then Demographic and aggression judgements\nOrder 2: Demographic and aggression judgements and then Gender categorization"}, "question5b": {"extra": [], "value": "Participants will be recruited through the Kwantlen Polytechnic University Psychology Research Pool System and will be granted 0.5% bonus course credit for their time. Subjects who are visually impaired (i.e., blindness or colour blindness) will be excluded from the study. The \u201cmasculine\u201d and \u201cfeminine\u201d clothing is gendered via its colour (e.g., brown for male and pink for female). Thus, participants must have full function of their colour vision or have visual aids such as glasses for proper visual perception. Participants who cannot see colours (or at all) will provide unusable data for the study.\n\nTo prevent participants from being overly vigilant in our activity of interest, the study name advertised on SONA will be \"Judgement of Pictures\".\n\nPotential participants will read: \u201cThe purpose of this research project is to explore people\u2019s judgments of others. This study requires you to USE A PC/LAPTOP! People who are visually impaired (blind or colour blind) may not participate in this study. Sorry for the inconvenience.\u201d\n\nData will be collected through the computerized database in \"Qualtrics\" using only a laptop or PC. If participants attempts to use a cellular device of any kind (e.g., Blackberry, Android, IPad, IPhone, etc.) to partake in the study, Qualtrics will automatically discontinue the study with a message reminder for them to \u201cPLEASE use a laptop or computer for this study!\u201d"}, "question6b": {"extra": [], "value": "Our target sample size is 282 participants. \n\nWe used the software program G*Power to conduct our power analysis. A priori power analysis determined that we require N = 240 to reach statistical significance for a medium-sized effect with power (1 - \u00df) set at 0.80 at the standard .05 alpha error probability. However, we will attempt to recruit an additional 15% (n = 42) of our targeted N to account for potential data loss due to manipulation check failures, incompletion, technical difficulties, etc. "}, "question7b": {"extra": [], "value": "If participants attempt to use a cellular device of any kind (e.g., Blackberry, Android, IPad, iPhone, etc.) to partake in the study, Qualtrics will automatically discontinue the study with a message reminder for them to \u201cPLEASE use a laptop or computer for this study!\u201d Participants may restart the survey on either a laptop or computer. "}, "question6b-upload": {"extra": [{"data": {"name": "GPower_Biasing Effects of Expectation on Person Perception 2020.JPG"}, "nodeId": "p2ru3", "sha256": "42191814c3c25b25e72fa8e0d63704b426842d9a2eb4a4f603240a2cd49b3408", "viewUrl": "/project/p2ru3/files/osfstorage/5e3a0be4f1369e001b8af94b", "selectedFileName": "GPower_Biasing Effects of Expectation on Person Perception 2020.JPG"}], "value": ""}}}, "exclusion-criteria": {"value": {"question8b": {"extra": [], "value": "Anticipated data exclusion criteria: \n\na). Participants who spend a disproportionate amount of time (e.g., hours) to complete the 15-minutes study.\nb). Participants who request to have their data deleted. \nc). Participants with incomplete data. \nd). Participants who indicate that they suffer from colour blindness. \ne). Participants who fail the manipulation checks - i.e., do not know the image on the sweatshirt of the individual or the colour of the individual\u2019s outfit. "}}}}}, "recommended-methods": {"value": {"procedure": {"value": {"question9b": {"extra": [], "value": "Participants will use either a laptop or a computer to participate \u2013 attempting to use any cellular devices will result in automatic termination of the survey (ballot box stuffing disabled). "}, "question9b-file": {"extra": [], "value": ""}}}}}, "recommended-analysis": {"value": {"specify": {"value": {"question6c": {"extra": [], "value": ""}, "question7c": {"extra": [], "value": "The data of participants who do not complete the study will not be used in analyses. "}, "question8c": {"extra": [], "value": ""}, "question9c": {"extra": [], "value": "Outlier ratings of continuous DVs may be replaced with the mean rating from the sample. Any manipulation of this kind will be clearly articulated in a manuscript prepared for publication."}, "question10c": {"extra": [], "value": "If assumptions of our parametrics tests are violated we will seek non-parametric options for data analysis. "}, "question11c": {"extra": [], "value": ""}}}}}, "description-hypothesis": {"value": {"question1a": {"extra": [], "value": "Gender-Ambiguous face\n\nTwo gender-ambiguous faces were counterbalanced in this research to enhance the generalizability of our findings. We do not expect any effect of this variable.\nGendered Clothing Manipulation\n\nH1 \u201cGender Judgment\u201d: We predict that pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result participants categorizing the individual in the gender category suggested by the clothing (MC or FC).\n\nH2 \u201cDemographic Judgments\u201d: We predict that a pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result in demographic judgments (height, weight) consistent with the gender category suggested by the clothing (MC or FC).\n\nH2.a: (DV: Height): Participants in the MC condition will estimate the individual to be taller than participants\u2019 estimations of the same individual in the FC condition.\n\nH2.b: (DV: Weight): Participants in the MC condition will estimate the individual to be heavier than participants\u2019 estimations of the same individual in the FC condition.\n\nH3 \u201cAggression Judgment\u201d: We predict that pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result in an aggression judgment consistent with the gender category suggested by the clothing (MC or FC). Specifically, participants in the MC condition would rate the individual to be more aggressive than participants\u2019 estimations of the same individual in the FC condition.\n\nGender Judgment Manipulation\n\nH4: \u201cDemographic and Aggression Judgments\u201d We predict a 2 Gendered-clothing (MC or FC) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) interaction on the height, weight and aggression variables.\n\nSpecifically, participants who are asked to categorize the gender of the individual first, i.e., prior to judging demographic and aggression variables, will provide responses to the demographic and aggression judgments that are more representative of their gender categorization (i.e., male is heavier, taller and more aggressive; female is shorter, lighter and less aggressive) than participants who are asked to gender categorize the individual as their last judgment, i.e., after judging demographics and character variables.\n\nH5 \u201cMetacognitive Judgments of Performance\u201d: We predict that participants will:\n\nH5.a. Be confident in their gender, demographic, and aggression judgments of the individual.\n\nH5.b. Report that they had a good view of the person in the image.\n\nH5.c. Report that they were fast in their categorization of gender regardless of their speed.\n\nH5.d. Be largely unaware that contextual variables \u2013 (i) clothing manipulation and (ii) time of gender judgment - affected their reporting. That is, first, when asked what they considered when categorizing the gender of the person in the image the majority of participants will report that the used biological features of the individual (entire face or facial features, shape and stature of the body) versus reporting contextual information found on the clothing (colour and image). Second, when asked \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) could have affected your judgments? Yes/No, we predict that the majority of participant will respond \u201cNO.\u201d\n\nPossible Exploratory\n\nEx.1 Gender categorization: We may explore if peoples gender categorizations had a relationship with the demographic, aggression and metacognitive variables in our study. This analysis is different than our gender manipulation because it will use gender categorization as the independent variable in our analysis, not gendered-clothing condition.\n\nEx.2 (DV: Age): We will explore if participants who categorize the individual as \u201cMale\u201d will estimate the age of the individual as younger than participants who categorize the individual as \u201cFemale.\u201d\n\nEx.3: We may explore if speed of responding is related to a higher amount of consistency between clothing condition and gender categorization, as well as judgments that are more congruent with the gender category.\n\nEx.4: We may explore the relationship between speed of reporting and metacognitive judgments. Ultimately testing if faster response times resulted in more validating metacognitive reports, i.e. more confident, better view, reporting that they were faster in their identification of gender.\n\nEx.5: We may also explore if the metacognitive judgments of participants who were congruent in their clothing condition/gender categorization varied from those who were incongruent."}, "question2a": {"extra": [], "value": "N/A"}, "question3a": {"extra": [], "value": "We will include two manipulation checks at the end of the study. Participants will be asked 1. \u201cWhat was the colour of the sweatshirt that the individual was wearing?\", and 2. \u201cWhat was the image on the sweatshirt?\u201d to verify that they paid attention to our visual manipulation."}}}, "recommended-hypothesis": {"value": {"question4a": {"extra": [], "value": ""}, "question5a": {"extra": [], "value": ""}, "question6a": {"extra": [], "value": ""}}}, "confirmatory-analyses-first": {"value": {"first": {"value": {"question1c": {"extra": [], "value": "We will use chi-square test for goodness of fit to analyze whether Face 1 and Face 2 performed similarly. We anticipate that they will, and the face variable will be collapsed in all subsequent analyses. \n\nPhi coefficient and the CI for \u0424 will be calculated using Cumming\u2019s Exploratory Software for Confidence Intervals (ESCI). Cohen\u2019s d and the CI of d will be calculated using Cumming\u2019s formulas, d=((M2-M1))/s and  \u2206 =  (\u03bc2- \u03bc1 )/(\u03b4\u221a(1/N1+1/N2)) respectively in ESCI. "}, "question2c": {"extra": [], "value": "See above. "}, "question3c": {"extra": [], "value": "See above. "}, "question4c": {"extra": [], "value": "N/A"}, "question5c": {"extra": [], "value": "N/A"}}}}}, "confirmatory-analyses-third": {"value": {"third": {"value": {"question1c": {"extra": [], "value": "Time of Gender Judgement \n\nH4: Multiple between-subject ANAOVAs will test the relationship between gendered outfit (FC or MC) and time of gender judgment (1st question, last question) on the variables of weight, height, age and aggression. This analysis will test if asking the gender question at the end of the demographic questions helps to mitigate the effect of gender perception on demographic reporting.  "}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}, "confirmatory-analyses-fourth": {"value": {"fourth": {"value": {"question1c": {"extra": [], "value": "Metacognitive Judgments\n\nH5. Confidence: A MANOVA will be used to compare the level of confidence between participants who make gender categorization congruent vs. incongruent to the gender category suggested by the clothing. Alternatively, we may calculate the Cronbach\u2019s alpha of the confidence questions, if internal consistency is high a composite \u201cconfidence\u201d variable will be calculated and used in a t-test analysis (IV: Congruence, DV: Confidence). \n\nH5.a. Confidence (DVs: Gender confidence, height confidence, weight confidence, age confidence, and aggression confidence). Descriptive statistics will be calculated for all the confidence measures. \n\nH5.b., H5.c. Good view and speed of reporting: Two univariate ANOVAs will test the variables of gendered-clothing and time of gender judgment on (i) reported quality of view and (ii) reported speed of reporting. \n\nH5.d. To test if participants were aware that contextual information was affecting their reporting we will code their open-ended responses using the following rubric. To ensure inter-rater reliability, a second coder will independently score 50% of the total self-report Information on the factors that influenced participants gender judgment. This analysis will demonstrate the participants were largely unaware of the effect of context and rather believe they were using features of the person to categorize their gender.  \n\nH5.e. We will calculate the descriptives of the following question: \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) could have affected your judgments?\u201d and show that most participants selected \u201cNO.\u201d We will then code the written responses of those who answered \u201cYES\u201d  to determine how they believed order affected their reporting. "}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}, "confirmatory-analyses-second": {"value": {"second": {"value": {"question1c": {"extra": [], "value": "Demographic and Character Judgements\n\nH1.a: (DV: Gender) We will use Chi-square test for goodness of fit to analyze whether our clothing manipulation influences participants\u2019 gender categorization. \n\nH2.a, H2.b, Ex.2., H3: (DVs: Height, Weight, Aggression) Factorial ANOVAs will be used to analyze participants\u2019 continuous outcome variables. \n\nEx: (DV: Age): T-tests will be used to analyze participants\u2019 estimation of Age. "}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}, "confirmatory-analyses-further": {"value": {"further": {"value": {"question1c": {"extra": [], "value": "Exploratory Analysis\n\n*We would like to mention here that we may or may not look at these aspects of the data. The following are points of interest:\n\nEx.1: Gender selection and demographic reporting. We may divide our sample into participants who selected \u201cmale\u201d and \u201cfemale.\u201d This gender-selected variable may then be used as an IV in our univariate ANOVAs in which we test if people\u2019s selections of gender affect how they report when making demographic and aggression judgments.   \n\nEx.3: If we explore if speed of responding is related to a higher amount of consistency between clothing condition and gender categorization we will use a logistic regression to do so. Pearson correlations will test if there is a relationship between speed of reporting and the demographic and aggression judgments in each of the clothing conditions (MC and FC). \n\nEx.4: If tested, Pearson correlations would be used to explore the relationship between speed of reporting and metacognitive judgments. Ultimately testing if faster response times resulted in more validating metacognitive reports, i.e. more confident, better view, reporting that they were faster in their identification of gender. \n\nEx.5: We may also explore if participants who were congruent in their clothing condition/gender categorization varied from those who were incongruent in their metacognitive reporting. An ANOVAs would be used to explore this relationship with congruency (congruent/incongruent) and time of gender judgment (1st or last) being used as our IVs and confidence, view, and speed reports as our DVs.  "}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}}, "registration_responses": {"looked": "No", "datacompletion": "No, data collection has not begun", "additionalComments": "Citations: \n\nHuart, J., Corneille, O., &amp; Becquart, E. (2005). Face-based categorization, context-based categorization, and distortions in the recollection of gender-ambiguous faces. Journal of Experimental Social Psychology, 41(6), 598-608. doi:10.1016/j.jesp.2004.10.007\n\nMapstone, L. (2015). Rihanna hides away under oversized gothic hoodie and baggy trousers for low-key arrival in Los Angeles after Paris love-in with Travis Scott [Online image]. MailOnline. Retrieved from: http://www.dailymail.co.uk/tvshowbiz/article-3262964/Rihanna-hides-away-oversized-gothic-hoodie-baggy-trousers-low-key-arrival-Los-Angeles-Paris-love-Travis-Scott.html ", "dataCollectionDates": "February 2020 - February 2023\n", "description-hypothesis.question1a": "Gender-Ambiguous face\n\nTwo gender-ambiguous faces were counterbalanced in this research to enhance the generalizability of our findings. We do not expect any effect of this variable.\nGendered Clothing Manipulation\n\nH1 \u201cGender Judgment\u201d: We predict that pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result participants categorizing the individual in the gender category suggested by the clothing (MC or FC).\n\nH2 \u201cDemographic Judgments\u201d: We predict that a pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result in demographic judgments (height, weight) consistent with the gender category suggested by the clothing (MC or FC).\n\nH2.a: (DV: Height): Participants in the MC condition will estimate the individual to be taller than participants\u2019 estimations of the same individual in the FC condition.\n\nH2.b: (DV: Weight): Participants in the MC condition will estimate the individual to be heavier than participants\u2019 estimations of the same individual in the FC condition.\n\nH3 \u201cAggression Judgment\u201d: We predict that pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result in an aggression judgment consistent with the gender category suggested by the clothing (MC or FC). Specifically, participants in the MC condition would rate the individual to be more aggressive than participants\u2019 estimations of the same individual in the FC condition.\n\nGender Judgment Manipulation\n\nH4: \u201cDemographic and Aggression Judgments\u201d We predict a 2 Gendered-clothing (MC or FC) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) interaction on the height, weight and aggression variables.\n\nSpecifically, participants who are asked to categorize the gender of the individual first, i.e., prior to judging demographic and aggression variables, will provide responses to the demographic and aggression judgments that are more representative of their gender categorization (i.e., male is heavier, taller and more aggressive; female is shorter, lighter and less aggressive) than participants who are asked to gender categorize the individual as their last judgment, i.e., after judging demographics and character variables.\n\nH5 \u201cMetacognitive Judgments of Performance\u201d: We predict that participants will:\n\nH5.a. Be confident in their gender, demographic, and aggression judgments of the individual.\n\nH5.b. Report that they had a good view of the person in the image.\n\nH5.c. Report that they were fast in their categorization of gender regardless of their speed.\n\nH5.d. Be largely unaware that contextual variables \u2013 (i) clothing manipulation and (ii) time of gender judgment - affected their reporting. That is, first, when asked what they considered when categorizing the gender of the person in the image the majority of participants will report that the used biological features of the individual (entire face or facial features, shape and stature of the body) versus reporting contextual information found on the clothing (colour and image). Second, when asked \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) could have affected your judgments? Yes/No, we predict that the majority of participant will respond \u201cNO.\u201d\n\nPossible Exploratory\n\nEx.1 Gender categorization: We may explore if peoples gender categorizations had a relationship with the demographic, aggression and metacognitive variables in our study. This analysis is different than our gender manipulation because it will use gender categorization as the independent variable in our analysis, not gendered-clothing condition.\n\nEx.2 (DV: Age): We will explore if participants who categorize the individual as \u201cMale\u201d will estimate the age of the individual as younger than participants who categorize the individual as \u201cFemale.\u201d\n\nEx.3: We may explore if speed of responding is related to a higher amount of consistency between clothing condition and gender categorization, as well as judgments that are more congruent with the gender category.\n\nEx.4: We may explore the relationship between speed of reporting and metacognitive judgments. Ultimately testing if faster response times resulted in more validating metacognitive reports, i.e. more confident, better view, reporting that they were faster in their identification of gender.\n\nEx.5: We may also explore if the metacognitive judgments of participants who were congruent in their clothing condition/gender categorization varied from those who were incongruent.", "description-hypothesis.question2a": "N/A", "description-hypothesis.question3a": "We will include two manipulation checks at the end of the study. Participants will be asked 1. \u201cWhat was the colour of the sweatshirt that the individual was wearing?\", and 2. \u201cWhat was the image on the sweatshirt?\u201d to verify that they paid attention to our visual manipulation.", "description-methods.design.question2a": "This is a 2 Gendered-clothing (male clothing [MC] or female clothing [FC]) x 2 Gender-ambiguous face (Face 1 or Face 2) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) between-subjects factorial design. This is an orthogonal study design.\n", "description-methods.design.question2b": "Dependent Variables: \n\n1. Demographic judgments of the individual in the image: categorical gender judgment (M or F), and continuous estimations of weight (open-ended), height (open-ended), and age (open-ended).\n\n2. Judgement of the social features of the individual in the image: level of aggression on a 9-point Likert scale (0 = \"Not aggressive\", 9 = \"Highly Aggressive\").\n\n3. Metacognitive judgment of the viewers experience: participant\u2019s confidence in their judgments (0 = \u201cNot Confident At All\u201d to 100 = \u201cExtremely Confident\u201d), the speed at which they made the gender judgment (open-ended), quality of the view of the individual\u2019s face (1 = \u201cVery Poor\u201d, 7 = \u201cVery Good\u201d), which factors the participant took into consideration when determining gender (open-ended), and how order of responding affected judgment (open-ended).", "description-methods.design.question3b": "We do not anticipate using any covariate. However, it is possible that we may use reported age as a covariate if we are seeking to understand our findings on the demographic measures for those in the MC and FC.   ", "recommended-analysis.specify.question6c": "", "recommended-analysis.specify.question7c": "The data of participants who do not complete the study will not be used in analyses. ", "recommended-analysis.specify.question8c": "", "recommended-analysis.specify.question9c": "Outlier ratings of continuous DVs may be replaced with the mean rating from the sample. Any manipulation of this kind will be clearly articulated in a manuscript prepared for publication.", "recommended-analysis.specify.question10c": "If assumptions of our parametrics tests are violated we will seek non-parametric options for data analysis. ", "recommended-analysis.specify.question11c": [], "recommended-methods.procedure.question9b": "Participants will use either a laptop or a computer to participate \u2013 attempting to use any cellular devices will result in automatic termination of the survey (ballot box stuffing disabled). ", "description-methods.procedure.question10b": "Manipulations and Measures\n\nThis is a 2 Gendered-clothing (male clothing [MC] or female clothing [FC]) x 2 Gender-ambiguous face (Face 1 or Face 2) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) between-subjects factorial design. \n\nDependent Variables\n\n1. Demographic judgments of the individual in the image: categorical gender judgment (M or F), and continuous estimations of weight (open-ended), height, (open-ended) and age (open-ended). \n\n2. Judgement on the social features of the individual in the image: level of aggression on a 9-point Likert scale (0 = \"Not aggressive\", 9 = \"Highly Aggressive\"). \n\n3. Metacognitive judgment of the viewers experience: (i) participant\u2019s confidence in each one of their demographic judgments (gender, weight, height, age) and aggression judgment, (ii) the estimated speed at which they made their gender judgment, (iii) quality of the view of the individual\u2019s face, (iv) which factors the participant took into consideration when determining the gender of the individual and (v) if they believe that the order that they answered the demographic questions could have affected their judgments. \n\nMaterials\n\nFace: Two gender-ambiguous faces were selected from a continuum of morphed male/female faces developed by Huart et al. (2005). Our Face 1 stimulus is a blend of 50% male and 50% female face (named \u201cMoprh 10-050\u201d in original paper; Huart et al., 2005), and our Face 2 stimulus is a blend of 70% female\u201330% male moderately ambiguous face (named \u201cMorph 7-030\u201d in original paper). \n\nClothing: We modified a single image by changing the colour and the logo on the clothing to make it either more \u201cmasculine\u201d or \u201cfeminine.\u201d The image was an anterior view of a person (the pop singer Rhianna) wearing a hooded sweatshirt and a pair of baggy pants (image retrieved from Google Image; Mapstone, 2015). The baggy clothing obscured the physique of the person. Photo editing software was used to alter the logo on the sweatshirt and the clothing colour. \n\nWe conducted a pilot study with four clothing stimuli to test their levels of perceived masculinity and femininity. Sixty undergraduate students (49 females, 11 males) participated in the study and were asked to rate on a 9-point Likert scale (1 = \u201cOnly Women\u201d; 9 = \u201cOnly Men\u201d) on whether men or women are more likely to wear the outfit presented. Descriptive results revealed two outfits were rated as relatively equal in magnitude; one on the quality of \u201cfeminine\u201d and one on the quality of \u201cmasculine\u201d while maintaining low variances. The feminine outfit selected was an entirely pink outfit with an image of a pair of red lips above the letters \u201cXOXO\u201d on the sweater (M = 2.88, SD = 1.42). The masculine outfit selected was black pants and a brown sweatshirt with an image of a woman in lingerie (M = 6.38, SD = 1.59). \n\nFinal stimuli: Photo editing software was used to incorporate each of the two faces (Face 1 and Face 2) with the masculine (i.e., black pants and a brown sweatshirt with an image of a woman in lingerie) and feminine (i.e., pink pants and a pink sweatshirt with an image of a pair of red lips above \u201cXOXO\u201d) outfits. A fringe of gender-neutral hair was added to the forehead area of each image to make the final images of the people appear more realistic. \n\nProcedure\n\nParticipants will use either a laptop or a computer to participate \u2013 attempting to use any cellular devices will result in automatic termination of the survey (ballot box stuffing disabled).\n\nScreen 1: Consent form \u2013 participants who click the \u201cyes, I would like to participate\u201d to continue and those who click \u201cNo, I do not consent to participating in this study\u201d will be brought to the end of the survey. All participants receive credit regardless of if they complete the survey.\n\nScreen 2: Participants are instructed to: \u201cPay attention to the images you are about to see, and answer the following questions about the image as quickly and honestly as possible.\u201d\n\nScreens 3-14: Participants make judgements on twelve filler task questions. These tasks require participants to make judgments on visual stimuli. For instance, how many red jelly beans are there in a jar of beans or what was the colour of horses seen in an image. The filler tasks are included to prevent participants from being overly vigilant in our activity of interest, which will be the final task.\n\nScreens 15-25: Participants make demographic and character judgments of a person who has a gender-ambiguous face (F1 or F4) is wearing clothing that has been modified to be either female (FC) or male (MC). Importantly the image of the person will remain on the screen while participants make all of the demographic judgments, their aggression judgment, as well as, their confidence judgments:\n\n*Half of participants will receive the gender question as the first judgment they make of the individual in the image; half will be asked to judge gender at the end of the person judgments:\n\nGender Judgment: \u201cPlease select the gender of this person:\u201d Screen presents a centered image of a person in either the MC or FC with one of the two gender-neutral faces (F1 or F4). There is a forced-choice option underneath for participants to select either \u201cMale\u201d or \u201cFemale\u201d.\n\nParticipants will receive one of two presentation options: Order1: male option on the left and female option on the right OR Order2: female option on the left and male option on the right.\n\nFollowing the gender judgment, a new screen asks participants to rate their confidence about their gender judgment while the image of the person remains on screen (0 = \"Not Confident At All\" to 100 = \"Extremely Confident\"). Their gender selection is not visible on the confidence screen.\n\nContinuous Demographic and Character Judgements (the order of the four questions will be randomly presented to participants): \n      a). Weight: \u201cPlease estimate the weight of the person in the image (in pounds/lbs)\u201d (Open-ended)\n      b). Height: \u201cPlease estimate the height of the person in the image (in ft and inches)\u201d (Open-ended)\n      c). Age: \u201cPlease estimate the age of the person in the image (in years)\u201d (Open-ended)\n      d). Aggression: \u201cRate how aggressive the person in the image seems\u201d (0 = \"Not aggressive\", 9 = \"Highly Aggressive\")\n\nFollowing each of the four judgements, a new screen will ask participants to rate their confidence about their judgement while the image of the person remains on screen (0 = \"Not Confident At All\", 100 = \"Extremely Confident\"). However, their response to the question is not visible to participants when they rate their confidence in their response. \n \n*The half of participants who did not receive the gender question at the outset of this task are asked the gender question at this point. \n\n*For each of the questions from screens 3-25, including confidence, participants are given a maximum of 10 minutes to respond, but they are allowed to respond and advance to the next question before the timer is up (timer is hidden from participants).\n\nScreens 26-29: Participants are asked follow-up questions regarding the image they saw.\n\nMetacognitive Questions (the order of the three questions will be counterbalanced between participants):\n     a). View of face: \u201cHow good of a view did you get of the person in the image?\u201d (Likert scale between 1-7 with 1 = Very Poor, 7 = Very Good).\n     b). Self-Reported Speed: \u201cEstimate how quickly you answered the question about the person\u2019s gender (in seconds):\u201d (Open-ended)\n     c). Factors the participant took into consideration when determining gender: \u201cWhat did you look in the image to determine the gender of the person (please be specific)?\u201d (Open-ended)\n     d). If the participant was aware of how order could affect their responding: \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) about the individual in the image could have affected your judgments?\u201d (Yes/No). If yes, \u201cYou answered yes, please answer how your judgments could have been affected by the order you received the questions?\u201d (open-ended)\n\nScreens 30-31: Manipulation Checks: \u201cWhat was the colour of the sweatshirt?\u201d (open-ended) and \u201cWhat was the logo on the sweatshirt?\u201d (open-ended)\n\nScreens 32-35: Demographics. Each question will be presented on separate screens (with the exception of the two questions about gender): \n1. \u201cWhat is your age?\u201d (Open-ended) \n2. \u201cAre you currently the same gender you were assigned at birth?\u201d (Open-ended) and \u201cWhat is your gender?\u201d (Options: Male/Female/Other [Please specify])\n3. \u201cDo you suffer from colour blindness?\u201d (Yes/No). If participant answers \"YES\", then they are prompted to answer a follow-up question: \u201cPlease list the colours that you cannot see:\u201d (Open-ended) \n4. \u201cMy ethnicity is (if mixed, select more than one or specify under \"other\")\u2026\u201d (Multiple Choice) \n\nScreen 36: Debriefing form outlining the purpose of the study and researchers\u2019 contact information. The following is placed at the end of the debriefing form: \"Thank you for participating in our study! We value your participation greatly. However, if you feel uncomfortable about your participation in the study today and would like your data removed, please enter 'erase my data'\" (Text box is provided)\n", "confirmatory-analyses-first.first.question1c": "We will use chi-square test for goodness of fit to analyze whether Face 1 and Face 2 performed similarly. We anticipate that they will, and the face variable will be collapsed in all subsequent analyses. \n\nPhi coefficient and the CI for \u0424 will be calculated using Cumming\u2019s Exploratory Software for Confidence Intervals (ESCI). Cohen\u2019s d and the CI of d will be calculated using Cumming\u2019s formulas, d=((M2-M1))/s and  \u2206 =  (\u03bc2- \u03bc1 )/(\u03b4\u221a(1/N1+1/N2)) respectively in ESCI. ", "confirmatory-analyses-first.first.question2c": "See above. ", "confirmatory-analyses-first.first.question3c": "See above. ", "confirmatory-analyses-first.first.question4c": "N/A", "confirmatory-analyses-first.first.question5c": "N/A", "confirmatory-analyses-third.third.question1c": "Time of Gender Judgement \n\nH4: Multiple between-subject ANAOVAs will test the relationship between gendered outfit (FC or MC) and time of gender judgment (1st question, last question) on the variables of weight, height, age and aggression. This analysis will test if asking the gender question at the end of the demographic questions helps to mitigate the effect of gender perception on demographic reporting.  ", "description-methods.planned-sample.question4b": "Participants will be randomly allocated into one of the following conditions:\n\nFace 1 and FC\nFace 1 and MC\nFace 2 and FC\nFace 2 and MC\n\nHalf of the participants within each condition above will also be sorted into the following DV orders:\n\nOrder 1: Gender categorization and then Demographic and aggression judgements\nOrder 2: Demographic and aggression judgements and then Gender categorization", "description-methods.planned-sample.question5b": "Participants will be recruited through the Kwantlen Polytechnic University Psychology Research Pool System and will be granted 0.5% bonus course credit for their time. Subjects who are visually impaired (i.e., blindness or colour blindness) will be excluded from the study. The \u201cmasculine\u201d and \u201cfeminine\u201d clothing is gendered via its colour (e.g., brown for male and pink for female). Thus, participants must have full function of their colour vision or have visual aids such as glasses for proper visual perception. Participants who cannot see colours (or at all) will provide unusable data for the study.\n\nTo prevent participants from being overly vigilant in our activity of interest, the study name advertised on SONA will be \"Judgement of Pictures\".\n\nPotential participants will read: \u201cThe purpose of this research project is to explore people\u2019s judgments of others. This study requires you to USE A PC/LAPTOP! People who are visually impaired (blind or colour blind) may not participate in this study. Sorry for the inconvenience.\u201d\n\nData will be collected through the computerized database in \"Qualtrics\" using only a laptop or PC. If participants attempts to use a cellular device of any kind (e.g., Blackberry, Android, IPad, IPhone, etc.) to partake in the study, Qualtrics will automatically discontinue the study with a message reminder for them to \u201cPLEASE use a laptop or computer for this study!\u201d", "description-methods.planned-sample.question6b": "Our target sample size is 282 participants. \n\nWe used the software program G*Power to conduct our power analysis. A priori power analysis determined that we require N = 240 to reach statistical significance for a medium-sized effect with power (1 - \u00df) set at 0.80 at the standard .05 alpha error probability. However, we will attempt to recruit an additional 15% (n = 42) of our targeted N to account for potential data loss due to manipulation check failures, incompletion, technical difficulties, etc. ", "description-methods.planned-sample.question7b": "If participants attempt to use a cellular device of any kind (e.g., Blackberry, Android, IPad, iPhone, etc.) to partake in the study, Qualtrics will automatically discontinue the study with a message reminder for them to \u201cPLEASE use a laptop or computer for this study!\u201d Participants may restart the survey on either a laptop or computer. ", "confirmatory-analyses-fourth.fourth.question1c": "Metacognitive Judgments\n\nH5. Confidence: A MANOVA will be used to compare the level of confidence between participants who make gender categorization congruent vs. incongruent to the gender category suggested by the clothing. Alternatively, we may calculate the Cronbach\u2019s alpha of the confidence questions, if internal consistency is high a composite \u201cconfidence\u201d variable will be calculated and used in a t-test analysis (IV: Congruence, DV: Confidence). \n\nH5.a. Confidence (DVs: Gender confidence, height confidence, weight confidence, age confidence, and aggression confidence). Descriptive statistics will be calculated for all the confidence measures. \n\nH5.b., H5.c. Good view and speed of reporting: Two univariate ANOVAs will test the variables of gendered-clothing and time of gender judgment on (i) reported quality of view and (ii) reported speed of reporting. \n\nH5.d. To test if participants were aware that contextual information was affecting their reporting we will code their open-ended responses using the following rubric. To ensure inter-rater reliability, a second coder will independently score 50% of the total self-report Information on the factors that influenced participants gender judgment. This analysis will demonstrate the participants were largely unaware of the effect of context and rather believe they were using features of the person to categorize their gender.  \n\nH5.e. We will calculate the descriptives of the following question: \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) could have affected your judgments?\u201d and show that most participants selected \u201cNO.\u201d We will then code the written responses of those who answered \u201cYES\u201d  to determine how they believed order affected their reporting. ", "confirmatory-analyses-second.second.question1c": "Demographic and Character Judgements\n\nH1.a: (DV: Gender) We will use Chi-square test for goodness of fit to analyze whether our clothing manipulation influences participants\u2019 gender categorization. \n\nH2.a, H2.b, Ex.2., H3: (DVs: Height, Weight, Aggression) Factorial ANOVAs will be used to analyze participants\u2019 continuous outcome variables. \n\nEx: (DV: Age): T-tests will be used to analyze participants\u2019 estimation of Age. ", "confirmatory-analyses-further.further.question1c": "Exploratory Analysis\n\n*We would like to mention here that we may or may not look at these aspects of the data. The following are points of interest:\n\nEx.1: Gender selection and demographic reporting. We may divide our sample into participants who selected \u201cmale\u201d and \u201cfemale.\u201d This gender-selected variable may then be used as an IV in our univariate ANOVAs in which we test if people\u2019s selections of gender affect how they report when making demographic and aggression judgments.   \n\nEx.3: If we explore if speed of responding is related to a higher amount of consistency between clothing condition and gender categorization we will use a logistic regression to do so. Pearson correlations will test if there is a relationship between speed of reporting and the demographic and aggression judgments in each of the clothing conditions (MC and FC). \n\nEx.4: If tested, Pearson correlations would be used to explore the relationship between speed of reporting and metacognitive judgments. Ultimately testing if faster response times resulted in more validating metacognitive reports, i.e. more confident, better view, reporting that they were faster in their identification of gender. \n\nEx.5: We may also explore if participants who were congruent in their clothing condition/gender categorization varied from those who were incongruent in their metacognitive reporting. An ANOVAs would be used to explore this relationship with congruency (congruent/incongruent) and time of gender judgment (1st or last) being used as our IVs and confidence, view, and speed reports as our DVs.  ", "description-methods.exclusion-criteria.question8b": "Anticipated data exclusion criteria: \n\na). Participants who spend a disproportionate amount of time (e.g., hours) to complete the 15-minutes study.\nb). Participants who request to have their data deleted. \nc). Participants with incomplete data. \nd). Participants who indicate that they suffer from colour blindness. \ne). Participants who fail the manipulation checks - i.e., do not know the image on the sweatshirt of the individual or the colour of the individual\u2019s outfit. ", "description-methods.planned-sample.question6b-upload": [{"file_id": "5e3a0be4f1369e001b8af94b", "file_name": "GPower_Biasing Effects of Expectation on Person Perception 2020.JPG", "file_urls": {"html": "https://osf.io/p2ru3/files/osfstorage/5e3a0be4f1369e001b8af94b", "download": "https://osf.io/download/ckjp8/"}, "file_hashes": {"sha256": "42191814c3c25b25e72fa8e0d63704b426842d9a2eb4a4f603240a2cd49b3408"}}]}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/mb6ut/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/mb6ut/comments/?format=json&filter%5Btarget%5D=mb6ut", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/mb6ut/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/mb6ut/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/mb6ut/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/mb6ut/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/mb6ut/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/mb6ut/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/mb6ut/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/mb6ut/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/mb6ut/linked_by_registrations/?format=json", "meta": {}}}}, "parent": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/?format=json", "meta": {}}}, "data": {"id": "j927s", "type": "registrations"}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/mb6ut/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/mb6ut/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/mb6ut/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/ca-1/?format=json", "meta": {}}}, "data": {"id": "ca-1", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/?format=json", "meta": {}}}, "data": {"id": "j927s", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/mb6ut/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/mb6ut/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/mb6ut/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/mb6ut/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/mb6ut/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/mb6ut/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/mb6ut/citation/?format=json", "meta": {}}}, "data": {"id": "mb6ut", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/85n6s/?format=json", "meta": {}}}, "data": {"id": "85n6s", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/pdtac/?format=json", "meta": {}}}, "data": {"id": "pdtac", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5730e99a9ad5a102c5745a8a/?format=json", "meta": {}}}, "data": {"id": "5730e99a9ad5a102c5745a8a", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/mb6ut/", "self": "https://api.osf.io/v2/registrations/mb6ut/"}}, {"id": "uygbe", "type": "registrations", "attributes": {"title": "Methods", "description": "", "category": "methods and measures", "custom_citation": "", "date_created": "2020-02-11T16:27:30.204868", "date_modified": "2020-02-08T01:52:29.680039", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "bc3ea16e856409fadeee23dfd576ea7ef523575e30643c4cadf3ea009f4f426b826af8cc5b40edf2121b42d55b2dffee4240e101d6221253f423ac305baf061d3ff18bdcf4076d1cd794ef31e50d7c1957b1d790e5b651882626243be32af3b5c762c6ba183a1bc6e738da9a4e1842484bb15e057a2b1394c98f22b323262bde09de46928e4b7b5248a1dd7f27fa4734", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-02-11T16:27:30.183020", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Pre-Registration in Social Psychology (van 't Veer & Giner-Sorolla, 2016): Pre-Registration", "registered_meta": {"looked": {"extra": [], "value": "No"}, "datacompletion": {"extra": [], "value": "No, data collection has not begun"}, "additionalComments": {"extra": [], "value": "Citations: \n\nHuart, J., Corneille, O., &amp; Becquart, E. (2005). Face-based categorization, context-based categorization, and distortions in the recollection of gender-ambiguous faces. Journal of Experimental Social Psychology, 41(6), 598-608. doi:10.1016/j.jesp.2004.10.007\n\nMapstone, L. (2015). Rihanna hides away under oversized gothic hoodie and baggy trousers for low-key arrival in Los Angeles after Paris love-in with Travis Scott [Online image]. MailOnline. Retrieved from: http://www.dailymail.co.uk/tvshowbiz/article-3262964/Rihanna-hides-away-oversized-gothic-hoodie-baggy-trousers-low-key-arrival-Los-Angeles-Paris-love-Travis-Scott.html "}, "dataCollectionDates": {"extra": [], "value": "February 2020 - February 2023\n"}, "description-methods": {"value": {"design": {"value": {"question2a": {"extra": [], "value": "This is a 2 Gendered-clothing (male clothing [MC] or female clothing [FC]) x 2 Gender-ambiguous face (Face 1 or Face 2) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) between-subjects factorial design. This is an orthogonal study design.\n"}, "question2b": {"extra": [], "value": "Dependent Variables: \n\n1. Demographic judgments of the individual in the image: categorical gender judgment (M or F), and continuous estimations of weight (open-ended), height (open-ended), and age (open-ended).\n\n2. Judgement of the social features of the individual in the image: level of aggression on a 9-point Likert scale (0 = \"Not aggressive\", 9 = \"Highly Aggressive\").\n\n3. Metacognitive judgment of the viewers experience: participant\u2019s confidence in their judgments (0 = \u201cNot Confident At All\u201d to 100 = \u201cExtremely Confident\u201d), the speed at which they made the gender judgment (open-ended), quality of the view of the individual\u2019s face (1 = \u201cVery Poor\u201d, 7 = \u201cVery Good\u201d), which factors the participant took into consideration when determining gender (open-ended), and how order of responding affected judgment (open-ended)."}, "question3b": {"extra": [], "value": "We do not anticipate using any covariate. However, it is possible that we may use reported age as a covariate if we are seeking to understand our findings on the demographic measures for those in the MC and FC.   "}}}, "procedure": {"value": {"question10b": {"extra": [], "value": "Manipulations and Measures\n\nThis is a 2 Gendered-clothing (male clothing [MC] or female clothing [FC]) x 2 Gender-ambiguous face (Face 1 or Face 2) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) between-subjects factorial design. \n\nDependent Variables\n\n1. Demographic judgments of the individual in the image: categorical gender judgment (M or F), and continuous estimations of weight (open-ended), height, (open-ended) and age (open-ended). \n\n2. Judgement on the social features of the individual in the image: level of aggression on a 9-point Likert scale (0 = \"Not aggressive\", 9 = \"Highly Aggressive\"). \n\n3. Metacognitive judgment of the viewers experience: (i) participant\u2019s confidence in each one of their demographic judgments (gender, weight, height, age) and aggression judgment, (ii) the estimated speed at which they made their gender judgment, (iii) quality of the view of the individual\u2019s face, (iv) which factors the participant took into consideration when determining the gender of the individual and (v) if they believe that the order that they answered the demographic questions could have affected their judgments. \n\nMaterials\n\nFace: Two gender-ambiguous faces were selected from a continuum of morphed male/female faces developed by Huart et al. (2005). Our Face 1 stimulus is a blend of 50% male and 50% female face (named \u201cMoprh 10-050\u201d in original paper; Huart et al., 2005), and our Face 2 stimulus is a blend of 70% female\u201330% male moderately ambiguous face (named \u201cMorph 7-030\u201d in original paper). \n\nClothing: We modified a single image by changing the colour and the logo on the clothing to make it either more \u201cmasculine\u201d or \u201cfeminine.\u201d The image was an anterior view of a person (the pop singer Rhianna) wearing a hooded sweatshirt and a pair of baggy pants (image retrieved from Google Image; Mapstone, 2015). The baggy clothing obscured the physique of the person. Photo editing software was used to alter the logo on the sweatshirt and the clothing colour. \n\nWe conducted a pilot study with four clothing stimuli to test their levels of perceived masculinity and femininity. Sixty undergraduate students (49 females, 11 males) participated in the study and were asked to rate on a 9-point Likert scale (1 = \u201cOnly Women\u201d; 9 = \u201cOnly Men\u201d) on whether men or women are more likely to wear the outfit presented. Descriptive results revealed two outfits were rated as relatively equal in magnitude; one on the quality of \u201cfeminine\u201d and one on the quality of \u201cmasculine\u201d while maintaining low variances. The feminine outfit selected was an entirely pink outfit with an image of a pair of red lips above the letters \u201cXOXO\u201d on the sweater (M = 2.88, SD = 1.42). The masculine outfit selected was black pants and a brown sweatshirt with an image of a woman in lingerie (M = 6.38, SD = 1.59). \n\nFinal stimuli: Photo editing software was used to incorporate each of the two faces (Face 1 and Face 2) with the masculine (i.e., black pants and a brown sweatshirt with an image of a woman in lingerie) and feminine (i.e., pink pants and a pink sweatshirt with an image of a pair of red lips above \u201cXOXO\u201d) outfits. A fringe of gender-neutral hair was added to the forehead area of each image to make the final images of the people appear more realistic. \n\nProcedure\n\nParticipants will use either a laptop or a computer to participate \u2013 attempting to use any cellular devices will result in automatic termination of the survey (ballot box stuffing disabled).\n\nScreen 1: Consent form \u2013 participants who click the \u201cyes, I would like to participate\u201d to continue and those who click \u201cNo, I do not consent to participating in this study\u201d will be brought to the end of the survey. All participants receive credit regardless of if they complete the survey.\n\nScreen 2: Participants are instructed to: \u201cPay attention to the images you are about to see, and answer the following questions about the image as quickly and honestly as possible.\u201d\n\nScreens 3-14: Participants make judgements on twelve filler task questions. These tasks require participants to make judgments on visual stimuli. For instance, how many red jelly beans are there in a jar of beans or what was the colour of horses seen in an image. The filler tasks are included to prevent participants from being overly vigilant in our activity of interest, which will be the final task.\n\nScreens 15-25: Participants make demographic and character judgments of a person who has a gender-ambiguous face (F1 or F4) is wearing clothing that has been modified to be either female (FC) or male (MC). Importantly the image of the person will remain on the screen while participants make all of the demographic judgments, their aggression judgment, as well as, their confidence judgments:\n\n*Half of participants will receive the gender question as the first judgment they make of the individual in the image; half will be asked to judge gender at the end of the person judgments:\n\nGender Judgment: \u201cPlease select the gender of this person:\u201d Screen presents a centered image of a person in either the MC or FC with one of the two gender-neutral faces (F1 or F4). There is a forced-choice option underneath for participants to select either \u201cMale\u201d or \u201cFemale\u201d.\n\nParticipants will receive one of two presentation options: Order1: male option on the left and female option on the right OR Order2: female option on the left and male option on the right.\n\nFollowing the gender judgment, a new screen asks participants to rate their confidence about their gender judgment while the image of the person remains on screen (0 = \"Not Confident At All\" to 100 = \"Extremely Confident\"). Their gender selection is not visible on the confidence screen.\n\nContinuous Demographic and Character Judgements (the order of the four questions will be randomly presented to participants): \n      a). Weight: \u201cPlease estimate the weight of the person in the image (in pounds/lbs)\u201d (Open-ended)\n      b). Height: \u201cPlease estimate the height of the person in the image (in ft and inches)\u201d (Open-ended)\n      c). Age: \u201cPlease estimate the age of the person in the image (in years)\u201d (Open-ended)\n      d). Aggression: \u201cRate how aggressive the person in the image seems\u201d (0 = \"Not aggressive\", 9 = \"Highly Aggressive\")\n\nFollowing each of the four judgements, a new screen will ask participants to rate their confidence about their judgement while the image of the person remains on screen (0 = \"Not Confident At All\", 100 = \"Extremely Confident\"). However, their response to the question is not visible to participants when they rate their confidence in their response. \n \n*The half of participants who did not receive the gender question at the outset of this task are asked the gender question at this point. \n\n*For each of the questions from screens 3-25, including confidence, participants are given a maximum of 10 minutes to respond, but they are allowed to respond and advance to the next question before the timer is up (timer is hidden from participants).\n\nScreens 26-29: Participants are asked follow-up questions regarding the image they saw.\n\nMetacognitive Questions (the order of the three questions will be counterbalanced between participants):\n     a). View of face: \u201cHow good of a view did you get of the person in the image?\u201d (Likert scale between 1-7 with 1 = Very Poor, 7 = Very Good).\n     b). Self-Reported Speed: \u201cEstimate how quickly you answered the question about the person\u2019s gender (in seconds):\u201d (Open-ended)\n     c). Factors the participant took into consideration when determining gender: \u201cWhat did you look in the image to determine the gender of the person (please be specific)?\u201d (Open-ended)\n     d). If the participant was aware of how order could affect their responding: \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) about the individual in the image could have affected your judgments?\u201d (Yes/No). If yes, \u201cYou answered yes, please answer how your judgments could have been affected by the order you received the questions?\u201d (open-ended)\n\nScreens 30-31: Manipulation Checks: \u201cWhat was the colour of the sweatshirt?\u201d (open-ended) and \u201cWhat was the logo on the sweatshirt?\u201d (open-ended)\n\nScreens 32-35: Demographics. Each question will be presented on separate screens (with the exception of the two questions about gender): \n1. \u201cWhat is your age?\u201d (Open-ended) \n2. \u201cAre you currently the same gender you were assigned at birth?\u201d (Open-ended) and \u201cWhat is your gender?\u201d (Options: Male/Female/Other [Please specify])\n3. \u201cDo you suffer from colour blindness?\u201d (Yes/No). If participant answers \"YES\", then they are prompted to answer a follow-up question: \u201cPlease list the colours that you cannot see:\u201d (Open-ended) \n4. \u201cMy ethnicity is (if mixed, select more than one or specify under \"other\")\u2026\u201d (Multiple Choice) \n\nScreen 36: Debriefing form outlining the purpose of the study and researchers\u2019 contact information. The following is placed at the end of the debriefing form: \"Thank you for participating in our study! We value your participation greatly. However, if you feel uncomfortable about your participation in the study today and would like your data removed, please enter 'erase my data'\" (Text box is provided)\n"}}}, "planned-sample": {"value": {"question4b": {"extra": [], "value": "Participants will be randomly allocated into one of the following conditions:\n\nFace 1 and FC\nFace 1 and MC\nFace 2 and FC\nFace 2 and MC\n\nHalf of the participants within each condition above will also be sorted into the following DV orders:\n\nOrder 1: Gender categorization and then Demographic and aggression judgements\nOrder 2: Demographic and aggression judgements and then Gender categorization"}, "question5b": {"extra": [], "value": "Participants will be recruited through the Kwantlen Polytechnic University Psychology Research Pool System and will be granted 0.5% bonus course credit for their time. Subjects who are visually impaired (i.e., blindness or colour blindness) will be excluded from the study. The \u201cmasculine\u201d and \u201cfeminine\u201d clothing is gendered via its colour (e.g., brown for male and pink for female). Thus, participants must have full function of their colour vision or have visual aids such as glasses for proper visual perception. Participants who cannot see colours (or at all) will provide unusable data for the study.\n\nTo prevent participants from being overly vigilant in our activity of interest, the study name advertised on SONA will be \"Judgement of Pictures\".\n\nPotential participants will read: \u201cThe purpose of this research project is to explore people\u2019s judgments of others. This study requires you to USE A PC/LAPTOP! People who are visually impaired (blind or colour blind) may not participate in this study. Sorry for the inconvenience.\u201d\n\nData will be collected through the computerized database in \"Qualtrics\" using only a laptop or PC. If participants attempts to use a cellular device of any kind (e.g., Blackberry, Android, IPad, IPhone, etc.) to partake in the study, Qualtrics will automatically discontinue the study with a message reminder for them to \u201cPLEASE use a laptop or computer for this study!\u201d"}, "question6b": {"extra": [], "value": "Our target sample size is 282 participants. \n\nWe used the software program G*Power to conduct our power analysis. A priori power analysis determined that we require N = 240 to reach statistical significance for a medium-sized effect with power (1 - \u00df) set at 0.80 at the standard .05 alpha error probability. However, we will attempt to recruit an additional 15% (n = 42) of our targeted N to account for potential data loss due to manipulation check failures, incompletion, technical difficulties, etc. "}, "question7b": {"extra": [], "value": "If participants attempt to use a cellular device of any kind (e.g., Blackberry, Android, IPad, iPhone, etc.) to partake in the study, Qualtrics will automatically discontinue the study with a message reminder for them to \u201cPLEASE use a laptop or computer for this study!\u201d Participants may restart the survey on either a laptop or computer. "}, "question6b-upload": {"extra": [{"data": {"name": "GPower_Biasing Effects of Expectation on Person Perception 2020.JPG"}, "nodeId": "p2ru3", "sha256": "42191814c3c25b25e72fa8e0d63704b426842d9a2eb4a4f603240a2cd49b3408", "viewUrl": "/project/p2ru3/files/osfstorage/5e3a0be4f1369e001b8af94b", "selectedFileName": "GPower_Biasing Effects of Expectation on Person Perception 2020.JPG"}], "value": ""}}}, "exclusion-criteria": {"value": {"question8b": {"extra": [], "value": "Anticipated data exclusion criteria: \n\na). Participants who spend a disproportionate amount of time (e.g., hours) to complete the 15-minutes study.\nb). Participants who request to have their data deleted. \nc). Participants with incomplete data. \nd). Participants who indicate that they suffer from colour blindness. \ne). Participants who fail the manipulation checks - i.e., do not know the image on the sweatshirt of the individual or the colour of the individual\u2019s outfit. "}}}}}, "recommended-methods": {"value": {"procedure": {"value": {"question9b": {"extra": [], "value": "Participants will use either a laptop or a computer to participate \u2013 attempting to use any cellular devices will result in automatic termination of the survey (ballot box stuffing disabled). "}, "question9b-file": {"extra": [], "value": ""}}}}}, "recommended-analysis": {"value": {"specify": {"value": {"question6c": {"extra": [], "value": ""}, "question7c": {"extra": [], "value": "The data of participants who do not complete the study will not be used in analyses. "}, "question8c": {"extra": [], "value": ""}, "question9c": {"extra": [], "value": "Outlier ratings of continuous DVs may be replaced with the mean rating from the sample. Any manipulation of this kind will be clearly articulated in a manuscript prepared for publication."}, "question10c": {"extra": [], "value": "If assumptions of our parametrics tests are violated we will seek non-parametric options for data analysis. "}, "question11c": {"extra": [], "value": ""}}}}}, "description-hypothesis": {"value": {"question1a": {"extra": [], "value": "Gender-Ambiguous face\n\nTwo gender-ambiguous faces were counterbalanced in this research to enhance the generalizability of our findings. We do not expect any effect of this variable.\nGendered Clothing Manipulation\n\nH1 \u201cGender Judgment\u201d: We predict that pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result participants categorizing the individual in the gender category suggested by the clothing (MC or FC).\n\nH2 \u201cDemographic Judgments\u201d: We predict that a pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result in demographic judgments (height, weight) consistent with the gender category suggested by the clothing (MC or FC).\n\nH2.a: (DV: Height): Participants in the MC condition will estimate the individual to be taller than participants\u2019 estimations of the same individual in the FC condition.\n\nH2.b: (DV: Weight): Participants in the MC condition will estimate the individual to be heavier than participants\u2019 estimations of the same individual in the FC condition.\n\nH3 \u201cAggression Judgment\u201d: We predict that pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result in an aggression judgment consistent with the gender category suggested by the clothing (MC or FC). Specifically, participants in the MC condition would rate the individual to be more aggressive than participants\u2019 estimations of the same individual in the FC condition.\n\nGender Judgment Manipulation\n\nH4: \u201cDemographic and Aggression Judgments\u201d We predict a 2 Gendered-clothing (MC or FC) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) interaction on the height, weight and aggression variables.\n\nSpecifically, participants who are asked to categorize the gender of the individual first, i.e., prior to judging demographic and aggression variables, will provide responses to the demographic and aggression judgments that are more representative of their gender categorization (i.e., male is heavier, taller and more aggressive; female is shorter, lighter and less aggressive) than participants who are asked to gender categorize the individual as their last judgment, i.e., after judging demographics and character variables.\n\nH5 \u201cMetacognitive Judgments of Performance\u201d: We predict that participants will:\n\nH5.a. Be confident in their gender, demographic, and aggression judgments of the individual.\n\nH5.b. Report that they had a good view of the person in the image.\n\nH5.c. Report that they were fast in their categorization of gender regardless of their speed.\n\nH5.d. Be largely unaware that contextual variables \u2013 (i) clothing manipulation and (ii) time of gender judgment - affected their reporting. That is, first, when asked what they considered when categorizing the gender of the person in the image the majority of participants will report that the used biological features of the individual (entire face or facial features, shape and stature of the body) versus reporting contextual information found on the clothing (colour and image). Second, when asked \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) could have affected your judgments? Yes/No, we predict that the majority of participant will respond \u201cNO.\u201d\n\nPossible Exploratory\n\nEx.1 Gender categorization: We may explore if peoples gender categorizations had a relationship with the demographic, aggression and metacognitive variables in our study. This analysis is different than our gender manipulation because it will use gender categorization as the independent variable in our analysis, not gendered-clothing condition.\n\nEx.2 (DV: Age): We will explore if participants who categorize the individual as \u201cMale\u201d will estimate the age of the individual as younger than participants who categorize the individual as \u201cFemale.\u201d\n\nEx.3: We may explore if speed of responding is related to a higher amount of consistency between clothing condition and gender categorization, as well as judgments that are more congruent with the gender category.\n\nEx.4: We may explore the relationship between speed of reporting and metacognitive judgments. Ultimately testing if faster response times resulted in more validating metacognitive reports, i.e. more confident, better view, reporting that they were faster in their identification of gender.\n\nEx.5: We may also explore if the metacognitive judgments of participants who were congruent in their clothing condition/gender categorization varied from those who were incongruent."}, "question2a": {"extra": [], "value": "N/A"}, "question3a": {"extra": [], "value": "We will include two manipulation checks at the end of the study. Participants will be asked 1. \u201cWhat was the colour of the sweatshirt that the individual was wearing?\", and 2. \u201cWhat was the image on the sweatshirt?\u201d to verify that they paid attention to our visual manipulation."}}}, "recommended-hypothesis": {"value": {"question4a": {"extra": [], "value": ""}, "question5a": {"extra": [], "value": ""}, "question6a": {"extra": [], "value": ""}}}, "confirmatory-analyses-first": {"value": {"first": {"value": {"question1c": {"extra": [], "value": "We will use chi-square test for goodness of fit to analyze whether Face 1 and Face 2 performed similarly. We anticipate that they will, and the face variable will be collapsed in all subsequent analyses. \n\nPhi coefficient and the CI for \u0424 will be calculated using Cumming\u2019s Exploratory Software for Confidence Intervals (ESCI). Cohen\u2019s d and the CI of d will be calculated using Cumming\u2019s formulas, d=((M2-M1))/s and  \u2206 =  (\u03bc2- \u03bc1 )/(\u03b4\u221a(1/N1+1/N2)) respectively in ESCI. "}, "question2c": {"extra": [], "value": "See above. "}, "question3c": {"extra": [], "value": "See above. "}, "question4c": {"extra": [], "value": "N/A"}, "question5c": {"extra": [], "value": "N/A"}}}}}, "confirmatory-analyses-third": {"value": {"third": {"value": {"question1c": {"extra": [], "value": "Time of Gender Judgement \n\nH4: Multiple between-subject ANAOVAs will test the relationship between gendered outfit (FC or MC) and time of gender judgment (1st question, last question) on the variables of weight, height, age and aggression. This analysis will test if asking the gender question at the end of the demographic questions helps to mitigate the effect of gender perception on demographic reporting.  "}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}, "confirmatory-analyses-fourth": {"value": {"fourth": {"value": {"question1c": {"extra": [], "value": "Metacognitive Judgments\n\nH5. Confidence: A MANOVA will be used to compare the level of confidence between participants who make gender categorization congruent vs. incongruent to the gender category suggested by the clothing. Alternatively, we may calculate the Cronbach\u2019s alpha of the confidence questions, if internal consistency is high a composite \u201cconfidence\u201d variable will be calculated and used in a t-test analysis (IV: Congruence, DV: Confidence). \n\nH5.a. Confidence (DVs: Gender confidence, height confidence, weight confidence, age confidence, and aggression confidence). Descriptive statistics will be calculated for all the confidence measures. \n\nH5.b., H5.c. Good view and speed of reporting: Two univariate ANOVAs will test the variables of gendered-clothing and time of gender judgment on (i) reported quality of view and (ii) reported speed of reporting. \n\nH5.d. To test if participants were aware that contextual information was affecting their reporting we will code their open-ended responses using the following rubric. To ensure inter-rater reliability, a second coder will independently score 50% of the total self-report Information on the factors that influenced participants gender judgment. This analysis will demonstrate the participants were largely unaware of the effect of context and rather believe they were using features of the person to categorize their gender.  \n\nH5.e. We will calculate the descriptives of the following question: \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) could have affected your judgments?\u201d and show that most participants selected \u201cNO.\u201d We will then code the written responses of those who answered \u201cYES\u201d  to determine how they believed order affected their reporting. "}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}, "confirmatory-analyses-second": {"value": {"second": {"value": {"question1c": {"extra": [], "value": "Demographic and Character Judgements\n\nH1.a: (DV: Gender) We will use Chi-square test for goodness of fit to analyze whether our clothing manipulation influences participants\u2019 gender categorization. \n\nH2.a, H2.b, Ex.2., H3: (DVs: Height, Weight, Aggression) Factorial ANOVAs will be used to analyze participants\u2019 continuous outcome variables. \n\nEx: (DV: Age): T-tests will be used to analyze participants\u2019 estimation of Age. "}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}, "confirmatory-analyses-further": {"value": {"further": {"value": {"question1c": {"extra": [], "value": "Exploratory Analysis\n\n*We would like to mention here that we may or may not look at these aspects of the data. The following are points of interest:\n\nEx.1: Gender selection and demographic reporting. We may divide our sample into participants who selected \u201cmale\u201d and \u201cfemale.\u201d This gender-selected variable may then be used as an IV in our univariate ANOVAs in which we test if people\u2019s selections of gender affect how they report when making demographic and aggression judgments.   \n\nEx.3: If we explore if speed of responding is related to a higher amount of consistency between clothing condition and gender categorization we will use a logistic regression to do so. Pearson correlations will test if there is a relationship between speed of reporting and the demographic and aggression judgments in each of the clothing conditions (MC and FC). \n\nEx.4: If tested, Pearson correlations would be used to explore the relationship between speed of reporting and metacognitive judgments. Ultimately testing if faster response times resulted in more validating metacognitive reports, i.e. more confident, better view, reporting that they were faster in their identification of gender. \n\nEx.5: We may also explore if participants who were congruent in their clothing condition/gender categorization varied from those who were incongruent in their metacognitive reporting. An ANOVAs would be used to explore this relationship with congruency (congruent/incongruent) and time of gender judgment (1st or last) being used as our IVs and confidence, view, and speed reports as our DVs.  "}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}}, "registration_responses": {"looked": "No", "datacompletion": "No, data collection has not begun", "additionalComments": "Citations: \n\nHuart, J., Corneille, O., &amp; Becquart, E. (2005). Face-based categorization, context-based categorization, and distortions in the recollection of gender-ambiguous faces. Journal of Experimental Social Psychology, 41(6), 598-608. doi:10.1016/j.jesp.2004.10.007\n\nMapstone, L. (2015). Rihanna hides away under oversized gothic hoodie and baggy trousers for low-key arrival in Los Angeles after Paris love-in with Travis Scott [Online image]. MailOnline. Retrieved from: http://www.dailymail.co.uk/tvshowbiz/article-3262964/Rihanna-hides-away-oversized-gothic-hoodie-baggy-trousers-low-key-arrival-Los-Angeles-Paris-love-Travis-Scott.html ", "dataCollectionDates": "February 2020 - February 2023\n", "description-hypothesis.question1a": "Gender-Ambiguous face\n\nTwo gender-ambiguous faces were counterbalanced in this research to enhance the generalizability of our findings. We do not expect any effect of this variable.\nGendered Clothing Manipulation\n\nH1 \u201cGender Judgment\u201d: We predict that pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result participants categorizing the individual in the gender category suggested by the clothing (MC or FC).\n\nH2 \u201cDemographic Judgments\u201d: We predict that a pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result in demographic judgments (height, weight) consistent with the gender category suggested by the clothing (MC or FC).\n\nH2.a: (DV: Height): Participants in the MC condition will estimate the individual to be taller than participants\u2019 estimations of the same individual in the FC condition.\n\nH2.b: (DV: Weight): Participants in the MC condition will estimate the individual to be heavier than participants\u2019 estimations of the same individual in the FC condition.\n\nH3 \u201cAggression Judgment\u201d: We predict that pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result in an aggression judgment consistent with the gender category suggested by the clothing (MC or FC). Specifically, participants in the MC condition would rate the individual to be more aggressive than participants\u2019 estimations of the same individual in the FC condition.\n\nGender Judgment Manipulation\n\nH4: \u201cDemographic and Aggression Judgments\u201d We predict a 2 Gendered-clothing (MC or FC) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) interaction on the height, weight and aggression variables.\n\nSpecifically, participants who are asked to categorize the gender of the individual first, i.e., prior to judging demographic and aggression variables, will provide responses to the demographic and aggression judgments that are more representative of their gender categorization (i.e., male is heavier, taller and more aggressive; female is shorter, lighter and less aggressive) than participants who are asked to gender categorize the individual as their last judgment, i.e., after judging demographics and character variables.\n\nH5 \u201cMetacognitive Judgments of Performance\u201d: We predict that participants will:\n\nH5.a. Be confident in their gender, demographic, and aggression judgments of the individual.\n\nH5.b. Report that they had a good view of the person in the image.\n\nH5.c. Report that they were fast in their categorization of gender regardless of their speed.\n\nH5.d. Be largely unaware that contextual variables \u2013 (i) clothing manipulation and (ii) time of gender judgment - affected their reporting. That is, first, when asked what they considered when categorizing the gender of the person in the image the majority of participants will report that the used biological features of the individual (entire face or facial features, shape and stature of the body) versus reporting contextual information found on the clothing (colour and image). Second, when asked \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) could have affected your judgments? Yes/No, we predict that the majority of participant will respond \u201cNO.\u201d\n\nPossible Exploratory\n\nEx.1 Gender categorization: We may explore if peoples gender categorizations had a relationship with the demographic, aggression and metacognitive variables in our study. This analysis is different than our gender manipulation because it will use gender categorization as the independent variable in our analysis, not gendered-clothing condition.\n\nEx.2 (DV: Age): We will explore if participants who categorize the individual as \u201cMale\u201d will estimate the age of the individual as younger than participants who categorize the individual as \u201cFemale.\u201d\n\nEx.3: We may explore if speed of responding is related to a higher amount of consistency between clothing condition and gender categorization, as well as judgments that are more congruent with the gender category.\n\nEx.4: We may explore the relationship between speed of reporting and metacognitive judgments. Ultimately testing if faster response times resulted in more validating metacognitive reports, i.e. more confident, better view, reporting that they were faster in their identification of gender.\n\nEx.5: We may also explore if the metacognitive judgments of participants who were congruent in their clothing condition/gender categorization varied from those who were incongruent.", "description-hypothesis.question2a": "N/A", "description-hypothesis.question3a": "We will include two manipulation checks at the end of the study. Participants will be asked 1. \u201cWhat was the colour of the sweatshirt that the individual was wearing?\", and 2. \u201cWhat was the image on the sweatshirt?\u201d to verify that they paid attention to our visual manipulation.", "description-methods.design.question2a": "This is a 2 Gendered-clothing (male clothing [MC] or female clothing [FC]) x 2 Gender-ambiguous face (Face 1 or Face 2) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) between-subjects factorial design. This is an orthogonal study design.\n", "description-methods.design.question2b": "Dependent Variables: \n\n1. Demographic judgments of the individual in the image: categorical gender judgment (M or F), and continuous estimations of weight (open-ended), height (open-ended), and age (open-ended).\n\n2. Judgement of the social features of the individual in the image: level of aggression on a 9-point Likert scale (0 = \"Not aggressive\", 9 = \"Highly Aggressive\").\n\n3. Metacognitive judgment of the viewers experience: participant\u2019s confidence in their judgments (0 = \u201cNot Confident At All\u201d to 100 = \u201cExtremely Confident\u201d), the speed at which they made the gender judgment (open-ended), quality of the view of the individual\u2019s face (1 = \u201cVery Poor\u201d, 7 = \u201cVery Good\u201d), which factors the participant took into consideration when determining gender (open-ended), and how order of responding affected judgment (open-ended).", "description-methods.design.question3b": "We do not anticipate using any covariate. However, it is possible that we may use reported age as a covariate if we are seeking to understand our findings on the demographic measures for those in the MC and FC.   ", "recommended-analysis.specify.question6c": "", "recommended-analysis.specify.question7c": "The data of participants who do not complete the study will not be used in analyses. ", "recommended-analysis.specify.question8c": "", "recommended-analysis.specify.question9c": "Outlier ratings of continuous DVs may be replaced with the mean rating from the sample. Any manipulation of this kind will be clearly articulated in a manuscript prepared for publication.", "recommended-analysis.specify.question10c": "If assumptions of our parametrics tests are violated we will seek non-parametric options for data analysis. ", "recommended-analysis.specify.question11c": [], "recommended-methods.procedure.question9b": "Participants will use either a laptop or a computer to participate \u2013 attempting to use any cellular devices will result in automatic termination of the survey (ballot box stuffing disabled). ", "description-methods.procedure.question10b": "Manipulations and Measures\n\nThis is a 2 Gendered-clothing (male clothing [MC] or female clothing [FC]) x 2 Gender-ambiguous face (Face 1 or Face 2) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) between-subjects factorial design. \n\nDependent Variables\n\n1. Demographic judgments of the individual in the image: categorical gender judgment (M or F), and continuous estimations of weight (open-ended), height, (open-ended) and age (open-ended). \n\n2. Judgement on the social features of the individual in the image: level of aggression on a 9-point Likert scale (0 = \"Not aggressive\", 9 = \"Highly Aggressive\"). \n\n3. Metacognitive judgment of the viewers experience: (i) participant\u2019s confidence in each one of their demographic judgments (gender, weight, height, age) and aggression judgment, (ii) the estimated speed at which they made their gender judgment, (iii) quality of the view of the individual\u2019s face, (iv) which factors the participant took into consideration when determining the gender of the individual and (v) if they believe that the order that they answered the demographic questions could have affected their judgments. \n\nMaterials\n\nFace: Two gender-ambiguous faces were selected from a continuum of morphed male/female faces developed by Huart et al. (2005). Our Face 1 stimulus is a blend of 50% male and 50% female face (named \u201cMoprh 10-050\u201d in original paper; Huart et al., 2005), and our Face 2 stimulus is a blend of 70% female\u201330% male moderately ambiguous face (named \u201cMorph 7-030\u201d in original paper). \n\nClothing: We modified a single image by changing the colour and the logo on the clothing to make it either more \u201cmasculine\u201d or \u201cfeminine.\u201d The image was an anterior view of a person (the pop singer Rhianna) wearing a hooded sweatshirt and a pair of baggy pants (image retrieved from Google Image; Mapstone, 2015). The baggy clothing obscured the physique of the person. Photo editing software was used to alter the logo on the sweatshirt and the clothing colour. \n\nWe conducted a pilot study with four clothing stimuli to test their levels of perceived masculinity and femininity. Sixty undergraduate students (49 females, 11 males) participated in the study and were asked to rate on a 9-point Likert scale (1 = \u201cOnly Women\u201d; 9 = \u201cOnly Men\u201d) on whether men or women are more likely to wear the outfit presented. Descriptive results revealed two outfits were rated as relatively equal in magnitude; one on the quality of \u201cfeminine\u201d and one on the quality of \u201cmasculine\u201d while maintaining low variances. The feminine outfit selected was an entirely pink outfit with an image of a pair of red lips above the letters \u201cXOXO\u201d on the sweater (M = 2.88, SD = 1.42). The masculine outfit selected was black pants and a brown sweatshirt with an image of a woman in lingerie (M = 6.38, SD = 1.59). \n\nFinal stimuli: Photo editing software was used to incorporate each of the two faces (Face 1 and Face 2) with the masculine (i.e., black pants and a brown sweatshirt with an image of a woman in lingerie) and feminine (i.e., pink pants and a pink sweatshirt with an image of a pair of red lips above \u201cXOXO\u201d) outfits. A fringe of gender-neutral hair was added to the forehead area of each image to make the final images of the people appear more realistic. \n\nProcedure\n\nParticipants will use either a laptop or a computer to participate \u2013 attempting to use any cellular devices will result in automatic termination of the survey (ballot box stuffing disabled).\n\nScreen 1: Consent form \u2013 participants who click the \u201cyes, I would like to participate\u201d to continue and those who click \u201cNo, I do not consent to participating in this study\u201d will be brought to the end of the survey. All participants receive credit regardless of if they complete the survey.\n\nScreen 2: Participants are instructed to: \u201cPay attention to the images you are about to see, and answer the following questions about the image as quickly and honestly as possible.\u201d\n\nScreens 3-14: Participants make judgements on twelve filler task questions. These tasks require participants to make judgments on visual stimuli. For instance, how many red jelly beans are there in a jar of beans or what was the colour of horses seen in an image. The filler tasks are included to prevent participants from being overly vigilant in our activity of interest, which will be the final task.\n\nScreens 15-25: Participants make demographic and character judgments of a person who has a gender-ambiguous face (F1 or F4) is wearing clothing that has been modified to be either female (FC) or male (MC). Importantly the image of the person will remain on the screen while participants make all of the demographic judgments, their aggression judgment, as well as, their confidence judgments:\n\n*Half of participants will receive the gender question as the first judgment they make of the individual in the image; half will be asked to judge gender at the end of the person judgments:\n\nGender Judgment: \u201cPlease select the gender of this person:\u201d Screen presents a centered image of a person in either the MC or FC with one of the two gender-neutral faces (F1 or F4). There is a forced-choice option underneath for participants to select either \u201cMale\u201d or \u201cFemale\u201d.\n\nParticipants will receive one of two presentation options: Order1: male option on the left and female option on the right OR Order2: female option on the left and male option on the right.\n\nFollowing the gender judgment, a new screen asks participants to rate their confidence about their gender judgment while the image of the person remains on screen (0 = \"Not Confident At All\" to 100 = \"Extremely Confident\"). Their gender selection is not visible on the confidence screen.\n\nContinuous Demographic and Character Judgements (the order of the four questions will be randomly presented to participants): \n      a). Weight: \u201cPlease estimate the weight of the person in the image (in pounds/lbs)\u201d (Open-ended)\n      b). Height: \u201cPlease estimate the height of the person in the image (in ft and inches)\u201d (Open-ended)\n      c). Age: \u201cPlease estimate the age of the person in the image (in years)\u201d (Open-ended)\n      d). Aggression: \u201cRate how aggressive the person in the image seems\u201d (0 = \"Not aggressive\", 9 = \"Highly Aggressive\")\n\nFollowing each of the four judgements, a new screen will ask participants to rate their confidence about their judgement while the image of the person remains on screen (0 = \"Not Confident At All\", 100 = \"Extremely Confident\"). However, their response to the question is not visible to participants when they rate their confidence in their response. \n \n*The half of participants who did not receive the gender question at the outset of this task are asked the gender question at this point. \n\n*For each of the questions from screens 3-25, including confidence, participants are given a maximum of 10 minutes to respond, but they are allowed to respond and advance to the next question before the timer is up (timer is hidden from participants).\n\nScreens 26-29: Participants are asked follow-up questions regarding the image they saw.\n\nMetacognitive Questions (the order of the three questions will be counterbalanced between participants):\n     a). View of face: \u201cHow good of a view did you get of the person in the image?\u201d (Likert scale between 1-7 with 1 = Very Poor, 7 = Very Good).\n     b). Self-Reported Speed: \u201cEstimate how quickly you answered the question about the person\u2019s gender (in seconds):\u201d (Open-ended)\n     c). Factors the participant took into consideration when determining gender: \u201cWhat did you look in the image to determine the gender of the person (please be specific)?\u201d (Open-ended)\n     d). If the participant was aware of how order could affect their responding: \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) about the individual in the image could have affected your judgments?\u201d (Yes/No). If yes, \u201cYou answered yes, please answer how your judgments could have been affected by the order you received the questions?\u201d (open-ended)\n\nScreens 30-31: Manipulation Checks: \u201cWhat was the colour of the sweatshirt?\u201d (open-ended) and \u201cWhat was the logo on the sweatshirt?\u201d (open-ended)\n\nScreens 32-35: Demographics. Each question will be presented on separate screens (with the exception of the two questions about gender): \n1. \u201cWhat is your age?\u201d (Open-ended) \n2. \u201cAre you currently the same gender you were assigned at birth?\u201d (Open-ended) and \u201cWhat is your gender?\u201d (Options: Male/Female/Other [Please specify])\n3. \u201cDo you suffer from colour blindness?\u201d (Yes/No). If participant answers \"YES\", then they are prompted to answer a follow-up question: \u201cPlease list the colours that you cannot see:\u201d (Open-ended) \n4. \u201cMy ethnicity is (if mixed, select more than one or specify under \"other\")\u2026\u201d (Multiple Choice) \n\nScreen 36: Debriefing form outlining the purpose of the study and researchers\u2019 contact information. The following is placed at the end of the debriefing form: \"Thank you for participating in our study! We value your participation greatly. However, if you feel uncomfortable about your participation in the study today and would like your data removed, please enter 'erase my data'\" (Text box is provided)\n", "confirmatory-analyses-first.first.question1c": "We will use chi-square test for goodness of fit to analyze whether Face 1 and Face 2 performed similarly. We anticipate that they will, and the face variable will be collapsed in all subsequent analyses. \n\nPhi coefficient and the CI for \u0424 will be calculated using Cumming\u2019s Exploratory Software for Confidence Intervals (ESCI). Cohen\u2019s d and the CI of d will be calculated using Cumming\u2019s formulas, d=((M2-M1))/s and  \u2206 =  (\u03bc2- \u03bc1 )/(\u03b4\u221a(1/N1+1/N2)) respectively in ESCI. ", "confirmatory-analyses-first.first.question2c": "See above. ", "confirmatory-analyses-first.first.question3c": "See above. ", "confirmatory-analyses-first.first.question4c": "N/A", "confirmatory-analyses-first.first.question5c": "N/A", "confirmatory-analyses-third.third.question1c": "Time of Gender Judgement \n\nH4: Multiple between-subject ANAOVAs will test the relationship between gendered outfit (FC or MC) and time of gender judgment (1st question, last question) on the variables of weight, height, age and aggression. This analysis will test if asking the gender question at the end of the demographic questions helps to mitigate the effect of gender perception on demographic reporting.  ", "description-methods.planned-sample.question4b": "Participants will be randomly allocated into one of the following conditions:\n\nFace 1 and FC\nFace 1 and MC\nFace 2 and FC\nFace 2 and MC\n\nHalf of the participants within each condition above will also be sorted into the following DV orders:\n\nOrder 1: Gender categorization and then Demographic and aggression judgements\nOrder 2: Demographic and aggression judgements and then Gender categorization", "description-methods.planned-sample.question5b": "Participants will be recruited through the Kwantlen Polytechnic University Psychology Research Pool System and will be granted 0.5% bonus course credit for their time. Subjects who are visually impaired (i.e., blindness or colour blindness) will be excluded from the study. The \u201cmasculine\u201d and \u201cfeminine\u201d clothing is gendered via its colour (e.g., brown for male and pink for female). Thus, participants must have full function of their colour vision or have visual aids such as glasses for proper visual perception. Participants who cannot see colours (or at all) will provide unusable data for the study.\n\nTo prevent participants from being overly vigilant in our activity of interest, the study name advertised on SONA will be \"Judgement of Pictures\".\n\nPotential participants will read: \u201cThe purpose of this research project is to explore people\u2019s judgments of others. This study requires you to USE A PC/LAPTOP! People who are visually impaired (blind or colour blind) may not participate in this study. Sorry for the inconvenience.\u201d\n\nData will be collected through the computerized database in \"Qualtrics\" using only a laptop or PC. If participants attempts to use a cellular device of any kind (e.g., Blackberry, Android, IPad, IPhone, etc.) to partake in the study, Qualtrics will automatically discontinue the study with a message reminder for them to \u201cPLEASE use a laptop or computer for this study!\u201d", "description-methods.planned-sample.question6b": "Our target sample size is 282 participants. \n\nWe used the software program G*Power to conduct our power analysis. A priori power analysis determined that we require N = 240 to reach statistical significance for a medium-sized effect with power (1 - \u00df) set at 0.80 at the standard .05 alpha error probability. However, we will attempt to recruit an additional 15% (n = 42) of our targeted N to account for potential data loss due to manipulation check failures, incompletion, technical difficulties, etc. ", "description-methods.planned-sample.question7b": "If participants attempt to use a cellular device of any kind (e.g., Blackberry, Android, IPad, iPhone, etc.) to partake in the study, Qualtrics will automatically discontinue the study with a message reminder for them to \u201cPLEASE use a laptop or computer for this study!\u201d Participants may restart the survey on either a laptop or computer. ", "confirmatory-analyses-fourth.fourth.question1c": "Metacognitive Judgments\n\nH5. Confidence: A MANOVA will be used to compare the level of confidence between participants who make gender categorization congruent vs. incongruent to the gender category suggested by the clothing. Alternatively, we may calculate the Cronbach\u2019s alpha of the confidence questions, if internal consistency is high a composite \u201cconfidence\u201d variable will be calculated and used in a t-test analysis (IV: Congruence, DV: Confidence). \n\nH5.a. Confidence (DVs: Gender confidence, height confidence, weight confidence, age confidence, and aggression confidence). Descriptive statistics will be calculated for all the confidence measures. \n\nH5.b., H5.c. Good view and speed of reporting: Two univariate ANOVAs will test the variables of gendered-clothing and time of gender judgment on (i) reported quality of view and (ii) reported speed of reporting. \n\nH5.d. To test if participants were aware that contextual information was affecting their reporting we will code their open-ended responses using the following rubric. To ensure inter-rater reliability, a second coder will independently score 50% of the total self-report Information on the factors that influenced participants gender judgment. This analysis will demonstrate the participants were largely unaware of the effect of context and rather believe they were using features of the person to categorize their gender.  \n\nH5.e. We will calculate the descriptives of the following question: \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) could have affected your judgments?\u201d and show that most participants selected \u201cNO.\u201d We will then code the written responses of those who answered \u201cYES\u201d  to determine how they believed order affected their reporting. ", "confirmatory-analyses-second.second.question1c": "Demographic and Character Judgements\n\nH1.a: (DV: Gender) We will use Chi-square test for goodness of fit to analyze whether our clothing manipulation influences participants\u2019 gender categorization. \n\nH2.a, H2.b, Ex.2., H3: (DVs: Height, Weight, Aggression) Factorial ANOVAs will be used to analyze participants\u2019 continuous outcome variables. \n\nEx: (DV: Age): T-tests will be used to analyze participants\u2019 estimation of Age. ", "confirmatory-analyses-further.further.question1c": "Exploratory Analysis\n\n*We would like to mention here that we may or may not look at these aspects of the data. The following are points of interest:\n\nEx.1: Gender selection and demographic reporting. We may divide our sample into participants who selected \u201cmale\u201d and \u201cfemale.\u201d This gender-selected variable may then be used as an IV in our univariate ANOVAs in which we test if people\u2019s selections of gender affect how they report when making demographic and aggression judgments.   \n\nEx.3: If we explore if speed of responding is related to a higher amount of consistency between clothing condition and gender categorization we will use a logistic regression to do so. Pearson correlations will test if there is a relationship between speed of reporting and the demographic and aggression judgments in each of the clothing conditions (MC and FC). \n\nEx.4: If tested, Pearson correlations would be used to explore the relationship between speed of reporting and metacognitive judgments. Ultimately testing if faster response times resulted in more validating metacognitive reports, i.e. more confident, better view, reporting that they were faster in their identification of gender. \n\nEx.5: We may also explore if participants who were congruent in their clothing condition/gender categorization varied from those who were incongruent in their metacognitive reporting. An ANOVAs would be used to explore this relationship with congruency (congruent/incongruent) and time of gender judgment (1st or last) being used as our IVs and confidence, view, and speed reports as our DVs.  ", "description-methods.exclusion-criteria.question8b": "Anticipated data exclusion criteria: \n\na). Participants who spend a disproportionate amount of time (e.g., hours) to complete the 15-minutes study.\nb). Participants who request to have their data deleted. \nc). Participants with incomplete data. \nd). Participants who indicate that they suffer from colour blindness. \ne). Participants who fail the manipulation checks - i.e., do not know the image on the sweatshirt of the individual or the colour of the individual\u2019s outfit. ", "description-methods.planned-sample.question6b-upload": [{"file_id": "5e3a0be4f1369e001b8af94b", "file_name": "GPower_Biasing Effects of Expectation on Person Perception 2020.JPG", "file_urls": {"html": "https://osf.io/p2ru3/files/osfstorage/5e3a0be4f1369e001b8af94b", "download": "https://osf.io/download/ckjp8/"}, "file_hashes": {"sha256": "42191814c3c25b25e72fa8e0d63704b426842d9a2eb4a4f603240a2cd49b3408"}}]}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/uygbe/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/uygbe/comments/?format=json&filter%5Btarget%5D=uygbe", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/uygbe/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/uygbe/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/uygbe/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/uygbe/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/uygbe/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/uygbe/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/uygbe/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/uygbe/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/uygbe/linked_by_registrations/?format=json", "meta": {}}}}, "parent": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/?format=json", "meta": {}}}, "data": {"id": "j927s", "type": "registrations"}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/uygbe/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/uygbe/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/uygbe/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/ca-1/?format=json", "meta": {}}}, "data": {"id": "ca-1", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/?format=json", "meta": {}}}, "data": {"id": "j927s", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/uygbe/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/uygbe/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/uygbe/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/uygbe/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/uygbe/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/uygbe/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/uygbe/citation/?format=json", "meta": {}}}, "data": {"id": "uygbe", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/85n6s/?format=json", "meta": {}}}, "data": {"id": "85n6s", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/jgsmh/?format=json", "meta": {}}}, "data": {"id": "jgsmh", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5730e99a9ad5a102c5745a8a/?format=json", "meta": {}}}, "data": {"id": "5730e99a9ad5a102c5745a8a", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/uygbe/", "self": "https://api.osf.io/v2/registrations/uygbe/"}}, {"id": "ha4p8", "type": "registrations", "attributes": {"title": "Procedure", "description": "", "category": "procedure", "custom_citation": "", "date_created": "2020-02-11T16:27:28.416145", "date_modified": "2020-02-09T19:25:44.153212", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "a749dbef338f92cceac735fa93cb9d7072e06af98914eeb7c640be3157b64985962f641e345e75e59850af7f56d11361517cb6b659ae267d238b0daafe3e5c3e8617723326f85e2476b899c87c5454f5c973d3db20502e8355a218629711f51bce5242d24acb655c3763d8be7d2ca64ac104e48d852ed65c7554578ee4a1371ce2c3039f069ff6233c323468f304b5f1", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-02-11T16:27:28.326345", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Pre-Registration in Social Psychology (van 't Veer & Giner-Sorolla, 2016): Pre-Registration", "registered_meta": {"looked": {"extra": [], "value": "No"}, "datacompletion": {"extra": [], "value": "No, data collection has not begun"}, "additionalComments": {"extra": [], "value": "Citations: \n\nHuart, J., Corneille, O., &amp; Becquart, E. (2005). Face-based categorization, context-based categorization, and distortions in the recollection of gender-ambiguous faces. Journal of Experimental Social Psychology, 41(6), 598-608. doi:10.1016/j.jesp.2004.10.007\n\nMapstone, L. (2015). Rihanna hides away under oversized gothic hoodie and baggy trousers for low-key arrival in Los Angeles after Paris love-in with Travis Scott [Online image]. MailOnline. Retrieved from: http://www.dailymail.co.uk/tvshowbiz/article-3262964/Rihanna-hides-away-oversized-gothic-hoodie-baggy-trousers-low-key-arrival-Los-Angeles-Paris-love-Travis-Scott.html "}, "dataCollectionDates": {"extra": [], "value": "February 2020 - February 2023\n"}, "description-methods": {"value": {"design": {"value": {"question2a": {"extra": [], "value": "This is a 2 Gendered-clothing (male clothing [MC] or female clothing [FC]) x 2 Gender-ambiguous face (Face 1 or Face 2) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) between-subjects factorial design. This is an orthogonal study design.\n"}, "question2b": {"extra": [], "value": "Dependent Variables: \n\n1. Demographic judgments of the individual in the image: categorical gender judgment (M or F), and continuous estimations of weight (open-ended), height (open-ended), and age (open-ended).\n\n2. Judgement of the social features of the individual in the image: level of aggression on a 9-point Likert scale (0 = \"Not aggressive\", 9 = \"Highly Aggressive\").\n\n3. Metacognitive judgment of the viewers experience: participant\u2019s confidence in their judgments (0 = \u201cNot Confident At All\u201d to 100 = \u201cExtremely Confident\u201d), the speed at which they made the gender judgment (open-ended), quality of the view of the individual\u2019s face (1 = \u201cVery Poor\u201d, 7 = \u201cVery Good\u201d), which factors the participant took into consideration when determining gender (open-ended), and how order of responding affected judgment (open-ended)."}, "question3b": {"extra": [], "value": "We do not anticipate using any covariate. However, it is possible that we may use reported age as a covariate if we are seeking to understand our findings on the demographic measures for those in the MC and FC.   "}}}, "procedure": {"value": {"question10b": {"extra": [], "value": "Manipulations and Measures\n\nThis is a 2 Gendered-clothing (male clothing [MC] or female clothing [FC]) x 2 Gender-ambiguous face (Face 1 or Face 2) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) between-subjects factorial design. \n\nDependent Variables\n\n1. Demographic judgments of the individual in the image: categorical gender judgment (M or F), and continuous estimations of weight (open-ended), height, (open-ended) and age (open-ended). \n\n2. Judgement on the social features of the individual in the image: level of aggression on a 9-point Likert scale (0 = \"Not aggressive\", 9 = \"Highly Aggressive\"). \n\n3. Metacognitive judgment of the viewers experience: (i) participant\u2019s confidence in each one of their demographic judgments (gender, weight, height, age) and aggression judgment, (ii) the estimated speed at which they made their gender judgment, (iii) quality of the view of the individual\u2019s face, (iv) which factors the participant took into consideration when determining the gender of the individual and (v) if they believe that the order that they answered the demographic questions could have affected their judgments. \n\nMaterials\n\nFace: Two gender-ambiguous faces were selected from a continuum of morphed male/female faces developed by Huart et al. (2005). Our Face 1 stimulus is a blend of 50% male and 50% female face (named \u201cMoprh 10-050\u201d in original paper; Huart et al., 2005), and our Face 2 stimulus is a blend of 70% female\u201330% male moderately ambiguous face (named \u201cMorph 7-030\u201d in original paper). \n\nClothing: We modified a single image by changing the colour and the logo on the clothing to make it either more \u201cmasculine\u201d or \u201cfeminine.\u201d The image was an anterior view of a person (the pop singer Rhianna) wearing a hooded sweatshirt and a pair of baggy pants (image retrieved from Google Image; Mapstone, 2015). The baggy clothing obscured the physique of the person. Photo editing software was used to alter the logo on the sweatshirt and the clothing colour. \n\nWe conducted a pilot study with four clothing stimuli to test their levels of perceived masculinity and femininity. Sixty undergraduate students (49 females, 11 males) participated in the study and were asked to rate on a 9-point Likert scale (1 = \u201cOnly Women\u201d; 9 = \u201cOnly Men\u201d) on whether men or women are more likely to wear the outfit presented. Descriptive results revealed two outfits were rated as relatively equal in magnitude; one on the quality of \u201cfeminine\u201d and one on the quality of \u201cmasculine\u201d while maintaining low variances. The feminine outfit selected was an entirely pink outfit with an image of a pair of red lips above the letters \u201cXOXO\u201d on the sweater (M = 2.88, SD = 1.42). The masculine outfit selected was black pants and a brown sweatshirt with an image of a woman in lingerie (M = 6.38, SD = 1.59). \n\nFinal stimuli: Photo editing software was used to incorporate each of the two faces (Face 1 and Face 2) with the masculine (i.e., black pants and a brown sweatshirt with an image of a woman in lingerie) and feminine (i.e., pink pants and a pink sweatshirt with an image of a pair of red lips above \u201cXOXO\u201d) outfits. A fringe of gender-neutral hair was added to the forehead area of each image to make the final images of the people appear more realistic. \n\nProcedure\n\nParticipants will use either a laptop or a computer to participate \u2013 attempting to use any cellular devices will result in automatic termination of the survey (ballot box stuffing disabled).\n\nScreen 1: Consent form \u2013 participants who click the \u201cyes, I would like to participate\u201d to continue and those who click \u201cNo, I do not consent to participating in this study\u201d will be brought to the end of the survey. All participants receive credit regardless of if they complete the survey.\n\nScreen 2: Participants are instructed to: \u201cPay attention to the images you are about to see, and answer the following questions about the image as quickly and honestly as possible.\u201d\n\nScreens 3-14: Participants make judgements on twelve filler task questions. These tasks require participants to make judgments on visual stimuli. For instance, how many red jelly beans are there in a jar of beans or what was the colour of horses seen in an image. The filler tasks are included to prevent participants from being overly vigilant in our activity of interest, which will be the final task.\n\nScreens 15-25: Participants make demographic and character judgments of a person who has a gender-ambiguous face (F1 or F4) is wearing clothing that has been modified to be either female (FC) or male (MC). Importantly the image of the person will remain on the screen while participants make all of the demographic judgments, their aggression judgment, as well as, their confidence judgments:\n\n*Half of participants will receive the gender question as the first judgment they make of the individual in the image; half will be asked to judge gender at the end of the person judgments:\n\nGender Judgment: \u201cPlease select the gender of this person:\u201d Screen presents a centered image of a person in either the MC or FC with one of the two gender-neutral faces (F1 or F4). There is a forced-choice option underneath for participants to select either \u201cMale\u201d or \u201cFemale\u201d.\n\nParticipants will receive one of two presentation options: Order1: male option on the left and female option on the right OR Order2: female option on the left and male option on the right.\n\nFollowing the gender judgment, a new screen asks participants to rate their confidence about their gender judgment while the image of the person remains on screen (0 = \"Not Confident At All\" to 100 = \"Extremely Confident\"). Their gender selection is not visible on the confidence screen.\n\nContinuous Demographic and Character Judgements (the order of the four questions will be randomly presented to participants): \n      a). Weight: \u201cPlease estimate the weight of the person in the image (in pounds/lbs)\u201d (Open-ended)\n      b). Height: \u201cPlease estimate the height of the person in the image (in ft and inches)\u201d (Open-ended)\n      c). Age: \u201cPlease estimate the age of the person in the image (in years)\u201d (Open-ended)\n      d). Aggression: \u201cRate how aggressive the person in the image seems\u201d (0 = \"Not aggressive\", 9 = \"Highly Aggressive\")\n\nFollowing each of the four judgements, a new screen will ask participants to rate their confidence about their judgement while the image of the person remains on screen (0 = \"Not Confident At All\", 100 = \"Extremely Confident\"). However, their response to the question is not visible to participants when they rate their confidence in their response. \n \n*The half of participants who did not receive the gender question at the outset of this task are asked the gender question at this point. \n\n*For each of the questions from screens 3-25, including confidence, participants are given a maximum of 10 minutes to respond, but they are allowed to respond and advance to the next question before the timer is up (timer is hidden from participants).\n\nScreens 26-29: Participants are asked follow-up questions regarding the image they saw.\n\nMetacognitive Questions (the order of the three questions will be counterbalanced between participants):\n     a). View of face: \u201cHow good of a view did you get of the person in the image?\u201d (Likert scale between 1-7 with 1 = Very Poor, 7 = Very Good).\n     b). Self-Reported Speed: \u201cEstimate how quickly you answered the question about the person\u2019s gender (in seconds):\u201d (Open-ended)\n     c). Factors the participant took into consideration when determining gender: \u201cWhat did you look in the image to determine the gender of the person (please be specific)?\u201d (Open-ended)\n     d). If the participant was aware of how order could affect their responding: \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) about the individual in the image could have affected your judgments?\u201d (Yes/No). If yes, \u201cYou answered yes, please answer how your judgments could have been affected by the order you received the questions?\u201d (open-ended)\n\nScreens 30-31: Manipulation Checks: \u201cWhat was the colour of the sweatshirt?\u201d (open-ended) and \u201cWhat was the logo on the sweatshirt?\u201d (open-ended)\n\nScreens 32-35: Demographics. Each question will be presented on separate screens (with the exception of the two questions about gender): \n1. \u201cWhat is your age?\u201d (Open-ended) \n2. \u201cAre you currently the same gender you were assigned at birth?\u201d (Open-ended) and \u201cWhat is your gender?\u201d (Options: Male/Female/Other [Please specify])\n3. \u201cDo you suffer from colour blindness?\u201d (Yes/No). If participant answers \"YES\", then they are prompted to answer a follow-up question: \u201cPlease list the colours that you cannot see:\u201d (Open-ended) \n4. \u201cMy ethnicity is (if mixed, select more than one or specify under \"other\")\u2026\u201d (Multiple Choice) \n\nScreen 36: Debriefing form outlining the purpose of the study and researchers\u2019 contact information. The following is placed at the end of the debriefing form: \"Thank you for participating in our study! We value your participation greatly. However, if you feel uncomfortable about your participation in the study today and would like your data removed, please enter 'erase my data'\" (Text box is provided)\n"}}}, "planned-sample": {"value": {"question4b": {"extra": [], "value": "Participants will be randomly allocated into one of the following conditions:\n\nFace 1 and FC\nFace 1 and MC\nFace 2 and FC\nFace 2 and MC\n\nHalf of the participants within each condition above will also be sorted into the following DV orders:\n\nOrder 1: Gender categorization and then Demographic and aggression judgements\nOrder 2: Demographic and aggression judgements and then Gender categorization"}, "question5b": {"extra": [], "value": "Participants will be recruited through the Kwantlen Polytechnic University Psychology Research Pool System and will be granted 0.5% bonus course credit for their time. Subjects who are visually impaired (i.e., blindness or colour blindness) will be excluded from the study. The \u201cmasculine\u201d and \u201cfeminine\u201d clothing is gendered via its colour (e.g., brown for male and pink for female). Thus, participants must have full function of their colour vision or have visual aids such as glasses for proper visual perception. Participants who cannot see colours (or at all) will provide unusable data for the study.\n\nTo prevent participants from being overly vigilant in our activity of interest, the study name advertised on SONA will be \"Judgement of Pictures\".\n\nPotential participants will read: \u201cThe purpose of this research project is to explore people\u2019s judgments of others. This study requires you to USE A PC/LAPTOP! People who are visually impaired (blind or colour blind) may not participate in this study. Sorry for the inconvenience.\u201d\n\nData will be collected through the computerized database in \"Qualtrics\" using only a laptop or PC. If participants attempts to use a cellular device of any kind (e.g., Blackberry, Android, IPad, IPhone, etc.) to partake in the study, Qualtrics will automatically discontinue the study with a message reminder for them to \u201cPLEASE use a laptop or computer for this study!\u201d"}, "question6b": {"extra": [], "value": "Our target sample size is 282 participants. \n\nWe used the software program G*Power to conduct our power analysis. A priori power analysis determined that we require N = 240 to reach statistical significance for a medium-sized effect with power (1 - \u00df) set at 0.80 at the standard .05 alpha error probability. However, we will attempt to recruit an additional 15% (n = 42) of our targeted N to account for potential data loss due to manipulation check failures, incompletion, technical difficulties, etc. "}, "question7b": {"extra": [], "value": "If participants attempt to use a cellular device of any kind (e.g., Blackberry, Android, IPad, iPhone, etc.) to partake in the study, Qualtrics will automatically discontinue the study with a message reminder for them to \u201cPLEASE use a laptop or computer for this study!\u201d Participants may restart the survey on either a laptop or computer. "}, "question6b-upload": {"extra": [{"data": {"name": "GPower_Biasing Effects of Expectation on Person Perception 2020.JPG"}, "nodeId": "p2ru3", "sha256": "42191814c3c25b25e72fa8e0d63704b426842d9a2eb4a4f603240a2cd49b3408", "viewUrl": "/project/p2ru3/files/osfstorage/5e3a0be4f1369e001b8af94b", "selectedFileName": "GPower_Biasing Effects of Expectation on Person Perception 2020.JPG"}], "value": ""}}}, "exclusion-criteria": {"value": {"question8b": {"extra": [], "value": "Anticipated data exclusion criteria: \n\na). Participants who spend a disproportionate amount of time (e.g., hours) to complete the 15-minutes study.\nb). Participants who request to have their data deleted. \nc). Participants with incomplete data. \nd). Participants who indicate that they suffer from colour blindness. \ne). Participants who fail the manipulation checks - i.e., do not know the image on the sweatshirt of the individual or the colour of the individual\u2019s outfit. "}}}}}, "recommended-methods": {"value": {"procedure": {"value": {"question9b": {"extra": [], "value": "Participants will use either a laptop or a computer to participate \u2013 attempting to use any cellular devices will result in automatic termination of the survey (ballot box stuffing disabled). "}, "question9b-file": {"extra": [], "value": ""}}}}}, "recommended-analysis": {"value": {"specify": {"value": {"question6c": {"extra": [], "value": ""}, "question7c": {"extra": [], "value": "The data of participants who do not complete the study will not be used in analyses. "}, "question8c": {"extra": [], "value": ""}, "question9c": {"extra": [], "value": "Outlier ratings of continuous DVs may be replaced with the mean rating from the sample. Any manipulation of this kind will be clearly articulated in a manuscript prepared for publication."}, "question10c": {"extra": [], "value": "If assumptions of our parametrics tests are violated we will seek non-parametric options for data analysis. "}, "question11c": {"extra": [], "value": ""}}}}}, "description-hypothesis": {"value": {"question1a": {"extra": [], "value": "Gender-Ambiguous face\n\nTwo gender-ambiguous faces were counterbalanced in this research to enhance the generalizability of our findings. We do not expect any effect of this variable.\nGendered Clothing Manipulation\n\nH1 \u201cGender Judgment\u201d: We predict that pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result participants categorizing the individual in the gender category suggested by the clothing (MC or FC).\n\nH2 \u201cDemographic Judgments\u201d: We predict that a pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result in demographic judgments (height, weight) consistent with the gender category suggested by the clothing (MC or FC).\n\nH2.a: (DV: Height): Participants in the MC condition will estimate the individual to be taller than participants\u2019 estimations of the same individual in the FC condition.\n\nH2.b: (DV: Weight): Participants in the MC condition will estimate the individual to be heavier than participants\u2019 estimations of the same individual in the FC condition.\n\nH3 \u201cAggression Judgment\u201d: We predict that pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result in an aggression judgment consistent with the gender category suggested by the clothing (MC or FC). Specifically, participants in the MC condition would rate the individual to be more aggressive than participants\u2019 estimations of the same individual in the FC condition.\n\nGender Judgment Manipulation\n\nH4: \u201cDemographic and Aggression Judgments\u201d We predict a 2 Gendered-clothing (MC or FC) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) interaction on the height, weight and aggression variables.\n\nSpecifically, participants who are asked to categorize the gender of the individual first, i.e., prior to judging demographic and aggression variables, will provide responses to the demographic and aggression judgments that are more representative of their gender categorization (i.e., male is heavier, taller and more aggressive; female is shorter, lighter and less aggressive) than participants who are asked to gender categorize the individual as their last judgment, i.e., after judging demographics and character variables.\n\nH5 \u201cMetacognitive Judgments of Performance\u201d: We predict that participants will:\n\nH5.a. Be confident in their gender, demographic, and aggression judgments of the individual.\n\nH5.b. Report that they had a good view of the person in the image.\n\nH5.c. Report that they were fast in their categorization of gender regardless of their speed.\n\nH5.d. Be largely unaware that contextual variables \u2013 (i) clothing manipulation and (ii) time of gender judgment - affected their reporting. That is, first, when asked what they considered when categorizing the gender of the person in the image the majority of participants will report that the used biological features of the individual (entire face or facial features, shape and stature of the body) versus reporting contextual information found on the clothing (colour and image). Second, when asked \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) could have affected your judgments? Yes/No, we predict that the majority of participant will respond \u201cNO.\u201d\n\nPossible Exploratory\n\nEx.1 Gender categorization: We may explore if peoples gender categorizations had a relationship with the demographic, aggression and metacognitive variables in our study. This analysis is different than our gender manipulation because it will use gender categorization as the independent variable in our analysis, not gendered-clothing condition.\n\nEx.2 (DV: Age): We will explore if participants who categorize the individual as \u201cMale\u201d will estimate the age of the individual as younger than participants who categorize the individual as \u201cFemale.\u201d\n\nEx.3: We may explore if speed of responding is related to a higher amount of consistency between clothing condition and gender categorization, as well as judgments that are more congruent with the gender category.\n\nEx.4: We may explore the relationship between speed of reporting and metacognitive judgments. Ultimately testing if faster response times resulted in more validating metacognitive reports, i.e. more confident, better view, reporting that they were faster in their identification of gender.\n\nEx.5: We may also explore if the metacognitive judgments of participants who were congruent in their clothing condition/gender categorization varied from those who were incongruent."}, "question2a": {"extra": [], "value": "N/A"}, "question3a": {"extra": [], "value": "We will include two manipulation checks at the end of the study. Participants will be asked 1. \u201cWhat was the colour of the sweatshirt that the individual was wearing?\", and 2. \u201cWhat was the image on the sweatshirt?\u201d to verify that they paid attention to our visual manipulation."}}}, "recommended-hypothesis": {"value": {"question4a": {"extra": [], "value": ""}, "question5a": {"extra": [], "value": ""}, "question6a": {"extra": [], "value": ""}}}, "confirmatory-analyses-first": {"value": {"first": {"value": {"question1c": {"extra": [], "value": "We will use chi-square test for goodness of fit to analyze whether Face 1 and Face 2 performed similarly. We anticipate that they will, and the face variable will be collapsed in all subsequent analyses. \n\nPhi coefficient and the CI for \u0424 will be calculated using Cumming\u2019s Exploratory Software for Confidence Intervals (ESCI). Cohen\u2019s d and the CI of d will be calculated using Cumming\u2019s formulas, d=((M2-M1))/s and  \u2206 =  (\u03bc2- \u03bc1 )/(\u03b4\u221a(1/N1+1/N2)) respectively in ESCI. "}, "question2c": {"extra": [], "value": "See above. "}, "question3c": {"extra": [], "value": "See above. "}, "question4c": {"extra": [], "value": "N/A"}, "question5c": {"extra": [], "value": "N/A"}}}}}, "confirmatory-analyses-third": {"value": {"third": {"value": {"question1c": {"extra": [], "value": "Time of Gender Judgement \n\nH4: Multiple between-subject ANAOVAs will test the relationship between gendered outfit (FC or MC) and time of gender judgment (1st question, last question) on the variables of weight, height, age and aggression. This analysis will test if asking the gender question at the end of the demographic questions helps to mitigate the effect of gender perception on demographic reporting.  "}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}, "confirmatory-analyses-fourth": {"value": {"fourth": {"value": {"question1c": {"extra": [], "value": "Metacognitive Judgments\n\nH5. Confidence: A MANOVA will be used to compare the level of confidence between participants who make gender categorization congruent vs. incongruent to the gender category suggested by the clothing. Alternatively, we may calculate the Cronbach\u2019s alpha of the confidence questions, if internal consistency is high a composite \u201cconfidence\u201d variable will be calculated and used in a t-test analysis (IV: Congruence, DV: Confidence). \n\nH5.a. Confidence (DVs: Gender confidence, height confidence, weight confidence, age confidence, and aggression confidence). Descriptive statistics will be calculated for all the confidence measures. \n\nH5.b., H5.c. Good view and speed of reporting: Two univariate ANOVAs will test the variables of gendered-clothing and time of gender judgment on (i) reported quality of view and (ii) reported speed of reporting. \n\nH5.d. To test if participants were aware that contextual information was affecting their reporting we will code their open-ended responses using the following rubric. To ensure inter-rater reliability, a second coder will independently score 50% of the total self-report Information on the factors that influenced participants gender judgment. This analysis will demonstrate the participants were largely unaware of the effect of context and rather believe they were using features of the person to categorize their gender.  \n\nH5.e. We will calculate the descriptives of the following question: \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) could have affected your judgments?\u201d and show that most participants selected \u201cNO.\u201d We will then code the written responses of those who answered \u201cYES\u201d  to determine how they believed order affected their reporting. "}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}, "confirmatory-analyses-second": {"value": {"second": {"value": {"question1c": {"extra": [], "value": "Demographic and Character Judgements\n\nH1.a: (DV: Gender) We will use Chi-square test for goodness of fit to analyze whether our clothing manipulation influences participants\u2019 gender categorization. \n\nH2.a, H2.b, Ex.2., H3: (DVs: Height, Weight, Aggression) Factorial ANOVAs will be used to analyze participants\u2019 continuous outcome variables. \n\nEx: (DV: Age): T-tests will be used to analyze participants\u2019 estimation of Age. "}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}, "confirmatory-analyses-further": {"value": {"further": {"value": {"question1c": {"extra": [], "value": "Exploratory Analysis\n\n*We would like to mention here that we may or may not look at these aspects of the data. The following are points of interest:\n\nEx.1: Gender selection and demographic reporting. We may divide our sample into participants who selected \u201cmale\u201d and \u201cfemale.\u201d This gender-selected variable may then be used as an IV in our univariate ANOVAs in which we test if people\u2019s selections of gender affect how they report when making demographic and aggression judgments.   \n\nEx.3: If we explore if speed of responding is related to a higher amount of consistency between clothing condition and gender categorization we will use a logistic regression to do so. Pearson correlations will test if there is a relationship between speed of reporting and the demographic and aggression judgments in each of the clothing conditions (MC and FC). \n\nEx.4: If tested, Pearson correlations would be used to explore the relationship between speed of reporting and metacognitive judgments. Ultimately testing if faster response times resulted in more validating metacognitive reports, i.e. more confident, better view, reporting that they were faster in their identification of gender. \n\nEx.5: We may also explore if participants who were congruent in their clothing condition/gender categorization varied from those who were incongruent in their metacognitive reporting. An ANOVAs would be used to explore this relationship with congruency (congruent/incongruent) and time of gender judgment (1st or last) being used as our IVs and confidence, view, and speed reports as our DVs.  "}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}}, "registration_responses": {"looked": "No", "datacompletion": "No, data collection has not begun", "additionalComments": "Citations: \n\nHuart, J., Corneille, O., &amp; Becquart, E. (2005). Face-based categorization, context-based categorization, and distortions in the recollection of gender-ambiguous faces. Journal of Experimental Social Psychology, 41(6), 598-608. doi:10.1016/j.jesp.2004.10.007\n\nMapstone, L. (2015). Rihanna hides away under oversized gothic hoodie and baggy trousers for low-key arrival in Los Angeles after Paris love-in with Travis Scott [Online image]. MailOnline. Retrieved from: http://www.dailymail.co.uk/tvshowbiz/article-3262964/Rihanna-hides-away-oversized-gothic-hoodie-baggy-trousers-low-key-arrival-Los-Angeles-Paris-love-Travis-Scott.html ", "dataCollectionDates": "February 2020 - February 2023\n", "description-hypothesis.question1a": "Gender-Ambiguous face\n\nTwo gender-ambiguous faces were counterbalanced in this research to enhance the generalizability of our findings. We do not expect any effect of this variable.\nGendered Clothing Manipulation\n\nH1 \u201cGender Judgment\u201d: We predict that pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result participants categorizing the individual in the gender category suggested by the clothing (MC or FC).\n\nH2 \u201cDemographic Judgments\u201d: We predict that a pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result in demographic judgments (height, weight) consistent with the gender category suggested by the clothing (MC or FC).\n\nH2.a: (DV: Height): Participants in the MC condition will estimate the individual to be taller than participants\u2019 estimations of the same individual in the FC condition.\n\nH2.b: (DV: Weight): Participants in the MC condition will estimate the individual to be heavier than participants\u2019 estimations of the same individual in the FC condition.\n\nH3 \u201cAggression Judgment\u201d: We predict that pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result in an aggression judgment consistent with the gender category suggested by the clothing (MC or FC). Specifically, participants in the MC condition would rate the individual to be more aggressive than participants\u2019 estimations of the same individual in the FC condition.\n\nGender Judgment Manipulation\n\nH4: \u201cDemographic and Aggression Judgments\u201d We predict a 2 Gendered-clothing (MC or FC) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) interaction on the height, weight and aggression variables.\n\nSpecifically, participants who are asked to categorize the gender of the individual first, i.e., prior to judging demographic and aggression variables, will provide responses to the demographic and aggression judgments that are more representative of their gender categorization (i.e., male is heavier, taller and more aggressive; female is shorter, lighter and less aggressive) than participants who are asked to gender categorize the individual as their last judgment, i.e., after judging demographics and character variables.\n\nH5 \u201cMetacognitive Judgments of Performance\u201d: We predict that participants will:\n\nH5.a. Be confident in their gender, demographic, and aggression judgments of the individual.\n\nH5.b. Report that they had a good view of the person in the image.\n\nH5.c. Report that they were fast in their categorization of gender regardless of their speed.\n\nH5.d. Be largely unaware that contextual variables \u2013 (i) clothing manipulation and (ii) time of gender judgment - affected their reporting. That is, first, when asked what they considered when categorizing the gender of the person in the image the majority of participants will report that the used biological features of the individual (entire face or facial features, shape and stature of the body) versus reporting contextual information found on the clothing (colour and image). Second, when asked \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) could have affected your judgments? Yes/No, we predict that the majority of participant will respond \u201cNO.\u201d\n\nPossible Exploratory\n\nEx.1 Gender categorization: We may explore if peoples gender categorizations had a relationship with the demographic, aggression and metacognitive variables in our study. This analysis is different than our gender manipulation because it will use gender categorization as the independent variable in our analysis, not gendered-clothing condition.\n\nEx.2 (DV: Age): We will explore if participants who categorize the individual as \u201cMale\u201d will estimate the age of the individual as younger than participants who categorize the individual as \u201cFemale.\u201d\n\nEx.3: We may explore if speed of responding is related to a higher amount of consistency between clothing condition and gender categorization, as well as judgments that are more congruent with the gender category.\n\nEx.4: We may explore the relationship between speed of reporting and metacognitive judgments. Ultimately testing if faster response times resulted in more validating metacognitive reports, i.e. more confident, better view, reporting that they were faster in their identification of gender.\n\nEx.5: We may also explore if the metacognitive judgments of participants who were congruent in their clothing condition/gender categorization varied from those who were incongruent.", "description-hypothesis.question2a": "N/A", "description-hypothesis.question3a": "We will include two manipulation checks at the end of the study. Participants will be asked 1. \u201cWhat was the colour of the sweatshirt that the individual was wearing?\", and 2. \u201cWhat was the image on the sweatshirt?\u201d to verify that they paid attention to our visual manipulation.", "description-methods.design.question2a": "This is a 2 Gendered-clothing (male clothing [MC] or female clothing [FC]) x 2 Gender-ambiguous face (Face 1 or Face 2) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) between-subjects factorial design. This is an orthogonal study design.\n", "description-methods.design.question2b": "Dependent Variables: \n\n1. Demographic judgments of the individual in the image: categorical gender judgment (M or F), and continuous estimations of weight (open-ended), height (open-ended), and age (open-ended).\n\n2. Judgement of the social features of the individual in the image: level of aggression on a 9-point Likert scale (0 = \"Not aggressive\", 9 = \"Highly Aggressive\").\n\n3. Metacognitive judgment of the viewers experience: participant\u2019s confidence in their judgments (0 = \u201cNot Confident At All\u201d to 100 = \u201cExtremely Confident\u201d), the speed at which they made the gender judgment (open-ended), quality of the view of the individual\u2019s face (1 = \u201cVery Poor\u201d, 7 = \u201cVery Good\u201d), which factors the participant took into consideration when determining gender (open-ended), and how order of responding affected judgment (open-ended).", "description-methods.design.question3b": "We do not anticipate using any covariate. However, it is possible that we may use reported age as a covariate if we are seeking to understand our findings on the demographic measures for those in the MC and FC.   ", "recommended-analysis.specify.question6c": "", "recommended-analysis.specify.question7c": "The data of participants who do not complete the study will not be used in analyses. ", "recommended-analysis.specify.question8c": "", "recommended-analysis.specify.question9c": "Outlier ratings of continuous DVs may be replaced with the mean rating from the sample. Any manipulation of this kind will be clearly articulated in a manuscript prepared for publication.", "recommended-analysis.specify.question10c": "If assumptions of our parametrics tests are violated we will seek non-parametric options for data analysis. ", "recommended-analysis.specify.question11c": [], "recommended-methods.procedure.question9b": "Participants will use either a laptop or a computer to participate \u2013 attempting to use any cellular devices will result in automatic termination of the survey (ballot box stuffing disabled). ", "description-methods.procedure.question10b": "Manipulations and Measures\n\nThis is a 2 Gendered-clothing (male clothing [MC] or female clothing [FC]) x 2 Gender-ambiguous face (Face 1 or Face 2) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) between-subjects factorial design. \n\nDependent Variables\n\n1. Demographic judgments of the individual in the image: categorical gender judgment (M or F), and continuous estimations of weight (open-ended), height, (open-ended) and age (open-ended). \n\n2. Judgement on the social features of the individual in the image: level of aggression on a 9-point Likert scale (0 = \"Not aggressive\", 9 = \"Highly Aggressive\"). \n\n3. Metacognitive judgment of the viewers experience: (i) participant\u2019s confidence in each one of their demographic judgments (gender, weight, height, age) and aggression judgment, (ii) the estimated speed at which they made their gender judgment, (iii) quality of the view of the individual\u2019s face, (iv) which factors the participant took into consideration when determining the gender of the individual and (v) if they believe that the order that they answered the demographic questions could have affected their judgments. \n\nMaterials\n\nFace: Two gender-ambiguous faces were selected from a continuum of morphed male/female faces developed by Huart et al. (2005). Our Face 1 stimulus is a blend of 50% male and 50% female face (named \u201cMoprh 10-050\u201d in original paper; Huart et al., 2005), and our Face 2 stimulus is a blend of 70% female\u201330% male moderately ambiguous face (named \u201cMorph 7-030\u201d in original paper). \n\nClothing: We modified a single image by changing the colour and the logo on the clothing to make it either more \u201cmasculine\u201d or \u201cfeminine.\u201d The image was an anterior view of a person (the pop singer Rhianna) wearing a hooded sweatshirt and a pair of baggy pants (image retrieved from Google Image; Mapstone, 2015). The baggy clothing obscured the physique of the person. Photo editing software was used to alter the logo on the sweatshirt and the clothing colour. \n\nWe conducted a pilot study with four clothing stimuli to test their levels of perceived masculinity and femininity. Sixty undergraduate students (49 females, 11 males) participated in the study and were asked to rate on a 9-point Likert scale (1 = \u201cOnly Women\u201d; 9 = \u201cOnly Men\u201d) on whether men or women are more likely to wear the outfit presented. Descriptive results revealed two outfits were rated as relatively equal in magnitude; one on the quality of \u201cfeminine\u201d and one on the quality of \u201cmasculine\u201d while maintaining low variances. The feminine outfit selected was an entirely pink outfit with an image of a pair of red lips above the letters \u201cXOXO\u201d on the sweater (M = 2.88, SD = 1.42). The masculine outfit selected was black pants and a brown sweatshirt with an image of a woman in lingerie (M = 6.38, SD = 1.59). \n\nFinal stimuli: Photo editing software was used to incorporate each of the two faces (Face 1 and Face 2) with the masculine (i.e., black pants and a brown sweatshirt with an image of a woman in lingerie) and feminine (i.e., pink pants and a pink sweatshirt with an image of a pair of red lips above \u201cXOXO\u201d) outfits. A fringe of gender-neutral hair was added to the forehead area of each image to make the final images of the people appear more realistic. \n\nProcedure\n\nParticipants will use either a laptop or a computer to participate \u2013 attempting to use any cellular devices will result in automatic termination of the survey (ballot box stuffing disabled).\n\nScreen 1: Consent form \u2013 participants who click the \u201cyes, I would like to participate\u201d to continue and those who click \u201cNo, I do not consent to participating in this study\u201d will be brought to the end of the survey. All participants receive credit regardless of if they complete the survey.\n\nScreen 2: Participants are instructed to: \u201cPay attention to the images you are about to see, and answer the following questions about the image as quickly and honestly as possible.\u201d\n\nScreens 3-14: Participants make judgements on twelve filler task questions. These tasks require participants to make judgments on visual stimuli. For instance, how many red jelly beans are there in a jar of beans or what was the colour of horses seen in an image. The filler tasks are included to prevent participants from being overly vigilant in our activity of interest, which will be the final task.\n\nScreens 15-25: Participants make demographic and character judgments of a person who has a gender-ambiguous face (F1 or F4) is wearing clothing that has been modified to be either female (FC) or male (MC). Importantly the image of the person will remain on the screen while participants make all of the demographic judgments, their aggression judgment, as well as, their confidence judgments:\n\n*Half of participants will receive the gender question as the first judgment they make of the individual in the image; half will be asked to judge gender at the end of the person judgments:\n\nGender Judgment: \u201cPlease select the gender of this person:\u201d Screen presents a centered image of a person in either the MC or FC with one of the two gender-neutral faces (F1 or F4). There is a forced-choice option underneath for participants to select either \u201cMale\u201d or \u201cFemale\u201d.\n\nParticipants will receive one of two presentation options: Order1: male option on the left and female option on the right OR Order2: female option on the left and male option on the right.\n\nFollowing the gender judgment, a new screen asks participants to rate their confidence about their gender judgment while the image of the person remains on screen (0 = \"Not Confident At All\" to 100 = \"Extremely Confident\"). Their gender selection is not visible on the confidence screen.\n\nContinuous Demographic and Character Judgements (the order of the four questions will be randomly presented to participants): \n      a). Weight: \u201cPlease estimate the weight of the person in the image (in pounds/lbs)\u201d (Open-ended)\n      b). Height: \u201cPlease estimate the height of the person in the image (in ft and inches)\u201d (Open-ended)\n      c). Age: \u201cPlease estimate the age of the person in the image (in years)\u201d (Open-ended)\n      d). Aggression: \u201cRate how aggressive the person in the image seems\u201d (0 = \"Not aggressive\", 9 = \"Highly Aggressive\")\n\nFollowing each of the four judgements, a new screen will ask participants to rate their confidence about their judgement while the image of the person remains on screen (0 = \"Not Confident At All\", 100 = \"Extremely Confident\"). However, their response to the question is not visible to participants when they rate their confidence in their response. \n \n*The half of participants who did not receive the gender question at the outset of this task are asked the gender question at this point. \n\n*For each of the questions from screens 3-25, including confidence, participants are given a maximum of 10 minutes to respond, but they are allowed to respond and advance to the next question before the timer is up (timer is hidden from participants).\n\nScreens 26-29: Participants are asked follow-up questions regarding the image they saw.\n\nMetacognitive Questions (the order of the three questions will be counterbalanced between participants):\n     a). View of face: \u201cHow good of a view did you get of the person in the image?\u201d (Likert scale between 1-7 with 1 = Very Poor, 7 = Very Good).\n     b). Self-Reported Speed: \u201cEstimate how quickly you answered the question about the person\u2019s gender (in seconds):\u201d (Open-ended)\n     c). Factors the participant took into consideration when determining gender: \u201cWhat did you look in the image to determine the gender of the person (please be specific)?\u201d (Open-ended)\n     d). If the participant was aware of how order could affect their responding: \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) about the individual in the image could have affected your judgments?\u201d (Yes/No). If yes, \u201cYou answered yes, please answer how your judgments could have been affected by the order you received the questions?\u201d (open-ended)\n\nScreens 30-31: Manipulation Checks: \u201cWhat was the colour of the sweatshirt?\u201d (open-ended) and \u201cWhat was the logo on the sweatshirt?\u201d (open-ended)\n\nScreens 32-35: Demographics. Each question will be presented on separate screens (with the exception of the two questions about gender): \n1. \u201cWhat is your age?\u201d (Open-ended) \n2. \u201cAre you currently the same gender you were assigned at birth?\u201d (Open-ended) and \u201cWhat is your gender?\u201d (Options: Male/Female/Other [Please specify])\n3. \u201cDo you suffer from colour blindness?\u201d (Yes/No). If participant answers \"YES\", then they are prompted to answer a follow-up question: \u201cPlease list the colours that you cannot see:\u201d (Open-ended) \n4. \u201cMy ethnicity is (if mixed, select more than one or specify under \"other\")\u2026\u201d (Multiple Choice) \n\nScreen 36: Debriefing form outlining the purpose of the study and researchers\u2019 contact information. The following is placed at the end of the debriefing form: \"Thank you for participating in our study! We value your participation greatly. However, if you feel uncomfortable about your participation in the study today and would like your data removed, please enter 'erase my data'\" (Text box is provided)\n", "confirmatory-analyses-first.first.question1c": "We will use chi-square test for goodness of fit to analyze whether Face 1 and Face 2 performed similarly. We anticipate that they will, and the face variable will be collapsed in all subsequent analyses. \n\nPhi coefficient and the CI for \u0424 will be calculated using Cumming\u2019s Exploratory Software for Confidence Intervals (ESCI). Cohen\u2019s d and the CI of d will be calculated using Cumming\u2019s formulas, d=((M2-M1))/s and  \u2206 =  (\u03bc2- \u03bc1 )/(\u03b4\u221a(1/N1+1/N2)) respectively in ESCI. ", "confirmatory-analyses-first.first.question2c": "See above. ", "confirmatory-analyses-first.first.question3c": "See above. ", "confirmatory-analyses-first.first.question4c": "N/A", "confirmatory-analyses-first.first.question5c": "N/A", "confirmatory-analyses-third.third.question1c": "Time of Gender Judgement \n\nH4: Multiple between-subject ANAOVAs will test the relationship between gendered outfit (FC or MC) and time of gender judgment (1st question, last question) on the variables of weight, height, age and aggression. This analysis will test if asking the gender question at the end of the demographic questions helps to mitigate the effect of gender perception on demographic reporting.  ", "description-methods.planned-sample.question4b": "Participants will be randomly allocated into one of the following conditions:\n\nFace 1 and FC\nFace 1 and MC\nFace 2 and FC\nFace 2 and MC\n\nHalf of the participants within each condition above will also be sorted into the following DV orders:\n\nOrder 1: Gender categorization and then Demographic and aggression judgements\nOrder 2: Demographic and aggression judgements and then Gender categorization", "description-methods.planned-sample.question5b": "Participants will be recruited through the Kwantlen Polytechnic University Psychology Research Pool System and will be granted 0.5% bonus course credit for their time. Subjects who are visually impaired (i.e., blindness or colour blindness) will be excluded from the study. The \u201cmasculine\u201d and \u201cfeminine\u201d clothing is gendered via its colour (e.g., brown for male and pink for female). Thus, participants must have full function of their colour vision or have visual aids such as glasses for proper visual perception. Participants who cannot see colours (or at all) will provide unusable data for the study.\n\nTo prevent participants from being overly vigilant in our activity of interest, the study name advertised on SONA will be \"Judgement of Pictures\".\n\nPotential participants will read: \u201cThe purpose of this research project is to explore people\u2019s judgments of others. This study requires you to USE A PC/LAPTOP! People who are visually impaired (blind or colour blind) may not participate in this study. Sorry for the inconvenience.\u201d\n\nData will be collected through the computerized database in \"Qualtrics\" using only a laptop or PC. If participants attempts to use a cellular device of any kind (e.g., Blackberry, Android, IPad, IPhone, etc.) to partake in the study, Qualtrics will automatically discontinue the study with a message reminder for them to \u201cPLEASE use a laptop or computer for this study!\u201d", "description-methods.planned-sample.question6b": "Our target sample size is 282 participants. \n\nWe used the software program G*Power to conduct our power analysis. A priori power analysis determined that we require N = 240 to reach statistical significance for a medium-sized effect with power (1 - \u00df) set at 0.80 at the standard .05 alpha error probability. However, we will attempt to recruit an additional 15% (n = 42) of our targeted N to account for potential data loss due to manipulation check failures, incompletion, technical difficulties, etc. ", "description-methods.planned-sample.question7b": "If participants attempt to use a cellular device of any kind (e.g., Blackberry, Android, IPad, iPhone, etc.) to partake in the study, Qualtrics will automatically discontinue the study with a message reminder for them to \u201cPLEASE use a laptop or computer for this study!\u201d Participants may restart the survey on either a laptop or computer. ", "confirmatory-analyses-fourth.fourth.question1c": "Metacognitive Judgments\n\nH5. Confidence: A MANOVA will be used to compare the level of confidence between participants who make gender categorization congruent vs. incongruent to the gender category suggested by the clothing. Alternatively, we may calculate the Cronbach\u2019s alpha of the confidence questions, if internal consistency is high a composite \u201cconfidence\u201d variable will be calculated and used in a t-test analysis (IV: Congruence, DV: Confidence). \n\nH5.a. Confidence (DVs: Gender confidence, height confidence, weight confidence, age confidence, and aggression confidence). Descriptive statistics will be calculated for all the confidence measures. \n\nH5.b., H5.c. Good view and speed of reporting: Two univariate ANOVAs will test the variables of gendered-clothing and time of gender judgment on (i) reported quality of view and (ii) reported speed of reporting. \n\nH5.d. To test if participants were aware that contextual information was affecting their reporting we will code their open-ended responses using the following rubric. To ensure inter-rater reliability, a second coder will independently score 50% of the total self-report Information on the factors that influenced participants gender judgment. This analysis will demonstrate the participants were largely unaware of the effect of context and rather believe they were using features of the person to categorize their gender.  \n\nH5.e. We will calculate the descriptives of the following question: \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) could have affected your judgments?\u201d and show that most participants selected \u201cNO.\u201d We will then code the written responses of those who answered \u201cYES\u201d  to determine how they believed order affected their reporting. ", "confirmatory-analyses-second.second.question1c": "Demographic and Character Judgements\n\nH1.a: (DV: Gender) We will use Chi-square test for goodness of fit to analyze whether our clothing manipulation influences participants\u2019 gender categorization. \n\nH2.a, H2.b, Ex.2., H3: (DVs: Height, Weight, Aggression) Factorial ANOVAs will be used to analyze participants\u2019 continuous outcome variables. \n\nEx: (DV: Age): T-tests will be used to analyze participants\u2019 estimation of Age. ", "confirmatory-analyses-further.further.question1c": "Exploratory Analysis\n\n*We would like to mention here that we may or may not look at these aspects of the data. The following are points of interest:\n\nEx.1: Gender selection and demographic reporting. We may divide our sample into participants who selected \u201cmale\u201d and \u201cfemale.\u201d This gender-selected variable may then be used as an IV in our univariate ANOVAs in which we test if people\u2019s selections of gender affect how they report when making demographic and aggression judgments.   \n\nEx.3: If we explore if speed of responding is related to a higher amount of consistency between clothing condition and gender categorization we will use a logistic regression to do so. Pearson correlations will test if there is a relationship between speed of reporting and the demographic and aggression judgments in each of the clothing conditions (MC and FC). \n\nEx.4: If tested, Pearson correlations would be used to explore the relationship between speed of reporting and metacognitive judgments. Ultimately testing if faster response times resulted in more validating metacognitive reports, i.e. more confident, better view, reporting that they were faster in their identification of gender. \n\nEx.5: We may also explore if participants who were congruent in their clothing condition/gender categorization varied from those who were incongruent in their metacognitive reporting. An ANOVAs would be used to explore this relationship with congruency (congruent/incongruent) and time of gender judgment (1st or last) being used as our IVs and confidence, view, and speed reports as our DVs.  ", "description-methods.exclusion-criteria.question8b": "Anticipated data exclusion criteria: \n\na). Participants who spend a disproportionate amount of time (e.g., hours) to complete the 15-minutes study.\nb). Participants who request to have their data deleted. \nc). Participants with incomplete data. \nd). Participants who indicate that they suffer from colour blindness. \ne). Participants who fail the manipulation checks - i.e., do not know the image on the sweatshirt of the individual or the colour of the individual\u2019s outfit. ", "description-methods.planned-sample.question6b-upload": [{"file_id": "5e3a0be4f1369e001b8af94b", "file_name": "GPower_Biasing Effects of Expectation on Person Perception 2020.JPG", "file_urls": {"html": "https://osf.io/p2ru3/files/osfstorage/5e3a0be4f1369e001b8af94b", "download": "https://osf.io/download/ckjp8/"}, "file_hashes": {"sha256": "42191814c3c25b25e72fa8e0d63704b426842d9a2eb4a4f603240a2cd49b3408"}}]}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ha4p8/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ha4p8/comments/?format=json&filter%5Btarget%5D=ha4p8", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ha4p8/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ha4p8/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ha4p8/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ha4p8/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ha4p8/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ha4p8/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ha4p8/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ha4p8/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ha4p8/linked_by_registrations/?format=json", "meta": {}}}}, "parent": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/?format=json", "meta": {}}}, "data": {"id": "j927s", "type": "registrations"}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ha4p8/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ha4p8/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/ha4p8/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/ca-1/?format=json", "meta": {}}}, "data": {"id": "ca-1", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/?format=json", "meta": {}}}, "data": {"id": "j927s", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ha4p8/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ha4p8/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/ha4p8/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ha4p8/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/ha4p8/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ha4p8/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/ha4p8/citation/?format=json", "meta": {}}}, "data": {"id": "ha4p8", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/85n6s/?format=json", "meta": {}}}, "data": {"id": "85n6s", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/bvr8u/?format=json", "meta": {}}}, "data": {"id": "bvr8u", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5730e99a9ad5a102c5745a8a/?format=json", "meta": {}}}, "data": {"id": "5730e99a9ad5a102c5745a8a", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/ha4p8/", "self": "https://api.osf.io/v2/registrations/ha4p8/"}}, {"id": "j927s", "type": "registrations", "attributes": {"title": "The Biasing Effects of Expectation on Person Perception", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-02-11T16:27:27.883199", "date_modified": "2020-02-07T21:18:06.153809", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": ["Bias", "Contextual Bias", "Expectation", "Gender", "Gender Ambiguous", "Perception"], "access_requests_enabled": false, "node_license": null, "analytics_key": "e09877c32565f03e7cae8def6f17a187f2bb3cf1e5382cb06d26139d93d020356b08ed5ac7fe47864f9f20c7a76388816fb038d8051755aa86d7dac1f83d7d021ab93e3f090bbd26b344f337600cb9e62379ba626885199f699527c149d661d8718ec741bad0581ef4579d3cdb7cbafd8b96e3cc45cb586c8f75723cceba0263d0e1ff4ffbfa0ad72cb28579fcdabe96", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-02-11T16:27:27.862186", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Pre-Registration in Social Psychology (van 't Veer & Giner-Sorolla, 2016): Pre-Registration", "registered_meta": {"looked": {"extra": [], "value": "No"}, "datacompletion": {"extra": [], "value": "No, data collection has not begun"}, "additionalComments": {"extra": [], "value": "Citations: \n\nHuart, J., Corneille, O., &amp; Becquart, E. (2005). Face-based categorization, context-based categorization, and distortions in the recollection of gender-ambiguous faces. Journal of Experimental Social Psychology, 41(6), 598-608. doi:10.1016/j.jesp.2004.10.007\n\nMapstone, L. (2015). Rihanna hides away under oversized gothic hoodie and baggy trousers for low-key arrival in Los Angeles after Paris love-in with Travis Scott [Online image]. MailOnline. Retrieved from: http://www.dailymail.co.uk/tvshowbiz/article-3262964/Rihanna-hides-away-oversized-gothic-hoodie-baggy-trousers-low-key-arrival-Los-Angeles-Paris-love-Travis-Scott.html "}, "dataCollectionDates": {"extra": [], "value": "February 2020 - February 2023\n"}, "description-methods": {"value": {"design": {"value": {"question2a": {"extra": [], "value": "This is a 2 Gendered-clothing (male clothing [MC] or female clothing [FC]) x 2 Gender-ambiguous face (Face 1 or Face 2) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) between-subjects factorial design. This is an orthogonal study design.\n"}, "question2b": {"extra": [], "value": "Dependent Variables: \n\n1. Demographic judgments of the individual in the image: categorical gender judgment (M or F), and continuous estimations of weight (open-ended), height (open-ended), and age (open-ended).\n\n2. Judgement of the social features of the individual in the image: level of aggression on a 9-point Likert scale (0 = \"Not aggressive\", 9 = \"Highly Aggressive\").\n\n3. Metacognitive judgment of the viewers experience: participant\u2019s confidence in their judgments (0 = \u201cNot Confident At All\u201d to 100 = \u201cExtremely Confident\u201d), the speed at which they made the gender judgment (open-ended), quality of the view of the individual\u2019s face (1 = \u201cVery Poor\u201d, 7 = \u201cVery Good\u201d), which factors the participant took into consideration when determining gender (open-ended), and how order of responding affected judgment (open-ended)."}, "question3b": {"extra": [], "value": "We do not anticipate using any covariate. However, it is possible that we may use reported age as a covariate if we are seeking to understand our findings on the demographic measures for those in the MC and FC.   "}}}, "procedure": {"value": {"question10b": {"extra": [], "value": "Manipulations and Measures\n\nThis is a 2 Gendered-clothing (male clothing [MC] or female clothing [FC]) x 2 Gender-ambiguous face (Face 1 or Face 2) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) between-subjects factorial design. \n\nDependent Variables\n\n1. Demographic judgments of the individual in the image: categorical gender judgment (M or F), and continuous estimations of weight (open-ended), height, (open-ended) and age (open-ended). \n\n2. Judgement on the social features of the individual in the image: level of aggression on a 9-point Likert scale (0 = \"Not aggressive\", 9 = \"Highly Aggressive\"). \n\n3. Metacognitive judgment of the viewers experience: (i) participant\u2019s confidence in each one of their demographic judgments (gender, weight, height, age) and aggression judgment, (ii) the estimated speed at which they made their gender judgment, (iii) quality of the view of the individual\u2019s face, (iv) which factors the participant took into consideration when determining the gender of the individual and (v) if they believe that the order that they answered the demographic questions could have affected their judgments. \n\nMaterials\n\nFace: Two gender-ambiguous faces were selected from a continuum of morphed male/female faces developed by Huart et al. (2005). Our Face 1 stimulus is a blend of 50% male and 50% female face (named \u201cMoprh 10-050\u201d in original paper; Huart et al., 2005), and our Face 2 stimulus is a blend of 70% female\u201330% male moderately ambiguous face (named \u201cMorph 7-030\u201d in original paper). \n\nClothing: We modified a single image by changing the colour and the logo on the clothing to make it either more \u201cmasculine\u201d or \u201cfeminine.\u201d The image was an anterior view of a person (the pop singer Rhianna) wearing a hooded sweatshirt and a pair of baggy pants (image retrieved from Google Image; Mapstone, 2015). The baggy clothing obscured the physique of the person. Photo editing software was used to alter the logo on the sweatshirt and the clothing colour. \n\nWe conducted a pilot study with four clothing stimuli to test their levels of perceived masculinity and femininity. Sixty undergraduate students (49 females, 11 males) participated in the study and were asked to rate on a 9-point Likert scale (1 = \u201cOnly Women\u201d; 9 = \u201cOnly Men\u201d) on whether men or women are more likely to wear the outfit presented. Descriptive results revealed two outfits were rated as relatively equal in magnitude; one on the quality of \u201cfeminine\u201d and one on the quality of \u201cmasculine\u201d while maintaining low variances. The feminine outfit selected was an entirely pink outfit with an image of a pair of red lips above the letters \u201cXOXO\u201d on the sweater (M = 2.88, SD = 1.42). The masculine outfit selected was black pants and a brown sweatshirt with an image of a woman in lingerie (M = 6.38, SD = 1.59). \n\nFinal stimuli: Photo editing software was used to incorporate each of the two faces (Face 1 and Face 2) with the masculine (i.e., black pants and a brown sweatshirt with an image of a woman in lingerie) and feminine (i.e., pink pants and a pink sweatshirt with an image of a pair of red lips above \u201cXOXO\u201d) outfits. A fringe of gender-neutral hair was added to the forehead area of each image to make the final images of the people appear more realistic. \n\nProcedure\n\nParticipants will use either a laptop or a computer to participate \u2013 attempting to use any cellular devices will result in automatic termination of the survey (ballot box stuffing disabled).\n\nScreen 1: Consent form \u2013 participants who click the \u201cyes, I would like to participate\u201d to continue and those who click \u201cNo, I do not consent to participating in this study\u201d will be brought to the end of the survey. All participants receive credit regardless of if they complete the survey.\n\nScreen 2: Participants are instructed to: \u201cPay attention to the images you are about to see, and answer the following questions about the image as quickly and honestly as possible.\u201d\n\nScreens 3-14: Participants make judgements on twelve filler task questions. These tasks require participants to make judgments on visual stimuli. For instance, how many red jelly beans are there in a jar of beans or what was the colour of horses seen in an image. The filler tasks are included to prevent participants from being overly vigilant in our activity of interest, which will be the final task.\n\nScreens 15-25: Participants make demographic and character judgments of a person who has a gender-ambiguous face (F1 or F4) is wearing clothing that has been modified to be either female (FC) or male (MC). Importantly the image of the person will remain on the screen while participants make all of the demographic judgments, their aggression judgment, as well as, their confidence judgments:\n\n*Half of participants will receive the gender question as the first judgment they make of the individual in the image; half will be asked to judge gender at the end of the person judgments:\n\nGender Judgment: \u201cPlease select the gender of this person:\u201d Screen presents a centered image of a person in either the MC or FC with one of the two gender-neutral faces (F1 or F4). There is a forced-choice option underneath for participants to select either \u201cMale\u201d or \u201cFemale\u201d.\n\nParticipants will receive one of two presentation options: Order1: male option on the left and female option on the right OR Order2: female option on the left and male option on the right.\n\nFollowing the gender judgment, a new screen asks participants to rate their confidence about their gender judgment while the image of the person remains on screen (0 = \"Not Confident At All\" to 100 = \"Extremely Confident\"). Their gender selection is not visible on the confidence screen.\n\nContinuous Demographic and Character Judgements (the order of the four questions will be randomly presented to participants): \n      a). Weight: \u201cPlease estimate the weight of the person in the image (in pounds/lbs)\u201d (Open-ended)\n      b). Height: \u201cPlease estimate the height of the person in the image (in ft and inches)\u201d (Open-ended)\n      c). Age: \u201cPlease estimate the age of the person in the image (in years)\u201d (Open-ended)\n      d). Aggression: \u201cRate how aggressive the person in the image seems\u201d (0 = \"Not aggressive\", 9 = \"Highly Aggressive\")\n\nFollowing each of the four judgements, a new screen will ask participants to rate their confidence about their judgement while the image of the person remains on screen (0 = \"Not Confident At All\", 100 = \"Extremely Confident\"). However, their response to the question is not visible to participants when they rate their confidence in their response. \n \n*The half of participants who did not receive the gender question at the outset of this task are asked the gender question at this point. \n\n*For each of the questions from screens 3-25, including confidence, participants are given a maximum of 10 minutes to respond, but they are allowed to respond and advance to the next question before the timer is up (timer is hidden from participants).\n\nScreens 26-29: Participants are asked follow-up questions regarding the image they saw.\n\nMetacognitive Questions (the order of the three questions will be counterbalanced between participants):\n     a). View of face: \u201cHow good of a view did you get of the person in the image?\u201d (Likert scale between 1-7 with 1 = Very Poor, 7 = Very Good).\n     b). Self-Reported Speed: \u201cEstimate how quickly you answered the question about the person\u2019s gender (in seconds):\u201d (Open-ended)\n     c). Factors the participant took into consideration when determining gender: \u201cWhat did you look in the image to determine the gender of the person (please be specific)?\u201d (Open-ended)\n     d). If the participant was aware of how order could affect their responding: \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) about the individual in the image could have affected your judgments?\u201d (Yes/No). If yes, \u201cYou answered yes, please answer how your judgments could have been affected by the order you received the questions?\u201d (open-ended)\n\nScreens 30-31: Manipulation Checks: \u201cWhat was the colour of the sweatshirt?\u201d (open-ended) and \u201cWhat was the logo on the sweatshirt?\u201d (open-ended)\n\nScreens 32-35: Demographics. Each question will be presented on separate screens (with the exception of the two questions about gender): \n1. \u201cWhat is your age?\u201d (Open-ended) \n2. \u201cAre you currently the same gender you were assigned at birth?\u201d (Open-ended) and \u201cWhat is your gender?\u201d (Options: Male/Female/Other [Please specify])\n3. \u201cDo you suffer from colour blindness?\u201d (Yes/No). If participant answers \"YES\", then they are prompted to answer a follow-up question: \u201cPlease list the colours that you cannot see:\u201d (Open-ended) \n4. \u201cMy ethnicity is (if mixed, select more than one or specify under \"other\")\u2026\u201d (Multiple Choice) \n\nScreen 36: Debriefing form outlining the purpose of the study and researchers\u2019 contact information. The following is placed at the end of the debriefing form: \"Thank you for participating in our study! We value your participation greatly. However, if you feel uncomfortable about your participation in the study today and would like your data removed, please enter 'erase my data'\" (Text box is provided)\n"}}}, "planned-sample": {"value": {"question4b": {"extra": [], "value": "Participants will be randomly allocated into one of the following conditions:\n\nFace 1 and FC\nFace 1 and MC\nFace 2 and FC\nFace 2 and MC\n\nHalf of the participants within each condition above will also be sorted into the following DV orders:\n\nOrder 1: Gender categorization and then Demographic and aggression judgements\nOrder 2: Demographic and aggression judgements and then Gender categorization"}, "question5b": {"extra": [], "value": "Participants will be recruited through the Kwantlen Polytechnic University Psychology Research Pool System and will be granted 0.5% bonus course credit for their time. Subjects who are visually impaired (i.e., blindness or colour blindness) will be excluded from the study. The \u201cmasculine\u201d and \u201cfeminine\u201d clothing is gendered via its colour (e.g., brown for male and pink for female). Thus, participants must have full function of their colour vision or have visual aids such as glasses for proper visual perception. Participants who cannot see colours (or at all) will provide unusable data for the study.\n\nTo prevent participants from being overly vigilant in our activity of interest, the study name advertised on SONA will be \"Judgement of Pictures\".\n\nPotential participants will read: \u201cThe purpose of this research project is to explore people\u2019s judgments of others. This study requires you to USE A PC/LAPTOP! People who are visually impaired (blind or colour blind) may not participate in this study. Sorry for the inconvenience.\u201d\n\nData will be collected through the computerized database in \"Qualtrics\" using only a laptop or PC. If participants attempts to use a cellular device of any kind (e.g., Blackberry, Android, IPad, IPhone, etc.) to partake in the study, Qualtrics will automatically discontinue the study with a message reminder for them to \u201cPLEASE use a laptop or computer for this study!\u201d"}, "question6b": {"extra": [], "value": "Our target sample size is 282 participants. \n\nWe used the software program G*Power to conduct our power analysis. A priori power analysis determined that we require N = 240 to reach statistical significance for a medium-sized effect with power (1 - \u00df) set at 0.80 at the standard .05 alpha error probability. However, we will attempt to recruit an additional 15% (n = 42) of our targeted N to account for potential data loss due to manipulation check failures, incompletion, technical difficulties, etc. "}, "question7b": {"extra": [], "value": "If participants attempt to use a cellular device of any kind (e.g., Blackberry, Android, IPad, iPhone, etc.) to partake in the study, Qualtrics will automatically discontinue the study with a message reminder for them to \u201cPLEASE use a laptop or computer for this study!\u201d Participants may restart the survey on either a laptop or computer. "}, "question6b-upload": {"extra": [{"data": {"name": "GPower_Biasing Effects of Expectation on Person Perception 2020.JPG"}, "nodeId": "p2ru3", "sha256": "42191814c3c25b25e72fa8e0d63704b426842d9a2eb4a4f603240a2cd49b3408", "viewUrl": "/project/j927s/files/osfstorage/5e42d5f9a057ec006ab09542/", "selectedFileName": "GPower_Biasing Effects of Expectation on Person Perception 2020.JPG"}], "value": ""}}}, "exclusion-criteria": {"value": {"question8b": {"extra": [], "value": "Anticipated data exclusion criteria: \n\na). Participants who spend a disproportionate amount of time (e.g., hours) to complete the 15-minutes study.\nb). Participants who request to have their data deleted. \nc). Participants with incomplete data. \nd). Participants who indicate that they suffer from colour blindness. \ne). Participants who fail the manipulation checks - i.e., do not know the image on the sweatshirt of the individual or the colour of the individual\u2019s outfit. "}}}}}, "recommended-methods": {"value": {"procedure": {"value": {"question9b": {"extra": [], "value": "Participants will use either a laptop or a computer to participate \u2013 attempting to use any cellular devices will result in automatic termination of the survey (ballot box stuffing disabled). "}, "question9b-file": {"extra": [], "value": ""}}}}}, "recommended-analysis": {"value": {"specify": {"value": {"question6c": {"extra": [], "value": ""}, "question7c": {"extra": [], "value": "The data of participants who do not complete the study will not be used in analyses. "}, "question8c": {"extra": [], "value": ""}, "question9c": {"extra": [], "value": "Outlier ratings of continuous DVs may be replaced with the mean rating from the sample. Any manipulation of this kind will be clearly articulated in a manuscript prepared for publication."}, "question10c": {"extra": [], "value": "If assumptions of our parametrics tests are violated we will seek non-parametric options for data analysis. "}, "question11c": {"extra": [], "value": ""}}}}}, "description-hypothesis": {"value": {"question1a": {"extra": [], "value": "Gender-Ambiguous face\n\nTwo gender-ambiguous faces were counterbalanced in this research to enhance the generalizability of our findings. We do not expect any effect of this variable.\nGendered Clothing Manipulation\n\nH1 \u201cGender Judgment\u201d: We predict that pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result participants categorizing the individual in the gender category suggested by the clothing (MC or FC).\n\nH2 \u201cDemographic Judgments\u201d: We predict that a pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result in demographic judgments (height, weight) consistent with the gender category suggested by the clothing (MC or FC).\n\nH2.a: (DV: Height): Participants in the MC condition will estimate the individual to be taller than participants\u2019 estimations of the same individual in the FC condition.\n\nH2.b: (DV: Weight): Participants in the MC condition will estimate the individual to be heavier than participants\u2019 estimations of the same individual in the FC condition.\n\nH3 \u201cAggression Judgment\u201d: We predict that pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result in an aggression judgment consistent with the gender category suggested by the clothing (MC or FC). Specifically, participants in the MC condition would rate the individual to be more aggressive than participants\u2019 estimations of the same individual in the FC condition.\n\nGender Judgment Manipulation\n\nH4: \u201cDemographic and Aggression Judgments\u201d We predict a 2 Gendered-clothing (MC or FC) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) interaction on the height, weight and aggression variables.\n\nSpecifically, participants who are asked to categorize the gender of the individual first, i.e., prior to judging demographic and aggression variables, will provide responses to the demographic and aggression judgments that are more representative of their gender categorization (i.e., male is heavier, taller and more aggressive; female is shorter, lighter and less aggressive) than participants who are asked to gender categorize the individual as their last judgment, i.e., after judging demographics and character variables.\n\nH5 \u201cMetacognitive Judgments of Performance\u201d: We predict that participants will:\n\nH5.a. Be confident in their gender, demographic, and aggression judgments of the individual.\n\nH5.b. Report that they had a good view of the person in the image.\n\nH5.c. Report that they were fast in their categorization of gender regardless of their speed.\n\nH5.d. Be largely unaware that contextual variables \u2013 (i) clothing manipulation and (ii) time of gender judgment - affected their reporting. That is, first, when asked what they considered when categorizing the gender of the person in the image the majority of participants will report that the used biological features of the individual (entire face or facial features, shape and stature of the body) versus reporting contextual information found on the clothing (colour and image). Second, when asked \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) could have affected your judgments? Yes/No, we predict that the majority of participant will respond \u201cNO.\u201d\n\nPossible Exploratory\n\nEx.1 Gender categorization: We may explore if peoples gender categorizations had a relationship with the demographic, aggression and metacognitive variables in our study. This analysis is different than our gender manipulation because it will use gender categorization as the independent variable in our analysis, not gendered-clothing condition.\n\nEx.2 (DV: Age): We will explore if participants who categorize the individual as \u201cMale\u201d will estimate the age of the individual as younger than participants who categorize the individual as \u201cFemale.\u201d\n\nEx.3: We may explore if speed of responding is related to a higher amount of consistency between clothing condition and gender categorization, as well as judgments that are more congruent with the gender category.\n\nEx.4: We may explore the relationship between speed of reporting and metacognitive judgments. Ultimately testing if faster response times resulted in more validating metacognitive reports, i.e. more confident, better view, reporting that they were faster in their identification of gender.\n\nEx.5: We may also explore if the metacognitive judgments of participants who were congruent in their clothing condition/gender categorization varied from those who were incongruent."}, "question2a": {"extra": [], "value": "N/A"}, "question3a": {"extra": [], "value": "We will include two manipulation checks at the end of the study. Participants will be asked 1. \u201cWhat was the colour of the sweatshirt that the individual was wearing?\", and 2. \u201cWhat was the image on the sweatshirt?\u201d to verify that they paid attention to our visual manipulation."}}}, "recommended-hypothesis": {"value": {"question4a": {"extra": [], "value": ""}, "question5a": {"extra": [], "value": ""}, "question6a": {"extra": [], "value": ""}}}, "confirmatory-analyses-first": {"value": {"first": {"value": {"question1c": {"extra": [], "value": "We will use chi-square test for goodness of fit to analyze whether Face 1 and Face 2 performed similarly. We anticipate that they will, and the face variable will be collapsed in all subsequent analyses. \n\nPhi coefficient and the CI for \u0424 will be calculated using Cumming\u2019s Exploratory Software for Confidence Intervals (ESCI). Cohen\u2019s d and the CI of d will be calculated using Cumming\u2019s formulas, d=((M2-M1))/s and  \u2206 =  (\u03bc2- \u03bc1 )/(\u03b4\u221a(1/N1+1/N2)) respectively in ESCI. "}, "question2c": {"extra": [], "value": "See above. "}, "question3c": {"extra": [], "value": "See above. "}, "question4c": {"extra": [], "value": "N/A"}, "question5c": {"extra": [], "value": "N/A"}}}}}, "confirmatory-analyses-third": {"value": {"third": {"value": {"question1c": {"extra": [], "value": "Time of Gender Judgement \n\nH4: Multiple between-subject ANAOVAs will test the relationship between gendered outfit (FC or MC) and time of gender judgment (1st question, last question) on the variables of weight, height, age and aggression. This analysis will test if asking the gender question at the end of the demographic questions helps to mitigate the effect of gender perception on demographic reporting.  "}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}, "confirmatory-analyses-fourth": {"value": {"fourth": {"value": {"question1c": {"extra": [], "value": "Metacognitive Judgments\n\nH5. Confidence: A MANOVA will be used to compare the level of confidence between participants who make gender categorization congruent vs. incongruent to the gender category suggested by the clothing. Alternatively, we may calculate the Cronbach\u2019s alpha of the confidence questions, if internal consistency is high a composite \u201cconfidence\u201d variable will be calculated and used in a t-test analysis (IV: Congruence, DV: Confidence). \n\nH5.a. Confidence (DVs: Gender confidence, height confidence, weight confidence, age confidence, and aggression confidence). Descriptive statistics will be calculated for all the confidence measures. \n\nH5.b., H5.c. Good view and speed of reporting: Two univariate ANOVAs will test the variables of gendered-clothing and time of gender judgment on (i) reported quality of view and (ii) reported speed of reporting. \n\nH5.d. To test if participants were aware that contextual information was affecting their reporting we will code their open-ended responses using the following rubric. To ensure inter-rater reliability, a second coder will independently score 50% of the total self-report Information on the factors that influenced participants gender judgment. This analysis will demonstrate the participants were largely unaware of the effect of context and rather believe they were using features of the person to categorize their gender.  \n\nH5.e. We will calculate the descriptives of the following question: \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) could have affected your judgments?\u201d and show that most participants selected \u201cNO.\u201d We will then code the written responses of those who answered \u201cYES\u201d  to determine how they believed order affected their reporting. "}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}, "confirmatory-analyses-second": {"value": {"second": {"value": {"question1c": {"extra": [], "value": "Demographic and Character Judgements\n\nH1.a: (DV: Gender) We will use Chi-square test for goodness of fit to analyze whether our clothing manipulation influences participants\u2019 gender categorization. \n\nH2.a, H2.b, Ex.2., H3: (DVs: Height, Weight, Aggression) Factorial ANOVAs will be used to analyze participants\u2019 continuous outcome variables. \n\nEx: (DV: Age): T-tests will be used to analyze participants\u2019 estimation of Age. "}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}, "confirmatory-analyses-further": {"value": {"further": {"value": {"question1c": {"extra": [], "value": "Exploratory Analysis\n\n*We would like to mention here that we may or may not look at these aspects of the data. The following are points of interest:\n\nEx.1: Gender selection and demographic reporting. We may divide our sample into participants who selected \u201cmale\u201d and \u201cfemale.\u201d This gender-selected variable may then be used as an IV in our univariate ANOVAs in which we test if people\u2019s selections of gender affect how they report when making demographic and aggression judgments.   \n\nEx.3: If we explore if speed of responding is related to a higher amount of consistency between clothing condition and gender categorization we will use a logistic regression to do so. Pearson correlations will test if there is a relationship between speed of reporting and the demographic and aggression judgments in each of the clothing conditions (MC and FC). \n\nEx.4: If tested, Pearson correlations would be used to explore the relationship between speed of reporting and metacognitive judgments. Ultimately testing if faster response times resulted in more validating metacognitive reports, i.e. more confident, better view, reporting that they were faster in their identification of gender. \n\nEx.5: We may also explore if participants who were congruent in their clothing condition/gender categorization varied from those who were incongruent in their metacognitive reporting. An ANOVAs would be used to explore this relationship with congruency (congruent/incongruent) and time of gender judgment (1st or last) being used as our IVs and confidence, view, and speed reports as our DVs.  "}, "question2c": {"extra": [], "value": ""}, "question3c": {"extra": [], "value": ""}, "question4c": {"extra": [], "value": ""}, "question5c": {"extra": [], "value": ""}}}}}}, "registration_responses": {"looked": "No", "datacompletion": "No, data collection has not begun", "additionalComments": "Citations: \n\nHuart, J., Corneille, O., &amp; Becquart, E. (2005). Face-based categorization, context-based categorization, and distortions in the recollection of gender-ambiguous faces. Journal of Experimental Social Psychology, 41(6), 598-608. doi:10.1016/j.jesp.2004.10.007\n\nMapstone, L. (2015). Rihanna hides away under oversized gothic hoodie and baggy trousers for low-key arrival in Los Angeles after Paris love-in with Travis Scott [Online image]. MailOnline. Retrieved from: http://www.dailymail.co.uk/tvshowbiz/article-3262964/Rihanna-hides-away-oversized-gothic-hoodie-baggy-trousers-low-key-arrival-Los-Angeles-Paris-love-Travis-Scott.html ", "dataCollectionDates": "February 2020 - February 2023\n", "description-hypothesis.question1a": "Gender-Ambiguous face\n\nTwo gender-ambiguous faces were counterbalanced in this research to enhance the generalizability of our findings. We do not expect any effect of this variable.\nGendered Clothing Manipulation\n\nH1 \u201cGender Judgment\u201d: We predict that pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result participants categorizing the individual in the gender category suggested by the clothing (MC or FC).\n\nH2 \u201cDemographic Judgments\u201d: We predict that a pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result in demographic judgments (height, weight) consistent with the gender category suggested by the clothing (MC or FC).\n\nH2.a: (DV: Height): Participants in the MC condition will estimate the individual to be taller than participants\u2019 estimations of the same individual in the FC condition.\n\nH2.b: (DV: Weight): Participants in the MC condition will estimate the individual to be heavier than participants\u2019 estimations of the same individual in the FC condition.\n\nH3 \u201cAggression Judgment\u201d: We predict that pairing gendered-clothing (MC or FC) with a gender-ambiguous face (Face 1 or Face 2) will result in an aggression judgment consistent with the gender category suggested by the clothing (MC or FC). Specifically, participants in the MC condition would rate the individual to be more aggressive than participants\u2019 estimations of the same individual in the FC condition.\n\nGender Judgment Manipulation\n\nH4: \u201cDemographic and Aggression Judgments\u201d We predict a 2 Gendered-clothing (MC or FC) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) interaction on the height, weight and aggression variables.\n\nSpecifically, participants who are asked to categorize the gender of the individual first, i.e., prior to judging demographic and aggression variables, will provide responses to the demographic and aggression judgments that are more representative of their gender categorization (i.e., male is heavier, taller and more aggressive; female is shorter, lighter and less aggressive) than participants who are asked to gender categorize the individual as their last judgment, i.e., after judging demographics and character variables.\n\nH5 \u201cMetacognitive Judgments of Performance\u201d: We predict that participants will:\n\nH5.a. Be confident in their gender, demographic, and aggression judgments of the individual.\n\nH5.b. Report that they had a good view of the person in the image.\n\nH5.c. Report that they were fast in their categorization of gender regardless of their speed.\n\nH5.d. Be largely unaware that contextual variables \u2013 (i) clothing manipulation and (ii) time of gender judgment - affected their reporting. That is, first, when asked what they considered when categorizing the gender of the person in the image the majority of participants will report that the used biological features of the individual (entire face or facial features, shape and stature of the body) versus reporting contextual information found on the clothing (colour and image). Second, when asked \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) could have affected your judgments? Yes/No, we predict that the majority of participant will respond \u201cNO.\u201d\n\nPossible Exploratory\n\nEx.1 Gender categorization: We may explore if peoples gender categorizations had a relationship with the demographic, aggression and metacognitive variables in our study. This analysis is different than our gender manipulation because it will use gender categorization as the independent variable in our analysis, not gendered-clothing condition.\n\nEx.2 (DV: Age): We will explore if participants who categorize the individual as \u201cMale\u201d will estimate the age of the individual as younger than participants who categorize the individual as \u201cFemale.\u201d\n\nEx.3: We may explore if speed of responding is related to a higher amount of consistency between clothing condition and gender categorization, as well as judgments that are more congruent with the gender category.\n\nEx.4: We may explore the relationship between speed of reporting and metacognitive judgments. Ultimately testing if faster response times resulted in more validating metacognitive reports, i.e. more confident, better view, reporting that they were faster in their identification of gender.\n\nEx.5: We may also explore if the metacognitive judgments of participants who were congruent in their clothing condition/gender categorization varied from those who were incongruent.", "description-hypothesis.question2a": "N/A", "description-hypothesis.question3a": "We will include two manipulation checks at the end of the study. Participants will be asked 1. \u201cWhat was the colour of the sweatshirt that the individual was wearing?\", and 2. \u201cWhat was the image on the sweatshirt?\u201d to verify that they paid attention to our visual manipulation.", "recommended-hypothesis.question4a": [], "recommended-hypothesis.question5a": "", "recommended-hypothesis.question6a": "", "description-methods.design.question2a": "This is a 2 Gendered-clothing (male clothing [MC] or female clothing [FC]) x 2 Gender-ambiguous face (Face 1 or Face 2) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) between-subjects factorial design. This is an orthogonal study design.\n", "description-methods.design.question2b": "Dependent Variables: \n\n1. Demographic judgments of the individual in the image: categorical gender judgment (M or F), and continuous estimations of weight (open-ended), height (open-ended), and age (open-ended).\n\n2. Judgement of the social features of the individual in the image: level of aggression on a 9-point Likert scale (0 = \"Not aggressive\", 9 = \"Highly Aggressive\").\n\n3. Metacognitive judgment of the viewers experience: participant\u2019s confidence in their judgments (0 = \u201cNot Confident At All\u201d to 100 = \u201cExtremely Confident\u201d), the speed at which they made the gender judgment (open-ended), quality of the view of the individual\u2019s face (1 = \u201cVery Poor\u201d, 7 = \u201cVery Good\u201d), which factors the participant took into consideration when determining gender (open-ended), and how order of responding affected judgment (open-ended).", "description-methods.design.question3b": "We do not anticipate using any covariate. However, it is possible that we may use reported age as a covariate if we are seeking to understand our findings on the demographic measures for those in the MC and FC.   ", "recommended-analysis.specify.question6c": "", "recommended-analysis.specify.question7c": "The data of participants who do not complete the study will not be used in analyses. ", "recommended-analysis.specify.question8c": "", "recommended-analysis.specify.question9c": "Outlier ratings of continuous DVs may be replaced with the mean rating from the sample. Any manipulation of this kind will be clearly articulated in a manuscript prepared for publication.", "recommended-analysis.specify.question10c": "If assumptions of our parametrics tests are violated we will seek non-parametric options for data analysis. ", "recommended-analysis.specify.question11c": [], "recommended-methods.procedure.question9b": "Participants will use either a laptop or a computer to participate \u2013 attempting to use any cellular devices will result in automatic termination of the survey (ballot box stuffing disabled). ", "description-methods.procedure.question10b": "Manipulations and Measures\n\nThis is a 2 Gendered-clothing (male clothing [MC] or female clothing [FC]) x 2 Gender-ambiguous face (Face 1 or Face 2) x 2 Time of gender judgment (Initial Judgment made before other judgments about the image, or last judgment) between-subjects factorial design. \n\nDependent Variables\n\n1. Demographic judgments of the individual in the image: categorical gender judgment (M or F), and continuous estimations of weight (open-ended), height, (open-ended) and age (open-ended). \n\n2. Judgement on the social features of the individual in the image: level of aggression on a 9-point Likert scale (0 = \"Not aggressive\", 9 = \"Highly Aggressive\"). \n\n3. Metacognitive judgment of the viewers experience: (i) participant\u2019s confidence in each one of their demographic judgments (gender, weight, height, age) and aggression judgment, (ii) the estimated speed at which they made their gender judgment, (iii) quality of the view of the individual\u2019s face, (iv) which factors the participant took into consideration when determining the gender of the individual and (v) if they believe that the order that they answered the demographic questions could have affected their judgments. \n\nMaterials\n\nFace: Two gender-ambiguous faces were selected from a continuum of morphed male/female faces developed by Huart et al. (2005). Our Face 1 stimulus is a blend of 50% male and 50% female face (named \u201cMoprh 10-050\u201d in original paper; Huart et al., 2005), and our Face 2 stimulus is a blend of 70% female\u201330% male moderately ambiguous face (named \u201cMorph 7-030\u201d in original paper). \n\nClothing: We modified a single image by changing the colour and the logo on the clothing to make it either more \u201cmasculine\u201d or \u201cfeminine.\u201d The image was an anterior view of a person (the pop singer Rhianna) wearing a hooded sweatshirt and a pair of baggy pants (image retrieved from Google Image; Mapstone, 2015). The baggy clothing obscured the physique of the person. Photo editing software was used to alter the logo on the sweatshirt and the clothing colour. \n\nWe conducted a pilot study with four clothing stimuli to test their levels of perceived masculinity and femininity. Sixty undergraduate students (49 females, 11 males) participated in the study and were asked to rate on a 9-point Likert scale (1 = \u201cOnly Women\u201d; 9 = \u201cOnly Men\u201d) on whether men or women are more likely to wear the outfit presented. Descriptive results revealed two outfits were rated as relatively equal in magnitude; one on the quality of \u201cfeminine\u201d and one on the quality of \u201cmasculine\u201d while maintaining low variances. The feminine outfit selected was an entirely pink outfit with an image of a pair of red lips above the letters \u201cXOXO\u201d on the sweater (M = 2.88, SD = 1.42). The masculine outfit selected was black pants and a brown sweatshirt with an image of a woman in lingerie (M = 6.38, SD = 1.59). \n\nFinal stimuli: Photo editing software was used to incorporate each of the two faces (Face 1 and Face 2) with the masculine (i.e., black pants and a brown sweatshirt with an image of a woman in lingerie) and feminine (i.e., pink pants and a pink sweatshirt with an image of a pair of red lips above \u201cXOXO\u201d) outfits. A fringe of gender-neutral hair was added to the forehead area of each image to make the final images of the people appear more realistic. \n\nProcedure\n\nParticipants will use either a laptop or a computer to participate \u2013 attempting to use any cellular devices will result in automatic termination of the survey (ballot box stuffing disabled).\n\nScreen 1: Consent form \u2013 participants who click the \u201cyes, I would like to participate\u201d to continue and those who click \u201cNo, I do not consent to participating in this study\u201d will be brought to the end of the survey. All participants receive credit regardless of if they complete the survey.\n\nScreen 2: Participants are instructed to: \u201cPay attention to the images you are about to see, and answer the following questions about the image as quickly and honestly as possible.\u201d\n\nScreens 3-14: Participants make judgements on twelve filler task questions. These tasks require participants to make judgments on visual stimuli. For instance, how many red jelly beans are there in a jar of beans or what was the colour of horses seen in an image. The filler tasks are included to prevent participants from being overly vigilant in our activity of interest, which will be the final task.\n\nScreens 15-25: Participants make demographic and character judgments of a person who has a gender-ambiguous face (F1 or F4) is wearing clothing that has been modified to be either female (FC) or male (MC). Importantly the image of the person will remain on the screen while participants make all of the demographic judgments, their aggression judgment, as well as, their confidence judgments:\n\n*Half of participants will receive the gender question as the first judgment they make of the individual in the image; half will be asked to judge gender at the end of the person judgments:\n\nGender Judgment: \u201cPlease select the gender of this person:\u201d Screen presents a centered image of a person in either the MC or FC with one of the two gender-neutral faces (F1 or F4). There is a forced-choice option underneath for participants to select either \u201cMale\u201d or \u201cFemale\u201d.\n\nParticipants will receive one of two presentation options: Order1: male option on the left and female option on the right OR Order2: female option on the left and male option on the right.\n\nFollowing the gender judgment, a new screen asks participants to rate their confidence about their gender judgment while the image of the person remains on screen (0 = \"Not Confident At All\" to 100 = \"Extremely Confident\"). Their gender selection is not visible on the confidence screen.\n\nContinuous Demographic and Character Judgements (the order of the four questions will be randomly presented to participants): \n      a). Weight: \u201cPlease estimate the weight of the person in the image (in pounds/lbs)\u201d (Open-ended)\n      b). Height: \u201cPlease estimate the height of the person in the image (in ft and inches)\u201d (Open-ended)\n      c). Age: \u201cPlease estimate the age of the person in the image (in years)\u201d (Open-ended)\n      d). Aggression: \u201cRate how aggressive the person in the image seems\u201d (0 = \"Not aggressive\", 9 = \"Highly Aggressive\")\n\nFollowing each of the four judgements, a new screen will ask participants to rate their confidence about their judgement while the image of the person remains on screen (0 = \"Not Confident At All\", 100 = \"Extremely Confident\"). However, their response to the question is not visible to participants when they rate their confidence in their response. \n \n*The half of participants who did not receive the gender question at the outset of this task are asked the gender question at this point. \n\n*For each of the questions from screens 3-25, including confidence, participants are given a maximum of 10 minutes to respond, but they are allowed to respond and advance to the next question before the timer is up (timer is hidden from participants).\n\nScreens 26-29: Participants are asked follow-up questions regarding the image they saw.\n\nMetacognitive Questions (the order of the three questions will be counterbalanced between participants):\n     a). View of face: \u201cHow good of a view did you get of the person in the image?\u201d (Likert scale between 1-7 with 1 = Very Poor, 7 = Very Good).\n     b). Self-Reported Speed: \u201cEstimate how quickly you answered the question about the person\u2019s gender (in seconds):\u201d (Open-ended)\n     c). Factors the participant took into consideration when determining gender: \u201cWhat did you look in the image to determine the gender of the person (please be specific)?\u201d (Open-ended)\n     d). If the participant was aware of how order could affect their responding: \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) about the individual in the image could have affected your judgments?\u201d (Yes/No). If yes, \u201cYou answered yes, please answer how your judgments could have been affected by the order you received the questions?\u201d (open-ended)\n\nScreens 30-31: Manipulation Checks: \u201cWhat was the colour of the sweatshirt?\u201d (open-ended) and \u201cWhat was the logo on the sweatshirt?\u201d (open-ended)\n\nScreens 32-35: Demographics. Each question will be presented on separate screens (with the exception of the two questions about gender): \n1. \u201cWhat is your age?\u201d (Open-ended) \n2. \u201cAre you currently the same gender you were assigned at birth?\u201d (Open-ended) and \u201cWhat is your gender?\u201d (Options: Male/Female/Other [Please specify])\n3. \u201cDo you suffer from colour blindness?\u201d (Yes/No). If participant answers \"YES\", then they are prompted to answer a follow-up question: \u201cPlease list the colours that you cannot see:\u201d (Open-ended) \n4. \u201cMy ethnicity is (if mixed, select more than one or specify under \"other\")\u2026\u201d (Multiple Choice) \n\nScreen 36: Debriefing form outlining the purpose of the study and researchers\u2019 contact information. The following is placed at the end of the debriefing form: \"Thank you for participating in our study! We value your participation greatly. However, if you feel uncomfortable about your participation in the study today and would like your data removed, please enter 'erase my data'\" (Text box is provided)\n", "confirmatory-analyses-first.first.question1c": "We will use chi-square test for goodness of fit to analyze whether Face 1 and Face 2 performed similarly. We anticipate that they will, and the face variable will be collapsed in all subsequent analyses. \n\nPhi coefficient and the CI for \u0424 will be calculated using Cumming\u2019s Exploratory Software for Confidence Intervals (ESCI). Cohen\u2019s d and the CI of d will be calculated using Cumming\u2019s formulas, d=((M2-M1))/s and  \u2206 =  (\u03bc2- \u03bc1 )/(\u03b4\u221a(1/N1+1/N2)) respectively in ESCI. ", "confirmatory-analyses-first.first.question2c": "See above. ", "confirmatory-analyses-first.first.question3c": "See above. ", "confirmatory-analyses-first.first.question4c": "N/A", "confirmatory-analyses-first.first.question5c": "N/A", "confirmatory-analyses-third.third.question1c": "Time of Gender Judgement \n\nH4: Multiple between-subject ANAOVAs will test the relationship between gendered outfit (FC or MC) and time of gender judgment (1st question, last question) on the variables of weight, height, age and aggression. This analysis will test if asking the gender question at the end of the demographic questions helps to mitigate the effect of gender perception on demographic reporting.  ", "confirmatory-analyses-third.third.question2c": "", "confirmatory-analyses-third.third.question3c": "", "confirmatory-analyses-third.third.question4c": "", "confirmatory-analyses-third.third.question5c": "", "description-methods.planned-sample.question4b": "Participants will be randomly allocated into one of the following conditions:\n\nFace 1 and FC\nFace 1 and MC\nFace 2 and FC\nFace 2 and MC\n\nHalf of the participants within each condition above will also be sorted into the following DV orders:\n\nOrder 1: Gender categorization and then Demographic and aggression judgements\nOrder 2: Demographic and aggression judgements and then Gender categorization", "description-methods.planned-sample.question5b": "Participants will be recruited through the Kwantlen Polytechnic University Psychology Research Pool System and will be granted 0.5% bonus course credit for their time. Subjects who are visually impaired (i.e., blindness or colour blindness) will be excluded from the study. The \u201cmasculine\u201d and \u201cfeminine\u201d clothing is gendered via its colour (e.g., brown for male and pink for female). Thus, participants must have full function of their colour vision or have visual aids such as glasses for proper visual perception. Participants who cannot see colours (or at all) will provide unusable data for the study.\n\nTo prevent participants from being overly vigilant in our activity of interest, the study name advertised on SONA will be \"Judgement of Pictures\".\n\nPotential participants will read: \u201cThe purpose of this research project is to explore people\u2019s judgments of others. This study requires you to USE A PC/LAPTOP! People who are visually impaired (blind or colour blind) may not participate in this study. Sorry for the inconvenience.\u201d\n\nData will be collected through the computerized database in \"Qualtrics\" using only a laptop or PC. If participants attempts to use a cellular device of any kind (e.g., Blackberry, Android, IPad, IPhone, etc.) to partake in the study, Qualtrics will automatically discontinue the study with a message reminder for them to \u201cPLEASE use a laptop or computer for this study!\u201d", "description-methods.planned-sample.question6b": "Our target sample size is 282 participants. \n\nWe used the software program G*Power to conduct our power analysis. A priori power analysis determined that we require N = 240 to reach statistical significance for a medium-sized effect with power (1 - \u00df) set at 0.80 at the standard .05 alpha error probability. However, we will attempt to recruit an additional 15% (n = 42) of our targeted N to account for potential data loss due to manipulation check failures, incompletion, technical difficulties, etc. ", "description-methods.planned-sample.question7b": "If participants attempt to use a cellular device of any kind (e.g., Blackberry, Android, IPad, iPhone, etc.) to partake in the study, Qualtrics will automatically discontinue the study with a message reminder for them to \u201cPLEASE use a laptop or computer for this study!\u201d Participants may restart the survey on either a laptop or computer. ", "recommended-methods.procedure.question9b-file": [], "confirmatory-analyses-fourth.fourth.question1c": "Metacognitive Judgments\n\nH5. Confidence: A MANOVA will be used to compare the level of confidence between participants who make gender categorization congruent vs. incongruent to the gender category suggested by the clothing. Alternatively, we may calculate the Cronbach\u2019s alpha of the confidence questions, if internal consistency is high a composite \u201cconfidence\u201d variable will be calculated and used in a t-test analysis (IV: Congruence, DV: Confidence). \n\nH5.a. Confidence (DVs: Gender confidence, height confidence, weight confidence, age confidence, and aggression confidence). Descriptive statistics will be calculated for all the confidence measures. \n\nH5.b., H5.c. Good view and speed of reporting: Two univariate ANOVAs will test the variables of gendered-clothing and time of gender judgment on (i) reported quality of view and (ii) reported speed of reporting. \n\nH5.d. To test if participants were aware that contextual information was affecting their reporting we will code their open-ended responses using the following rubric. To ensure inter-rater reliability, a second coder will independently score 50% of the total self-report Information on the factors that influenced participants gender judgment. This analysis will demonstrate the participants were largely unaware of the effect of context and rather believe they were using features of the person to categorize their gender.  \n\nH5.e. We will calculate the descriptives of the following question: \u201cDo you think that the order that you answered the demographic questions (age, height, weight, gender) could have affected your judgments?\u201d and show that most participants selected \u201cNO.\u201d We will then code the written responses of those who answered \u201cYES\u201d  to determine how they believed order affected their reporting. ", "confirmatory-analyses-fourth.fourth.question2c": "", "confirmatory-analyses-fourth.fourth.question3c": "", "confirmatory-analyses-fourth.fourth.question4c": "", "confirmatory-analyses-fourth.fourth.question5c": "", "confirmatory-analyses-second.second.question1c": "Demographic and Character Judgements\n\nH1.a: (DV: Gender) We will use Chi-square test for goodness of fit to analyze whether our clothing manipulation influences participants\u2019 gender categorization. \n\nH2.a, H2.b, Ex.2., H3: (DVs: Height, Weight, Aggression) Factorial ANOVAs will be used to analyze participants\u2019 continuous outcome variables. \n\nEx: (DV: Age): T-tests will be used to analyze participants\u2019 estimation of Age. ", "confirmatory-analyses-second.second.question2c": "", "confirmatory-analyses-second.second.question3c": "", "confirmatory-analyses-second.second.question4c": "", "confirmatory-analyses-second.second.question5c": "", "confirmatory-analyses-further.further.question1c": "Exploratory Analysis\n\n*We would like to mention here that we may or may not look at these aspects of the data. The following are points of interest:\n\nEx.1: Gender selection and demographic reporting. We may divide our sample into participants who selected \u201cmale\u201d and \u201cfemale.\u201d This gender-selected variable may then be used as an IV in our univariate ANOVAs in which we test if people\u2019s selections of gender affect how they report when making demographic and aggression judgments.   \n\nEx.3: If we explore if speed of responding is related to a higher amount of consistency between clothing condition and gender categorization we will use a logistic regression to do so. Pearson correlations will test if there is a relationship between speed of reporting and the demographic and aggression judgments in each of the clothing conditions (MC and FC). \n\nEx.4: If tested, Pearson correlations would be used to explore the relationship between speed of reporting and metacognitive judgments. Ultimately testing if faster response times resulted in more validating metacognitive reports, i.e. more confident, better view, reporting that they were faster in their identification of gender. \n\nEx.5: We may also explore if participants who were congruent in their clothing condition/gender categorization varied from those who were incongruent in their metacognitive reporting. An ANOVAs would be used to explore this relationship with congruency (congruent/incongruent) and time of gender judgment (1st or last) being used as our IVs and confidence, view, and speed reports as our DVs.  ", "confirmatory-analyses-further.further.question2c": "", "confirmatory-analyses-further.further.question3c": "", "confirmatory-analyses-further.further.question4c": "", "confirmatory-analyses-further.further.question5c": "", "description-methods.exclusion-criteria.question8b": "Anticipated data exclusion criteria: \n\na). Participants who spend a disproportionate amount of time (e.g., hours) to complete the 15-minutes study.\nb). Participants who request to have their data deleted. \nc). Participants with incomplete data. \nd). Participants who indicate that they suffer from colour blindness. \ne). Participants who fail the manipulation checks - i.e., do not know the image on the sweatshirt of the individual or the colour of the individual\u2019s outfit. ", "description-methods.planned-sample.question6b-upload": [{"file_id": "5e42d5f9a057ec006ab09542", "file_name": "GPower_Biasing Effects of Expectation on Person Perception 2020.JPG", "file_urls": {"html": "https://osf.io/project/j927s/files/osfstorage/5e42d5f9a057ec006ab09542", "download": "https://osf.io/download/5e42d5f9a057ec006ab09542"}, "file_hashes": {"sha256": "42191814c3c25b25e72fa8e0d63704b426842d9a2eb4a4f603240a2cd49b3408"}}]}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/comments/?format=json&filter%5Btarget%5D=j927s", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/j927s/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/ca-1/?format=json", "meta": {}}}, "data": {"id": "ca-1", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/?format=json", "meta": {}}}, "data": {"id": "j927s", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/j927s/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/j927s/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/j927s/citation/?format=json", "meta": {}}}, "data": {"id": "j927s", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/85n6s/?format=json", "meta": {}}}, "data": {"id": "85n6s", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/p2ru3/?format=json", "meta": {}}}, "data": {"id": "p2ru3", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5730e99a9ad5a102c5745a8a/?format=json", "meta": {}}}, "data": {"id": "5730e99a9ad5a102c5745a8a", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/j927s/", "self": "https://api.osf.io/v2/registrations/j927s/"}}, {"id": "d5jtb", "type": "registrations", "attributes": {"title": "Effect of early initiation of renal replacement therapy in patients with acute respiratory distress syndrome: a systematic review and meta-analysis.", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-02-07T14:21:30.100414", "date_modified": "2020-02-11T15:08:36.683329", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "ac457d67e6308c5beadf74d7b75cbd6d7bdbcbaa960d630178f3405b36dee9dc5adca97f858e9aed14e9a31680ea53436860c3ef17401c73cd71b96b3f80416b092ad19fb073e0d545b369f21e2cec69eecdc6fe7dd2034ec6bfa6445c4a120d91fb6cc672970321c66a28473ec852534a0bae99c558900d917e90378d79f278e46c32400f30a55d9f0ea971ab05fd4c", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": "10.1995/1995", "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-02-07T14:21:30.053468", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "OSF Preregistration", "registered_meta": {"q1": {"extra": [], "value": "Effect of early initiation of renal replacement therapy in patients with acute respiratory distress syndrome: a systematic review and meta-analysis."}, "q2": {"extra": [], "value": "Tong Zhaohui, Shao, Shuai, Kang, Hanyujie"}, "q3": {"extra": [], "value": "The optimal timing of initiation of renal replacement therapy (RRT) for patients with sepsis-associated acute kidney injury (SA-AKI) has been extensively studied in various studies. However, it is still unclear. As a result, we performed the meta-analysis to evaluate the influence of early and late initiation of RRT among SA-AKI patients."}, "q4": {"extra": [], "value": "If early initiation of renal therapy is better, the mortality of sa-aki patients will be lower than that of late initiation of renal therapy."}, "q5": {"extra": [], "value": "Meta-Analysis - A systematic review of published studies."}, "q6": {"extra": [], "value": ["No blinding is involved in this study."]}, "q7": {"extra": [], "value": ""}, "q8": {"value": {"question": {"extra": [], "value": "Acute kidney injury (AKI) is an independent risk factor for death, which can increase mortality by more than 50%. Recent evidence also suggests that lung\u2013kidney interactions are involved both in AKI-associated acute lung injury and as renal consequences of acute respiratory distress syndrome (ARDS). Renal replacement therapy (RRT) has long been considered as one of the effective treatments for AKI, which can promote the recovery of renal function in patients. However, in patients with AKI caused by ARDS, when is the best time to start RRT has been inconclusive.This review and meta-analysis reviewed all previous clinical trials in order to assess the best time of initiation of RRT in septic patients.\nWe choose research that meets the standards by reading the title, abstract and full text of previous RCT or retrospective analysis. Finally, it was included in the meta-analysis, and the subgroup analysis and meta-regression analysis were carried out.  \nIn concordance with the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, we performed this study. A systematic search of clinical trials published between January 1, 1968, and September 4, 2019, was conducted using Pubmed, Embase, Cochrane Library, Web of Science. The search terms used sepsis, septic shock, acute kidney injury, renal replacement therapy, initiation. We had no filter on the type of trial and language. References were identified for inclusion by screening their titles and abstracts and the related studies were selected for further analysis. Case reports, duplicates, studies not focused on the SA-AKI patients, studies consisting of pregnant patients or patients were not 18 years old, studies didn\u2019t provide the outcomes which we needed and those articles which didn\u2019t compare the early initiation strategy with the late initiation strategy clearly were excluded. The abstracts and full articles were selected for the assessment of quality and the synthesis of data by two researchers. We contacted the authors of the eligible articles for further details, if available. Any controversial issue was resolved by discussing with the third person. \nThe risk of bias of the included randomized controlled trial will be assessed by the Cochrane Collaboration Risk of Bias tool and rated as\"low,\" \"unclear,\" or \"high\" in several domains. Two investigators will evaluate the bias from random sequence generation, allocation concealment, blinding of participants and personnel, blinding of outcome assessment, incomplete outcome data, selective reporting and other bias. We will choose Newcastle-Ottawa Scale for cohort studies at the same time. Disagreements will be resolved by discussion, with involvement of a third review author where necessary."}, "uploader": {"extra": [], "value": ""}}}, "q9": {"extra": [], "value": ""}, "q10": {"extra": [], "value": "Registration prior to any human observation of the data"}, "q11": {"extra": [], "value": ""}, "q12": {"value": {"question": {"extra": [], "value": "The inclusion criteria will be as follows: 1) randomized controlled trials or cohort trials; 2) adult (age greater than 18 years old) patients who were diagnosed with AKI caused by ARDS; 3) used renal replacement therapy earlier in the study groups and used renal replacement therapy later in the control groups; 4) had years of research development or publication; 5) studies which provided the primary outcomes or the secondary outcomes clearly.\n\nThe exclusion criteria will be as follows: 1) case reports, letters, reviews, meta-analyses, or expert opinions; 2) no patients with ARDS; 3) studies which included patients who were under 18 years old; 4) study groups didn't use renal replacement therapy; 5) control groups didn't use the renal replacemnet therapy. 6) duplicates; 7) the studies didn't report primary outcomes or secondary outcomes; 8) multiple publication; 9) unclear outcome; 10) the statistical method is incorrect and cannot be corrected; 11) incomplete data and unclear outcome."}, "uploader": {"extra": [], "value": ""}}}, "q13": {"extra": [], "value": "The literature systematically searched yielded 2385 references in four electronic databases that were subsequently refined to 11 eligible studies for further consideration which included two RCTs and 9 cohort studies.  Overall, two RCTs with a total of 836 patients were concluded in this meta-analysis. At the same time. nine retrospective cohort studies with a total of 1730 patients ultimately met our standards."}, "q14": {"extra": [], "value": ""}, "q15": {"extra": [], "value": ""}, "q16": {"value": {"question": {"extra": [], "value": ""}, "uploader": {"extra": [], "value": ""}}}, "q17": {"value": {"question": {"extra": [], "value": "The primary outcomes were 28-day mortality and cumulative survival among participants. The secondary outcomes were ICU length of stay (LOS), hospital LOS and duration of RRT."}, "uploader": {"extra": [], "value": ""}}}, "q18": {"value": {"question": {"extra": [], "value": ""}, "uploader": {"extra": [], "value": ""}}}, "q19": {"value": {"question": {"extra": [], "value": "We will presente the risk ratios (RR) with 95% confidence intervals (CI) for dichotomous outcomes. Values for continuous outcomes will be given as the mean (standard deviation).  Meta-analysis will be performed using the M-H random effects model. Statistical heterogeneity across trials will be tested by I\u00b2 testing and we will value I\u00b2 greater than 50% regarded as being indicative of moderate-to-high heterogeneity. In the meta-analyses of main outcomes, we will do sensitivity analyses by sequentially omitting one study each time or use subgroup(separately or simultaneously) to find out the influence of each trial. Use a funnel plot and Egger's test to evaluate its publication bias in the analysis. The quality of evidence for important outcomes will be evaluated by the principles of GRADE system. Statistical analyses will be conducted using Review Manager Version 5.3 (Cochrane IMS, Oxford, UK) , Stata version 15.1 and GRADE Pro version 3.6 (GRADE Working Group).\nWe will use subgroup to achive sensitive analysis. We will conducte three subgroups: 1. Use \"time\" to define \"early\" and \"late\"/use \"biomarkers\" to define \"early\" and \"late\"/ use \"RIFLE crieria\"to define \"early\" and \"late\"/use \"ARDS diagnostic criteria\"to define \"early\" and \"late\". 2. The modality of renal replacement therapy used in patients(\"used continuous renal replacement therapy alone\" or \"use continuous renal replacement therapy and intermittent hemodialysis together\" )."}, "uploader": {"extra": [], "value": ""}}}, "q20": {"extra": [], "value": ""}, "q21": {"extra": [], "value": ""}, "q22": {"extra": [], "value": ""}, "q23": {"extra": [], "value": ""}, "q24": {"extra": [], "value": ""}, "q25": {"extra": [], "value": ""}}, "registration_responses": {"q1": "Effect of early initiation of renal replacement therapy in patients with acute respiratory distress syndrome: a systematic review and meta-analysis.", "q2": "Tong Zhaohui, Shao, Shuai, Kang, Hanyujie", "q3": "The optimal timing of initiation of renal replacement therapy (RRT) for patients with sepsis-associated acute kidney injury (SA-AKI) has been extensively studied in various studies. However, it is still unclear. As a result, we performed the meta-analysis to evaluate the influence of early and late initiation of RRT among SA-AKI patients.", "q4": "If early initiation of renal therapy is better, the mortality of sa-aki patients will be lower than that of late initiation of renal therapy.", "q5": "Meta-Analysis - A systematic review of published studies.", "q6": ["No blinding is involved in this study."], "q7": "", "q9": "", "q10": "Registration prior to any human observation of the data", "q11": "", "q13": "The literature systematically searched yielded 2385 references in four electronic databases that were subsequently refined to 11 eligible studies for further consideration which included two RCTs and 9 cohort studies.  Overall, two RCTs with a total of 836 patients were concluded in this meta-analysis. At the same time. nine retrospective cohort studies with a total of 1730 patients ultimately met our standards.", "q14": "", "q15": "", "q20": "", "q21": "", "q22": "", "q23": "", "q24": "", "q25": "", "q8.question": "Acute kidney injury (AKI) is an independent risk factor for death, which can increase mortality by more than 50%. Recent evidence also suggests that lung\u2013kidney interactions are involved both in AKI-associated acute lung injury and as renal consequences of acute respiratory distress syndrome (ARDS). Renal replacement therapy (RRT) has long been considered as one of the effective treatments for AKI, which can promote the recovery of renal function in patients. However, in patients with AKI caused by ARDS, when is the best time to start RRT has been inconclusive.This review and meta-analysis reviewed all previous clinical trials in order to assess the best time of initiation of RRT in septic patients.\nWe choose research that meets the standards by reading the title, abstract and full text of previous RCT or retrospective analysis. Finally, it was included in the meta-analysis, and the subgroup analysis and meta-regression analysis were carried out.  \nIn concordance with the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, we performed this study. A systematic search of clinical trials published between January 1, 1968, and September 4, 2019, was conducted using Pubmed, Embase, Cochrane Library, Web of Science. The search terms used sepsis, septic shock, acute kidney injury, renal replacement therapy, initiation. We had no filter on the type of trial and language. References were identified for inclusion by screening their titles and abstracts and the related studies were selected for further analysis. Case reports, duplicates, studies not focused on the SA-AKI patients, studies consisting of pregnant patients or patients were not 18 years old, studies didn\u2019t provide the outcomes which we needed and those articles which didn\u2019t compare the early initiation strategy with the late initiation strategy clearly were excluded. The abstracts and full articles were selected for the assessment of quality and the synthesis of data by two researchers. We contacted the authors of the eligible articles for further details, if available. Any controversial issue was resolved by discussing with the third person. \nThe risk of bias of the included randomized controlled trial will be assessed by the Cochrane Collaboration Risk of Bias tool and rated as\"low,\" \"unclear,\" or \"high\" in several domains. Two investigators will evaluate the bias from random sequence generation, allocation concealment, blinding of participants and personnel, blinding of outcome assessment, incomplete outcome data, selective reporting and other bias. We will choose Newcastle-Ottawa Scale for cohort studies at the same time. Disagreements will be resolved by discussion, with involvement of a third review author where necessary.", "q8.uploader": [], "q12.question": "The inclusion criteria will be as follows: 1) randomized controlled trials or cohort trials; 2) adult (age greater than 18 years old) patients who were diagnosed with AKI caused by ARDS; 3) used renal replacement therapy earlier in the study groups and used renal replacement therapy later in the control groups; 4) had years of research development or publication; 5) studies which provided the primary outcomes or the secondary outcomes clearly.\n\nThe exclusion criteria will be as follows: 1) case reports, letters, reviews, meta-analyses, or expert opinions; 2) no patients with ARDS; 3) studies which included patients who were under 18 years old; 4) study groups didn't use renal replacement therapy; 5) control groups didn't use the renal replacemnet therapy. 6) duplicates; 7) the studies didn't report primary outcomes or secondary outcomes; 8) multiple publication; 9) unclear outcome; 10) the statistical method is incorrect and cannot be corrected; 11) incomplete data and unclear outcome.", "q12.uploader": [], "q16.question": "", "q16.uploader": [], "q17.question": "The primary outcomes were 28-day mortality and cumulative survival among participants. The secondary outcomes were ICU length of stay (LOS), hospital LOS and duration of RRT.", "q17.uploader": [], "q18.question": "", "q18.uploader": [], "q19.question": "We will presente the risk ratios (RR) with 95% confidence intervals (CI) for dichotomous outcomes. Values for continuous outcomes will be given as the mean (standard deviation).  Meta-analysis will be performed using the M-H random effects model. Statistical heterogeneity across trials will be tested by I\u00b2 testing and we will value I\u00b2 greater than 50% regarded as being indicative of moderate-to-high heterogeneity. In the meta-analyses of main outcomes, we will do sensitivity analyses by sequentially omitting one study each time or use subgroup(separately or simultaneously) to find out the influence of each trial. Use a funnel plot and Egger's test to evaluate its publication bias in the analysis. The quality of evidence for important outcomes will be evaluated by the principles of GRADE system. Statistical analyses will be conducted using Review Manager Version 5.3 (Cochrane IMS, Oxford, UK) , Stata version 15.1 and GRADE Pro version 3.6 (GRADE Working Group).\nWe will use subgroup to achive sensitive analysis. We will conducte three subgroups: 1. Use \"time\" to define \"early\" and \"late\"/use \"biomarkers\" to define \"early\" and \"late\"/ use \"RIFLE crieria\"to define \"early\" and \"late\"/use \"ARDS diagnostic criteria\"to define \"early\" and \"late\". 2. The modality of renal replacement therapy used in patients(\"used continuous renal replacement therapy alone\" or \"use continuous renal replacement therapy and intermittent hemodialysis together\" ).", "q19.uploader": []}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/d5jtb/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/d5jtb/comments/?format=json&filter%5Btarget%5D=d5jtb", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/d5jtb/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/d5jtb/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/d5jtb/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/d5jtb/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/d5jtb/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/d5jtb/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/d5jtb/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/d5jtb/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/d5jtb/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/d5jtb/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/d5jtb/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/d5jtb/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/d5jtb/?format=json", "meta": {}}}, "data": {"id": "d5jtb", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/d5jtb/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/d5jtb/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/d5jtb/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/d5jtb/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/d5jtb/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/d5jtb/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/d5jtb/citation/?format=json", "meta": {}}}, "data": {"id": "d5jtb", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/r3v2q/?format=json", "meta": {}}}, "data": {"id": "r3v2q", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/9rjh8/?format=json", "meta": {}}}, "data": {"id": "9rjh8", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5c08457ed283380029cf73bf/?format=json", "meta": {}}}, "data": {"id": "5c08457ed283380029cf73bf", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/d5jtb/", "self": "https://api.osf.io/v2/registrations/d5jtb/"}}, {"id": "9482r", "type": "registrations", "attributes": {"title": "RAPID Study KCL", "description": "Remote Assessment of Prognosis in Depression", "category": "project", "custom_citation": "", "date_created": "2020-02-11T14:51:13.954372", "date_modified": "2020-02-11T14:52:14.847606", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "c3f1dcb061f0208d0b57dc04b783ef0ac6360ffcbe0e4b81e39a91fc1f445dcdce87503684bd29f7775b3b39807e45032726197e2025ee170369c2db1046b977e8b317c518cfb32316b9669fb93862a01afeb99c794cdf57c9b0b537d0332e3ab1c6ee58bb0f9daf18d78cef73b40b952e39bc22fc7c473d27a0433822c9aca15a495900ec765850db3fb8086e3f46ec", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-02-11T14:51:13.934988", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "OSF Preregistration", "registered_meta": {"q1": {"extra": [], "value": "Remote Assessment of Prognosis In Depression "}, "q2": {"extra": [], "value": "Valeria de Angel"}, "q3": {"extra": [], "value": "Remote measurement technologies (RMTs) like smartphones and wrist-worn devices (eg. Fitbits) are being increasingly used to collect health data in people with experience of mental health problems, in the hopes of improving diagnosis, treatment and illness management. In order for digital devices to be implemented and used appropriately for the above purposes,  feasibility and acceptability of using these methods of data collection need to be established. This study will aim to do this in the context of psychological therapy. It will describe the clinical population in terms of digital markers and evaluate their value as prognostic markers of recovery after psychological treatment. "}, "q4": {"extra": [], "value": "The overarching aim of this project is to determine the feasibility of using RMTs, such as smartphones and wearable devices, to collect behavioural and clinical data in people undergoing therapy for depressive disorders, and whether they can be potentially useful markers of depression and changes in clinical state. As a feasibility study, there are no testable hypotheses.\n\nSecondary objectives include identifying candidate signals for digital biomarkers by determining the extent to which objective features as measured via RMTs correlate with clinical characteristics, and exploring whether these signals have prognostic value in the context of psychological treatments.\n"}, "q5": {"extra": [], "value": "Observational Study - Data is collected from study subjects that are not randomly assigned to a treatment. This includes surveys, \u201cnatural experiments,\u201d and regression discontinuity designs."}, "q6": {"extra": [], "value": ["No blinding is involved in this study."]}, "q7": {"extra": [], "value": ""}, "q8": {"value": {"question": {"extra": [], "value": "This is an observational, prospective cohort study of people in psychological therapy for depression. It will use RMTs to gather data for 10 months; 1 month pre-treatment, during psychological treatment (which can run from 1.5 to 3 months), and 6 months post treatment. "}, "uploader": {"extra": [], "value": ""}}}, "q9": {"extra": [], "value": ""}, "q10": {"extra": [], "value": "Registration prior to creation of data"}, "q11": {"extra": [], "value": ""}, "q12": {"value": {"question": {"extra": [], "value": "Setting: \n\nParticipants will be drawn from Improving Access to Psychological Therapies services in London \u2013 a self-referral outpatient programme which seeks to increase its reach to providing evidence-based psychological treatments for adults with depression and anxiety disorders.\n\nInclusion criteria: \n-Aged 18 or over \n-Current depressive episode as measured by The Mini International Neuropsychiatric Interview (MINI)  \n-On the waiting list for psychological treatment for depressive disorders at IAPT services.  \n-Existing ownership of Android smartphone with enough memory space for the relevant apps. \n-Willing and able to complete self-reported assessments via smartphone. \n-Willing to use a wrist worn device for duration of the study \n-Able to give informed consent for participation. \n-Sufficient English language skills to understand consent process and questionnaires. \n\nExclusion criteria: \n-Lifetime diagnosis of bipolar disorder, schizophrenia, MDD with psychotic features, schizoaffective disorders as these have different digital patterns to depression. \n-Health anxieties that may significantly worsen with constant monitoring of behaviours.  \n-Planned hospitalisation during study period \n-Extensive sharing of smartphone with friends or family. \n-Pregnancy (because of disruptions to digital signatures).\n\nStudy Timeline:\nOnce contact has been established with participants, we will enrol them and begin measures at least one month before they are due to start treatment. We will calculate this time based on the length of their current waiting list status and correspondence with the clinical teams. It is estimated that one month will be sufficient for the participant to adjust to and iron out any issues with the technology, and to obtain baseline pre-treatment measures. Figure 2 below shows the full timeline. Enrolment and the start of monitoring will ideally happen on the same day, if this is not possible due to unforeseen circumstances, they should be held within a maximum 3 months of each other. Any longer than 3 months and consent procedures will be gone through again, and a new consent form signed. Treatment may last fewer than 3 months, or patients may drop out of treatment. In these cases, the 6-month follow-up will commence on the day of their last treatment session. We will continue to include those who drop out as this is an important clinical outcome. "}, "uploader": {"extra": [], "value": ""}}}, "q13": {"extra": [], "value": "Being predominantly a feasibility study, there is no need for a formal sample size calculation (Billingham, Whitehead, &amp; Julious, 2013). In this context, we will recruit 50 participants. "}, "q14": {"extra": [], "value": "A sample size of 50 would be sufficiently powered to detect a correlation coefficient of 0.39 and above, assuming a significance level (alpha value) of 0.05 and Type 2 error (Beta) value of 0.20. Based on previous studies, we expect such an effect size (e.g., Averill et al., 2018; Berke, Choudhury, Ali, &amp; Rabbi, 2011; Szklo-Coxe, Young, Peppard, Finn, &amp; Benca, 2010). "}, "q15": {"extra": [], "value": ""}, "q16": {"value": {"question": {"extra": [], "value": ""}, "uploader": {"extra": [], "value": ""}}}, "q17": {"value": {"question": {"extra": [], "value": "Absolute attrition and missing data rates will be evaluated to inform the primary outcome. Using regression analyses, we will also investigate whether any baseline data can predict dropouts or missing data. In order to investigate feasibility of recruitment, frequency data will be presented, stating number of people contacted, and a flowchart of participant recruitment/enrolment and dropouts.\n\nFor secondary outcomes see attached document."}, "uploader": {"extra": [{"data": {"name": "Secondary Outcomes.docx"}, "nodeId": "pmyta", "sha256": "3a6a04e05dfe36129f34682a687f5d5b6ab78829ae12dcf28583ce54aacf3c2c", "viewUrl": "/project/9482r/files/osfstorage/5e42bf65a057ec006ab06ebc/", "selectedFileName": "Secondary Outcomes.docx"}], "value": ""}}}, "q18": {"value": {"question": {"extra": [], "value": ""}, "uploader": {"extra": [], "value": ""}}}, "q19": {"value": {"question": {"extra": [], "value": "Primary aim:  \n\nAbsolute attrition and missing data rates will be evaluated to inform the primary outcome. Using regression analyses, we will also investigate whether any baseline data can predict dropouts or missing data. In order to investigate feasibility of recruitment, frequency data will be presented, stating number of people contacted, and a flowchart of participant recruitment/enrolment and dropouts. We will attempt to compare any available demographics and clinical characteristics of those accepting to enter the study with the average for the local service to find out the representativeness of our sample. \n\n \nSecondary aims: \n\nFirstly, we will extract significant features from the dataset that may be related to clinical outcomes. Low mood, for example, may be associated with disrupted sleep patterns or increased phone usage. These include things like, change in location throughout the day, amount of time spent on communication applications.  \n \nDescriptive statistics for baseline demographics, clinical and other baseline data will be presented. We will use parametric/non-parametric statistical tests, depending on the type of variable, to analyse any between group differences \u2013 severity of depression will be analysed against all outcome measures. Multiple linear regression will be used for model selection for descriptive purposes.  \n \nDigital features that account for sleep, activity, sociability, cognition will be extracted from sensor data and correlated against scores on scales of depressive symptoms. Feature extraction will follow the methods used by Ranjan and colleagues (2018) in the RADAR-Base platform. Regression analyses will also be carried out for scores on impairment and other factors contributing to depression, e.g. anxiety, social support, self-esteem, rumination, stress, alcohol use, to see whether higher impairment is associated with any of the extracted features. Self- report scores are taken ever few weeks, whereas sensor data is continuously being generated, sensor data will therefore be divided to match the self-report timescales for statistical analysis. \n\nIn order to unearth digital profiles in the sample, individuals will be clustered together based on their response patterns using latent class analysis. This person-centred approach will unpick some of the heterogeneity in the sample and assumes there are underlying latent variables that underpin distinct symptom profiles (Masyn, 2013), and has been used extensively in the construction of the subtypes of depression (Lanza &amp; Rhoades, 2013). This model will aid in the description of longitudinal behavioural patterns in this sample.  \n\nIn addition to exploring the ability of those features to predict current levels of depressive and impairment between groups, the changes within individuals will be analysed. Following from the methods used in Iniesta et al., 2018, we will use machine learning on the extracted aggregated digital features and clinical information in our sample to derive models predicting recovery after treatment. A penalised logistic model will then be carried out, with the area under the curve statistic as a measure of the goodness-of-fit. The area under the ROC curve ranges from 0.5 and 1.0 with larger values are indicative of better fit. The penalised logistic regression method allows the use of all sensor data (instead of calculating an average across time points) as predictor of the outcome and can detect time-dependent relationships. We would therefore be able to study the period of time in which the predictors are more strongly associated to the outcomes (Ben-Zeev, Scherer, Wang, Xie, &amp; Campbell, 2015). \n\nWhere data is missing at random and assuming it is not significantly high, multiple imputation methods will be carried out. If missing data is high, this may be incorporated into the model as a predictor, or otherwise used informatively. "}, "uploader": {"extra": [], "value": ""}}}, "q20": {"extra": [], "value": ""}, "q21": {"extra": [], "value": ""}, "q22": {"extra": [], "value": ""}, "q23": {"extra": [], "value": "Where data is missing at random and assuming it is not significantly high, multiple imputation methods will be carried out. If missing data is high, this may be incorporated into the model as a predictor, or otherwise used informatively. "}, "q24": {"extra": [], "value": "All secondary analyses, as mentioned in the statistical models section will be exploratory."}, "q25": {"extra": [], "value": ""}}, "registration_responses": {"q1": "Remote Assessment of Prognosis In Depression ", "q2": "Valeria de Angel", "q3": "Remote measurement technologies (RMTs) like smartphones and wrist-worn devices (eg. Fitbits) are being increasingly used to collect health data in people with experience of mental health problems, in the hopes of improving diagnosis, treatment and illness management. In order for digital devices to be implemented and used appropriately for the above purposes,  feasibility and acceptability of using these methods of data collection need to be established. This study will aim to do this in the context of psychological therapy. It will describe the clinical population in terms of digital markers and evaluate their value as prognostic markers of recovery after psychological treatment. ", "q4": "The overarching aim of this project is to determine the feasibility of using RMTs, such as smartphones and wearable devices, to collect behavioural and clinical data in people undergoing therapy for depressive disorders, and whether they can be potentially useful markers of depression and changes in clinical state. As a feasibility study, there are no testable hypotheses.\n\nSecondary objectives include identifying candidate signals for digital biomarkers by determining the extent to which objective features as measured via RMTs correlate with clinical characteristics, and exploring whether these signals have prognostic value in the context of psychological treatments.\n", "q5": "Observational Study - Data is collected from study subjects that are not randomly assigned to a treatment. This includes surveys, \u201cnatural experiments,\u201d and regression discontinuity designs.", "q6": ["No blinding is involved in this study."], "q7": "", "q9": "", "q10": "Registration prior to creation of data", "q11": "", "q13": "Being predominantly a feasibility study, there is no need for a formal sample size calculation (Billingham, Whitehead, &amp; Julious, 2013). In this context, we will recruit 50 participants. ", "q14": "A sample size of 50 would be sufficiently powered to detect a correlation coefficient of 0.39 and above, assuming a significance level (alpha value) of 0.05 and Type 2 error (Beta) value of 0.20. Based on previous studies, we expect such an effect size (e.g., Averill et al., 2018; Berke, Choudhury, Ali, &amp; Rabbi, 2011; Szklo-Coxe, Young, Peppard, Finn, &amp; Benca, 2010). ", "q15": "", "q20": "", "q21": "", "q22": "", "q23": "Where data is missing at random and assuming it is not significantly high, multiple imputation methods will be carried out. If missing data is high, this may be incorporated into the model as a predictor, or otherwise used informatively. ", "q24": "All secondary analyses, as mentioned in the statistical models section will be exploratory.", "q25": "", "q8.question": "This is an observational, prospective cohort study of people in psychological therapy for depression. It will use RMTs to gather data for 10 months; 1 month pre-treatment, during psychological treatment (which can run from 1.5 to 3 months), and 6 months post treatment. ", "q8.uploader": [], "q12.question": "Setting: \n\nParticipants will be drawn from Improving Access to Psychological Therapies services in London \u2013 a self-referral outpatient programme which seeks to increase its reach to providing evidence-based psychological treatments for adults with depression and anxiety disorders.\n\nInclusion criteria: \n-Aged 18 or over \n-Current depressive episode as measured by The Mini International Neuropsychiatric Interview (MINI)  \n-On the waiting list for psychological treatment for depressive disorders at IAPT services.  \n-Existing ownership of Android smartphone with enough memory space for the relevant apps. \n-Willing and able to complete self-reported assessments via smartphone. \n-Willing to use a wrist worn device for duration of the study \n-Able to give informed consent for participation. \n-Sufficient English language skills to understand consent process and questionnaires. \n\nExclusion criteria: \n-Lifetime diagnosis of bipolar disorder, schizophrenia, MDD with psychotic features, schizoaffective disorders as these have different digital patterns to depression. \n-Health anxieties that may significantly worsen with constant monitoring of behaviours.  \n-Planned hospitalisation during study period \n-Extensive sharing of smartphone with friends or family. \n-Pregnancy (because of disruptions to digital signatures).\n\nStudy Timeline:\nOnce contact has been established with participants, we will enrol them and begin measures at least one month before they are due to start treatment. We will calculate this time based on the length of their current waiting list status and correspondence with the clinical teams. It is estimated that one month will be sufficient for the participant to adjust to and iron out any issues with the technology, and to obtain baseline pre-treatment measures. Figure 2 below shows the full timeline. Enrolment and the start of monitoring will ideally happen on the same day, if this is not possible due to unforeseen circumstances, they should be held within a maximum 3 months of each other. Any longer than 3 months and consent procedures will be gone through again, and a new consent form signed. Treatment may last fewer than 3 months, or patients may drop out of treatment. In these cases, the 6-month follow-up will commence on the day of their last treatment session. We will continue to include those who drop out as this is an important clinical outcome. ", "q12.uploader": [], "q16.question": "", "q16.uploader": [], "q17.question": "Absolute attrition and missing data rates will be evaluated to inform the primary outcome. Using regression analyses, we will also investigate whether any baseline data can predict dropouts or missing data. In order to investigate feasibility of recruitment, frequency data will be presented, stating number of people contacted, and a flowchart of participant recruitment/enrolment and dropouts.\n\nFor secondary outcomes see attached document.", "q17.uploader": [{"file_id": "5e42bf65a057ec006ab06ebc", "file_name": "Secondary Outcomes.docx", "file_urls": {"html": "https://osf.io/project/9482r/files/osfstorage/5e42bf65a057ec006ab06ebc", "download": "https://osf.io/download/5e42bf65a057ec006ab06ebc"}, "file_hashes": {"sha256": "3a6a04e05dfe36129f34682a687f5d5b6ab78829ae12dcf28583ce54aacf3c2c"}}], "q18.question": "", "q18.uploader": [], "q19.question": "Primary aim:  \n\nAbsolute attrition and missing data rates will be evaluated to inform the primary outcome. Using regression analyses, we will also investigate whether any baseline data can predict dropouts or missing data. In order to investigate feasibility of recruitment, frequency data will be presented, stating number of people contacted, and a flowchart of participant recruitment/enrolment and dropouts. We will attempt to compare any available demographics and clinical characteristics of those accepting to enter the study with the average for the local service to find out the representativeness of our sample. \n\n \nSecondary aims: \n\nFirstly, we will extract significant features from the dataset that may be related to clinical outcomes. Low mood, for example, may be associated with disrupted sleep patterns or increased phone usage. These include things like, change in location throughout the day, amount of time spent on communication applications.  \n \nDescriptive statistics for baseline demographics, clinical and other baseline data will be presented. We will use parametric/non-parametric statistical tests, depending on the type of variable, to analyse any between group differences \u2013 severity of depression will be analysed against all outcome measures. Multiple linear regression will be used for model selection for descriptive purposes.  \n \nDigital features that account for sleep, activity, sociability, cognition will be extracted from sensor data and correlated against scores on scales of depressive symptoms. Feature extraction will follow the methods used by Ranjan and colleagues (2018) in the RADAR-Base platform. Regression analyses will also be carried out for scores on impairment and other factors contributing to depression, e.g. anxiety, social support, self-esteem, rumination, stress, alcohol use, to see whether higher impairment is associated with any of the extracted features. Self- report scores are taken ever few weeks, whereas sensor data is continuously being generated, sensor data will therefore be divided to match the self-report timescales for statistical analysis. \n\nIn order to unearth digital profiles in the sample, individuals will be clustered together based on their response patterns using latent class analysis. This person-centred approach will unpick some of the heterogeneity in the sample and assumes there are underlying latent variables that underpin distinct symptom profiles (Masyn, 2013), and has been used extensively in the construction of the subtypes of depression (Lanza &amp; Rhoades, 2013). This model will aid in the description of longitudinal behavioural patterns in this sample.  \n\nIn addition to exploring the ability of those features to predict current levels of depressive and impairment between groups, the changes within individuals will be analysed. Following from the methods used in Iniesta et al., 2018, we will use machine learning on the extracted aggregated digital features and clinical information in our sample to derive models predicting recovery after treatment. A penalised logistic model will then be carried out, with the area under the curve statistic as a measure of the goodness-of-fit. The area under the ROC curve ranges from 0.5 and 1.0 with larger values are indicative of better fit. The penalised logistic regression method allows the use of all sensor data (instead of calculating an average across time points) as predictor of the outcome and can detect time-dependent relationships. We would therefore be able to study the period of time in which the predictors are more strongly associated to the outcomes (Ben-Zeev, Scherer, Wang, Xie, &amp; Campbell, 2015). \n\nWhere data is missing at random and assuming it is not significantly high, multiple imputation methods will be carried out. If missing data is high, this may be incorporated into the model as a predictor, or otherwise used informatively. ", "q19.uploader": []}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9482r/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9482r/comments/?format=json&filter%5Btarget%5D=9482r", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9482r/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9482r/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9482r/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9482r/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9482r/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9482r/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9482r/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9482r/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9482r/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9482r/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9482r/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/9482r/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/us/?format=json", "meta": {}}}, "data": {"id": "us", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9482r/?format=json", "meta": {}}}, "data": {"id": "9482r", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9482r/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9482r/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/9482r/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9482r/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/9482r/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9482r/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9482r/citation/?format=json", "meta": {}}}, "data": {"id": "9482r", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/xudqt/?format=json", "meta": {}}}, "data": {"id": "xudqt", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/pmyta/?format=json", "meta": {}}}, "data": {"id": "pmyta", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5c08457ed283380029cf73bf/?format=json", "meta": {}}}, "data": {"id": "5c08457ed283380029cf73bf", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/9482r/", "self": "https://api.osf.io/v2/registrations/9482r/"}}, {"id": "7ec8y", "type": "registrations", "attributes": {"title": "Disengaging overt attention from emotional faces", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-02-11T14:37:52.826691", "date_modified": "2020-02-11T14:36:37.319124", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "9750187b420e18e8d1b4f2019023b5cad12e10e17c3991bb8aac8ab125c935f46aa883376f54244f7990f421e29c7ec9d20feb29b4d7a5d4a8d60cabb8742e3837e4ae5f22accb3f4cd412ca062dd67864a405e7b63dbf45c7089b35111d99b44968899e70ab841cdf49c75bddfb1c6cb80b924ddc7e885aeec8a90df22e7650dc06196242a2c170424af7c039af8ecb", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-02-11T14:37:52.809685", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "OSF Preregistration", "registered_meta": {"q1": {"extra": [], "value": "Disengaging overt attention from emotional faces"}, "q2": {"extra": [], "value": "Louisa Kulke, Lena Br\u00fcmmer, Arezoo Pooresmaeili, Annekathrin Schacht"}, "q3": {"extra": [], "value": "The goal of this study is to investigate saccadic and neural mechanisms involved in disengagement of overt attention from emotional faces. \nAmple research has indicated that participants are slower at shifting attention to a peripheral stimulus when they need to first disengage from a central stimulus (competition condition), than when no central stimulus is present and therefore no disengagement is required (non-competition condition, e.g. Atkinson &amp; Braddick, 2012 (review); Atkinson, Hood, Braddick, &amp; Wattam-Bell, 1988; Atkinson, Hood, Wattam-Bell, &amp; Braddick, 1992; Butcher, Kalverboer, &amp; Geuze, 2000; Hood &amp; Atkinson, 1993; Kulke, Atkinson &amp; Braddick, 2015). Faster saccades in the non-competition condition coincide with shorter latencies of early neural responses (ERPs), including a posterior positivity between 100 and 160 ms after onset of the peripheral stimulus (Kulke, 2015). However, the emotional content of the peripheral stimulus did not affect saccades and early ERPs but only showed effects on later ERPs that occurred after saccades had been completed (Kulke, 2019). \nThe shift of attention between the central and the peripheral stimulus involves both a disengagement from the central stimulus, as well as an engagement with the peripheral stimulus. Therefore, the effect of emotional content on shifts of attention may depend on whether the central or the peripheral stimulus convey emotions. Our previous preregistered study (https://osf.io/324ds) examined the effect of emotional content of the peripheral stimulus on the saccadic engagement with it. However, it remains unclear, whether the disengagement from the central stimulus (measured through latencies of eye-movements and through ERPs to the peripheral stimulus) is affected by its emotional content. The current study will therefore investigate the effect of emotional expressions of the central stimulus on overt attention shifts towards the peripheral stimulus by combining eye-tracking and EEG. Faces with happy, neutral or angry expressions will be presented in the center of the screen and if participants fixate on these central faces, a neutral face will appear in the left or right periphery. Participants\u2019 eye-movements towards the peripheral face and EPRs will be measured.\nThe study addresses the following questions:\n1.\tDo saccade latencies to peripheral stimuli differ as a function of the presence of a salient central distractor and its emotional expression?\n2.\tDo early neural responses, measured through EEG, differ as a function of the presence of a salient central distractor and its emotional expression?\n3.\tAre these attention shifts related to personality traits?"}, "q4": {"extra": [], "value": "1.\tSaccade latencies are longer in competition than in non-competition conditions.\n2.\tSaccade latencies differ depending on the expression of the central face, with longer latencies when the face shows an emotional compared to a neutral expression.\n3.\tThere is an interaction effect of competition condition and expression on saccade latency, with effects of emotion being larger in the competition than in the non-competition condition.\n4.\tERP latencies in posterior regions (~P1) in response to the peripheral face are longer in competition than in non-competition conditions.\n5.\tERP latencies in posterior regions in response to the peripheral face differ depending on the expression of the central face, with longer latencies when the central face shows an emotional compared to a neutral expression.\n6.\tThere is an interaction effect of competition condition and expression on ERP latency in posterior regions in response to the peripheral face, with effects of emotion being larger in the competition than in the non-competition condition\n7.\tEPN amplitudes in response to the central face are larger for happy and angry than for neutral faces\n8.\tLPC amplitudes in response to the central face differ as a function of its emotional expression \n9.\tParticipants with high compared to low BIS scores will disengage slower (i.e. make slower saccades away) from angry faces.\n10.\tParticipants with high compared to low BAS scores will disengage slower (i.e. make slower saccades away) from happy faces.\n11.\tObserved effects of emotional compared to neutral faces are larger for people with higher scores on the \u201cReading Mind in the Eye\u201d test.\n12.\tDisengagement latency differences between angry and neutral faces will differ between people with high and low SIAS scores. \n13.\tDisengagement latencies differ between people with high and low SIAS scores.\n14.\tParticipants with high compared to low SIAS scores show longer P1 latency in response to the peripheral face if it follows an angry compared to a neutral central face. "}, "q5": {"extra": [], "value": "Experiment - A researcher randomly assigns treatments to study subjects, this includes field or lab experiments. This is also known as an intervention experiment and includes randomized controlled trials."}, "q6": {"extra": [], "value": ["No blinding is involved in this study."]}, "q7": {"extra": [], "value": ""}, "q8": {"value": {"question": {"extra": [], "value": "In a repeated measures design, expression of the central face (happy, neutral and angry) and competition condition (competition and non-competition) will be manipulated within participants. Questionnaire scores will be compared between participants"}, "uploader": {"extra": [], "value": ""}}}, "q9": {"extra": [], "value": "Stimuli with happy, angry, or neutral facial expressions will be presented in a randomized order, with equal numbers of male and female faces for each expression. Competition and non-competition conditions will be presented in random order, with expression of the central face fully counterbalanced per condition. The screen side on which stimuli appear will be counterbalanced with all stimuli appearing equally often on the left and right side of the screen. The order in which stimuli are presented at the left or right side of the screen will be randomized. "}, "q10": {"extra": [], "value": "Registration prior to creation of data"}, "q11": {"extra": [], "value": "NA"}, "q12": {"value": {"question": {"extra": [], "value": "Healthy subjects between 18 and 35 years will be tested. Subjects will be recruited via posters, advertisements, local databases and leaflets. They will receive course credit or monetary compensation in return for participation. "}, "uploader": {"extra": [], "value": ""}}}, "q13": {"extra": [], "value": "40 participants will be tested. If subjects need to be excluded, additional subjects will be tested until the predetermined number of subjects can be included."}, "q14": {"extra": [], "value": "Sample size calculations were conduction in G*Power (version 3.1.9.2), in line with a previously preregistered study (https://osf.io/324ds). Differences in saccade latency between competition and non-competition conditions (Kulke, Atkinson &amp; Braddick, under revision) had an effect size dz = 0.723. The required sample size for two-tailed tests with an alpha of .05 and a power of .95 is 27 (one-tailed 23). Differences in P1 latency between competition and non-competition conditions had an effect size dz = 0.677 (Kulke, Atkinson &amp; Braddick, under revision). The required sample size for two-tailed tests with an alpha of .05 and a power of .95 is 31 (one-tailed 26). Analyses determining the sample size to detect the EPN effect found by Kulke (2019) based on a partial eta squared of 0.247 showed that 6 participants would be required to detect the effect. Therefore, the maximum determined required sample size is 31. To account for potential overestimation of the effect, 40 participants will be tested."}, "q15": {"extra": [], "value": "The data collection will be stopped once the predetermined sample size has been reached after subjects have been excluded."}, "q16": {"value": {"question": {"extra": [], "value": "The emotional expression of the central face (happy, neutral or angry) will be manipulated. The peripheral face will always show a neutral expression. Whether the central face remains visible in the center of fixation (competition condition) or whether it disappears (non-competition condition) will be manipulated. The side on which the face appears (left or right periphery) will be counterbalanced. The gender of the target faces will be counterbalanced. Images of ten different individuals will be used, and every individual will be shown expressing each of the expressions. Images will be selected from the Karolinska Directed Emotional Faces (KDEF) database and luminance will be controlled."}, "uploader": {"extra": [], "value": ""}}}, "q17": {"value": {"question": {"extra": [], "value": "This study will determine latencies of the first saccade towards the peripheral stimulus and ERPs to the central and the peripheral stimulus. Preprocessing of eye movement data will be based on previous research.\nRegarding ERPs, the amplitude and latency of an early positive deflection (~P1), and the amplitude of the EPN and the LPC will be measured.\nQuestionnaire scores on the Autism Quotient (Baron-Cohen, Wheelwright, Skinner, Martin, &amp; Clubley, 2001), the \u201cReading Mind in the Eye\u201d test (Baron-Cohen, Jolliffe, Mortimore, &amp; Robertson, 1997), the Social-Interaction-Anxiety Scale (SIAS) (Stangier, Heidenreich, Berardi, Golbs, &amp; Hoyer, 1999) and the BIS/BAS test (Strobel, Beauducel, Debener, &amp; Brocke, 2001) will be collected."}, "uploader": {"extra": [], "value": ""}}}, "q18": {"value": {"question": {"extra": [], "value": "EEG data will be preprocessed based on previous research (Kulke, Atkinson &amp; Braddick, 2016; Kulke, 2019). Initially, independent Component analysis (ICA) will be conducted and eye components will be rejected.\nBased on previous studies, the maximal positive deflection between 100 and 180 ms after target onset within posterior areas will be determined in two lateral occipital electrode clusters around O1 and O2 (see Kulke, 2019). Its amplitude and latency will be computed within each of the conditions (excluding trials in which the first saccade did not go to the correct location). \nThe mean EPN amplitude will be extracted between 250 and 350 ms after stimulus onset in an occipito-parietal electrode cluster including electrodes O1, O2, P9, P10, PO7 and PO8. The mean LPC amplitude will be quantified in a time window between 400 and 600 ms after stimulus onset in an occipito-parietal electrode cluster including Pz, POz, PO3 and PO4. Regions of interest and time windows for both components are based on previous research."}, "uploader": {"extra": [], "value": ""}}}, "q19": {"value": {"question": {"extra": [], "value": "1., 2. &amp; 3. A repeated measures ANOVA will be conducted to investigate the effects of competition condition (competition or non-competition) and valence (happy, neutral, angry) on saccade latency. T-tests will be conducted to compare saccade latency between conditions.\n4., 5. &amp; 6. A repeated measures ANOVA will be conducted to investigate the effects of competition condition (competition or non-competition) and valence (happy, neutral, angry) on the latency of the early posterior response (~P1) in response to the peripheral face. T-tests will be conducted to compare this latency between conditions.\n7. A repeated measures ANOVA will be conducted to investigate the effects of valence (happy, neutral, angry) on EPN amplitude in response to the central face. T-tests will be conducted to compare this amplitude between conditions.\n8. A repeated measures ANOVA will be conducted to investigate the effects of valence (happy, neutral, angry) on LPC amplitude in response to the central face. Potential significant effects will be followed up using t-tests.\n\n9. In order to test if people with high compared to low BIS scores will disengage slower from angry faces, a linear model will predict saccade and P1 latency from BIS score.\n10. In order to test if people with high compared to low BAS scores disengage slower from happy faces, a linear model will predict saccade and P1 latency from BAS score.\n11. In order to test if observed effects are larger for people with higher scores on the \u201cReading Mind in the Eye\u201d (RME) test, the interaction of RME score with the observed effects will be investigated using a mixed model.\n12. &amp; 13. To test if participants with high compared to low SIAS scores disengage slower from angry compared to neutral faces, a mixed model will be computed predicting saccade latency from SIAS score and valence.\n14. To test if participants with high compared to low SIAS scores show longer P1 latency in response to the peripheral face if it follows an angry compared to a neutral central faces, a mixed model will be computed predicting P1 latency from SIAS score and valence. \n15. AQ scores will be analyzed and it will be reported whether any participants scored above the 32+ cut-off to distinguish groups with autism from groups without autism."}, "uploader": {"extra": [], "value": ""}}}, "q20": {"extra": [], "value": "EEG data will be processed as described above."}, "q21": {"extra": [], "value": "For non-directional hypotheses (see above), standard p-values of 0.05 will be used as a cut-off. For directional hypotheses, p = .10 will be used as a cut-off (comparable to one-sided testing). "}, "q22": {"extra": [], "value": "Subjects will be excluded from further analyses if they fail to finish the experiment, in case of experimenter or technical failures, or if excessive noise is detected during preprocessing (more than 50% of trials missing or noisy in any of the measures). They will not be tested if they are not healthy (according to self-report) or if they are not between 18 and 35 years of age."}, "q23": {"extra": [], "value": "In case a participant needs to be excluded, an additional subject will be tested to reach the required sample size determined above. "}, "q24": {"extra": [], "value": ""}, "q25": {"extra": [], "value": "EEG data will be collected using a 64-electrodes system plus additional mastoid and eye electrodes. "}}, "registration_responses": {"q1": "Disengaging overt attention from emotional faces", "q2": "Louisa Kulke, Lena Br\u00fcmmer, Arezoo Pooresmaeili, Annekathrin Schacht", "q3": "The goal of this study is to investigate saccadic and neural mechanisms involved in disengagement of overt attention from emotional faces. \nAmple research has indicated that participants are slower at shifting attention to a peripheral stimulus when they need to first disengage from a central stimulus (competition condition), than when no central stimulus is present and therefore no disengagement is required (non-competition condition, e.g. Atkinson &amp; Braddick, 2012 (review); Atkinson, Hood, Braddick, &amp; Wattam-Bell, 1988; Atkinson, Hood, Wattam-Bell, &amp; Braddick, 1992; Butcher, Kalverboer, &amp; Geuze, 2000; Hood &amp; Atkinson, 1993; Kulke, Atkinson &amp; Braddick, 2015). Faster saccades in the non-competition condition coincide with shorter latencies of early neural responses (ERPs), including a posterior positivity between 100 and 160 ms after onset of the peripheral stimulus (Kulke, 2015). However, the emotional content of the peripheral stimulus did not affect saccades and early ERPs but only showed effects on later ERPs that occurred after saccades had been completed (Kulke, 2019). \nThe shift of attention between the central and the peripheral stimulus involves both a disengagement from the central stimulus, as well as an engagement with the peripheral stimulus. Therefore, the effect of emotional content on shifts of attention may depend on whether the central or the peripheral stimulus convey emotions. Our previous preregistered study (https://osf.io/324ds) examined the effect of emotional content of the peripheral stimulus on the saccadic engagement with it. However, it remains unclear, whether the disengagement from the central stimulus (measured through latencies of eye-movements and through ERPs to the peripheral stimulus) is affected by its emotional content. The current study will therefore investigate the effect of emotional expressions of the central stimulus on overt attention shifts towards the peripheral stimulus by combining eye-tracking and EEG. Faces with happy, neutral or angry expressions will be presented in the center of the screen and if participants fixate on these central faces, a neutral face will appear in the left or right periphery. Participants\u2019 eye-movements towards the peripheral face and EPRs will be measured.\nThe study addresses the following questions:\n1.\tDo saccade latencies to peripheral stimuli differ as a function of the presence of a salient central distractor and its emotional expression?\n2.\tDo early neural responses, measured through EEG, differ as a function of the presence of a salient central distractor and its emotional expression?\n3.\tAre these attention shifts related to personality traits?", "q4": "1.\tSaccade latencies are longer in competition than in non-competition conditions.\n2.\tSaccade latencies differ depending on the expression of the central face, with longer latencies when the face shows an emotional compared to a neutral expression.\n3.\tThere is an interaction effect of competition condition and expression on saccade latency, with effects of emotion being larger in the competition than in the non-competition condition.\n4.\tERP latencies in posterior regions (~P1) in response to the peripheral face are longer in competition than in non-competition conditions.\n5.\tERP latencies in posterior regions in response to the peripheral face differ depending on the expression of the central face, with longer latencies when the central face shows an emotional compared to a neutral expression.\n6.\tThere is an interaction effect of competition condition and expression on ERP latency in posterior regions in response to the peripheral face, with effects of emotion being larger in the competition than in the non-competition condition\n7.\tEPN amplitudes in response to the central face are larger for happy and angry than for neutral faces\n8.\tLPC amplitudes in response to the central face differ as a function of its emotional expression \n9.\tParticipants with high compared to low BIS scores will disengage slower (i.e. make slower saccades away) from angry faces.\n10.\tParticipants with high compared to low BAS scores will disengage slower (i.e. make slower saccades away) from happy faces.\n11.\tObserved effects of emotional compared to neutral faces are larger for people with higher scores on the \u201cReading Mind in the Eye\u201d test.\n12.\tDisengagement latency differences between angry and neutral faces will differ between people with high and low SIAS scores. \n13.\tDisengagement latencies differ between people with high and low SIAS scores.\n14.\tParticipants with high compared to low SIAS scores show longer P1 latency in response to the peripheral face if it follows an angry compared to a neutral central face. ", "q5": "Experiment - A researcher randomly assigns treatments to study subjects, this includes field or lab experiments. This is also known as an intervention experiment and includes randomized controlled trials.", "q6": ["No blinding is involved in this study."], "q7": "", "q9": "Stimuli with happy, angry, or neutral facial expressions will be presented in a randomized order, with equal numbers of male and female faces for each expression. Competition and non-competition conditions will be presented in random order, with expression of the central face fully counterbalanced per condition. The screen side on which stimuli appear will be counterbalanced with all stimuli appearing equally often on the left and right side of the screen. The order in which stimuli are presented at the left or right side of the screen will be randomized. ", "q10": "Registration prior to creation of data", "q11": "NA", "q13": "40 participants will be tested. If subjects need to be excluded, additional subjects will be tested until the predetermined number of subjects can be included.", "q14": "Sample size calculations were conduction in G*Power (version 3.1.9.2), in line with a previously preregistered study (https://osf.io/324ds). Differences in saccade latency between competition and non-competition conditions (Kulke, Atkinson &amp; Braddick, under revision) had an effect size dz = 0.723. The required sample size for two-tailed tests with an alpha of .05 and a power of .95 is 27 (one-tailed 23). Differences in P1 latency between competition and non-competition conditions had an effect size dz = 0.677 (Kulke, Atkinson &amp; Braddick, under revision). The required sample size for two-tailed tests with an alpha of .05 and a power of .95 is 31 (one-tailed 26). Analyses determining the sample size to detect the EPN effect found by Kulke (2019) based on a partial eta squared of 0.247 showed that 6 participants would be required to detect the effect. Therefore, the maximum determined required sample size is 31. To account for potential overestimation of the effect, 40 participants will be tested.", "q15": "The data collection will be stopped once the predetermined sample size has been reached after subjects have been excluded.", "q20": "EEG data will be processed as described above.", "q21": "For non-directional hypotheses (see above), standard p-values of 0.05 will be used as a cut-off. For directional hypotheses, p = .10 will be used as a cut-off (comparable to one-sided testing). ", "q22": "Subjects will be excluded from further analyses if they fail to finish the experiment, in case of experimenter or technical failures, or if excessive noise is detected during preprocessing (more than 50% of trials missing or noisy in any of the measures). They will not be tested if they are not healthy (according to self-report) or if they are not between 18 and 35 years of age.", "q23": "In case a participant needs to be excluded, an additional subject will be tested to reach the required sample size determined above. ", "q24": "", "q25": "EEG data will be collected using a 64-electrodes system plus additional mastoid and eye electrodes. ", "q8.question": "In a repeated measures design, expression of the central face (happy, neutral and angry) and competition condition (competition and non-competition) will be manipulated within participants. Questionnaire scores will be compared between participants", "q8.uploader": [], "q12.question": "Healthy subjects between 18 and 35 years will be tested. Subjects will be recruited via posters, advertisements, local databases and leaflets. They will receive course credit or monetary compensation in return for participation. ", "q12.uploader": [], "q16.question": "The emotional expression of the central face (happy, neutral or angry) will be manipulated. The peripheral face will always show a neutral expression. Whether the central face remains visible in the center of fixation (competition condition) or whether it disappears (non-competition condition) will be manipulated. The side on which the face appears (left or right periphery) will be counterbalanced. The gender of the target faces will be counterbalanced. Images of ten different individuals will be used, and every individual will be shown expressing each of the expressions. Images will be selected from the Karolinska Directed Emotional Faces (KDEF) database and luminance will be controlled.", "q16.uploader": [], "q17.question": "This study will determine latencies of the first saccade towards the peripheral stimulus and ERPs to the central and the peripheral stimulus. Preprocessing of eye movement data will be based on previous research.\nRegarding ERPs, the amplitude and latency of an early positive deflection (~P1), and the amplitude of the EPN and the LPC will be measured.\nQuestionnaire scores on the Autism Quotient (Baron-Cohen, Wheelwright, Skinner, Martin, &amp; Clubley, 2001), the \u201cReading Mind in the Eye\u201d test (Baron-Cohen, Jolliffe, Mortimore, &amp; Robertson, 1997), the Social-Interaction-Anxiety Scale (SIAS) (Stangier, Heidenreich, Berardi, Golbs, &amp; Hoyer, 1999) and the BIS/BAS test (Strobel, Beauducel, Debener, &amp; Brocke, 2001) will be collected.", "q17.uploader": [], "q18.question": "EEG data will be preprocessed based on previous research (Kulke, Atkinson &amp; Braddick, 2016; Kulke, 2019). Initially, independent Component analysis (ICA) will be conducted and eye components will be rejected.\nBased on previous studies, the maximal positive deflection between 100 and 180 ms after target onset within posterior areas will be determined in two lateral occipital electrode clusters around O1 and O2 (see Kulke, 2019). Its amplitude and latency will be computed within each of the conditions (excluding trials in which the first saccade did not go to the correct location). \nThe mean EPN amplitude will be extracted between 250 and 350 ms after stimulus onset in an occipito-parietal electrode cluster including electrodes O1, O2, P9, P10, PO7 and PO8. The mean LPC amplitude will be quantified in a time window between 400 and 600 ms after stimulus onset in an occipito-parietal electrode cluster including Pz, POz, PO3 and PO4. Regions of interest and time windows for both components are based on previous research.", "q18.uploader": [], "q19.question": "1., 2. &amp; 3. A repeated measures ANOVA will be conducted to investigate the effects of competition condition (competition or non-competition) and valence (happy, neutral, angry) on saccade latency. T-tests will be conducted to compare saccade latency between conditions.\n4., 5. &amp; 6. A repeated measures ANOVA will be conducted to investigate the effects of competition condition (competition or non-competition) and valence (happy, neutral, angry) on the latency of the early posterior response (~P1) in response to the peripheral face. T-tests will be conducted to compare this latency between conditions.\n7. A repeated measures ANOVA will be conducted to investigate the effects of valence (happy, neutral, angry) on EPN amplitude in response to the central face. T-tests will be conducted to compare this amplitude between conditions.\n8. A repeated measures ANOVA will be conducted to investigate the effects of valence (happy, neutral, angry) on LPC amplitude in response to the central face. Potential significant effects will be followed up using t-tests.\n\n9. In order to test if people with high compared to low BIS scores will disengage slower from angry faces, a linear model will predict saccade and P1 latency from BIS score.\n10. In order to test if people with high compared to low BAS scores disengage slower from happy faces, a linear model will predict saccade and P1 latency from BAS score.\n11. In order to test if observed effects are larger for people with higher scores on the \u201cReading Mind in the Eye\u201d (RME) test, the interaction of RME score with the observed effects will be investigated using a mixed model.\n12. &amp; 13. To test if participants with high compared to low SIAS scores disengage slower from angry compared to neutral faces, a mixed model will be computed predicting saccade latency from SIAS score and valence.\n14. To test if participants with high compared to low SIAS scores show longer P1 latency in response to the peripheral face if it follows an angry compared to a neutral central faces, a mixed model will be computed predicting P1 latency from SIAS score and valence. \n15. AQ scores will be analyzed and it will be reported whether any participants scored above the 32+ cut-off to distinguish groups with autism from groups without autism.", "q19.uploader": []}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/7ec8y/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/7ec8y/comments/?format=json&filter%5Btarget%5D=7ec8y", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/7ec8y/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/7ec8y/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/7ec8y/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/7ec8y/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/7ec8y/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/7ec8y/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/7ec8y/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/7ec8y/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/7ec8y/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/7ec8y/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/7ec8y/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/7ec8y/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/de-1/?format=json", "meta": {}}}, "data": {"id": "de-1", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/7ec8y/?format=json", "meta": {}}}, "data": {"id": "7ec8y", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/7ec8y/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/7ec8y/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/7ec8y/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/7ec8y/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/7ec8y/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/7ec8y/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/7ec8y/citation/?format=json", "meta": {}}}, "data": {"id": "7ec8y", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/gydjw/?format=json", "meta": {}}}, "data": {"id": "gydjw", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/6ufdm/?format=json", "meta": {}}}, "data": {"id": "6ufdm", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5c08457ed283380029cf73bf/?format=json", "meta": {}}}, "data": {"id": "5c08457ed283380029cf73bf", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/7ec8y/", "self": "https://api.osf.io/v2/registrations/7ec8y/"}}, {"id": "9pysg", "type": "registrations", "attributes": {"title": "Efficacy and safety of SGLT2 inhibitors in the treatment of type 2 diabetes: protocol for a systematic review incorporating unpublished clinical study reports", "description": "Protocol for Systematic Review Supplementary Material", "category": "project", "custom_citation": "", "date_created": "2020-01-14T16:32:29.896878", "date_modified": "2020-01-14T16:33:48.237396", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": {"copyright_holders": [""], "year": "2020"}, "analytics_key": "25cedf1705cbbd23df0a9b94126700df07a64429c95bdb1675c719dbe22537d1a41c787570f1ef793add2913ca0aa7150caa3911f27d910f082f65a6e0ce1eb000baafe96b3fb37ae6a6102cb02de5944c517e97951b7a0363f3c336cf3ec9824dcf55f1e8e7a618879032fddb0f0004721cbbc5f443a1ccce7b15e7497913b4ec6f214a16692511c08378c740653eef", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-01-14T16:32:29.860276", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Open-Ended Registration", "registered_meta": {"summary": {"extra": [], "value": "Protocol for Systematic Review Supplementary Material"}, "uploader": {"extra": [], "value": ""}}, "registration_responses": {"summary": "Protocol for Systematic Review Supplementary Material"}, "subjects": []}, "relationships": {"license": {"links": {"related": {"href": "https://api.osf.io/v2/licenses/563c1cf88c5e4a3877f9e96a/?format=json", "meta": {}}}, "data": {"id": "563c1cf88c5e4a3877f9e96a", "type": "licenses"}}, "children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9pysg/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9pysg/comments/?format=json&filter%5Btarget%5D=9pysg", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9pysg/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9pysg/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9pysg/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9pysg/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9pysg/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9pysg/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9pysg/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9pysg/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9pysg/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9pysg/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9pysg/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/9pysg/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/de-1/?format=json", "meta": {}}}, "data": {"id": "de-1", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9pysg/?format=json", "meta": {}}}, "data": {"id": "9pysg", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9pysg/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9pysg/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/9pysg/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9pysg/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/9pysg/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9pysg/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/9pysg/citation/?format=json", "meta": {}}}, "data": {"id": "9pysg", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/8tdac/?format=json", "meta": {}}}, "data": {"id": "8tdac", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/7sp5m/?format=json", "meta": {}}}, "data": {"id": "7sp5m", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5df83f7dd28338001ac0ab0d/?format=json", "meta": {}}}, "data": {"id": "5df83f7dd28338001ac0ab0d", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/9pysg/", "self": "https://api.osf.io/v2/registrations/9pysg/"}}, {"id": "g6x8m", "type": "registrations", "attributes": {"title": "How does the Communication of Uncertainty differ as a function of Face-Threat?", "description": "", "category": "project", "custom_citation": "", "date_created": "2020-02-11T14:11:27.016824", "date_modified": "2020-02-05T17:26:43.411097", "registration": true, "preprint": false, "fork": false, "collection": false, "tags": [], "access_requests_enabled": false, "node_license": null, "analytics_key": "e1658b63a7cb52fb6815b49a32014ad86c4e705b817502b75577c7c7981bae427527652190df7579f59e6966b54c351d91423cd5d6a458116e5e126d704ef4b4d54f7263da0d068f6261c9d74e3e5e02d06034ed98838fa996f4cf522d619d8e626a5a0cdee9030157ae7687cfa8d498227ea1ab131a20cb1bbf222558c01ea74210003e025f5110c5af62620d5e3af4", "current_user_can_comment": false, "current_user_permissions": ["read"], "current_user_is_contributor": false, "current_user_is_contributor_or_group_member": false, "wiki_enabled": true, "public": true, "article_doi": null, "pending_embargo_approval": false, "pending_embargo_termination_approval": false, "embargoed": false, "pending_registration_approval": false, "archiving": false, "pending_withdrawal": false, "withdrawn": false, "date_registered": "2020-02-11T14:11:26.994483", "date_withdrawn": null, "embargo_end_date": null, "withdrawal_justification": null, "registration_supplement": "Preregistration Template from AsPredicted.org", "registered_meta": {"data": {"extra": [], "value": "No, no data have been collected for this study yet."}, "name": {"extra": [], "value": "Does the communication of uncertainty differ as a function of face-threat?"}, "other": {"extra": [], "value": "No."}, "sample": {"extra": [], "value": "Within Part 1, a target sample of 144 adults (36 responses per condition), aged 18 and over will be recruited. Within Part 2, a target sample of 180 adults (8 sets of ratings per participant i.e., 2 sets of ratings per condition), aged 18 and over will be recruited."}, "analyses": {"extra": [], "value": "Part 1 and 2: A 2x2 independent groups ANOVA will be conducted on each DV, followed by post-hoc analysis where appropriate. If required by journal policies / reviewers we will alternatively analyse the data using a Linear Mixed Effect Model to account for the crossed random effects across subjects and items. Linguistic content within letters will be analysed using the Linguistic Inquiry and Word Count program (LIWC; Pennebaker, Booth &amp; Francis, 2007)."}, "outliers": {"extra": [], "value": "Data quality and seriousness checks are included within the survey. Firstly, participants are asked after completing the task, whether or not they took the task seriously and whether or not they think we should use their data. Those who identify that they did not take the task seriously will be removed from analysis. Secondly, participants are asked to identify whether or not they encountered any distractions, or took significant breaks while completing the task. Those who identify that this is the case will be removed from analysis. Finally, participants are asked if they have ever worked as a health professional (such as a doctor or nurse). Those who indicate that they have worked as a health professional will be removed from analysis."}, "dependent": {"extra": [], "value": "Part 1: DV1 (Number of Uncertainty Terms), such as hedges (maybe, could), probability terms (possibly, likely) and dispreferred markers (well, fortunately); DV2 (Number of Words); DV3 (Time Taken)\n\nPart 2: DV1 (Accuracy); DV2 (Clarity); DV3 (Politeness) of responses."}, "conditions": {"extra": [], "value": "In part 1 participants will be randomly assigned to read one of 24 vignettes (4 versions of 6 different scenarios = 24). See example below\n===========================================================================\nExample Vignette \u2013 Mr Wilson (Alzheimer\u2019s)\n\nImagine that you are a specialist at a medical practice. You receive some information about a patient, Mr Wilson, from his family doctor Dr David White.\n\nMr Wilson is 38 years old. He has a partner and a son aged 6. He has been a digital marketing manager for the past 4 years and earns around \u00a336,000 per year. Some of Mr Wilsons interests include supporting his son\u2019s football team once per week, dinner dates with his partner and regular trips to the bar with his friends. The majority of his spare time is allocated to family and friends, so Mr Wilson describes himself as un-active, often choosing convenient food options, but he intends to make lifestyle changes.\n\nMr Wilson has been to see Dr White a number of times in recent weeks reporting forgetfulness, difficulty when making decisions and a sense of disorientation while in familiar places. He has recently undergone a brain scan to find out what is wrong.\n\nYou see the results and the brain scans shows signs of brain cell degeneration. You think that Mr Wilson has Alzheimer\u2019s Disease. Alzheimer\u2019s Disease is known to be difficult to diagnose, (so you are uncertain / but you are certain).\n\nTASK \u2013 You are tasked with communicating this information in a letter to (the family doctor of Mr Wilson / Mr Wilson). This letter has been started for you below\u2026\n===========================================================================\nThe vignette will include information that is either certain or uncertain. Also, when asked to communicate information, participants will be tasked with writing a letter to either the patient\u2019s family doctor (Low Face-Threat), or to the patient themselves (High Face-Threat).\n\nWithin part 2, a second group of participants will view the letters written from part 1, rating these on the above metrics. Order of presentation will be counterbalanced to ensure that respondents view letters written under all conditions."}, "hypothesis": {"extra": [], "value": "This is a two-part study. \n\nIn part one participants will be asked to put themselves in the position of a specialist health professional.  They will be given information about a patient\u2019s diagnosis and tasked with communicating that information in a letter to either the patient themselves (high face threat) or to the patient\u2019s family doctor (low face threat). The certainty of the diagnosis will also be manipulated (certain vs uncertain).\n \nIt is hypothesised that\u2026\n1.\tParticipants will produce more uncertainty terms (DV1), produce more words (DV2) and take longer to write the letter (DV3) when they are communicating directly with the patient (vs communicating with the family doctor).\n2.\tParticipants will produce more uncertainty terms (DV1), produce more words (DV2) and take longer to write the letter (DV3) when they are communicating a diagnosis that is uncertain (vs certain).\n3.\tAn interaction effect will occur whereby the effect of information certainty on the number of uncertainty terms (DV1), number of words (DV2) and time taken (DV3) is larger under high face-threat (vs. low face-threat).\n\nIn part 2 a different set of participants will rate the letters produced in part 1 for Accuracy (DV1), Clarity (DV2) and Politeness (DV3). \n\nIt is hypothesised that\u2026\n1.\tParticipants rate the letters as being less accurate (DV1), less clear (DV2) and more polite (DV3) when they are communicating directly with the patient (vs communicating with the family doctor).\n2.\tParticipants rate the letters as being less accurate (DV1), less clear (DV2) and more polite (DV3) when they are communicating a diagnosis that is uncertain (vs certain).\n3.\tAn interaction effect will occur whereby the effect of information certainty on the accuracy of information (DV1) and clarity of information (DV2) is larger under low face threat (vs. high face-threat). Also, the effect of information certainty on interpreted politeness (DV3) will be larger under high face-threat (vs. low face-threat)."}, "study_type": {"extra": [], "value": "Experiment"}, "study_type_other": {"extra": [], "value": ""}}, "registration_responses": {"data": "No, no data have been collected for this study yet.", "name": "Does the communication of uncertainty differ as a function of face-threat?", "other": "No.", "sample": "Within Part 1, a target sample of 144 adults (36 responses per condition), aged 18 and over will be recruited. Within Part 2, a target sample of 180 adults (8 sets of ratings per participant i.e., 2 sets of ratings per condition), aged 18 and over will be recruited.", "analyses": "Part 1 and 2: A 2x2 independent groups ANOVA will be conducted on each DV, followed by post-hoc analysis where appropriate. If required by journal policies / reviewers we will alternatively analyse the data using a Linear Mixed Effect Model to account for the crossed random effects across subjects and items. Linguistic content within letters will be analysed using the Linguistic Inquiry and Word Count program (LIWC; Pennebaker, Booth &amp; Francis, 2007).", "outliers": "Data quality and seriousness checks are included within the survey. Firstly, participants are asked after completing the task, whether or not they took the task seriously and whether or not they think we should use their data. Those who identify that they did not take the task seriously will be removed from analysis. Secondly, participants are asked to identify whether or not they encountered any distractions, or took significant breaks while completing the task. Those who identify that this is the case will be removed from analysis. Finally, participants are asked if they have ever worked as a health professional (such as a doctor or nurse). Those who indicate that they have worked as a health professional will be removed from analysis.", "dependent": "Part 1: DV1 (Number of Uncertainty Terms), such as hedges (maybe, could), probability terms (possibly, likely) and dispreferred markers (well, fortunately); DV2 (Number of Words); DV3 (Time Taken)\n\nPart 2: DV1 (Accuracy); DV2 (Clarity); DV3 (Politeness) of responses.", "conditions": "In part 1 participants will be randomly assigned to read one of 24 vignettes (4 versions of 6 different scenarios = 24). See example below\n===========================================================================\nExample Vignette \u2013 Mr Wilson (Alzheimer\u2019s)\n\nImagine that you are a specialist at a medical practice. You receive some information about a patient, Mr Wilson, from his family doctor Dr David White.\n\nMr Wilson is 38 years old. He has a partner and a son aged 6. He has been a digital marketing manager for the past 4 years and earns around \u00a336,000 per year. Some of Mr Wilsons interests include supporting his son\u2019s football team once per week, dinner dates with his partner and regular trips to the bar with his friends. The majority of his spare time is allocated to family and friends, so Mr Wilson describes himself as un-active, often choosing convenient food options, but he intends to make lifestyle changes.\n\nMr Wilson has been to see Dr White a number of times in recent weeks reporting forgetfulness, difficulty when making decisions and a sense of disorientation while in familiar places. He has recently undergone a brain scan to find out what is wrong.\n\nYou see the results and the brain scans shows signs of brain cell degeneration. You think that Mr Wilson has Alzheimer\u2019s Disease. Alzheimer\u2019s Disease is known to be difficult to diagnose, (so you are uncertain / but you are certain).\n\nTASK \u2013 You are tasked with communicating this information in a letter to (the family doctor of Mr Wilson / Mr Wilson). This letter has been started for you below\u2026\n===========================================================================\nThe vignette will include information that is either certain or uncertain. Also, when asked to communicate information, participants will be tasked with writing a letter to either the patient\u2019s family doctor (Low Face-Threat), or to the patient themselves (High Face-Threat).\n\nWithin part 2, a second group of participants will view the letters written from part 1, rating these on the above metrics. Order of presentation will be counterbalanced to ensure that respondents view letters written under all conditions.", "hypothesis": "This is a two-part study. \n\nIn part one participants will be asked to put themselves in the position of a specialist health professional.  They will be given information about a patient\u2019s diagnosis and tasked with communicating that information in a letter to either the patient themselves (high face threat) or to the patient\u2019s family doctor (low face threat). The certainty of the diagnosis will also be manipulated (certain vs uncertain).\n \nIt is hypothesised that\u2026\n1.\tParticipants will produce more uncertainty terms (DV1), produce more words (DV2) and take longer to write the letter (DV3) when they are communicating directly with the patient (vs communicating with the family doctor).\n2.\tParticipants will produce more uncertainty terms (DV1), produce more words (DV2) and take longer to write the letter (DV3) when they are communicating a diagnosis that is uncertain (vs certain).\n3.\tAn interaction effect will occur whereby the effect of information certainty on the number of uncertainty terms (DV1), number of words (DV2) and time taken (DV3) is larger under high face-threat (vs. low face-threat).\n\nIn part 2 a different set of participants will rate the letters produced in part 1 for Accuracy (DV1), Clarity (DV2) and Politeness (DV3). \n\nIt is hypothesised that\u2026\n1.\tParticipants rate the letters as being less accurate (DV1), less clear (DV2) and more polite (DV3) when they are communicating directly with the patient (vs communicating with the family doctor).\n2.\tParticipants rate the letters as being less accurate (DV1), less clear (DV2) and more polite (DV3) when they are communicating a diagnosis that is uncertain (vs certain).\n3.\tAn interaction effect will occur whereby the effect of information certainty on the accuracy of information (DV1) and clarity of information (DV2) is larger under low face threat (vs. high face-threat). Also, the effect of information certainty on interpreted politeness (DV3) will be larger under high face-threat (vs. low face-threat).", "study_type": "Experiment"}, "subjects": []}, "relationships": {"children": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/g6x8m/children/?format=json", "meta": {}}}}, "comments": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/g6x8m/comments/?format=json&filter%5Btarget%5D=g6x8m", "meta": {}}}}, "contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/g6x8m/contributors/?format=json", "meta": {}}}}, "bibliographic_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/g6x8m/bibliographic_contributors/?format=json", "meta": {}}}}, "implicit_contributors": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/g6x8m/implicit_contributors/?format=json", "meta": {}}}}, "files": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/g6x8m/files/?format=json", "meta": {}}}}, "wikis": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/g6x8m/wikis/?format=json", "meta": {}}}}, "forks": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/g6x8m/forks/?format=json", "meta": {}}}}, "node_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/g6x8m/node_links/?format=json", "meta": {}}}}, "linked_by_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/g6x8m/linked_by_nodes/?format=json", "meta": {}}}}, "linked_by_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/g6x8m/linked_by_registrations/?format=json", "meta": {}}}}, "identifiers": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/g6x8m/identifiers/?format=json", "meta": {}}}}, "affiliated_institutions": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/g6x8m/institutions/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/g6x8m/relationships/institutions/?format=json", "meta": {}}}}, "region": {"links": {"related": {"href": "https://api.osf.io/v2/regions/de-1/?format=json", "meta": {}}}, "data": {"id": "de-1", "type": "regions"}}, "root": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/g6x8m/?format=json", "meta": {}}}, "data": {"id": "g6x8m", "type": "registrations"}}, "logs": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/g6x8m/logs/?format=json", "meta": {}}}}, "linked_nodes": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/g6x8m/linked_nodes/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/g6x8m/relationships/linked_nodes/?format=json", "meta": {}}}}, "linked_registrations": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/g6x8m/linked_registrations/?format=json", "meta": {}}, "self": {"href": "https://api.osf.io/v2/registrations/g6x8m/relationships/linked_registrations/?format=json", "meta": {}}}}, "view_only_links": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/g6x8m/view_only_links/?format=json", "meta": {}}}}, "citation": {"links": {"related": {"href": "https://api.osf.io/v2/registrations/g6x8m/citation/?format=json", "meta": {}}}, "data": {"id": "g6x8m", "type": "registrations"}}, "registered_by": {"links": {"related": {"href": "https://api.osf.io/v2/users/ebmht/?format=json", "meta": {}}}, "data": {"id": "ebmht", "type": "users"}}, "registered_from": {"links": {"related": {"href": "https://api.osf.io/v2/nodes/zu2an/?format=json", "meta": {}}}, "data": {"id": "zu2an", "type": "nodes"}}, "registration_schema": {"links": {"related": {"href": "https://api.osf.io/v2/schemas/registrations/5d2d2268d28338002c2432d2/?format=json", "meta": {}}}, "data": {"id": "5d2d2268d28338002c2432d2", "type": "registration-schemas"}}, "provider": {"links": {"related": {"href": "https://api.osf.io/v2/providers/registrations/osf/?format=json", "meta": {}}}}}, "links": {"html": "https://osf.io/g6x8m/", "self": "https://api.osf.io/v2/registrations/g6x8m/"}}], "links": {"first": "https://api.osf.io/v2/registrations/?filter%5Bdate_created%5D%5Bgt%5D=2019-12-31&format=json", "last": "https://api.osf.io/v2/registrations/?filter%5Bdate_created%5D%5Bgt%5D=2019-12-31&format=json&page=547", "prev": "https://api.osf.io/v2/registrations/?filter%5Bdate_created%5D%5Bgt%5D=2019-12-31&format=json&page=319", "next": "https://api.osf.io/v2/registrations/?filter%5Bdate_created%5D%5Bgt%5D=2019-12-31&format=json&page=321", "meta": {"total": 5469, "per_page": 10}}}